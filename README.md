# Предсказание размера обучающего множества для задач сегментации

Этот репозиторий содержит проект по созданию нейронной сети для предсказания размера обучающей выборки на основе эмбеддингов четырех изображений. Проект включает несколько этапов, каждый из которых представлен отдельным Jupyter Notebook файлом. Также имеется веб-интерфейс, реализованный с использованием Streamlit, для взаимодействия с моделью.

## Содержание

1. [Получение и обработка данных](#1-получение-и-обработка-данных)
2. [Аппроксимация зависимости метрики от размера выборки](#2-аппроксимация-зависимости-метрики-от-размера-выборки)
3. [Обучение модели на основе эмбеддингов InceptionV3](#3-обучение-модели-на-основе-эмбеддингов-inceptionv3)
4. [Обучение модели на основе эмбеддингов CLIP](#4-обучение-модели-на-основе-эмбеддингов-clip)
5. [Веб-интерфейс Streamlit](#5-веб-интерфейс-streamlit)
6. [Запуск с использованием Docker](#6-запуск-с-использованием-docker)

## 1. Получение и обработка данных

В этом файле выполняется загрузка датасетов сегментации, разделение тренировочных выборок на части и сбор информации о том, как изменяется метрика mAP (mean Average Precision) в зависимости от размера обучающей выборки.

Файл: `01_Data_Download_and_Preprocessing.ipynb`

## 2. Аппроксимация зависимости метрики от размера выборки

Этот файл включает обработку данных о зависимости метрики mAP от размера тренировочной выборки. Здесь аппроксимируется симметричная сигмоида, и определяются четыре параметра, которые сохраняются для дальнейшего использования.

Файл: `02_MAP_vs_Training_Size_Approximation.ipynb`

## 3. Обучение модели на основе эмбеддингов InceptionV3

Файл содержит обучение модели нейронной сети, которая принимает на вход эмбеддинги четырех изображений, полученные от модели InceptionV3, и предсказывает четыре параметра аппроксимирующей функции.

Файл: `03_NN_Training_InceptionV3_Embeddings.ipynb`

## 4. Обучение модели на основе эмбеддингов CLIP

В этом файле проводится обучение модели нейронной сети, которая принимает на вход эмбеддинги четырех изображений, полученные от модели CLIP, и предсказывает четыре параметра аппроксимирующей функции.

Файл: `04_NN_Training_CLIP_Embeddings.ipynb`

## 5. Веб-интерфейс Streamlit

В директории `app` находится веб-приложение, реализованное с использованием Streamlit, которое позволяет взаимодействовать с обученными моделями.

### Содержимое директории `app`

- `app.py`: основной файл приложения Streamlit.
- `models.py`: содержит классы двух моделей для входа от InceptionV3 и от CLIP.
- `Dockerfile`: файл для создания Docker-образа приложения.
- `docker-compose.yml`: файл для запуска приложения с использованием Docker Compose.
- `weights`: директория с файлами весов моделей (необходимо загрузить из предоставленной ссылки).

### Инструкции по загрузке весов моделей

Пользователю необходимо загрузить веса моделей из [этой ссылки](https://drive.google.com/file/d/1HcRVF6EYlf5jCeYfwduqeQlyePwrw9EZ/view?usp=sharing) и поместить их в директорию `app/weights`.

## 6. Запуск с использованием Docker

Для запуска приложения с использованием Docker выполните следующие шаги:

1. Клонируйте репозиторий:
    ```sh
    git clone https://github.com/yourusername/your-repo-name.git
    ```
2. Перейдите в директорию `app`:
    ```sh
    cd your-repo-name/app
    ```
3. Убедитесь, что веса моделей загружены и находятся в директории `app/weights`.

4. Постройте и запустите контейнеры с помощью Docker Compose:
    ```sh
    docker-compose up --build
    ```
5. Откройте браузер и перейдите по адресу `http://localhost:8501`, чтобы получить доступ к веб-интерфейсу Streamlit.

## Установка и запуск без Docker

1. Клонируйте репозиторий:
    ```sh
    git clone https://github.com/yourusername/your-repo-name.git
    ```
2. Установите необходимые зависимости:
    ```sh
    pip install -r requirements.txt
    ```
3. Перейдите в директорию `app` и запустите Streamlit:
    ```sh
    cd app
    streamlit run app.py
    ```
