{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8385865,"sourceType":"datasetVersion","datasetId":4987561},{"sourceId":8390523,"sourceType":"datasetVersion","datasetId":4990805},{"sourceId":8393276,"sourceType":"datasetVersion","datasetId":4992939},{"sourceId":8394090,"sourceType":"datasetVersion","datasetId":4993535},{"sourceId":8394682,"sourceType":"datasetVersion","datasetId":4993946},{"sourceId":8399323,"sourceType":"datasetVersion","datasetId":4997251},{"sourceId":8399696,"sourceType":"datasetVersion","datasetId":4997537},{"sourceId":8403939,"sourceType":"datasetVersion","datasetId":5000676},{"sourceId":8410186,"sourceType":"datasetVersion","datasetId":5005351},{"sourceId":8411187,"sourceType":"datasetVersion","datasetId":5006080},{"sourceId":8411615,"sourceType":"datasetVersion","datasetId":5006405},{"sourceId":8418804,"sourceType":"datasetVersion","datasetId":5011646},{"sourceId":8421051,"sourceType":"datasetVersion","datasetId":5013359},{"sourceId":8422694,"sourceType":"datasetVersion","datasetId":5014585}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":40368.790587,"end_time":"2024-05-20T18:39:33.797758","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-20T07:26:45.007171","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### data_dict_values = {\n    \"/kaggle/input/inception-v3-5-layers/feet-14\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798], {0: [0.007998354528394015, 0.009186754695156445, 0.008606147362525655], 1: [0.00775809305467159, 0.008903405699157952, 0.008382683998575368], 2: [0.007887510576507899, 0.009103264708327785, 0.008562617676043854], 3: [0.007976761185197552, 0.009388700674636881, 0.008472458499193772], 4: [0.008128921287880645, 0.010154590113724642, 0.00850070571371787], 5: [0.007777691908847677, 0.0088727719247368, 0.008399757590166312], 6: [0.007728506288320197, 0.008925087505984126, 0.008373548157532135], 7: [0.00922948596582026, 0.011387562413643438, 0.010004604964653085], 8: [0.009830105175118833, 0.01251470127853226, 0.010431511796459335], 9: [0.016232632608481602, 0.019250071054154397, 0.017880939756424352], 10: [0.01935813575332595, 0.02293274723464134, 0.02102244627053116], 11: [0.03425884742571537, 0.04044085641633806, 0.038434687557811785], 12: [0.04348134417605419, 0.05240234796048973, 0.047807220757631], 13: [0.7981414008473514, 0.9163071983531503, 0.9120677936747674], 14: [0.7829313328541312, 0.8999052024619988, 0.8962770705551195], 15: [0.8516539468266477, 0.9710455780590502, 0.9674561977170949], 16: [0.8536735498868964, 0.9682566104016648, 0.9651736808008498], 17: [0.8588358408876923, 0.9799326545384144, 0.9734864856131226], 18: [0.8497393672611633, 0.9699663571856967, 0.9645029513350497], 19: [0.8635390078208035, 0.9812904353758635, 0.9788204133404986], 20: [0.8617617248661877, 0.9794687936804066, 0.9754417767302282], 21: [0.8760845551371942, 0.9906307617911677, 0.9906307617911677], 22: [0.8717054321633478, 0.9896689377609824, 0.9823136387936259], 23: [0.8701107039804393, 0.9855825263512683, 0.9833251114642599], 24: [0.8733750949821143, 0.9853035088529142, 0.9838939900788438], 25: [0.8819648821786743, 0.9932877672086295, 0.9926266327789218], 26: [0.8790231199776593, 0.9909304828747634, 0.9905754429422742], 27: [0.8838101028026351, 0.99353427951164, 0.9926268733698828], 28: [0.8846179088115191, 0.9945065438616797, 0.9944012353854589], 29: [0.8863253598167073, 0.9937535216622144, 0.993593643603107], 30: [0.8860260420530294, 0.9946859343310154, 0.9946859343310154], 31: [0.8900228137370331, 0.9942468477482512, 0.9929516034785504], 32: [0.8918687133999349, 0.9947486941655109, 0.9936764230504587], 33: [0.8939017732115857, 0.9945112735354713, 0.99383857915555], 34: [0.8890425994672396, 0.9947250961055922, 0.9946205199771376], 35: [0.8877155300228857, 0.994787841623121, 0.9938895497235121], 36: [0.8940336882822384, 0.994746474861131, 0.993369735424209], 37: [0.8979569180213647, 0.9947461150065121, 0.9940615391532804], 38: [0.8908205747221919, 0.9948128898128897, 0.989775218597761], 39: [0.8874347168912688, 0.9908177650817663, 0.9884066460270458], 40: [0.8819347661732373, 0.9941696593954032, 0.9891731380794928], 41: [0.9026834142949844, 0.9947899103912531, 0.9932512573099025], 42: [0.8888564668594213, 0.9944103379029563, 0.9914626929817277], 43: [0.9084754651315252, 0.994937106918239, 0.9934879287301139], 44: [0.9001682192796154, 0.9949368421052632, 0.9946894055713972], 45: [0.896276146033532, 0.9949789029535866, 0.99381288981289], 46: [0.8887798363767214, 0.9908135959379993, 0.9797658349701502]}),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798], {0: [0.09892962035492356, 0.40163173155167986, 0.014662934220732851], 1: [0.10113660103127971, 0.40329807465597584, 0.01648577324287875], 2: [0.10584619509103628, 0.41705065163569305, 0.019499622399136687], 3: [0.10591507638310642, 0.39134358443533607, 0.023099556331968894], 4: [0.10019158738109853, 0.40329584488608256, 0.015185162494471084], 5: [0.10069920491487246, 0.4040003415934325, 0.015139720114589953], 6: [0.10091417134150753, 0.406265182083427, 0.015119261611292727], 7: [0.09997847390328289, 0.40081468689748245, 0.01543510029045614], 8: [0.1067330600599038, 0.40701773508207806, 0.019459384556308565], 9: [0.10215558281750241, 0.4086055640211645, 0.01584299533521601], 10: [0.0994836384013073, 0.39800521158917135, 0.014926956826945878], 11: [0.10279224865150687, 0.4073965378781563, 0.01618064006894619], 12: [0.11581784334729402, 0.42712908494758495, 0.028022672467896893], 13: [0.11589260147103111, 0.4201370716682721, 0.032607721550127], 14: [0.11991276939967557, 0.4148117325915483, 0.0375052713652459], 15: [0.17691861149689067, 0.5232267168675975, 0.0873566473234966], 16: [0.16880202335527644, 0.4499058220713004, 0.10518904302790524], 17: [0.1842173781301652, 0.4871343804462917, 0.11479913986531448], 18: [0.1898183282975505, 0.4338546598966946, 0.15079174936608475], 19: [0.20198576448287614, 0.43736722659590505, 0.16485031491536503], 20: [0.2189986948584171, 0.4969719394288895, 0.18009029488959255], 21: [0.24004367014081476, 0.5057910473189927, 0.205944313496134], 22: [0.23363529519410303, 0.43304066845535405, 0.2279646784296716], 23: [0.22034788125068086, 0.42688942121837964, 0.21062831072906638], 24: [0.2419699754785069, 0.4553459340624745, 0.2367572996298349], 25: [0.270509873247238, 0.5653502652898462, 0.23368649409499692], 26: [0.3666159406453924, 0.6933735833879693, 0.3421496154170459], 27: [0.40826485020165737, 0.690628267406223, 0.44212700718583764], 28: [0.4684731431356406, 0.7380452746102495, 0.5184658113258719], 29: [0.4663265046283055, 0.7312231794779913, 0.5132384421147744], 30: [0.5316439790583471, 0.7831365063889217, 0.6207467752654828], 31: [0.6172030170361442, 0.8889392441728063, 0.7220900309183674], 32: [0.5838570068299775, 0.8487205663587575, 0.669130210584135], 33: [0.613960426611672, 0.8627906814757499, 0.7148091641434495], 34: [0.6199259455399561, 0.8881403605983574, 0.7380822297478603], 35: [0.6222147571708176, 0.8899533118000833, 0.7434705815838851], 36: [0.668266770876346, 0.9389943899638536, 0.8114730069646731], 37: [0.7400075975543821, 0.9712208594769346, 0.8849857567116524], 38: [0.761895180511927, 0.9821907225292617, 0.923380519509047], 39: [0.7675897183213495, 0.9885534808249657, 0.9280972968708029], 40: [0.7605734308294767, 0.9823408852137526, 0.9082295822542125], 41: [0.7971594044260384, 0.9881876290937505, 0.947517820634634], 42: [0.7975621301798486, 0.9885885517024114, 0.9589244983968043], 43: [0.8163970609936456, 0.9940370426796746, 0.9750281669733426], 44: [0.8231825523420877, 0.9936776292807672, 0.9676820062564402], 45: [0.8340230908344877, 0.9928582389487659, 0.9720237802088895], 46: [0.8387619358358073, 0.9942433378763396, 0.9819185662927272]})],\n    \"/kaggle/input/inception-v3-5-layers/fire_smoke-9\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 5547], {0: [0.004309738487204959, 0.010190138537048058, 0.0030427838933050214], 1: [0.007238929803151254, 0.0172410078950734, 0.004682047450070102], 2: [0.008123202971976504, 0.024350421674937076, 0.003784745794349811], 3: [0.004506835509932795, 0.011079506310911463, 0.003242522296274854], 4: [0.004588575961124107, 0.011078758427185377, 0.0033152228162653466], 5: [0.008589189455033135, 0.020812717863936948, 0.004074721756666993], 6: [0.010141039199365468, 0.028847284205794414, 0.005715550626609227], 7: [0.00501405229036718, 0.012137764482922262, 0.0038301799251778137], 8: [0.006137303734647368, 0.014726843048551838, 0.004821040575657805], 9: [0.005182273894050138, 0.01285080331560163, 0.003527300181069827], 10: [0.006131302142478332, 0.014732375139883342, 0.004556187258730222], 11: [0.010779592682672586, 0.02522147124538395, 0.008908497908006487], 12: [0.015160865959343895, 0.03267128816130754, 0.012678667426227955], 13: [0.011356489801539372, 0.025872400471797903, 0.008804736789684376], 14: [0.01920785374528337, 0.03998083828098778, 0.018125115674527768], 15: [0.03653406847426869, 0.07687766235732223, 0.03360895697810619], 16: [0.04112408864278057, 0.08655268909702922, 0.03722549511092096], 17: [0.04097315392167668, 0.0822701228698159, 0.03825291762331404], 18: [0.07037661633082522, 0.13923107821626515, 0.06565956964341448], 19: [0.07795981798843724, 0.1541374524501223, 0.07350120977762166], 20: [0.0869686742267406, 0.1746664171918359, 0.08039824170764678], 21: [0.11833452992140789, 0.22466300110041054, 0.1153788859670807], 22: [0.13248546394021707, 0.25560347592761173, 0.12247176621725193], 23: [0.11696914263698535, 0.2231947920574006, 0.11350763760059185], 24: [0.10857816457172227, 0.20514777894404015, 0.10508028565586415], 25: [0.16707921982235083, 0.3119870188330641, 0.15785225627865257], 26: [0.17096360699216817, 0.3354945162878056, 0.16195481606704026], 27: [0.1952185877457914, 0.36497683667105657, 0.19357684260904717], 28: [0.22320196980930432, 0.42564935444591023, 0.21464093215245525], 29: [0.22122198725235376, 0.4087460604678488, 0.21637250571679476], 30: [0.2374982134628516, 0.4505027610508526, 0.227056818571207], 31: [0.26089421695633724, 0.48021548685186694, 0.25968873169946294], 32: [0.23796213426109142, 0.4340999150453334, 0.23732592928591806], 33: [0.27434429456885084, 0.49306924679867975, 0.2777839627276582], 34: [0.26609469626515836, 0.4834997410966854, 0.2622562680227589], 35: [0.2822975081097789, 0.503029186942081, 0.27742929569850455], 36: [0.2798180293308566, 0.49266545323443733, 0.28978696606197835], 37: [0.30600154068763763, 0.5358015743601838, 0.3178154369788656], 38: [0.32007414547699736, 0.5587669274562794, 0.33284141543841833], 39: [0.3356177936877436, 0.565806083834372, 0.35587116136638736], 40: [0.3444941641122567, 0.5819465565171443, 0.3636492554824774], 41: [0.3586149680703147, 0.6059498916389048, 0.37968517165469096], 42: [0.3646245203329669, 0.6141754283884128, 0.3816795837284852], 43: [0.3841073840077559, 0.6348431491869873, 0.41482302479601973], 44: [0.38051050704521433, 0.6451776162622822, 0.4016602312050267], 45: [0.40130298692050753, 0.663834273877685, 0.42284009939196876], 46: [0.40315397888989823, 0.667894904077666, 0.4194895403590558], 47: [0.3975723963026492, 0.6628025131347448, 0.42062913057200835], 48: [0.4077849564272576, 0.6777686533479249, 0.43384934496937905], 49: [0.3951814217785716, 0.6548503082784937, 0.4206075116116008], 50: [0.40133907018173487, 0.6647329759760354, 0.43590261750084663]}), ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 4780], {0: [0.024339225853127176, 0.06186804499106979, 0.014666177176581337], 1: [0.02350079168276324, 0.05907361582617281, 0.015350440849210884], 2: [0.024308948866415703, 0.06077941905543305, 0.016274942890439462], 3: [0.02397455701220614, 0.061561307644508324, 0.01398654383806493], 4: [0.024198546985278367, 0.061134941384204076, 0.016017983601988483], 5: [0.023786525602374646, 0.05985364178027771, 0.015021179824650071], 6: [0.02390614983703211, 0.05966124664875782, 0.015434795213103012], 7: [0.023647256251869565, 0.05968363808709146, 0.014398160283572861], 8: [0.025740385637299062, 0.06590112494866997, 0.015273724290597292], 9: [0.027177958294232845, 0.06985297106438354, 0.016776873713009354], 10: [0.02343993887056995, 0.059612166208818096, 0.014788122106236836], 11: [0.028520663668529067, 0.07346530320681001, 0.016968058960658266], 12: [0.04164385614228776, 0.10247726615668276, 0.026404456904740838], 13: [0.043082588542674057, 0.10434211024998646, 0.030311019901306854], 14: [0.03866455949189512, 0.09510500268557924, 0.02532182899736583], 15: [0.0691209532999195, 0.15781593945798988, 0.053364010450618976], 16: [0.07137109309809546, 0.17860914773232467, 0.048895317650961626], 17: [0.07317583984831078, 0.16638374590165678, 0.04953853900034826], 18: [0.09761531083326627, 0.22041376836833698, 0.07310362791907879], 19: [0.10146405591771693, 0.23844574278492942, 0.0706546699245156], 20: [0.10493159602297346, 0.23950714148125163, 0.07956361948158197], 21: [0.10375021411481891, 0.24268784116682876, 0.07267919418758494], 22: [0.12119537386592735, 0.27147414914570844, 0.0953718877981932], 23: [0.12859552813472278, 0.28579678780421724, 0.10097302232669308], 24: [0.12834870404289983, 0.27989414899668874, 0.10623807441939949], 25: [0.142372751680378, 0.2965408560640956, 0.1230892563016629], 26: [0.14208056597568797, 0.30532059732283046, 0.12116653981631131], 27: [0.15967719909894068, 0.34169366845560323, 0.13408713358063684], 28: [0.15679193689561474, 0.3328636570424348, 0.13786700182153577], 29: [0.16226624154552027, 0.3352098272833294, 0.1443289385856427], 30: [0.17437137141035167, 0.35019718604526257, 0.15320396853118215], 31: [0.20353455314131047, 0.39915886748144147, 0.1822015933750385], 32: [0.21754402537088452, 0.4144514304046123, 0.1933292754168527], 33: [0.27757683466138594, 0.5034381464142668, 0.26301046034701164], 34: [0.22124240123189085, 0.43353223327919715, 0.2020725651645209], 35: [0.22901180850329098, 0.42270457823090857, 0.2286359319456981], 36: [0.23362241507012377, 0.4337733335665743, 0.22389364448879098], 37: [0.30422831347083834, 0.5271749872991524, 0.30741006026673046], 38: [0.34570090266874676, 0.5816749490242867, 0.36386275777859795], 39: [0.3064537384505889, 0.5286539124601661, 0.3222321753155176], 40: [0.3491826704198632, 0.6001147972600628, 0.34609270030616457], 41: [0.349998147803014, 0.5928730510725069, 0.359774107455506], 42: [0.37572165883156305, 0.6395587129230649, 0.3995307238949951], 43: [0.3886371471102743, 0.6624188238546813, 0.3983360492256699], 44: [0.3877651580530025, 0.6425243302930391, 0.3992048821538361], 45: [0.43374683035852407, 0.6967514229974542, 0.47370241428318166], 46: [0.40272606648217896, 0.6548595863832771, 0.41444784549480507], 47: [0.4396485163364777, 0.7003090096539795, 0.4665947873310354], 48: [0.4574796716883074, 0.7175568034852118, 0.4936002911958044]})],\n    \"/kaggle/input/inception-v3-5-layers/puddle-segmentation-8\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1920], {0: [0.005767803699574613, 0.015378912758548328, 0.0036575018568473635], 1: [0.005780178197380123, 0.014889149411762614, 0.003945753320144483], 2: [0.005671208904902321, 0.015196289150207197, 0.0037253008841769113], 3: [0.00595891899814536, 0.01569107834754266, 0.003924486322505436], 4: [0.005730666202207515, 0.014976556070235628, 0.004038536403151532], 5: [0.0057390446475614355, 0.015142671708810217, 0.003923136231725862], 6: [0.005854115479306049, 0.0156488735685828, 0.0037806502955590017], 7: [0.005775415409261029, 0.014855354110889618, 0.0037924339602038847], 8: [0.00534949811814986, 0.015022020358416507, 0.0034431452164729185], 9: [0.005657967430566261, 0.015134343906586146, 0.0037995035504118143], 10: [0.005834088578082629, 0.015199233750444314, 0.0038429623679299488], 11: [0.00555471896532994, 0.015896772640371523, 0.003276916827035084], 12: [0.0057984587217343566, 0.015619861948740514, 0.003942831648904268], 13: [0.00951466002922904, 0.026409401316923785, 0.005461376932358174], 14: [0.006952008324712504, 0.02191656559743893, 0.0032572642214634103], 15: [0.009452353796663938, 0.024153429669886744, 0.0065739274268204525], 16: [0.012805186810680127, 0.033719849861955406, 0.005606299942420792], 17: [0.010806740340784864, 0.03217519854077283, 0.006420966906870081], 18: [0.018395372761523136, 0.04492804818941307, 0.012531748230694804], 19: [0.013123388199831176, 0.037697732485290035, 0.006619020963569627], 20: [0.014202910659996829, 0.03864849360469294, 0.006872149711502448], 21: [0.04318804022134852, 0.10138255170309496, 0.03342595389820645], 22: [0.03758527969389328, 0.08595586238668158, 0.02573023744487271], 23: [0.03439732955686092, 0.08366112594571701, 0.024696474194397106], 24: [0.0313012981241691, 0.07989269395189595, 0.02375912689627755], 25: [0.06275632908926744, 0.14480924491376682, 0.04071355705090627], 26: [0.08109451390706006, 0.16511979713738076, 0.06960438815384354], 27: [0.10586606683463262, 0.20219610565086935, 0.09929491363635205], 28: [0.1896476523399516, 0.35088268962978725, 0.18114863259558678], 29: [0.19019322716424064, 0.36992829353186013, 0.19249985926008198], 30: [0.2033856454793142, 0.37931803090479915, 0.20771419672305286], 31: [0.2792758253187597, 0.5018272306830417, 0.28582403994007854], 32: [0.2672825054888255, 0.47213625142615556, 0.2746525075769104], 33: [0.24725948272524034, 0.4629427330003708, 0.24606693000388724], 34: [0.2137770817101973, 0.4011042944031486, 0.21367591648918308], 35: [0.2964331251954459, 0.5134458619035233, 0.323058918953795], 36: [0.29659197366834966, 0.5215572571881989, 0.31059660248833737], 37: [0.33542960412780953, 0.5906692018950054, 0.36569200750015407], 38: [0.3503207286610876, 0.6287915423012425, 0.35334979359091245], 39: [0.3869315113716004, 0.6462145039773699, 0.42696408440929345], 40: [0.40172935425852535, 0.6907764314214497, 0.42612175090975785], 41: [0.4174862403772658, 0.7390277481926906, 0.41253083491789916], 42: [0.47763366278639535, 0.7762768989560697, 0.5424564151205312]})],\n    \"/kaggle/input/inception-v3-5-layers/Coffee-Fruit-Maturity-‚òïüçí-5\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 334], {0: [0.0043832675666966555, 0.010790611201889752, 0.0025171650647451715], 1: [0.004742927871270386, 0.012041211364186137, 0.0031163372946694705], 2: [0.004482873606201503, 0.011314824479685431, 0.0024656721647339976], 3: [0.004190695813152592, 0.010589900805590186, 0.0024147210574191106], 4: [0.004095874397013892, 0.010292301465870922, 0.0031229885255605735], 5: [0.00394253304836991, 0.0101393836671748, 0.002462050295801408], 6: [0.003990822395319815, 0.010159147999296615, 0.0024506679311098556], 7: [0.00391713864459896, 0.010171268571489912, 0.0028642670986670114], 8: [0.006578964501028533, 0.012755158029328298, 0.006682816725608488], 9: [0.007303369877798516, 0.013289095882026368, 0.006948749526634904], 10: [0.013224529617926875, 0.023351334852095746, 0.012610005442359996], 11: [0.015530015511371823, 0.029367404038925963, 0.01364054564102549], 12: [0.026759823381839215, 0.05556329737054069, 0.023334399315545273], 13: [0.032228866089321975, 0.06627959988554431, 0.029423410885106114], 14: [0.061366537198085304, 0.1281299939916393, 0.04459293952014909], 15: [0.08272361803950319, 0.18087707557950075, 0.0568777241298792], 16: [0.10490360514823356, 0.2291145624629202, 0.0654964145657824], 17: [0.1380933052138151, 0.27628618867030763, 0.09639109991990419], 18: [0.13923581059254206, 0.28698939983393756, 0.08884215293343213], 19: [0.28674729610135696, 0.5892770932125873, 0.20029733049325288], 20: [0.30601462479703223, 0.5963853016681515, 0.250844734075444], 21: [0.31494660793745777, 0.5897592387615328, 0.29089152558199727], 22: [0.32403400846217056, 0.6036156796443343, 0.3122290698055177], 23: [0.354473004207336, 0.6721502603439848, 0.3482766691164254], 24: [0.3586302840818588, 0.6685019185662247, 0.3568368062076278], 25: [0.34560209781871515, 0.6743607219296294, 0.2854076422772345], 26: [0.34892159647780285, 0.6561798571689575, 0.3164798456410948], 27: [0.3886638743737353, 0.7405942789156426, 0.3470839421312015], 28: [0.3924786439890853, 0.7459682714775008, 0.3486060343756443], 29: [0.39478615733970923, 0.7548035803485175, 0.3545645612546237], 30: [0.39688311464396664, 0.7593457632599241, 0.38147243184883867], 31: [0.40506841229991936, 0.7668424176725905, 0.3911601686900259], 32: [0.4906333292437613, 0.847004250888171, 0.5161988249297683], 33: [0.46146418312940557, 0.8261547645000662, 0.44345777431294114], 34: [0.491091867093769, 0.8550977518898158, 0.5098801460568837], 35: [0.4964720580905036, 0.8604330006749761, 0.5055879316361478], 36: [0.5078153555879694, 0.8799055360477802, 0.5215929371382722], 37: [0.5198956424803816, 0.9137038853788146, 0.4919854219096993], 38: [0.5326361654891317, 0.9076212167281197, 0.5274179481097611]}),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 258], {0: [0.008131848309780119, 0.03292688574384428, 0.0], 1: [0.0, 0.0, 0.0], 2: [0.010214312568998081, 0.0375353718071387, 0.0], 3: [0.008326599975373643, 0.03729891562962557, 0.0], 4: [0.00768356305936051, 0.0338626766185417, 0.0], 5: [0.011337375794324957, 0.0443309463808433, 0.0], 6: [0.010948416690180332, 0.04494239482200647, 0.0], 7: [0.007879666376228098, 0.032293680693462, 0.0], 8: [0.011803700674015472, 0.045695001545207115, 0.004543959775368945], 9: [0.010212325276917962, 0.03735273264506661, 0.004660230702166186], 10: [0.008999816664609448, 0.035951673255764885, 0.0], 11: [0.008304324244798619, 0.03701718839228771, 0.0], 12: [0.03273335998318437, 0.056047670523502555, 0.028858180051150893], 13: [0.0528482085001233, 0.08258160964398048, 0.04835785239373473], 14: [0.07890622832470533, 0.11221988039555694, 0.07961921850584606], 15: [0.09281934106980905, 0.11552664884341482, 0.09217240789261197], 16: [0.1415694487050729, 0.1794310416613459, 0.16113117062640048], 17: [0.211404129086277, 0.27692954094556427, 0.22845563190429657], 18: [0.2221233215354624, 0.28850138227165856, 0.2393984679919387], 19: [0.2282419878062596, 0.2922757783275347, 0.2620855468812524], 20: [0.2535293099499869, 0.32457833167629413, 0.2911839399041192], 21: [0.23268427650996615, 0.2918484380524293, 0.2627523849658205], 22: [0.26155899486247147, 0.3363794576128357, 0.2928056831884488], 23: [0.24187183709099275, 0.316535078568892, 0.27150057035440356], 24: [0.31768953054241866, 0.415387659136413, 0.3601502394156383], 25: [0.29920797281269407, 0.38470625198315656, 0.33146330288615083], 26: [0.31736262421027683, 0.40328017057916943, 0.36916949748085903], 27: [0.31081107643035927, 0.4065735373731117, 0.36106398338199885], 28: [0.36609462461682984, 0.46323000313915697, 0.4181239955607953], 29: [0.3803791538787282, 0.488721568319899, 0.43403344752822093], 30: [0.4135600001489828, 0.5374679902946647, 0.4835578423716676], 31: [0.4485441942702659, 0.5911802756282553, 0.5255049350613507], 32: [0.3597647122319919, 0.4888140034244172, 0.41688212126938895], 33: [0.5058852903413678, 0.6501893135778659, 0.5911603743682743], 34: [0.3789313021245919, 0.5087920610514247, 0.45503998168417], 35: [0.48815122347984374, 0.6490043481984935, 0.5776667931477938], 36: [0.5464709091399467, 0.7089341889024068, 0.6282781434070452], 37: [0.5048625433247822, 0.6836816528718817, 0.5951482289796615]}),\n     ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 608], {0: [0.06428346978561376, 0.10510348116731151, 0.06915527417968158], 1: [0.06502848810070382, 0.10573590834270281, 0.06947555435343768], 2: [0.06632467960400874, 0.10660761512309457, 0.07089794722022365], 3: [0.06539158486120906, 0.10651148381969418, 0.06959408202275562], 4: [0.06532804116017743, 0.10633702587989917, 0.06971757742264001], 5: [0.06549767923507557, 0.10610799058186675, 0.07022049114254324], 6: [0.06517626812518376, 0.1057627858268293, 0.0697264710669174], 7: [0.08474269817241362, 0.13359707493486137, 0.09120157139232357], 8: [0.0942463750626468, 0.1483007595362178, 0.10088717998155818], 9: [0.09449175712895354, 0.15063746659126767, 0.10112459152627183], 10: [0.08994366335342552, 0.14428459896419682, 0.09819226280580215], 11: [0.10194865055227476, 0.16059114132108818, 0.10943497968036872], 12: [0.22037979601733643, 0.33304178977935844, 0.23913101389296731], 13: [0.20200814728661576, 0.3062535170314191, 0.2175274064763726], 14: [0.26140669218442936, 0.381255923820467, 0.2854057104782408], 15: [0.34324609918390303, 0.46643797825076605, 0.38736972710902284], 16: [0.35333169072476983, 0.4803972069824206, 0.4001741727259559], 17: [0.36272604071330405, 0.4923577099401724, 0.41205166299055607], 18: [0.37542046897228243, 0.5074410484956973, 0.4232987390005021], 19: [0.38713919584943024, 0.5242494087050363, 0.43978399855231026], 20: [0.38308302062805555, 0.5187878563936148, 0.43523930103241415], 21: [0.4095248117936444, 0.5702021744576211, 0.4523384584217697], 22: [0.41267081300377706, 0.5606567631942765, 0.46738971314206124], 23: [0.4327995667407517, 0.577609905270944, 0.48607755203925274], 24: [0.4320527561964532, 0.5794138814553911, 0.49027624799519676], 25: [0.4550839947584211, 0.6223452506164999, 0.5103340599937674], 26: [0.45682972296999524, 0.6238444890356337, 0.5018408145109254], 27: [0.4951385880608309, 0.6708755905596946, 0.549702889925845], 28: [0.4991031245174618, 0.6809113828305362, 0.5518216533158236], 29: [0.5159468708182532, 0.6951936557724256, 0.5610453232238022], 30: [0.5290186606513547, 0.7260166184996313, 0.5890699330016917], 31: [0.59476522642522, 0.8013761816598605, 0.6705765386868654], 32: [0.5601249432029896, 0.7552714826597982, 0.6207887604720157], 33: [0.5873255966945193, 0.7877533675874974, 0.6576067374963497], 34: [0.5419801414984413, 0.7444393518824233, 0.6040143534631943], 35: [0.5880173166089369, 0.7948186162671224, 0.6580496667592464], 36: [0.6186688862487523, 0.8351874102432519, 0.7004530673783985], 37: [0.5985845977944334, 0.808199900274875, 0.6680194176258925], 38: [0.6084115905271821, 0.8279458534635777, 0.6784006640478818], 39: [0.6711499413427768, 0.8887769807140071, 0.7489788532142728], 40: [0.6514792458660785, 0.8736793167568638, 0.7540814674753213]}),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 513], {0: [0.004552271095823858, 0.013938777477781139, 0.0021951074453086584], 1: [0.005449573892195469, 0.014205934520770317, 0.0048405090359084045], 2: [0.007997870082572148, 0.01678126034286128, 0.00843276813301648], 3: [0.012235548952876235, 0.01907573841411522, 0.013299616279928286], 4: [0.016694655195877584, 0.022836101056733855, 0.018254083883495222], 5: [0.004134991496696876, 0.012943531423622824, 0.0024042126617483], 6: [0.003678456448098847, 0.01160356377102906, 0.002266690148642217], 7: [0.005081160121912649, 0.013330944359720964, 0.0036844634912797866], 8: [0.011925643561351775, 0.022055611990316918, 0.011156199188737208], 9: [0.01208512068179822, 0.023272092254803308, 0.011563020352335097], 10: [0.017023969746364213, 0.027252044657513273, 0.017961636126426327], 11: [0.023380981278945688, 0.03403658295065442, 0.02651672016118432], 12: [0.0327848725522704, 0.04505210794574412, 0.03746550915617982], 13: [0.03961254277046399, 0.054508812590512504, 0.04540984035215949], 14: [0.18809020804057805, 0.2629385629924818, 0.21879615562457105], 15: [0.2292053987820392, 0.3110394073591759, 0.26163553513995325], 16: [0.2485979219929158, 0.33579456000218133, 0.28908759887588265], 17: [0.25533533887004345, 0.34599014709243336, 0.29727008262759363], 18: [0.2566639851699618, 0.3457836590028123, 0.29579057616579474], 19: [0.2826738165543328, 0.38338581418713724, 0.31513305684010673], 20: [0.2501351214887197, 0.3384251849311151, 0.2914688489859031], 21: [0.292839641776035, 0.3987261089710328, 0.3211377687705692], 22: [0.2565321700480392, 0.3464162842515197, 0.29667131408969377], 23: [0.3075505502665205, 0.41127727840470335, 0.3457277705261971], 24: [0.2569215586397038, 0.34586610109885246, 0.29841190608628615], 25: [0.3208811132182622, 0.4245656686632929, 0.3615338873576523], 26: [0.3352661316670563, 0.44136919257097723, 0.37175398606761334], 27: [0.34569050107236043, 0.4532327540589558, 0.38080793235310223], 28: [0.38652327049099006, 0.5044852446848241, 0.42961589334437233], 29: [0.4024100399705639, 0.5219118135301452, 0.4667280605137172], 30: [0.4098765564755863, 0.5237148438298138, 0.467610113557497], 31: [0.43699596018403775, 0.5748433667533854, 0.49603423693429305], 32: [0.46297655765326085, 0.6063826566657909, 0.5253464776790926], 33: [0.48559284507334766, 0.6245160975140254, 0.5578977753019756], 34: [0.49108464595248724, 0.6283974228701374, 0.5619916223119654], 35: [0.49274339976461673, 0.6422490418733079, 0.5512699184345567], 36: [0.4849562878000313, 0.6519173620074278, 0.5422755866553118], 37: [0.5638683632118352, 0.7245219626965692, 0.6324188005107945], 38: [0.5828534654489945, 0.7654109016410409, 0.6707351501599044], 39: [0.6489407723077976, 0.8581059231962682, 0.722093918649653], 40: [0.6468125047766566, 0.841900918320968, 0.7501580337447797]}),\n      ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1759], {0: [0.2459235775876472, 0.36547504293476, 0.2679661941637643], 1: [0.24670297302156965, 0.3630067664902056, 0.2750002092931449], 2: [0.2655265443975919, 0.3940672686757132, 0.292942951452275], 3: [0.26814285564372625, 0.4066805294558913, 0.28944866273270997], 4: [0.24434696261915695, 0.3620639410329166, 0.26509125379019627], 5: [0.2449966130260027, 0.3626483360117213, 0.265678392755471], 6: [0.24328752852185218, 0.36041598714736167, 0.26652093909174324], 7: [0.2824369189753517, 0.4195470159701137, 0.31000328239142344], 8: [0.28432427213177613, 0.4209649741479402, 0.3148608556582835], 9: [0.30086601486107056, 0.45012133141032085, 0.33169589920122], 10: [0.309366533545976, 0.458219768548895, 0.3409638584075492], 11: [0.31557589878489384, 0.46720864150662217, 0.3511062202657743], 12: [0.3260812412262014, 0.4902109238397898, 0.35536740792783544], 13: [0.42421895824708544, 0.6409919778575666, 0.45745630503373086], 14: [0.4308854017040131, 0.654725729242695, 0.46665296496160524], 15: [0.43472160813259786, 0.6572502825243759, 0.46917116663667124], 16: [0.4391361626153967, 0.6644410672425423, 0.4775060376113804], 17: [0.44168433523294615, 0.6775099476145531, 0.4733183426391858], 18: [0.4830998584040163, 0.7621326179677401, 0.502467690308452], 19: [0.4800143389867585, 0.7541650701879863, 0.5041015395576376], 20: [0.48274492333123514, 0.7678354879888993, 0.5015569407723325], 21: [0.4539369571253113, 0.7540793927943275, 0.46130111915301847], 22: [0.4868141519163059, 0.7768527910401519, 0.5069352958814333], 23: [0.5010276341374162, 0.7956331690601035, 0.5237193803665445], 24: [0.4851094807092923, 0.796830106895587, 0.4914251299955135], 25: [0.48716300233124415, 0.7687499817910748, 0.5070007302644308], 26: [0.48147596280643956, 0.7720854537224423, 0.500445035375777], 27: [0.4890705421601904, 0.8116029528931601, 0.49676124896292206], 28: [0.5258987659077092, 0.8471296840372834, 0.5497483472921212], 29: [0.5356485714375204, 0.8556401337328523, 0.5663284535372775], 30: [0.5321088134664614, 0.8503559860414206, 0.5595524457009372], 31: [0.5396495817175415, 0.8706063620242144, 0.5662750133931992], 32: [0.5603304188215316, 0.8823585441121877, 0.589637109508028], 33: [0.5656185672336804, 0.8907143161906126, 0.5939635457286483], 34: [0.5692846298130901, 0.9037093558119283, 0.5952264333945332], 35: [0.5656556890740511, 0.8957357827347187, 0.5997616556157928], 36: [0.5713827891210541, 0.8980054450182602, 0.609028017439528], 37: [0.580333420556403, 0.9029289689225535, 0.6174825743350407], 38: [0.5808497158240733, 0.9125297078385703, 0.6074955172772686], 39: [0.5777325656779301, 0.9060607289011378, 0.6129928763220355], 40: [0.6198721986574328, 0.9332556471750534, 0.6643225593822455], 41: [0.6628937980735252, 0.9409707880893188, 0.7453318384661778], 42: [0.7070727514995867, 0.9488084248668002, 0.7735362866608244]})],\n    \"/kaggle/input/inception-v3-5-layers/Severstal-steel-defects-1\": [(),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1224], {0: [0.009769487409325168, 0.026604948249164054, 0.006480238056347294], 1: [0.009478993260218654, 0.02423779618753069, 0.006602552088508273], 2: [0.010341383839544013, 0.02697216766879576, 0.007588693153757429], 3: [0.009284449309863711, 0.02419124935953818, 0.006663177361335815], 4: [0.010204302751452024, 0.027839111345760434, 0.006916800605532724], 5: [0.009381647632145438, 0.024598454267012636, 0.006777152592846535], 6: [0.009386504537841765, 0.02434918956848631, 0.006779065977334062], 7: [0.010590281438832663, 0.02880906443272219, 0.007231142606863108], 8: [0.010111167466400573, 0.025414570883376113, 0.006888751464516879], 9: [0.010072985820095835, 0.027694209090372856, 0.007159154980653447], 10: [0.010236568832958547, 0.02773116549902007, 0.006853174496534563], 11: [0.009851009440829605, 0.024687536592223943, 0.007132238516481348], 12: [0.010413546525770045, 0.02774497794428554, 0.0071719261572264215], 13: [0.01044948121686292, 0.02563836237948733, 0.007114380300956459], 14: [0.010165892555995492, 0.025677780534716112, 0.006709685362142568], 15: [0.019121543778979528, 0.05849088837519251, 0.009646717490249772], 16: [0.005840300934688912, 0.014125431014524866, 0.003936691501690599], 17: [0.017727242612951513, 0.04643256513893365, 0.011729333158949116], 18: [0.046275715035527167, 0.12990053620463357, 0.025344135981597994], 19: [0.04576107674165355, 0.12101054686317149, 0.0233388451461146], 20: [0.040843628964919956, 0.11253101541125121, 0.01835242913070653], 21: [0.06720415691881516, 0.19896565979899186, 0.02806258332865736], 22: [0.05881231952255907, 0.16122233188486873, 0.033335955362792324], 23: [0.06373060198135029, 0.17646556815391173, 0.037937539998637096], 24: [0.03782662133358692, 0.11402690144343271, 0.015049428847016329], 25: [0.07163343335501368, 0.20629340815836678, 0.039543356271590696], 26: [0.0761449468780614, 0.211617205432652, 0.03718158611741819], 27: [0.07268140197277798, 0.19546362807455017, 0.0292239085045456], 28: [0.09920363656941628, 0.2696634459881376, 0.05035881232093513], 29: [0.09111077549550262, 0.23650285121841788, 0.05830652411200499], 30: [0.11215949833817604, 0.31281534068037026, 0.057026616384438636], 31: [0.13426224403480486, 0.37401308365786484, 0.04244949566833738], 32: [0.1198708852531847, 0.3329757235502016, 0.052446530754257335], 33: [0.15227361260036204, 0.41276437845783687, 0.07568448373178271], 34: [0.15578150699038518, 0.40092006501890676, 0.0889094636809819], 35: [0.15696288422727986, 0.4169353624155368, 0.07047360520653106], 36: [0.18744515874525253, 0.46460433653364236, 0.12304671528383815], 37: [0.18836981754890564, 0.45534205177870646, 0.1419443001369297], 38: [0.19713580087196547, 0.46939909871318813, 0.14606755029658253], 39: [0.20400317644661298, 0.49870469883386326, 0.15512963458013693], 40: [0.2111515222825536, 0.5086646869129183, 0.16580633379846915], 41: [0.23089979872572391, 0.5501850793535288, 0.14858644138871774]}), ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1307], {0: [2.4430535778439726e-05, 9.798239204166596e-05, 0.0], 1: [2.4334123765562446e-05, 9.751159312281111e-05, 0.0], 2: [2.5764965063410722e-05, 0.0001290753136576628, 0.0], 3: [4.1855616126227963e-05, 9.66692117593455e-05, 3.2113867839401886e-05], 4: [4.8079900622430554e-05, 0.00016079613762002166, 2.655067778665558e-05], 5: [6.999258023785469e-05, 0.0002509712816041871, 2.4697221167153037e-05], 6: [2.9800554809434352e-05, 0.00010037603198396378, 0.0], 7: [6.824369489163225e-05, 0.00014831373634857287, 4.84248664799076e-05], 8: [7.34036126908182e-05, 0.0003103097848123344, 3.817956544395035e-05], 9: [6.352798084304336e-05, 0.00014752554711064509, 4.868063864558572e-05], 10: [9.837629060118036e-05, 0.00024910526849195345, 4.844197471536725e-05], 11: [0.00012047349194508059, 0.00027707626596698657, 4.8290753059929336e-05], 12: [0.00028609317599842635, 0.0008356068626681879, 0.00014027810507470317], 13: [0.00030212412827650104, 0.0008692685894441955, 0.00021753250148559425], 14: [0.0001951018664665272, 0.000545539322171516, 9.401342197651037e-05], 15: [0.001808225114532834, 0.006866900274320107, 0.0007467991816275206], 16: [0.0006759555447836029, 0.002438833193971045, 0.00030317915719261254], 17: [0.0015058073399403103, 0.004810673395565755, 0.00044249668911471837], 18: [0.0033239680159966424, 0.012941390437948307, 0.0014595725040616725], 19: [0.006223817510620051, 0.026340513108802942, 0.0020262588950236723], 20: [0.005947802162618727, 0.02429722522297365, 0.0013488878944585337], 21: [0.00759275598486929, 0.02926615835986187, 0.001926703088147123], 22: [0.006419275447459624, 0.027979331038445646, 0.0016227010529834252], 23: [0.007917055588042345, 0.03212745057510586, 0.0021351700502106707], 24: [0.010663492714722623, 0.045463191726432914, 0.00237780566279142], 25: [0.018030506445934506, 0.07209414649404997, 0.0033436898826363823], 26: [0.012231764099410866, 0.049519567276570454, 0.002764889793447839], 27: [0.013566424224237697, 0.05457102011507156, 0.0033261867745463386], 28: [0.017209625915245358, 0.0656569476177123, 0.004696065450627261], 29: [0.014325958758460027, 0.05912126775486359, 0.0032570586477976937], 30: [0.019340365864588465, 0.07733004874223869, 0.004142447904251247], 31: [0.027528212677826104, 0.10516155417924448, 0.006931177343221159], 32: [0.02759542029173051, 0.10735615662188996, 0.006959394054085785], 33: [0.024576179975451105, 0.09714935000764742, 0.006942151718755261], 34: [0.03237183027934867, 0.11511018898392467, 0.014526398843460605], 35: [0.027157531218768394, 0.097741739872444, 0.010215128737273215], 36: [0.059052828351052675, 0.22507369126028437, 0.015142256271210148], 37: [0.06307970422755868, 0.2419726326819778, 0.014679202574080553], 38: [0.04556112261826713, 0.15566386511974836, 0.01831711933391053], 39: [0.05423936035076552, 0.18822867458760278, 0.017804054442793933], 40: [0.08589613254902705, 0.27125285502990604, 0.035914137233290136], 41: [0.10285475757900171, 0.31135945056518255, 0.04788891342766041]}) ,\n                                                                     ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 6001, 6501, 7001, 7499], {0: [0.005538223202118748, 0.013822092415417627, 0.0016560149644592299], 1: [0.004346462389038137, 0.012127009117321442, 0.0015178391848426045], 2: [0.004350853497934683, 0.013667518725207085, 0.0016743281208349268], 3: [0.00420501419322256, 0.012649171310203688, 0.0015567493661716768], 4: [0.004218150310424327, 0.012650120277527065, 0.001611123561930375], 5: [0.003935670743844741, 0.011689179183846668, 0.0016175316597020636], 6: [0.004097805000850558, 0.01169512195112728, 0.0016297474339753198], 7: [0.005404680415840605, 0.013810085011652986, 0.0016130785230819482], 8: [0.004465727852821931, 0.012591250339315027, 0.0016619972059374283], 9: [0.004261783343651361, 0.012052962805626254, 0.00154404976935872], 10: [0.004187728655127404, 0.012582759930963885, 0.0015464104232407678], 11: [0.004066082305398228, 0.012551093171259606, 0.001657380694926422], 12: [0.004200933935910748, 0.012797467032223704, 0.0015916950352406485], 13: [0.0039970480237938215, 0.012093175838963629, 0.0016737329853310427], 14: [0.003937237196144241, 0.01184020616047433, 0.0016601251634684345], 15: [0.004771059593790276, 0.015935388010946454, 0.0016766684332338345], 16: [0.003881762604007302, 0.011992649572096989, 0.0016578632915293762], 17: [0.0036705942625488873, 0.01296968132309482, 0.0016462100483945169], 18: [0.006040130492347404, 0.02019500374800487, 0.0017890621812292427], 19: [0.005264658829059171, 0.01930474783216786, 0.0019226746490063902], 20: [0.0035232318235013382, 0.011409224295688266, 0.001416629741767979], 21: [0.005851221574850424, 0.012252451319952378, 0.005520823766460173], 22: [0.007477949276669779, 0.026009335724185345, 0.0029310785579142636], 23: [0.016240259326519027, 0.04596921661952382, 0.010676063251625498], 24: [0.006772681264974899, 0.023876159108021655, 0.0031314240321029447], 25: [0.008210203679174317, 0.029685621656617766, 0.0027577208640970686], 26: [0.02221913580397237, 0.07172121871352376, 0.00797106415541496], 27: [0.0417313693513296, 0.12531216328731698, 0.017582997017847032], 28: [0.03102252400870641, 0.09331434176639754, 0.013489052750478693], 29: [0.044158462816932156, 0.14107777353039383, 0.01873896357835764], 30: [0.044457087009185575, 0.14279338494386595, 0.016813806575987866], 31: [0.051211250245100925, 0.15267669662291622, 0.022946635161754752], 32: [0.05209312557505312, 0.15678841221280881, 0.02349348405960678], 33: [0.04605440984841263, 0.15030502261707857, 0.018474601810912577], 34: [0.02725511799529503, 0.0924698394556195, 0.008986316768838612], 35: [0.0616856660077318, 0.17494525923537307, 0.028850422208741688], 36: [0.06527012131950258, 0.19955861933233343, 0.026613816783278038], 37: [0.08607649330132297, 0.25312073486046216, 0.038103958982958305], 38: [0.05212777017437471, 0.16618737728437058, 0.019845447924377122], 39: [0.09689113517954653, 0.2664142047895619, 0.04884797855690781], 40: [0.11062017838087042, 0.30175615662841493, 0.05325861855255173], 41: [0.1057086295185358, 0.29322248659958383, 0.052371863526845606], 42: [0.11325695005073108, 0.3005280603397089, 0.05595352233303387], 43: [0.131336873516134, 0.33481504491346814, 0.07484733605803387], 44: [0.13145405093244342, 0.34317056961087, 0.06925986644323304], 45: [0.15289088072677573, 0.37370589996540604, 0.09631112685592032], 46: [0.11448990867868777, 0.3048870932926058, 0.06017864267501828], 47: [0.1394888346217264, 0.36838736282511253, 0.07620344540671324], 48: [0.15713186926011, 0.3913832048619935, 0.09479741233887902], 49: [0.14083511627186576, 0.3614494174167298, 0.07828938102445182], 50: [0.11554357031312801, 0.312813451052946, 0.055323290917323686], 51: [0.1507420120693957, 0.37637487887676513, 0.0914973906709415], 52: [0.14221238956779955, 0.37628384135901, 0.07986823077435032], 53: [0.15726977616231594, 0.39969749088712536, 0.08844140560966415]})],\n    \"/kaggle/input/inception-v3-5-layers/screw-detection-17\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1580], {0: [0.000770625985317857, 0.0018597987903011563, 0.0006011388144548122], 1: [0.0007549018921197488, 0.0018853779726192693, 0.0006014872599295142], 2: [0.0008052856612417499, 0.0020242773134035, 0.0005665930008920241], 3: [0.0008125701497462667, 0.0019686583138860893, 0.0006210794569082219], 4: [0.0007947746467401248, 0.0019358399378284256, 0.0005851699194782462], 5: [0.0007919100651942937, 0.001976468254483093, 0.0005847878976656366], 6: [0.0007861640712827321, 0.0019462695315900062, 0.0005697322148112622], 7: [0.001032335729630853, 0.002698143367408451, 0.0007750910626168091], 8: [0.0011621628795622364, 0.003058681126010471, 0.0008201361708550124], 9: [0.0011745924147386717, 0.003094208900899621, 0.0008700163882713922], 10: [0.0012888588713878557, 0.0033495133029946274, 0.0009484835500950023], 11: [0.0011473157863014028, 0.0029994584944230316, 0.0008482212455630717], 12: [0.02875223444983855, 0.07772727585945273, 0.018315793879209247], 13: [0.011449006370940835, 0.032084067471084436, 0.006115037858232815], 14: [0.028510171738846058, 0.07589397185984162, 0.017621886286086796], 15: [0.09676004161737126, 0.27441337540921684, 0.04833711331120833], 16: [0.09330480804500971, 0.2770178247391941, 0.044999937952339336], 17: [0.12859473769094817, 0.3388584630627649, 0.06763859988766946], 18: [0.14718936200556115, 0.36926616901998355, 0.09103926395995031], 19: [0.1553014640434681, 0.38387270553676867, 0.09857356834861378], 20: [0.15387814146040027, 0.3902523804551246, 0.08555474497749052], 21: [0.18217044987740844, 0.4630667315519265, 0.1070859262683519], 22: [0.1783493508154344, 0.4465503915399014, 0.1050878025383412], 23: [0.2007715188239449, 0.48562075901885304, 0.12477186195258425], 24: [0.19184955984173108, 0.47768206128845225, 0.11231962228612681], 25: [0.25062855021567426, 0.5889103807661487, 0.16467086378826912], 26: [0.24770910068885565, 0.5764943090328399, 0.1593505271966637], 27: [0.28123912720944866, 0.6423951564749659, 0.19419101019130214], 28: [0.3370382398792139, 0.7273130621124787, 0.26723269670992617], 29: [0.35031427337883897, 0.7468450577089822, 0.28557924392094974], 30: [0.37671410657287663, 0.792362191785438, 0.3104180149283501], 31: [0.4014903491196914, 0.8374301373218102, 0.31302060999872894], 32: [0.3986166725237628, 0.830261958197823, 0.3096461917922039], 33: [0.4191401779019577, 0.8498536547129231, 0.34982698048701805], 34: [0.4191544151080839, 0.8532625230350239, 0.3536013311648832], 35: [0.41013206718333484, 0.8418096523959734, 0.31199925773418824], 36: [0.46932461696593053, 0.907118675828535, 0.40871748695441257], 37: [0.5158423410031832, 0.9330679131483771, 0.5290842278226183], 38: [0.5161196962608345, 0.9354264028949137, 0.5311295593575123], 39: [0.5304105061110845, 0.9395578061601391, 0.5780707749192809], 40: [0.5525709172252045, 0.9599236673782737, 0.594389635194213], 41: [0.5706045366999072, 0.9680163749752138, 0.6233512232984615], 42: [0.5941662722852963, 0.9798813707353841, 0.6821916810903237]})],\n    \"/kaggle/input/inception-v3-5-layers/bolt_111-1\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 884], {0: [0.03732909392733925, 0.05436125865451772, 0.03789211157610565], 1: [0.04313108869019169, 0.05869137291677035, 0.04293175209580316], 2: [0.04051434193699395, 0.05853948504178171, 0.041794576299084306], 3: [0.03888307219725865, 0.055373499114090285, 0.03991034370233813], 4: [0.03814695883896477, 0.05360111288708404, 0.04007529376166833], 5: [0.03866460158281902, 0.06200275402941833, 0.039194392205021654], 6: [0.04004913134353611, 0.06144113580629664, 0.04009592711033276], 7: [0.04973258595370731, 0.07115563100727486, 0.05332534149592829], 8: [0.045611706503321595, 0.06622553450333638, 0.047100668954751], 9: [0.039625931808497696, 0.05718798870288493, 0.04023165297204187], 10: [0.041295606170888226, 0.05844847967811681, 0.04334360650824472], 11: [0.04636572386967205, 0.06369415627634348, 0.04953812973767203], 12: [0.15523096341697412, 0.21484490288369557, 0.16590532819344112], 13: [0.1581209705063889, 0.21845970685927113, 0.16673682122809436], 14: [0.3029271010742841, 0.42483546232970315, 0.29270975150767276], 15: [0.44124713800910154, 0.5745527990796636, 0.44388948211547113], 16: [0.48547346022969273, 0.6053842286234298, 0.4950273066618888], 17: [0.5130404444971922, 0.6283751124584598, 0.5264873452522736], 18: [0.5810253889339758, 0.6712533692318661, 0.6109518662708334], 19: [0.5422006997283824, 0.6384304275322723, 0.555826736338926], 20: [0.5849906196399886, 0.67916593280811, 0.6181527546405259], 21: [0.6889035256826352, 0.7677508693334948, 0.7388814155290436], 22: [0.6572471655217493, 0.7274918700842807, 0.7025993996598267], 23: [0.7027461304559977, 0.774984191615899, 0.7382693920374721], 24: [0.6558269477022504, 0.7485646665971468, 0.6794963600828616], 25: [0.7433504496474305, 0.85068057603183, 0.7929277632195039], 26: [0.7258473459144019, 0.7935255867851742, 0.7640094785825178], 27: [0.7740026367572723, 0.8749319696361783, 0.818026615359257], 28: [0.7830085513879659, 0.8961044724343096, 0.8152978710345212], 29: [0.7931780228188076, 0.9028534910449222, 0.8195768555678963], 30: [0.7519763085585212, 0.8397851825590824, 0.7923584751620558], 31: [0.8220700533635702, 0.9205395916724368, 0.8584864729992892], 32: [0.8172461686159671, 0.9145900458299511, 0.8523661216586389], 33: [0.8184913731763237, 0.9252707520741308, 0.8653891505951363], 34: [0.7949638337215681, 0.9061790817382415, 0.8135538823055252], 35: [0.8307800050014371, 0.9407567256004874, 0.8578483890851629], 36: [0.8391589990685056, 0.9483991554905126, 0.8515904838545763], 37: [0.8505072623086978, 0.959385312859629, 0.8945968545638557], 38: [0.8783725636468231, 0.9737494179378801, 0.9169171897907158], 39: [0.8853095824792367, 0.9727138288089983, 0.9372908328811261], 40: [0.8935090588947503, 0.9868382291220735, 0.9645793400756434]})],\n    \"/kaggle/input/inception-v3-5-layers/affected-leaves-initialD-16\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 784], {0: [0.0009648174732195883, 0.0028178851808111738, 0.0001503653952083562], 1: [0.0011777065880646715, 0.0030670481008942163, 0.0005410858714596273], 2: [0.0011952472047582687, 0.003275530505378074, 0.0002645050525387631], 3: [0.0013951803576652245, 0.0037877567709668925, 0.0003889233171491715], 4: [0.001338396578624604, 0.0038417235103431744, 0.0005041290286478589], 5: [0.0012065622626346259, 0.0035523356059169744, 0.00027312187327645677], 6: [0.0013500216316454814, 0.0038541749223526913, 0.0003854511194709294], 7: [0.0012319153627687626, 0.003380634327740593, 0.00026929512198446904], 8: [0.0012706326733457098, 0.0031742434523661604, 0.0002749379210239915], 9: [0.001445970143507394, 0.003675143219580039, 0.00040730845368411843], 10: [0.0015522083548023496, 0.0035454091243741614, 0.00039486457436069104], 11: [0.0015592602747386628, 0.003859700043131529, 0.0003992321800389272], 12: [0.003006208045374276, 0.007857601174728526, 0.0014090569704411525], 13: [0.002643126948080184, 0.006202362672026683, 0.0012737864045524814], 14: [0.0026508901991772896, 0.007191872379543474, 0.0008375798314715402], 15: [0.006299795282822485, 0.015059589473675139, 0.0035945213977412746], 16: [0.01575619602952242, 0.03671879950377577, 0.006803022673978262], 17: [0.012180077969407645, 0.02711651911439746, 0.008859721556182545], 18: [0.024154100900705786, 0.057875318616300256, 0.01815700999712995], 19: [0.03332919556024304, 0.07527411409749793, 0.02644419988437603], 20: [0.03750224472545956, 0.08187739296882712, 0.025809854615846888], 21: [0.05231600513891601, 0.11339252356758983, 0.04157998521961655], 22: [0.042627827180686285, 0.09685477679264506, 0.020520830235715305], 23: [0.03921935431573256, 0.09739576116428135, 0.016786575234167628], 24: [0.054207597095445335, 0.11936134096962375, 0.04283588528486542], 25: [0.042693960037071065, 0.09985554798929194, 0.026201660448996567], 26: [0.05561455556426899, 0.1389374525432139, 0.03412044808183042], 27: [0.05697834151393353, 0.13814833953388092, 0.0385922946363049], 28: [0.06476092836578007, 0.1514796817898807, 0.04193045540155688], 29: [0.07845673319908711, 0.16787190398729684, 0.06628485528195269], 30: [0.09641316359601775, 0.2090013958828067, 0.0742175784568015], 31: [0.09756400584688031, 0.20884586359758722, 0.07531086605312083], 32: [0.10137226501787236, 0.2047664740484272, 0.09030479009669133], 33: [0.10790993786100198, 0.225535607635401, 0.0893579624532852], 34: [0.10239425195064952, 0.2515594092672877, 0.07974709939594471], 35: [0.10961503541768144, 0.23882210360133363, 0.07121221789429827], 36: [0.14740581154724489, 0.321758799410188, 0.10967076391870684], 37: [0.14803803627706222, 0.31685561274773105, 0.10835903922151666], 38: [0.1501196974516013, 0.32377072534064616, 0.111512998359787], 39: [0.20011575324857828, 0.43222385307922007, 0.13432115556663715], 40: [0.22010128451880676, 0.4706091563909349, 0.17339295687351236]}),(),(),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 723], {0: [0.026666383613665922, 0.08319679002191673, 0.0186797362325532], 1: [0.02579794587749947, 0.07980120777221343, 0.01876384928826815], 2: [0.025650319660917555, 0.08432838575361931, 0.015412819083723193], 3: [0.02740431848162126, 0.08773308919072653, 0.01704846878186069], 4: [0.02590077539107103, 0.08025360571450077, 0.017452107914975902], 5: [0.026247962430024956, 0.08169659793031234, 0.019568031748649538], 6: [0.02587977279133526, 0.07821847046836992, 0.01750043612749891], 7: [0.027187738211315694, 0.08084242133596255, 0.018513706278624413], 8: [0.02811168232962736, 0.08702082235297137, 0.016664407872622734], 9: [0.026957676829300697, 0.08433303763630394, 0.018199004145807218], 10: [0.027829938341163585, 0.0857864315502649, 0.01921898685393961], 11: [0.026360046760539924, 0.08096654980755591, 0.01574235546512458], 12: [0.06798013240297038, 0.16372112889485188, 0.04920431616669141], 13: [0.07210903817525455, 0.17004478667787754, 0.050211491174606875], 14: [0.08069836316605258, 0.2071952584068616, 0.05872431047741873], 15: [0.16525372415817366, 0.3761015011554109, 0.12450097882266523], 16: [0.17175161643610665, 0.401675366748029, 0.12331715887098586], 17: [0.1696284959462132, 0.36994670772538696, 0.12194264273172345], 18: [0.23448978459445624, 0.460655892517039, 0.2009800212527311], 19: [0.23860755390782362, 0.4662139215547659, 0.1985617526597795], 20: [0.212517755300727, 0.43799005306704225, 0.1675020491834289], 21: [0.23391356117618142, 0.4830002397741595, 0.17607137538858297], 22: [0.24636814448618133, 0.49529774081762323, 0.1940399243996726], 23: [0.281990121337586, 0.5304284697190956, 0.25771644810243816], 24: [0.2859260516326997, 0.5128400743323706, 0.26960085846093607], 25: [0.32784083842863904, 0.5883174593763638, 0.2761018650537861], 26: [0.3192374633003058, 0.5613483019512115, 0.3105440154834885], 27: [0.3109580403984508, 0.6045655561384328, 0.24167170146187905], 28: [0.3639898008045663, 0.671869701873087, 0.3413781492880589], 29: [0.3475366597144033, 0.6428781735616343, 0.3254133745244938], 30: [0.3790120488004499, 0.6885435781121241, 0.3347063410630491], 31: [0.42088192923749446, 0.7204074391089008, 0.42293561824469633], 32: [0.3924525709447125, 0.6971675172441827, 0.3507841593050036], 33: [0.4095969689659105, 0.6902692454752971, 0.4252651389188799], 34: [0.4117398879546596, 0.732082542971865, 0.3951003878985142], 35: [0.44067861349821735, 0.7441123315194291, 0.4446288447197344], 36: [0.46515451376368466, 0.7903396631936819, 0.47046163532974405], 37: [0.4684376037141818, 0.7811362539242813, 0.4341570609552159], 38: [0.4736519236098631, 0.8088752869382562, 0.483775901071853], 39: [0.49484557012915076, 0.8155358911512767, 0.5158827601359935], 40: [0.49993015644932626, 0.8445293447619234, 0.5116265964115005]}),[],[],\n                                                   ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 482], {0: [0.012837737512905891, 0.019948571583258752, 0.01273564399746801], 1: [0.013268403254651211, 0.020572523749169375, 0.013759313234300942], 2: [0.013456301455694718, 0.020803581365057108, 0.01392894234458162], 3: [0.015314461038937771, 0.02249096146637405, 0.016441909607699735], 4: [0.015094430735285944, 0.022697889661510918, 0.015651237512549772], 5: [0.014749213351174614, 0.021890274700518637, 0.015332508099711874], 6: [0.017081133556148435, 0.025491816745053145, 0.01808512261898425], 7: [0.019342737997046514, 0.03305473697027564, 0.017347054499194436], 8: [0.018300696838624734, 0.029956388986662565, 0.017737733645772837], 9: [0.01518034799006624, 0.022087029543426413, 0.016115854976268936], 10: [0.024710808638240076, 0.0423905535625199, 0.024720043292001708], 11: [0.01574876364756857, 0.023633031823456555, 0.016371040770751286], 12: [0.03694562155692125, 0.06774384822628515, 0.02922605263240323], 13: [0.047138008672603135, 0.08429569741014836, 0.0416304527921711], 14: [0.0386629691359808, 0.06977732465628762, 0.040077220408324024], 15: [0.062202859323534, 0.09963893231421019, 0.05748886270604246], 16: [0.06452162908151546, 0.09955061854441033, 0.058884472610910316], 17: [0.06669297544487743, 0.10342010376591078, 0.06680209055730058], 18: [0.06851395705161697, 0.10383791550816915, 0.07183673347368524], 19: [0.1478629625293691, 0.27992886682113144, 0.13332878501591314], 20: [0.12246913013020763, 0.24810533505879184, 0.10202657192558029], 21: [0.14721367880087705, 0.2991309205569048, 0.1025220615228126], 22: [0.15719580608557274, 0.3205521245173635, 0.12096924764021674], 23: [0.170004702473749, 0.36276038326036997, 0.11995823674303348], 24: [0.15308022574574784, 0.3098935355129032, 0.13296656649680175], 25: [0.16413898040943015, 0.33753168957105917, 0.13841275816583065], 26: [0.17560392151098536, 0.3478991704327435, 0.17332408315630204], 27: [0.21154212532918365, 0.40423434843211725, 0.1828476567659135], 28: [0.24928039807955105, 0.4532731960997466, 0.22515590371291921], 29: [0.25102786660998755, 0.47033013663402984, 0.2253740177305882], 30: [0.25413847142686297, 0.48345946812224755, 0.25470700731561335], 31: [0.26064743176672106, 0.49229659937572173, 0.26184472392528424], 32: [0.28778011751199506, 0.5037112647298283, 0.2894330861717931], 33: [0.31723155112432927, 0.5433105723359005, 0.3217623896447071], 34: [0.3353471881880673, 0.5462293656360487, 0.3749078288317852], 35: [0.32610478155933914, 0.5609796717444182, 0.32574695760118094], 36: [0.35767958672470923, 0.5556271297800165, 0.37556448696137334], 37: [0.3813547585962684, 0.6314618675485512, 0.396815806652106], 38: [0.4250209448786027, 0.6820996288897648, 0.43623438258017927], 39: [0.33358299068564345, 0.5824411637605011, 0.3454862829726758]})],\n    \"/kaggle/input/inception-v3-5-layers/solarpanels_full-1\": [(),(),([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 969], {0: [8.510821795272173e-05, 0.00034129760468762935, 0.0], 1: [8.786511028980625e-05, 0.00032540404370670736, 3.06414510807197e-05], 2: [0.00012076039200242239, 0.00038230336581699206, 0.0], 3: [8.989839679761789e-05, 0.00037865289527306146, 0.0], 4: [0.0001258286828118176, 0.00044280887831486034, 0.0], 5: [0.00015747261786065915, 0.000540067286111662, 0.0], 6: [8.58270386759242e-05, 0.0003782549782178404, 0.0], 7: [8.377297107806232e-05, 0.0003266513665748058, 0.0], 8: [0.00010392182210191466, 0.00037289497999415096, 0.0], 9: [8.844484157945468e-05, 0.00034969330479146495, 0.0], 10: [8.935667507676867e-05, 0.0003556058573019966, 0.0], 11: [8.825319600163063e-05, 0.00036805154333501797, 0.0], 12: [8.815965304514821e-05, 0.0003711528500537928, 0.0], 13: [0.00012094416402756464, 0.0005735779161679408, 0.0], 14: [0.00017730956502874225, 0.0006096747239111643, 9.88553378773957e-05], 15: [9.42434633637914e-05, 0.00038737884796705325, 3.3909530994632965e-05], 16: [9.970344430045475e-05, 0.00037291549776938564, 0.0], 17: [0.00011406901405642978, 0.0004221723556195934, 3.2429603370307504e-05], 18: [0.00036484752656628755, 0.0010222636672829297, 0.00010275399817200317], 19: [0.00040377280848481745, 0.0013185466649904367, 0.00012848563650110038], 20: [0.00024333044857974953, 0.001054589855802851, 5.0121283866011504e-05], 21: [0.0017968615362713275, 0.007792786318901811, 0.00014992702440233687], 22: [0.0020941536087318233, 0.009849430758107111, 0.0013577015418089053], 23: [0.004062182197309978, 0.013202893409124662, 0.000676709137531371], 24: [0.0239230567515768, 0.07658056808389918, 0.0047219461249651444], 25: [0.01220185467018325, 0.03955426195871909, 0.007645455951012313], 26: [0.013288792459886456, 0.03860334785287242, 0.006905359744346821], 27: [0.023915981008495228, 0.07957361948506429, 0.006112262282901369], 28: [0.07331974891255535, 0.22087757089333013, 0.025682447969696764], 29: [0.030935934722492904, 0.09347799210725362, 0.008287099650725977], 30: [0.03602138312075091, 0.11865585664213164, 0.009465212098273588], 31: [0.10491073677751087, 0.30608754911661074, 0.036446928270346256], 32: [0.08478898452774615, 0.23512429787752198, 0.034411987981565695], 33: [0.10629430632046655, 0.3447343303577381, 0.0285729653450781], 34: [0.12025042704578988, 0.3630967219084624, 0.03880260498950371], 35: [0.11324470177596084, 0.3104743001025111, 0.0426458052099116], 36: [0.1583676215047674, 0.4177813657896303, 0.07402129663336866], 37: [0.18433956661347015, 0.4873951465347287, 0.09534684179405618], 38: [0.20748206818347303, 0.5476627802054216, 0.09244261444903035], 39: [0.2353314767456105, 0.5862825064069449, 0.11110155634617623], 40: [0.23920314365363474, 0.5718421509490272, 0.1417849280530536]}),()],\n    \"/kaggle/input/inception-v3-5-layers/Pothole-Detection-9\": [([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 2539], {0: [0.002227729296095378, 0.005361294462911356, 0.0016583516892033033], 1: [0.0020014771585026244, 0.00476338185661084, 0.0015311830425362358], 2: [0.001967599707510882, 0.004856354878482477, 0.0015134203416287163], 3: [0.0019421694612822365, 0.004723971285407612, 0.0013889010167556627], 4: [0.001975963563109217, 0.004730573587828044, 0.0014062960519465552], 5: [0.0019157972319545549, 0.004709378710265009, 0.0014212904221374873], 6: [0.0019684879565298454, 0.004808777623938056, 0.001495732190915728], 7: [0.0030588170883455667, 0.007515713718411281, 0.0021930790807309962], 8: [0.0032765413706996654, 0.009068760589693754, 0.001917154475403018], 9: [0.003079465753965948, 0.0075241830039075065, 0.0022692453528093044], 10: [0.0043350797047050785, 0.011003258358115086, 0.002668033137338868], 11: [0.0031672849553424248, 0.007356895685805917, 0.0023408099718852118], 12: [0.007128271373174044, 0.017201060233249132, 0.00498232660236406], 13: [0.007790046753117908, 0.01851708463997798, 0.005041454883732158], 14: [0.004725464549593528, 0.01143151483902624, 0.0031075262582494377], 15: [0.01349320137342829, 0.03109463613619366, 0.009991894304762902], 16: [0.015257318918167498, 0.03159573181748425, 0.012694375869804793], 17: [0.02052815103350921, 0.03848703251313703, 0.01837314156534123], 18: [0.023344886584500277, 0.04302103374027026, 0.021433270330668178], 19: [0.012227550633930507, 0.02812790611344726, 0.009872345528865992], 20: [0.015651178685806535, 0.03294446466364414, 0.011913198439722453], 21: [0.050709120761069856, 0.09873665392259827, 0.046123918307871076], 22: [0.051207459065769026, 0.1099545027027429, 0.04014911393547564], 23: [0.027899023866829287, 0.06203873929603383, 0.01908477888697498], 24: [0.08045641091145372, 0.15817058030884049, 0.07304918029621732], 25: [0.09608619126545184, 0.19008332727023614, 0.08575204546187971], 26: [0.05479184733542849, 0.11424231345516186, 0.0488296510195083], 27: [0.09983040661461007, 0.19653908627103794, 0.09571532225584009], 28: [0.14598650691183387, 0.26645946988750147, 0.1476433695844609], 29: [0.1308154724294382, 0.25304287419217153, 0.12638933444482295], 30: [0.11708164231473259, 0.23147486096733258, 0.10953253136531413], 31: [0.14658574577241643, 0.3052290191352698, 0.12046071758919907], 32: [0.19978627139201938, 0.3627928858052931, 0.19047113227269455], 33: [0.1814150893588087, 0.3539794706145762, 0.17023855681760822], 34: [0.19874411644235018, 0.37279235723161885, 0.17051165001003046], 35: [0.2164169167130357, 0.41043297706204507, 0.19921909451954709], 36: [0.22210371739512066, 0.4164279345337347, 0.21010995464808305], 37: [0.298136605625031, 0.5212440577864943, 0.30314495496501387], 38: [0.3188457491130962, 0.5589896640015874, 0.3175589807633921], 39: [0.3364338083199438, 0.600008658843726, 0.34651602520679836], 40: [0.3771785408881777, 0.6398932954230241, 0.3898188029695836], 41: [0.40532443141521135, 0.6594265701607992, 0.4440881748351378], 42: [0.42798482078634204, 0.7067575466336802, 0.4355665519386819], 43: [0.43510282382816756, 0.7219423792187031, 0.46976493311370116], 44: [0.44068777822264665, 0.7249151979898123, 0.47729648470741737]})]\n}## Load datasets ","metadata":{"papermill":{"duration":0.009106,"end_time":"2024-05-20T07:26:47.871999","exception":false,"start_time":"2024-05-20T07:26:47.862893","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# !pip install roboflow\n\n# from roboflow import Roboflow\n# rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n# project = rf.workspace(\"university-dltie\").project(\"severstal-steel-defects\")\n# dataset = project.version(1).download(\"yolov8\")\n\n# project = rf.workspace(\"roboarm\").project(\"feet-qevah\")\n# dataset = project.version(14).download(\"yolov8\")\n\n# project = rf.workspace(\"hanyang-university-bd2kb\").project(\"puddle-segmentation\")\n# dataset = project.version(8).download(\"yolov8\")\n\n# project = rf.workspace(\"imacs-pothole-detection-wo8mu\").project(\"pothole-detection-irkz9\")\n# dataset = project.version(9).download(\"yolov8\")\n\n# project = rf.workspace(\"lasttest-6gwfw\").project(\"fire_smoke-tfcpd\")\n# dataset = project.version(9).download(\"yolov8\")\n\n# project = rf.workspace(\"juan-aguilera\").project(\"solarpanels_full\")\n# dataset = project.version(1).download(\"yolov8\")\n\n# project = rf.workspace(\"riyou\").project(\"bolt_111\")\n# dataset = project.version(1).download(\"yolov8\")\n# # \n# project = rf.workspace(\"detection-label\").project(\"screw-detection-dry0a\")\n# dataset = project.version(17).download(\"yolov8\")\n\n# project = rf.workspace(\"ciencia-cafeto\").project(\"coffee-fruit-maturity-befkg\")\n# dataset = project.version(5).download(\"yolov8\")\n\n# project = rf.workspace(\"thesisp1classification\").project(\"affected-leaves-initiald\")\n# dataset = project.version(16).download(\"yolov8\")","metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:26:47.891543Z","iopub.status.busy":"2024-05-20T07:26:47.890645Z","iopub.status.idle":"2024-05-20T07:26:47.896864Z","shell.execute_reply":"2024-05-20T07:26:47.896008Z"},"papermill":{"duration":0.01806,"end_time":"2024-05-20T07:26:47.898850","exception":false,"start_time":"2024-05-20T07:26:47.880790","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import os \n# root = \"/kaggle/input/inception-v3-5-layers/\"\n# folders = os.listdir(root)\n# # folders.remove('.virtual_documents')\n# folders.remove('model_inception_fc.pt')\n# folders","metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:26:47.916668Z","iopub.status.busy":"2024-05-20T07:26:47.916387Z","iopub.status.idle":"2024-05-20T07:26:47.920158Z","shell.execute_reply":"2024-05-20T07:26:47.919356Z"},"papermill":{"duration":0.014774,"end_time":"2024-05-20T07:26:47.922070","exception":false,"start_time":"2024-05-20T07:26:47.907296","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# dst_path = r\"/kaggle/working/\"\n# for folder in folders:\n#     shutil.copytree(root+folder, dst_path+folder)\n# print('Copied')","metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:26:47.940629Z","iopub.status.busy":"2024-05-20T07:26:47.940036Z","iopub.status.idle":"2024-05-20T07:26:47.944154Z","shell.execute_reply":"2024-05-20T07:26:47.943249Z"},"papermill":{"duration":0.015836,"end_time":"2024-05-20T07:26:47.946272","exception":false,"start_time":"2024-05-20T07:26:47.930436","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# from pathlib import Path\n# from collections import defaultdict\n# import shutil\n\n\n# for folder in folders:\n#     os.makedirs(root+folder+\"/all\",exist_ok=True)\n#     dst_path = root+folder+\"/all\"\n#     dirs = [root+folder+\"/\"+object if os.path.isdir(root+folder+\"/\"+object) else None for object in os.listdir(root+folder)]\n#     # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –∫ label —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n#     classes = defaultdict(set)\n#     empty_count = 0\n#     for split_foler in dirs:\n#         if split_foler == None:\n#             continue\n#         for txt_path in Path(split_foler+\"/labels\").glob(\"*.txt\"):\n#             with txt_path.open() as f:\n#                 text = f.read()\n#                 # –ö–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞,\n#                 # –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n#                 for obj in text.split('\\n'):\n#                     if len(obj) > 0:\n#                         classes[obj.split()[0]].add(txt_path)\n#                     else:\n#                         print(f\"–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {txt_path}\")\n#                         empty_count += 1\n#     print(f\"–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - {empty_count}\")\n#     for class_dir in classes.keys():\n#         os.makedirs(root+folder+\"/all/\"+class_dir, exist_ok=True)\n#         for path in classes[class_dir]:\n#             dst_path = root+folder+\"/all/\"+class_dir\n            \n#             src_path_split = str(path).split('.')\n#             src_path_split[-1] = 'jpg'\n#             src_path = \".\".join(src_path_split)\n#             src_path_split = str(src_path).split('/')\n#             src_path_split[-2] = 'images'\n#             src_path = \"/\".join(src_path_split)\n            \n#             path_name_split = path.name.split('.')\n#             path_name_split[-1] = 'jpg'\n#             dst_path = os.path.join(dst_path, \".\".join(path_name_split))\n#             shutil.copyfile(src_path, dst_path)\n            ","metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:26:47.966186Z","iopub.status.busy":"2024-05-20T07:26:47.965892Z","iopub.status.idle":"2024-05-20T07:26:47.971970Z","shell.execute_reply":"2024-05-20T07:26:47.971236Z"},"papermill":{"duration":0.017947,"end_time":"2024-05-20T07:26:47.974075","exception":false,"start_time":"2024-05-20T07:26:47.956128","status":"completed"},"tags":[]},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# target_map = {\n#     \"/kaggle/working/feet-14\": [[0.0119, 41.9859, 38.8603, 0.879],[0.1025, 3.0357, 133.6913, 0.8022]],\n#     \"/kaggle/working/fire_smoke-9\": [[-0.0036, 2.1481, 124.9397, 0.3805], [0.0115, 1.4661, 174.7387, 0.4091]],\n#     \"/kaggle/working/puddle-segmentation-8\": [[-0.0, 3.3689, 155.2318, 0.4046]],\n#     \"/kaggle/working/Coffee-Fruit-Maturity-‚òïüçí-5\": [[-0.0041, 3.288, 75.4753, 0.4966], [-0.0078, 2.1229, 91.8668, 0.5552],\n#                                                    [0.0423, 1.932, 63.8946, 0.6417], [-0.0235, 1.5128, 101.9465, 0.6775],\n#                                                    [0.2193, 1.2946, 61.1097, 0.6437]],\n#     \"/kaggle/working/Severstal-steel-defects-1\": [[],[0.0082, 2.6074, 147.6241, 0.2191], [-0.0022, 1.5466, 341.0034, 0.1066],\n#                                                  [-0.0017, 1.3496, 330.4605, 0.141]],\n#     \"/kaggle/working/screw-detection-17\": [[-0.009, 2.2032, 114.963, 0.5666]],\n#     \"/kaggle/working/bolt_111-1\": [[0.0201, 3.3812, 56.3712, 0.8386]],\n#     \"/kaggle/working/affected-leaves-initialD-16\": [[-0.0032, 1.7717, 201.2386, 0.2305],[],[],[0.0127, 2.196, 84.6248, 0.4941],[],[],\n#                                                    [0.0123, 2.4492, 114.5023,  0.4006]],\n#     \"/kaggle/working/solarpanels_full-1\": [[],[],[-0.0019, 3.617, 197.8735, 0.2345],[]],\n#     \"/kaggle/working/Pothole-Detection-9\": [[-0.0047, 2.07, 209.2555, 0.4204]]\n# }","metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:26:47.992946Z","iopub.status.busy":"2024-05-20T07:26:47.992134Z","iopub.status.idle":"2024-05-20T07:26:47.997019Z","shell.execute_reply":"2024-05-20T07:26:47.996307Z"},"papermill":{"duration":0.016198,"end_time":"2024-05-20T07:26:47.998950","exception":false,"start_time":"2024-05-20T07:26:47.982752","status":"completed"},"tags":[]},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"! pip install diffusers","metadata":{"execution":{"iopub.execute_input":"2024-03-19T17:44:36.564472Z","iopub.status.busy":"2024-03-19T17:44:36.564144Z","iopub.status.idle":"2024-03-19T17:44:55.955485Z","shell.execute_reply":"2024-03-19T17:44:55.954248Z","shell.execute_reply.started":"2024-03-19T17:44:36.564447Z"},"papermill":{"duration":0.008534,"end_time":"2024-05-20T07:26:48.016315","exception":false,"start_time":"2024-05-20T07:26:48.007781","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"from diffusers import StableDiffusionPipeline, AutoencoderKL\nimport torch\ndevice = torch.device(\"cuda\")\nvae = AutoencoderKL.from_pretrained(\n    'CompVis/stable-diffusion-v1-4', subfolder='vae', use_auth_token=True\n)\nvae = vae.to(device)\n","metadata":{"execution":{"iopub.execute_input":"2024-03-17T14:46:05.392191Z","iopub.status.busy":"2024-03-17T14:46:05.391913Z","iopub.status.idle":"2024-03-17T14:46:26.691491Z","shell.execute_reply":"2024-03-17T14:46:26.690481Z","shell.execute_reply.started":"2024-03-17T14:46:05.392166Z"},"papermill":{"duration":0.008339,"end_time":"2024-05-20T07:26:48.033523","exception":false,"start_time":"2024-05-20T07:26:48.025184","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.00826,"end_time":"2024-05-20T07:26:48.050461","exception":false,"start_time":"2024-05-20T07:26:48.042201","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import torch \ndef preprocess(pil_image):\n    pil_image = pil_image.convert(\"RGB\")\n    processing_pipe = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5]),\n    ])\n    tensor = processing_pipe(pil_image)\n    tensor = tensor.reshape(1, 3, 512, 512)\n    return tensor\n\ndef encode_vae(img_tensor):\n    diag_gaussian_distrib_obj = vae.encode(img_tensor.to(device), return_dict=False)\n    img_latent = diag_gaussian_distrib_obj[0].sample().detach()\n    img_latent *= 0.18215\n    return img_latent","metadata":{"execution":{"iopub.execute_input":"2024-03-17T14:46:26.693460Z","iopub.status.busy":"2024-03-17T14:46:26.692891Z","iopub.status.idle":"2024-03-17T14:46:26.700659Z","shell.execute_reply":"2024-03-17T14:46:26.699684Z","shell.execute_reply.started":"2024-03-17T14:46:26.693434Z"},"papermill":{"duration":0.009362,"end_time":"2024-05-20T07:26:48.068386","exception":false,"start_time":"2024-05-20T07:26:48.059024","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torchvision import models, transforms\ndevice = torch.device(\"cuda\")\n# Function to get image embedding using InceptionV3\n# Load the pretrained InceptionV3 model\nincept = models.inception_v3(pretrained=True).to(device)\n\n# Remove the final fully connected layer to get embeddings from the penultimate layer\nincept.fc = torch.nn.Identity()\n\n# Ensure the model is in evaluation mode\nincept.eval()\n\ndef get_image_embedding(image_tensor):\n    # Ensure image tensor is in the expected shape [3, 512, 512]\n#     if image_tensor.shape != (3, 512, 512):\n#         raise ValueError(\"Input tensor must have shape [3, 512, 512]\")\n\n    # Resize and normalize the image tensor to fit InceptionV3 input requirements\n    preprocess = transforms.Compose([\n        transforms.Resize(299),  # Resize the image to 299x299\n        transforms.CenterCrop(299),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    \n    image_tensor = preprocess(image_tensor)\n\n    # Add a batch dimension since PyTorch models expect inputs in the form [batch_size, C, H, W]\n#     image_tensor = image_tensor.unsqueeze(0)  # Shape becomes [1, 3, 299, 299]\n\n    \n\n    # No need to track gradients for this operation\n    with torch.no_grad():\n        # Get the embeddings for the image\n        embeddings = incept(image_tensor)\n\n    return embeddings","metadata":{"papermill":{"duration":8.151337,"end_time":"2024-05-20T07:26:56.228700","exception":false,"start_time":"2024-05-20T07:26:48.077363","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T20:39:11.908297Z","iopub.execute_input":"2024-05-22T20:39:11.908707Z","iopub.status.idle":"2024-05-22T20:39:21.369236Z","shell.execute_reply.started":"2024-05-22T20:39:11.908665Z","shell.execute_reply":"2024-05-22T20:39:21.368210Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104M/104M [00:00<00:00, 141MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Sample dictionary containing dataset paths and target values\ndata_dict_train = {\n    \"/kaggle/input/isaid-class-0/isaid_class_0\": [-0.0102, 1.5506, 67.5199, 0.4249],\n    \"/kaggle/input/isaid-class-1/isaid_class_1\": [0.0127, 2.3777, 54.6548, 0.3957],\n    \"/kaggle/input/isaid-class-2/result_dataset\":[-0.0148, 2.6068, 93.2110, 0.5870],\n    \"/kaggle/input/isaid-class-3/isaid_class_3\": [0.0099, 8.4763, 78.6146, 0.6437],\n    \"/kaggle/input/isaid-class-4/isaid_class_4\": [-0.0033, 2.4899, 151.1589, 0.5122],\n    \"/kaggle/input/isaid-class-5/isaid_class_5\": [0.0095, 3.4640, 172.8092, 0.4001],\n    \"/kaggle/input/isaid-class-6/isaid_class_6\": [-0.0065, 1.4245, 491.7785, 0.2680],\n    \"/kaggle/input/isaid-class-7/isaid_class_7\": [-0.0187, 1.4367, 128.9433, 0.3541],\n    \"/kaggle/input/isaid-class-9/isaid_class_9\": [0.0073, 2.8414, 50.2065, 0.3631],\n    \"/kaggle/input/isaid-class-10/isaid_class_10\": [-0.0024, 2.6081, 79.1674, 0.3928],\n}\ndata_dict_test = {\n    \"/kaggle/input/isaid-class-11/isaid_class_11\": [-0.0102, 2.5869, 68.5268, 0.4260],\n    \"/kaggle/input/isaid-class-12/isaid_class_12\": [0.0050, 1.6710, 197.5782, 0.5161],\n    \"/kaggle/input/isaid-class-13/isaid_class_13\": [0.0672, 2.0697, 91.6943, 0.5657],\n    \"/kaggle/input/isaid-class-14/isaid_class_14\": [-0.0003, 1.7025, 173.7523, 0.4158]\n}                  \ndata_dict_values_train = {\n    \"/kaggle/input/isaid-class-0/isaid_class_0\":([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 4926], {0: [0.015352601351563947, 0.026240795026951987, 0.015238983625578042], 1: [0.020436301065801896, 0.0348445830572628, 0.021302274534150182], 2: [0.01608780655541516, 0.02734417092793671, 0.01618901234424217], 3: [0.015240620639674981, 0.02616653878702481, 0.015213803266353257], 4: [0.015276274009947721, 0.02617834830202461, 0.015254660266301812], 5: [0.015531106826170125, 0.0267630289465002, 0.01542788014108639], 6: [0.01500420634553741, 0.02576810416900546, 0.015023187091333181], 7: [0.018944619799450935, 0.032792894171560186, 0.019067344218191284], 8: [0.023541070110172604, 0.03840348338225638, 0.025156871022382305], 9: [0.027455497827180365, 0.04645982776932296, 0.02749232854673882], 10: [0.028963374588690464, 0.048744307327856624, 0.030215342318230885], 11: [0.029000427475763202, 0.049971669898156004, 0.029680151175505362], 12: [0.15812957849796636, 0.3187882202202479, 0.13540486648169436], 13: [0.14053669115091755, 0.2763383909423148, 0.1271443745148008], 14: [0.14633545965995245, 0.2891901847934286, 0.13322015392104578], 15: [0.2203101018637504, 0.4848779937787284, 0.1660658110723032], 16: [0.20974217550041313, 0.4838085758177738, 0.14287575772961333], 17: [0.23521178823253336, 0.5150748545944948, 0.17770894836339177], 18: [0.21803457788724118, 0.49169696361348864, 0.15288742177034523], 19: [0.2181772498997529, 0.49368094861290257, 0.1555360400103991], 20: [0.24146180363375297, 0.5387912040303141, 0.17865235931440604], 21: [0.2451502392470674, 0.538862764915265, 0.18798247241642638], 22: [0.2507942042142466, 0.5565677474024914, 0.18754066508845693], 23: [0.24113180817019475, 0.5248300527106108, 0.18379209825849366], 24: [0.23911105937285643, 0.5389596124856709, 0.1738289476287642], 25: [0.2623761397301613, 0.5853274243538117, 0.19761373650258635], 26: [0.2771946521063635, 0.5858231273598528, 0.22324222794004417], 27: [0.284623692257824, 0.6320642796455277, 0.21306817844756037], 28: [0.322388338943841, 0.6949941227573654, 0.2538848044485249], 29: [0.2967860357373059, 0.6621854369132132, 0.22471339822035344], 30: [0.35475130186497195, 0.7017306238665506, 0.31993013705857076], 31: [0.34397798178328914, 0.7009309069106434, 0.2966381237180205], 32: [0.30952700387312093, 0.7013751045809022, 0.23015138486478315], 33: [0.32822556183386487, 0.7140075268946864, 0.26034112441771096], 34: [0.33733137408619995, 0.7239471882837023, 0.2726341799800865], 35: [0.32786170364700734, 0.6981434014694978, 0.26863528515887786], 36: [0.3879353337312804, 0.7705681999666973, 0.34626459361185585], 37: [0.3813583113509975, 0.7611460616026013, 0.3426109170948726], 38: [0.40238112018136657, 0.784980090623964, 0.3701244554427319], 39: [0.41195912858401373, 0.794478127235374, 0.37842126937167214], 40: [0.42265745792340637, 0.8100504968478425, 0.403731617626032], 41: [0.4228928612639196, 0.8157527441825964, 0.39880577135051054], 42: [0.4339947476693563, 0.8272393815999382, 0.4125989832623227], 43: [0.42303662478126, 0.8195124394273182, 0.3914773447934533], 44: [0.42502690519809183, 0.8245858199090885, 0.3979357703391062], 45: [0.4049110003428399, 0.815853890395035, 0.35691037125104075], 46: [0.4380653607572144, 0.8265845388978234, 0.4205189444200731], 47: [0.43939570151302004, 0.8389066612426909, 0.41572618531705857], 48: [0.4306245223552855, 0.8300171588690751, 0.4108443267145127]}),\n    \"/kaggle/input/isaid-class-1/isaid_class_1\":([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1515], {0: [0.02811217342876528, 0.04666246781898223, 0.027905343766392074], 1: [0.028465708362394055, 0.04830515402829994, 0.02827995115573653], 2: [0.031255267674703144, 0.049223706459051525, 0.03063214695421558], 3: [0.02943373589274123, 0.04914898536727807, 0.02957322380885202], 4: [0.02961318323523891, 0.05027652259182591, 0.029780101702713436], 5: [0.031945053725716356, 0.05059028587989722, 0.030698803857856883], 6: [0.02964389050417444, 0.04984305576099327, 0.029505624741252953], 7: [0.029186098590941907, 0.047341107443940766, 0.02906366013173199], 8: [0.0276426837395284, 0.042297920126557864, 0.02739117750675049], 9: [0.02706608143392804, 0.04263343806047135, 0.027127663297207116], 10: [0.029364278772456204, 0.047104381739908545, 0.028877353780208843], 11: [0.02613795465092401, 0.04201044039565237, 0.025370542809044664], 12: [0.16919892216029125, 0.3160512021182963, 0.1686366219647111], 13: [0.16429042596896856, 0.31097824940052193, 0.159418324747239], 14: [0.16469056544384444, 0.31486832422189476, 0.1533729830687709], 15: [0.23618896232187603, 0.4698718392431731, 0.21475882337543306], 16: [0.23293912380111967, 0.46449705743641767, 0.20991178374873085], 17: [0.24317199192237537, 0.46525088584400115, 0.2366808178976591], 18: [0.26240693945685006, 0.49781344087226037, 0.25802494895167144], 19: [0.2679625701669507, 0.5178110006914735, 0.25507511754389456], 20: [0.2629380073319383, 0.5198298457805386, 0.2361409378559022], 21: [0.27822019670328024, 0.5495642536779853, 0.25099125843528397], 22: [0.29290836430558004, 0.5648143108329121, 0.2727831473523071], 23: [0.2896033532740886, 0.5364834542092223, 0.2903325351051766], 24: [0.30299781238493817, 0.5722254457545819, 0.29309606693662027], 25: [0.32868294006642707, 0.6118695632781003, 0.321920521859351], 26: [0.30746995337922833, 0.5795132839779056, 0.2945666360198777], 27: [0.34913033369653074, 0.6312205349977542, 0.35464025121773257], 28: [0.36076859936293226, 0.6406497118097567, 0.3714550775484391], 29: [0.34414698302859403, 0.6367675704361031, 0.34584491058777017], 30: [0.3412313635904625, 0.640803605848751, 0.3344323397118708], 31: [0.3728454119933017, 0.6701035753226381, 0.38314495661510484], 32: [0.36814935041948893, 0.662133942039049, 0.3719516592208071], 33: [0.35326340939588424, 0.6598476719839936, 0.34339502466796507], 34: [0.3677758517258583, 0.6716652524533733, 0.37532819688163555], 35: [0.3790024003966466, 0.6705985028766813, 0.4018786606276058], 36: [0.3876066898603563, 0.6840297425917834, 0.4051893717672019], 37: [0.3899191938320342, 0.6851738394741259, 0.41180262118588284], 38: [0.3760559649898959, 0.6799389039782064, 0.373333710326241], 39: [0.3984322201037216, 0.6976277115916191, 0.4118561114719967], 40: [0.42672233549220895, 0.7298696090600479, 0.4551051267336567], 41: [0.43459209862513487, 0.7462969363843458, 0.45723443293095845], 42: [0.40320302144257186, 0.7242484835393589, 0.4072366099770981]}),\n    \"/kaggle/input/isaid-class-2/result_dataset\":([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 785],{0: [0.00072627609593769, 0.0013807013967008547, 0.0007645075173472244], 1: [0.0009748506041133582, 0.0017597112242339322, 0.0010213500640633513], 2: [0.0007930031802009695, 0.0014808325706799777, 0.0009102377544655867], 3: [0.0007138656371080626, 0.001397637626037033, 0.0006955676751715158], 4: [0.0006535916074144749, 0.0012463294286570827, 0.00050353475143497], 5: [0.0009951871372152752, 0.0020576850745273535, 0.0008899326136003328], 6: [0.0006111822903464437, 0.001253167063800782, 0.0005061958438638842], 7: [0.0010369170651709058, 0.0017684873514361471, 0.001233957241613316], 8: [0.0008595032834171134, 0.0015356747990922478, 0.0009784594387760924], 9: [0.001217823507561634, 0.0021890391273167234, 0.0013463187959507098], 10: [0.0009507923710860355, 0.0015712806311922666, 0.0010715335897484297], 11: [0.00127729483291219, 0.0025457297748276717, 0.0013130318951200832], 12: [0.006116397737577384, 0.01125306378039422, 0.006088791518640352], 13: [0.007815384708977491, 0.014540806918662358, 0.007553442784344393], 14: [0.005820309989120686, 0.009840168632069376, 0.005886542778975077], 15: [0.06194532859493155, 0.10726718680265321, 0.06224643385782934], 16: [0.0898322703342054, 0.15446626212313674, 0.0889560184339772], 17: [0.10074397127155932, 0.16727585354640506, 0.10971532467237158], 18: [0.2120588216544407, 0.3298558539207591, 0.23773088209917906], 19: [0.25546947718242663, 0.38620693351829355, 0.28627761121274076], 20: [0.2094564004767047, 0.31394713777874644, 0.23146698929460718], 21: [0.23214273096587007, 0.35732493877634147, 0.2610867879297509], 22: [0.3209773037248768, 0.47405255863327866, 0.3515447911141357], 23: [0.24976827333525659, 0.3829202407875977, 0.2742403505019027], 24: [0.27483569066496566, 0.4058411999521985, 0.3155637133307062], 25: [0.3514230641644688, 0.50830567022233, 0.3912016127639116], 26: [0.374654641864289, 0.5569710221722681, 0.40325795002179515], 27: [0.3776182497327353, 0.5430747590232188, 0.4066847788016543], 28: [0.4349913302367162, 0.6342097862410465, 0.4867432901864175], 29: [0.4195720458043479, 0.6221241726862676, 0.44863639731336347], 30: [0.42963568201776586, 0.6126430853519228, 0.4832222412825006], 31: [0.43839818738892794, 0.6132574967968474, 0.4828416853170329], 32: [0.46681326047487925, 0.6636705922066848, 0.5462983264601129], 33: [0.47770182379781884, 0.6848480607067999, 0.5534048908466632], 34: [0.4820190271217813, 0.7057407526014134, 0.4932680119977562], 35: [0.5076424888569749, 0.7298832903353281, 0.5951928176863827], 36: [0.5237912781382904, 0.7601525860243856, 0.5801564392889293], 37: [0.5778955462730331, 0.82331102965643, 0.6514130091826307], 38: [0.5918340886768715, 0.8302317832220094, 0.6702880978634702], 39: [0.5997088122258591, 0.848947683837515, 0.6617610724523268], 40: [0.6084889802573784, 0.86285763719758, 0.6636826889361584]}),\n    \"/kaggle/input/isaid-class-3/isaid_class_3\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 218], {0: [0.001870247082969049, 0.0038187336879301056, 0.001912307085944131], 1: [0.002813917258760298, 0.006688366769382752, 0.002095064969070844], 2: [0.001764232862611806, 0.003245913004432781, 0.0016452157366781935], 3: [0.00212195150460529, 0.0037771738010183298, 0.0020351257238679964], 4: [0.0017442509018414584, 0.0032121177167457617, 0.001578185045372821], 5: [0.0016521430348360893, 0.0031860552644092477, 0.0015728820763867492], 6: [0.0021315123164240175, 0.003830529365267977, 0.0020656396486042005], 7: [0.0017781231787926306, 0.003360002148009027, 0.001390968648602851], 8: [0.003904568483388227, 0.00999806871843818, 0.003298603475709998], 9: [0.0032160514766654083, 0.004878773433698182, 0.0035852977519935346], 10: [0.004174113993806741, 0.00865615304102269, 0.003787043658561701], 11: [0.004030555978071379, 0.0062218066760793295, 0.004521096316213413], 12: [0.006291259820315033, 0.02536330768147986, 0.005166318149566694], 13: [0.03299964885187515, 0.053003264607157145, 0.041115953096806365], 14: [0.03807594356457054, 0.06347758904839336, 0.04605117276135654], 15: [0.05557080969122722, 0.09283381113416128, 0.06889539907500666], 16: [0.07450636133713692, 0.11029671861291797, 0.0882071103015491], 17: [0.11016623359234942, 0.16746887486566203, 0.13306525964045743], 18: [0.13317186194964709, 0.19912010709183264, 0.16010688099728332], 19: [0.15213443674022728, 0.24958319008582358, 0.1853878980843918], 20: [0.17348689036676032, 0.2714346187468647, 0.20503418049279043], 21: [0.4595772655113753, 0.6183160580388952, 0.5390006120790859], 22: [0.48951346758435577, 0.6678402378440557, 0.6165804264083423], 23: [0.5023313227101267, 0.6831490399046691, 0.6290962909789892], 24: [0.5211705108086504, 0.7030916450884366, 0.6494784654618102], 25: [0.5966421619791633, 0.7571743217246762, 0.707750751848196], 26: [0.6365289535002452, 0.8189164658440304, 0.7477659489842354], 27: [0.5216106489054451, 0.6808175004289362, 0.6197981402733244], 28: [0.5829266730431191, 0.7706676528860711, 0.7026661177292173], 29: [0.5405905963991571, 0.7283095257021565, 0.6463203433520014], 30: [0.6276736994032738, 0.8599020782210204, 0.6982985345630552], 31: [0.6438597132059753, 0.8759225247549811, 0.7562509972299302], 32: [0.6631421141757532, 0.8465250566696001, 0.7816937164951823], 33: [0.684530306252231, 0.8723069820856318, 0.767221105593123], 34: [0.6890020049095058, 0.8887974107917226, 0.805802632815971], 35: [0.6756427235667655, 0.8902214173394978, 0.811595550591627], 36: [0.7152753089833659, 0.9004020943576628, 0.8571012514592138]}),\n    \"/kaggle/input/isaid-class-4/isaid_class_4\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 605], {0: [0.0022463668094654245, 0.004645394562823112, 0.0018289197756900248], 1: [0.002565362185639597, 0.004146783199401082, 0.002599530266792674], 2: [0.002221060690469606, 0.004707011128809769, 0.0021239730785845463], 3: [0.002187804971615661, 0.004989355673673777, 0.002114533900805495], 4: [0.002189767559169043, 0.004817279509578766, 0.0018918537448314248], 5: [0.002655950580362432, 0.0047812287935900385, 0.003038199002038187], 6: [0.003095145144542304, 0.005479042643057949, 0.003118727976554687], 7: [0.0031072187240511473, 0.005887381673216646, 0.0026197215547275414], 8: [0.002075020994201147, 0.004192755396628932, 0.0018737682209764232], 9: [0.0019934594286552766, 0.004124632243186279, 0.0018499620212572986], 10: [0.002207613732985951, 0.004750441213252018, 0.0018729388606447458], 11: [0.001988962323835593, 0.004105813249979554, 0.0018509452857039894], 12: [0.005049936127639766, 0.008899464370838217, 0.004723132000326565], 13: [0.007092967304648333, 0.012252082499214088, 0.0070749373913772205], 14: [0.00767940638117042, 0.013846411555727833, 0.007144511988579184], 15: [0.023619402897068924, 0.034943572745669796, 0.02431036106275783], 16: [0.03183656852915817, 0.0464307403151011, 0.03252582793436251], 17: [0.03556470545455448, 0.049197918907023755, 0.03716804584674895], 18: [0.05201957603919527, 0.08284044228556393, 0.05543361679365782], 19: [0.06787609505409557, 0.10514821980276923, 0.07337238004893848], 20: [0.08270758406174006, 0.12090209517264382, 0.09229409660919213], 21: [0.10205351432746552, 0.15122565964935125, 0.11512774402739086], 22: [0.10651838227076446, 0.15227549523574996, 0.11572984378457127], 23: [0.10603156793747166, 0.1508839485452835, 0.12314644899385618], 24: [0.12202800513501506, 0.17109384876015588, 0.14020333363804907], 25: [0.1286913063776591, 0.1803220226844156, 0.14680501388795228], 26: [0.12516345734182566, 0.17733520118526303, 0.13156667260686356], 27: [0.1505472088790432, 0.2070571581702969, 0.1704810181477537], 28: [0.2407967108248855, 0.3325341534907624, 0.27226580780397847], 29: [0.24763616098001692, 0.33012038115139686, 0.2830456380899294], 30: [0.2831703492866709, 0.38832271717867706, 0.31090554177991286], 31: [0.26516688805788907, 0.36657811628549747, 0.30457407384727153], 32: [0.3146582161174645, 0.4429690507013994, 0.3429484480115747], 33: [0.3196104972419973, 0.43798541924466905, 0.34826565898130146], 34: [0.3337933011655534, 0.47380749417816387, 0.37528986992854435], 35: [0.34160557789801355, 0.4877450975680822, 0.37417745817712117], 36: [0.37455337685079504, 0.5427759344446108, 0.4146882547185998], 37: [0.3852970807243055, 0.5529902387808997, 0.42970370091516763], 38: [0.4727122486348371, 0.659066137704615, 0.517512592175041], 39: [0.49062029456390743, 0.6886699272014786, 0.5778284936509567], 40: [0.5250449559476362, 0.7407778927114588, 0.6022594064790567]}),\n    \"/kaggle/input/isaid-class-5/isaid_class_5\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1315], {0: [0.010051830821767051, 0.022868435143284974, 0.008457127763034426], 1: [0.010128939591495377, 0.021714940603859225, 0.009129810995682778], 2: [0.010156668509684916, 0.021524610192198108, 0.007760814672504045], 3: [0.010060579758773483, 0.022636320506902424, 0.0086882582041929], 4: [0.010010871859057024, 0.02207845077702281, 0.00914107760790331], 5: [0.010063912709775018, 0.022193574982183016, 0.008981994367975062], 6: [0.009956916526497928, 0.02109814445116022, 0.009171191436438969], 7: [0.010662184709563042, 0.021087313289431836, 0.010473138090224699], 8: [0.010869903134118756, 0.02371453131992452, 0.009957001198806421], 9: [0.010340814968898823, 0.021990394346510164, 0.009944235564387125], 10: [0.010212289147927446, 0.02278249935253085, 0.009447711193232984], 11: [0.01032528346827503, 0.02186079091046349, 0.009878746793893549], 12: [0.011966353378118112, 0.027309085136708176, 0.00937383984443685], 13: [0.013109640647384407, 0.028353312589538167, 0.01171973781936364], 14: [0.013734873112283172, 0.030592000335222847, 0.011057875338422968], 15: [0.015615278565569915, 0.038113978718454844, 0.010371814105525517], 16: [0.02082504416059507, 0.04349081926406079, 0.01824468718969607], 17: [0.02287194153556734, 0.05122187190768874, 0.016323809725107507], 18: [0.023113789005644515, 0.04895067684000897, 0.020096025858882916], 19: [0.0246577297262329, 0.049151166821641105, 0.02119349765163502], 20: [0.037643252633216544, 0.07702862890906226, 0.028953058346946454], 21: [0.03397071439004044, 0.06567341131092931, 0.0293795889265158], 22: [0.04170211619984136, 0.08066003547287018, 0.03652067692116025], 23: [0.049474659989007096, 0.09352775823421147, 0.04673364472143526], 24: [0.04854718483379599, 0.10320751751239726, 0.045033914852144176], 25: [0.06391424518182291, 0.135339659385155, 0.06259576544272874], 26: [0.05575163386022146, 0.10975168793381278, 0.05252699969836416], 27: [0.09962690274060244, 0.19581615885465845, 0.09245864684243986], 28: [0.10348658356681353, 0.2037773970439483, 0.09051758145177054], 29: [0.1252410586807658, 0.25553023969657596, 0.11469326105391876], 30: [0.14739833981867062, 0.3152815863668401, 0.1208965423702489], 31: [0.20136379326191384, 0.3896792061436662, 0.19865692199193427], 32: [0.2406680043260719, 0.47546103128609335, 0.20004987256389067], 33: [0.26651267188246586, 0.44534385189966647, 0.2560032933136916], 34: [0.20970406235922226, 0.3820287819513399, 0.1902537027063791], 35: [0.22529217942748817, 0.4229802160494292, 0.18998285786315502], 36: [0.33438751783861875, 0.5964870452359184, 0.3125944734922336], 37: [0.3269169673580646, 0.6203419556413077, 0.318096011077523], 38: [0.3611879802134547, 0.5967368863409376, 0.3911211161767505], 39: [0.37781446224733245, 0.6385412297093414, 0.3846508474162879], 40: [0.38994037475454024, 0.677269149170549, 0.38716376887249604], 41: [0.44431049206870404, 0.7715157798678445, 0.4588836180325303]}),\n    \"/kaggle/input/isaid-class-6/isaid_class_6\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2498], {0: [0.00013485786541263988, 0.0002654738235115107, 0.00012661814929888616], 1: [0.00013870369405352006, 0.00025085905650850125, 0.00012499732430628182], 2: [0.00014677206712191202, 0.00032285973038887096, 8.347875179996591e-05], 3: [0.00019676632833335838, 0.0006256572589435379, 9.056752481142815e-05], 4: [0.0002394988058931093, 0.0003754903971559594, 0.0002537901456213844], 5: [0.00013990611276153906, 0.0002991971646042283, 0.00012410473497104197], 6: [0.00012158811975459599, 0.0002422471587721859, 8.10173977202974e-05], 7: [0.00011909066751726062, 0.00033464236445940386, 7.328884960469387e-05], 8: [0.00012934152174644628, 0.00031023954033419554, 7.811988978316799e-05], 9: [0.00010611737851663649, 0.00030605095034353047, 3.855286816900411e-05], 10: [9.881154278191845e-05, 0.00030041466035851693, 3.89955895458896e-05], 11: [0.0001166756496273946, 0.00037648488721479323, 3.824784491570354e-05], 12: [0.00012858690245185376, 0.0003317455177012724, 7.605290404620392e-05], 13: [0.00016628676126043894, 0.0004600232579000094, 0.00011917062649037324], 14: [0.0001606391233770671, 0.00041808382641234614, 4.42539296828997e-05], 15: [0.00033315667027042535, 0.0009196349885239745, 0.00024796806733143323], 16: [0.00026653116852278316, 0.0006434703960601555, 0.0001090052340859704], 17: [0.00034194923126739925, 0.0009466409794767995, 0.00013731915949488193], 18: [0.002902436469146516, 0.0080453222880436, 0.0008947228169828007], 19: [0.003099330964204872, 0.006813879270495014, 0.00033492941161914765], 20: [0.003547046654900944, 0.006729107059037987, 0.0052429490070176115], 21: [0.004987974729330761, 0.016031104855975312, 0.0010174388915031554], 22: [0.006838742896348303, 0.01779913122241053, 0.006263106027850588], 23: [0.007945458559699118, 0.021957305994906865, 0.0066419952332819445], 24: [0.0051989943908523125, 0.01850682552098217, 0.0013590325822033288], 25: [0.009686033196533498, 0.0318234894381526, 0.006647255903082907], 26: [0.009265413286837781, 0.02772854011760021, 0.00236424183403639], 27: [0.01682971566272055, 0.054061617052273046, 0.006169476735968261], 28: [0.018045828126797798, 0.055196119348761744, 0.006836183400322168], 29: [0.03164578455627219, 0.09603197428516937, 0.010309317718019451], 30: [0.03763359569012863, 0.11032045420644089, 0.015735938659931253], 31: [0.04806648951028243, 0.1383582695367525, 0.01824302931296548], 32: [0.04383580269092442, 0.12798973690904236, 0.015267445330846374], 33: [0.06714686529737961, 0.19538994367542745, 0.024843964625879282], 34: [0.07342837455129207, 0.2121297004716612, 0.03158217392251917], 35: [0.07070791292544301, 0.1929433552624614, 0.03861405842877802], 36: [0.0798290474285178, 0.22287855532818418, 0.04567055724985969], 37: [0.08562132664214722, 0.22021131201413038, 0.05099819332232238], 38: [0.1132056915156177, 0.29507979398120365, 0.06572277460735747], 39: [0.12789797439705766, 0.32030245603223384, 0.07768284024343891], 40: [0.16639403967351157, 0.41933498525005825, 0.1020709242035689], 41: [0.22275703880043746, 0.5260196704641545, 0.16337707161643344], 42: [0.24211129254096728, 0.5377527576375633, 0.19425535393998664], 43: [0.2519126275603582, 0.579381919508936, 0.18775069595708976]}),\n    \"/kaggle/input/isaid-class-7/isaid_class_7\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 6001, 6501, 6816], {0: [0.0002586831134767624, 0.000705663424291446, 0.00011754793310984318], 1: [0.0004878796478256413, 0.0013623621454360256, 0.0002582614106734191], 2: [0.0008115027135247683, 0.0021772134007911575, 0.0007562730807498205], 3: [0.0013846986103416875, 0.003063766447620576, 0.001375814400925334], 4: [0.0020414622476870635, 0.004909765400474823, 0.0017799303998037189], 5: [0.0002352008413456722, 0.0004700874206775565, 0.0002353729948025873], 6: [0.0002452805409383965, 0.0005840416206929137, 0.00023358423163327154], 7: [3.265633844152079e-05, 0.00010885446147173596, 0.0], 8: [0.00020731150253717293, 0.0005981731638652602, 0.00019664159014212582], 9: [0.00020890099291226508, 0.00036826787902848854, 0.00024582029287059464], 10: [0.00023792272154353226, 0.0005996093047081531, 0.00019763636625670704], 11: [0.0004747993182314247, 0.0012059841410644492, 0.0003921277515441546], 12: [0.01127477593086841, 0.020858757830648916, 0.010897568134867367], 13: [0.006137883063506535, 0.011795954318317196, 0.00639266712206737], 14: [0.0073301097626501, 0.013576926086288339, 0.007392253647080697], 15: [0.07335383536332266, 0.14343773747368985, 0.06665180464713998], 16: [0.062338491128317186, 0.11820090048479158, 0.05737635394063695], 17: [0.0783330491023476, 0.15158101450067074, 0.07147536447394462], 18: [0.1011651457855508, 0.203504893872754, 0.08642061783610909], 19: [0.12305169433971752, 0.24657623959865022, 0.10926987517307203], 20: [0.11496082797822116, 0.23625777135208959, 0.1000902528693452], 21: [0.09608351566655347, 0.19680700264622245, 0.08197507271377703], 22: [0.10731322961987164, 0.22068525094196012, 0.08900755060778053], 23: [0.12272178976107533, 0.2434572240085994, 0.10918853723638693], 24: [0.11242073071173768, 0.22842665121555844, 0.09815371946297392], 25: [0.16426347480188327, 0.3112598209172952, 0.15541764405294287], 26: [0.1320053608948325, 0.2629754489542691, 0.11784762222160604], 27: [0.16141032242179343, 0.3165471358398812, 0.1436051404179788], 28: [0.18883172669030443, 0.3496893756919683, 0.183937903770641], 29: [0.19066817132778296, 0.3491123030882187, 0.18881583292535487], 30: [0.21045359642193073, 0.3768954118547848, 0.21677411115745693], 31: [0.21291996577617095, 0.39015020147055257, 0.21617020629063138], 32: [0.19915111580913408, 0.3624937010563809, 0.2026808559544842], 33: [0.23712090136001157, 0.417126015040587, 0.24958877535560042], 34: [0.21666411559856463, 0.39278306371082355, 0.22306872239794834], 35: [0.23590636588231423, 0.4170609213166336, 0.24867874392602032], 36: [0.2443183551588183, 0.44976900213015125, 0.24432359143806423], 37: [0.25108292447012615, 0.4537377832078614, 0.26123833597760004], 38: [0.2666010597312768, 0.4801734008214042, 0.27859290090075073], 39: [0.26041700331591217, 0.497308180009607, 0.2548309044740867], 40: [0.3087363960174005, 0.5522870000358497, 0.3152018583988447], 41: [0.3227138090836074, 0.5426739329221946, 0.3600023112703772], 42: [0.3312567964298148, 0.5696570023976122, 0.36019119814372286], 43: [0.3417812644189301, 0.5808935488965553, 0.37279795995380666], 44: [0.34277172673163225, 0.5940821828895145, 0.36875237692723056], 45: [0.34070140803672333, 0.5831046810408486, 0.3673077135389571], 46: [0.36425931699210895, 0.6159346186851495, 0.39716066132034317], 47: [0.36620769393694014, 0.6192890562007968, 0.4083913560902691], 48: [0.36966161213119403, 0.6144467258738063, 0.40708936910998933], 49: [0.35144817108450377, 0.5965173375840606, 0.3857255105824339], 50: [0.37097619360407486, 0.6352800773458154, 0.40366674425877], 51: [0.3776320688470117, 0.6320483060811306, 0.41638504122511505], 52: [0.38660333523291457, 0.6390405426415421, 0.43623139069274963]}),\n    \"/kaggle/input/isaid-class-9/isaid_class_9\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 216], {0: [0.013633970111955957, 0.039656674587681816, 0.006850561749852119], 1: [0.013464023537533665, 0.039827700984656274, 0.006860222012946598], 2: [0.012214850444288473, 0.041066633683667766, 0.006379189803361005], 3: [0.01362395796490482, 0.04153037396620989, 0.008062268855388383], 4: [0.014689017199065393, 0.045546335684972676, 0.008077008039040314], 5: [0.01435663493030496, 0.04668187025990801, 0.007181835462275151], 6: [0.015422176853964404, 0.04590153144068014, 0.008636151637315383], 7: [0.05236486098155644, 0.14008283691755224, 0.023676150803744463], 8: [0.03578313936888805, 0.09852169574272202, 0.013076818419675562], 9: [0.027722100803124455, 0.07235230514539301, 0.010443448516749708], 10: [0.04127000660228155, 0.10912668974652906, 0.018817033389783022], 11: [0.044218656291121664, 0.11745790194951417, 0.024829147766612963], 12: [0.13212579952922063, 0.3460402334350475, 0.05562844485700993], 13: [0.08518492497848149, 0.23523670140960268, 0.03297508286981968], 14: [0.15852245099840256, 0.4028894048415049, 0.06590326666893481], 15: [0.30571802713922297, 0.7249055532472279, 0.16173098088364452], 16: [0.24007090658438762, 0.6843360928985617, 0.05933110273800961], 17: [0.21258691001928817, 0.6379581777815152, 0.06869677979907109], 18: [0.2939035069256958, 0.7681170174029752, 0.1427177790559347], 19: [0.24466289395729932, 0.6198604006817143, 0.09749073376575665], 20: [0.19857246488522262, 0.5411013448311268, 0.07054459130134567], 21: [0.2984192162575968, 0.8150460387556996, 0.11617395751869668], 22: [0.25691772345976344, 0.6860236116639525, 0.11331847799159513], 23: [0.31252346863570124, 0.8093444694713493, 0.13708234159197377], 24: [0.29273820171428, 0.7617888886257651, 0.13481535285554477], 25: [0.3479079781679464, 0.8675955562730667, 0.18483354066648416], 26: [0.31507582697320846, 0.8200909979825497, 0.14139669647032851], 27: [0.3113995796157747, 0.8077279238698354, 0.14039391855655323], 28: [0.37030532130022903, 0.8775540231336987, 0.192687335485717], 29: [0.37372791738882033, 0.8668724775555519, 0.19757789880106935], 30: [0.3391836075931586, 0.816890796802956, 0.19446405829214408], 31: [0.37627227343804226, 0.8646017369995566, 0.2152893161004866], 32: [0.3501896629765983, 0.8097607701225664, 0.23659983062641518], 33: [0.3301167527903545, 0.8275125251672516, 0.17867325202248113], 34: [0.3095004748170361, 0.8184632363644333, 0.12671307540241797], 35: [0.42227861455349053, 0.9292134080038195, 0.24348791610822018], 36: [0.35793095406490194, 0.8763701446259522, 0.19008473631795467]}),\n    \"/kaggle/input/isaid-class-10/isaid_class_10\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1338], {0: [0.00934450467038234, 0.02446910266180801, 0.004976655150219355], 1: [0.009124356332582389, 0.023915929706903, 0.0048598309018567645], 2: [0.009075300131074372, 0.024140836622150687, 0.004906961858405978], 3: [0.008400654014499692, 0.02238039169105142, 0.004150683234101107], 4: [0.008540758509940086, 0.02333564822368616, 0.0041806097037101544], 5: [0.008550881640231892, 0.02335346041055998, 0.004186114127111024], 6: [0.008521289408813283, 0.022763677340918477, 0.004209049614910004], 7: [0.00848147862350027, 0.02150425020400866, 0.004838136910636096], 8: [0.008763116984728973, 0.02274929635142671, 0.005160740341134945], 9: [0.011055611647154752, 0.025998178403542724, 0.007179082475216432], 10: [0.008295777268755638, 0.023473847203293263, 0.004247669539479547], 11: [0.00966714262047652, 0.024990814822538104, 0.00514092803616939], 12: [0.024093884190766746, 0.0504538628370779, 0.019849307568835593], 13: [0.03255870286595493, 0.07390450184163576, 0.02301841897160307], 14: [0.037080408302319554, 0.08618139198330249, 0.027232967548379443], 15: [0.09846929479239594, 0.22973614464422676, 0.06561358384846355], 16: [0.12052227494822812, 0.2770701590612886, 0.087921447240311], 17: [0.10707043626014648, 0.23822421017098636, 0.07561228315528591], 18: [0.1886330525479111, 0.46059997060047586, 0.11407418656760712], 19: [0.19107548897803747, 0.4587775941479049, 0.12278888215980187], 20: [0.18917378879915508, 0.47342693467712244, 0.10883263046670426], 21: [0.19426560636939774, 0.4745116560232966, 0.11588847720399043], 22: [0.24823444711220674, 0.5782453893560378, 0.17267068559469292], 23: [0.24936513733771845, 0.578596864410198, 0.1752269735854557], 24: [0.23557267332641355, 0.5772646170983272, 0.1461246561096351], 25: [0.2575182882004748, 0.6164376934779009, 0.17783083446563966], 26: [0.26333506468815365, 0.6209130050512938, 0.18048704525163595], 27: [0.30413190301331783, 0.6677885474370965, 0.22507038514009106], 28: [0.3189183561182008, 0.6705546109678018, 0.25404787325508627], 29: [0.3064496637423855, 0.6741901853004119, 0.23824674371342702], 30: [0.3266768962095739, 0.7292351590202638, 0.23916490369187615], 31: [0.3434515381518047, 0.7294278819951022, 0.2783566240852643], 32: [0.3436818868772966, 0.7026140062585104, 0.2948309221573785], 33: [0.311861055840096, 0.7021189705310654, 0.20691867677221715], 34: [0.34444913265068094, 0.7270897699032187, 0.28175901278668875], 35: [0.3417690185180485, 0.7248151736499965, 0.264486772542311], 36: [0.35331855842124105, 0.7419795608969935, 0.275470219808954], 37: [0.36173308984644675, 0.7371748435782712, 0.2900117868316167], 38: [0.38215952269594794, 0.7536834095977626, 0.3583205159702032], 39: [0.3992666347583974, 0.7858069839079054, 0.3473050701215389], 40: [0.40978139765855764, 0.8023950466963671, 0.36578063993208076], 41: [0.4543332323995295, 0.8201076523762776, 0.461217312844512]}),\n}\ndata_dict_values_test = {\n    \"/kaggle/input/isaid-class-11/isaid_class_11\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 866], {0: [0.004349964361526861, 0.005807284972455908, 0.0046626609764075025], 1: [0.006017078590678247, 0.007529769263823189, 0.006044446518050368], 2: [0.011615514498186947, 0.012637189204731147, 0.011757577631716866], 3: [0.01718718601173152, 0.019829009488264958, 0.018861238259749488], 4: [0.004498978174104389, 0.005546732515643585, 0.004853165933266002], 5: [0.004505113736943153, 0.00549474032124042, 0.004765019777209273], 6: [0.004627239507283015, 0.005586188774776251, 0.0049184510779598355], 7: [0.005053242376725208, 0.006161093442273578, 0.005474842582654428], 8: [0.004611029719701611, 0.005584953601816201, 0.0048566919362650965], 9: [0.004998782447535306, 0.006035614680950597, 0.0053611699643478115], 10: [0.00466729116748372, 0.005593452495471938, 0.004907538675030999], 11: [0.0050655499716559345, 0.006049283280627477, 0.005344178305428398], 12: [0.0034388889779928995, 0.005844390542589995, 0.003088189736562251], 13: [0.006796063451357834, 0.010642800221091996, 0.007235263796621921], 14: [0.006474607954856817, 0.011067053883051908, 0.007177330395849968], 15: [0.23583471590837296, 0.447277052758129, 0.2590499831535757], 16: [0.2159596983320184, 0.40750773601130896, 0.20945698334146767], 17: [0.23289469264888968, 0.4583355382745509, 0.23923958559000377], 18: [0.2449114701486131, 0.4696730783646612, 0.23926787877650732], 19: [0.22768052562190938, 0.4755450059473026, 0.19918836126552789], 20: [0.23992936900864087, 0.4736118582971994, 0.24785955806757848], 21: [0.2450475946996878, 0.4646085503272505, 0.2391269854058881], 22: [0.28126924475859943, 0.5445205769985508, 0.28322013850912975], 23: [0.2774036439666284, 0.5199179358715575, 0.3034350717554546], 24: [0.270533512079946, 0.48326451088635314, 0.27999843726835477], 25: [0.2841090524184973, 0.5273787889447449, 0.2849307989965838], 26: [0.325356239885321, 0.5809438693841463, 0.31731012196239516], 27: [0.3382576841456465, 0.5877273562295302, 0.3770634179579666], 28: [0.3414330377513456, 0.5782400450006344, 0.3648256721356313], 29: [0.34829849345489367, 0.5978926145535068, 0.3714853110024853], 30: [0.36617802128112453, 0.6187582946613841, 0.36424645915314824], 31: [0.3731787505355974, 0.6448312207441887, 0.4030201430693497], 32: [0.38113188703433487, 0.6606058898019794, 0.38637038356154557], 33: [0.3861627842222084, 0.6545635652554715, 0.4165678880608107], 34: [0.375839981242968, 0.6420124446332449, 0.3954981269391636], 35: [0.3930565736364211, 0.6639660002230773, 0.4133888619855577], 36: [0.4000489329931421, 0.6686989443210503, 0.41684179440158686], 37: [0.40890076199818626, 0.6604498533239354, 0.4291705317906504], 38: [0.44355277286723493, 0.7040810538331298, 0.47347386891382837], 39: [0.46181660103943434, 0.7217850521402033, 0.4780127743166681], 40: [0.46576369502487325, 0.768139010899229, 0.4785303831154304]}),\n    \"/kaggle/input/isaid-class-12/isaid_class_12\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1175], {0: [0.015438559894023651, 0.037580578266678676, 0.01208337711155651], 1: [0.01656843008509089, 0.03891330413304871, 0.013752806697234096], 2: [0.015062393449130212, 0.03672779812877871, 0.011773251625356597], 3: [0.01613321175143611, 0.03865844485446225, 0.01217000067847714], 4: [0.015278461274556404, 0.039022313220697935, 0.012492879038985872], 5: [0.015168409252213508, 0.03673332138800091, 0.011813310866082312], 6: [0.014572777985951519, 0.03602230950002217, 0.011803058727385997], 7: [0.015049609114715142, 0.03613954113540342, 0.012170939252858925], 8: [0.01713406703231323, 0.04002987127256827, 0.01242608757868868], 9: [0.014765357591323164, 0.03595122186550492, 0.011893265114778189], 10: [0.01607659708888324, 0.03718601532039761, 0.012217491163702814], 11: [0.016194622720298764, 0.037371657181195096, 0.011172492248778794], 12: [0.02895229383081574, 0.06095757253231497, 0.027033307229268708], 13: [0.027901299701266542, 0.06117122453562119, 0.025796274247993033], 14: [0.026020732180712186, 0.053371832345012485, 0.0238165995675673], 15: [0.049855234752533006, 0.09485310121413135, 0.047556776147063565], 16: [0.051130712570499295, 0.09789420396783564, 0.045649753061151814], 17: [0.04948851611856728, 0.09234490169222957, 0.041065275581867705], 18: [0.08062509967861138, 0.1406499637150524, 0.08568018464853502], 19: [0.08184242418005255, 0.1391089885395564, 0.09000212575342545], 20: [0.09009239984548775, 0.15243538848065935, 0.09188873212514448], 21: [0.1192966458843681, 0.19589761659818575, 0.11898492764050364], 22: [0.1276360610305275, 0.21591709789444932, 0.13705118525048265], 23: [0.13846055000784813, 0.22249050088308897, 0.15390691448545912], 24: [0.1077138677830437, 0.18193601134466292, 0.1104403224992705], 25: [0.12855962740667956, 0.21963825299233447, 0.12894467600882223], 26: [0.12148957372457318, 0.1957995409962458, 0.13010694110061122], 27: [0.1343244838849022, 0.21353616459726257, 0.14488021639750503], 28: [0.1758344935648653, 0.2701144606663579, 0.20358649453063654], 29: [0.19570984307360997, 0.30041771305061593, 0.2209510066492192], 30: [0.20816120427592383, 0.30035753719925495, 0.24035037803343798], 31: [0.24864001790020646, 0.35998063595958196, 0.29881075392350037], 32: [0.2330755423889343, 0.33877052396373253, 0.25963417733977756], 33: [0.26830080093522707, 0.38474131845175247, 0.3094583745228525], 34: [0.22392715355126183, 0.30891641118208324, 0.26825678658754004], 35: [0.2917736433719553, 0.40640625776423595, 0.32512582108367843], 36: [0.31711367349544517, 0.4519605693067161, 0.35192514771959904], 37: [0.3421521021374441, 0.46940916392326104, 0.3944716355739491], 38: [0.3682237305946626, 0.5096173171051309, 0.41428947851293235], 39: [0.4053007987721415, 0.5281502281101096, 0.43520686727048824], 40: [0.4504902912336015, 0.6672676927661881, 0.4818630776273039], 41: [0.5479373662400725, 0.7570013128595495, 0.5846545039434571]}),\n    \"/kaggle/input/isaid-class-13/isaid_class_13\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3503], {0: [0.07322013958505334, 0.22865390701417687, 0.01640075478516509], 1: [0.0730848110121684, 0.2292092664784361, 0.015440061120457857], 2: [0.07450395803667517, 0.23552022690054616, 0.016815761101837794], 3: [0.07355216662237686, 0.23151050417380087, 0.01584864645618559], 4: [0.07374497716795705, 0.23320544401947751, 0.015966067410169482], 5: [0.07434231349656338, 0.23314364944263466, 0.01651091893171401], 6: [0.07361892127022733, 0.23204179970299071, 0.01608887714572336], 7: [0.08665890086109583, 0.2631804098242783, 0.023325424676922925], 8: [0.07372337791488467, 0.23123550247252878, 0.01607715795823046], 9: [0.09606846420435826, 0.294059146054418, 0.02567320581227592], 10: [0.09460837405449843, 0.2884017653545251, 0.025783417661556514], 11: [0.09411122190410728, 0.2869947700504646, 0.024687538314986088], 12: [0.16371821773605338, 0.45242987030920423, 0.057775800754720524], 13: [0.16430062781066196, 0.45273799983992763, 0.056544322017573534], 14: [0.16355016184777466, 0.45220565504668425, 0.05670823236771143], 15: [0.19457342100627534, 0.5084252755421871, 0.09265528776705345], 16: [0.2069191572805881, 0.5380952050659901, 0.08695570763272434], 17: [0.1933413080515694, 0.5067457865434815, 0.08728365300683923], 18: [0.24471106582323662, 0.5955477417180357, 0.13683543556275984], 19: [0.25081518245427936, 0.6096000063305125, 0.14431054845605878], 20: [0.25771879986191537, 0.612046636532701, 0.15687520254485515], 21: [0.26643373262900694, 0.6151407174274981, 0.16846156948048688], 22: [0.30057097701473257, 0.6646656197721592, 0.20897062807058575], 23: [0.2957778496752609, 0.6559067617493105, 0.20681233821505812], 24: [0.29393283489963645, 0.6579423435390866, 0.20514822359578178], 25: [0.35889592629429606, 0.7427107146858956, 0.28203966406382447], 26: [0.36590412989368426, 0.7416176645674248, 0.30926266133296176], 27: [0.41085244277475674, 0.7812725186122446, 0.38889589798372853], 28: [0.43541573358488844, 0.8035496961448916, 0.4213316509630635], 29: [0.4458967110281978, 0.811062773521257, 0.4540667663471859], 30: [0.43273432895478364, 0.8066842812346621, 0.43348618022978497], 31: [0.4524136207133151, 0.8295427209609473, 0.46131158660193033], 32: [0.4655212023042523, 0.8449651169711098, 0.4750302177154959], 33: [0.45565614368429763, 0.842035582632516, 0.4543104191999763], 34: [0.4752692552040075, 0.8483813712737968, 0.49846576904973683], 35: [0.4809402026058634, 0.8411466507140862, 0.5079761792242672], 36: [0.485185390929071, 0.8470298251236592, 0.5131529616031392], 37: [0.5183426352920284, 0.8644922809896313, 0.579401586271187], 38: [0.5325235589667386, 0.8855129072044797, 0.5970789879919368], 39: [0.5250121747853925, 0.8864461215856559, 0.5704882603080716], 40: [0.5427644017803523, 0.9006926629314908, 0.6119636106809572], 41: [0.5610640151499305, 0.8968243147934689, 0.643515146379985], 42: [0.5818644311704338, 0.918105057679788, 0.6694152512619598], 43: [0.5939103860873973, 0.9272086559292998, 0.693717749784261], 44: [0.5644692829288129, 0.9260916486221362, 0.6315146202287911], 45: [0.575494848533425, 0.9293341962977247, 0.664720121294568], 46: [0.5744557034575173, 0.9219022591480142, 0.6665113364664386]}),\n    \"/kaggle/input/isaid-class-14/isaid_class_14\": ([2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3124], {0: [0.006437533402572582, 0.018656832282125186, 0.003698162071376821], 1: [0.00999063726335362, 0.022674839603869398, 0.008155742692456542], 2: [0.006620863299810147, 0.01863185643559812, 0.0036378451632481943], 3: [0.010145687761700627, 0.02313199809528459, 0.008255925802247814], 4: [0.007001003947486884, 0.020056955107257114, 0.004079544673504856], 5: [0.01042482165283986, 0.024435681034627104, 0.008407697287532824], 6: [0.007325315767227995, 0.02052772350783245, 0.004555080280530926], 7: [0.010636448100410773, 0.025319279902242586, 0.008449859902855726], 8: [0.010248181604209424, 0.027181144833069982, 0.006562181443011773], 9: [0.012288034970793277, 0.029326798529898505, 0.009181509797776037], 10: [0.01263758928529895, 0.03127821051382744, 0.009178338696005706], 11: [0.00962240604405411, 0.027014334609643947, 0.00547117965044438], 12: [0.023470296652297835, 0.06211469531041783, 0.013482166615060933], 13: [0.025800324714368585, 0.06988032573988054, 0.015648569505929875], 14: [0.02490034662775132, 0.06870455930532691, 0.015061722402007875], 15: [0.04185013507969636, 0.11960811948740917, 0.019730421324221308], 16: [0.04331800288090484, 0.12019538995053376, 0.02238310750842993], 17: [0.04147300201455445, 0.12134800081330324, 0.019642486423109937], 18: [0.07730256715782884, 0.21294283503709788, 0.035520142043394404], 19: [0.07467836856673239, 0.2033982050481949, 0.035491249243160196], 20: [0.07757948824351175, 0.21276408998498458, 0.036527065529660556], 21: [0.08907044081805923, 0.23774348663355999, 0.04723140855584816], 22: [0.10706816836470219, 0.27589272170883705, 0.059336601961199296], 23: [0.10484832706430358, 0.27899024956556284, 0.05648911800911286], 24: [0.1092562730713724, 0.2832083342979491, 0.059234103317429204], 25: [0.13226296592542172, 0.3394551378290968, 0.07063923184953326], 26: [0.12976442898205573, 0.33874806306301647, 0.06998626514060012], 27: [0.1308510848767123, 0.33518340114927225, 0.06990594800801833], 28: [0.16424273171693227, 0.40288013968880404, 0.09777438940762734], 29: [0.1658647571865796, 0.40811313394780707, 0.0997160725123662], 30: [0.18559056048369965, 0.45996697460106434, 0.10613945752231832], 31: [0.19856707541492585, 0.5055283853769306, 0.11678304763535427], 32: [0.22264477424854817, 0.5455657546799106, 0.13796205204001583], 33: [0.21290689615094055, 0.5270778964382091, 0.13043784111459927], 34: [0.22188552239014708, 0.5451922770322181, 0.13825005744581817], 35: [0.24944384199432473, 0.6066781514753934, 0.16406543221019398], 36: [0.27067460744746963, 0.6344983201901214, 0.19213395444681558], 37: [0.3038857941424169, 0.6832966110580287, 0.22585466158851328], 38: [0.3221533150570283, 0.7174337401621507, 0.2434749726798736], 39: [0.3318973686689386, 0.7239454014796551, 0.26342579902206764], 40: [0.38367846082410695, 0.7750852122862854, 0.33866746971818384], 41: [0.387625755998384, 0.7922600314962801, 0.3376251507721591], 42: [0.40920490481666477, 0.8283281810059032, 0.361734535494731], 43: [0.4314007287075675, 0.8325527993798567, 0.42157267246113844], 44: [0.4114615054994372, 0.8206046272777215, 0.35715003251301153], 45: [0.43841451929622377, 0.8377878339799532, 0.4321585269394078]})\n}","metadata":{"papermill":{"duration":0.223963,"end_time":"2024-05-20T07:26:56.462712","exception":false,"start_time":"2024-05-20T07:26:56.238749","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T20:39:26.020955Z","iopub.execute_input":"2024-05-22T20:39:26.021495Z","iopub.status.idle":"2024-05-22T20:39:26.251000Z","shell.execute_reply.started":"2024-05-22T20:39:26.021461Z","shell.execute_reply":"2024-05-22T20:39:26.249892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport itertools\nimport random\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm\nimport numpy as np\nimport cv2\ntorch.manual_seed(1337)\n\ndevice = torch.device(\"cuda\")\n\nclass CustomDataset(Dataset):\n    def __init__(self, data_dict, data_dict_values, transform=None, max_combinations=None, split_ratios=(0.7, 0.15, 0.15), split='train'):\n        \"\"\"\n        :param data_dict: Dictionary of data paths.\n        :param data_dict_values: Additional meta information for the data.\n        :param transform: Image transformations.\n        :param max_combinations: Max number of combinations to generate.\n        :param split_ratios: Tuple of train, validation, and test split ratios.\n        :param split: 'train', 'val', or 'test' to specify the dataset split.\n        \"\"\"\n        self.data_dict = data_dict\n        self.data_dict_values = data_dict_values\n        self.transform = transform\n        self.max_combinations = max_combinations\n        self.split_ratios = split_ratios\n        self.split = split\n        random.seed(10)\n        self.samples = self.generate_samples()\n\n    def generate_samples(self):\n        samples = []\n        for dataset_path in self.data_dict.keys():\n            class_index = int(dataset_path.split('/')[3].split(\"-\")[-1])\n            class_values = self.data_dict[dataset_path]\n            if class_values == []:\n                continue\n            class_folder = os.path.join(dataset_path, 'train', \"images\")\n            label_folder = os.path.join(dataset_path, 'train', \"labels\")\n            learning_curve_data = self.data_dict_values[dataset_path]\n            if os.path.isdir(class_folder):\n                all_images = [os.path.join(class_folder, file) for file in os.listdir(class_folder) if file.endswith((\".jpg\", \".png\"))]\n                all_labels = [os.path.join(label_folder, file) for file in os.listdir(class_folder) if file.endswith((\".txt\"))]\n                # Select the appropriate split\n                split_images = all_images\n\n                num_images = len(split_images)\n                if num_images >= 4:\n                    combinations_to_generate = self.calculate_combinations(num_images, 4)\n                    combinations_to_generate = min(combinations_to_generate, self.max_combinations) if self.max_combinations else combinations_to_generate\n\n                    generated_combinations = set()\n                    while len(generated_combinations) < combinations_to_generate:\n                        indices = tuple(sorted(random.sample(range(num_images), 4)))\n                        if indices not in generated_combinations:\n                            generated_combinations.add(indices)\n                            combination_images = [split_images[i] for i in indices]\n                            combination_labels = [label_folder+\"/\"+image_path.split(\"/\")[-1].split(\".\")[0]+\".txt\" for image_path in combination_images]\n                            samples.append((combination_images, combination_labels, class_index, class_values, learning_curve_data))\n        return samples\n\n    @staticmethod\n    def split_data(images, ratios):\n        random.seed(10)\n        random.shuffle(images)\n        train_end = int(len(images) * ratios[0])\n        val_end = train_end + int(len(images) * ratios[1])\n        return images[:train_end], images[train_end:val_end], images[val_end:]\n\n    @staticmethod\n    def calculate_combinations(n, r):\n        from math import factorial\n        return factorial(n) // (factorial(r) * factorial(n - r))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        image_paths, label_paths, class_index, target_values, learning_curve_data = self.samples[idx]\n        images = []\n        labels = []\n        for image_path in image_paths:\n            image = Image.open(image_path)\n            if self.transform:\n                image = self.transform(image)\n            images.append(image)\n        image_width = 800\n        image_height = 800\n        for label_path in label_paths:\n            with open(label_path, 'r') as file:\n                lines = file.readlines()\n                coordinates = []\n                for line in lines:\n                    if line.strip().startswith(str(class_index)):\n                        coords = list(map(float, line.strip().split()[1::]))\n                        pixel_coords = []\n                        for i in range(0, len(coords), 2):\n                            x = int(coords[i] * image_width)\n                            y = int(coords[i + 1] * image_height)\n                            pixel_coords.append((x, y))\n                        coordinates.append(pixel_coords)\n            mask_coordinates = coordinates\n            mask = np.zeros((image_width,image_height), dtype=np.uint8)  # Create a blank mask with the same height and width as the image\n            for coords in mask_coordinates:\n                # Convert the list of tuples to a numpy array\n                points = np.array(coords, dtype=np.int32)\n                cv2.fillPoly(mask, [points], 255)  # Fill the polygon defined by points with white color (255)\n            label_image = Image.fromarray(mask)\n            if self.transform:\n                label_image = self.transform(label_image)\n            labels.append(label_image)\n        train_sizes, map_values_dict = learning_curve_data\n        map_values = [map_values_dict[class_id][0] for class_id in sorted(map_values_dict)]\n        labels = torch.stack(labels).repeat(1, 3, 1, 1)\n        return torch.stack(images), labels, torch.tensor(target_values), torch.tensor(train_sizes), torch.tensor(map_values)\n\n\n\n\n\n# Define your transformation pipeline\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images if needed\n    transforms.ToTensor(),  # Convert PIL images to tensors\n    transforms.Normalize([0.5], [0.5]),\n])\n\n\nfor key, values in data_dict_train.items():\n    data_dict_train[key] = list(np.array(values)+10)\n\nfor key, values in data_dict_test.items():\n    data_dict_test[key] = list(np.array(values)+10)\n# Create a custom dataset\ntrain_dataset = CustomDataset(data_dict=data_dict_train,data_dict_values = data_dict_values_train, transform=transform, max_combinations = 2000, split=\"train\")\ntest_dataset = CustomDataset(data_dict=data_dict_test,data_dict_values = data_dict_values_test, transform=transform, max_combinations = 500, split=\"test\")\n# You can access the dataset like any other PyTorch dataset\n# For example, you can iterate over it with a DataLoader\nbatch_size = 1  # Adjust batch size as needed\ndata_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Now you can iterate over data_loader to get batches of images and their corresponding target values\n# data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nprint(len(train_dataset),len(test_dataset))\n# Now you can iterate over data_loader to get batches of images and their corresponding target values\n# for images, targets, train_sizes, map_values in tqdm(data_loader):\n# #     print(images.shape)\n#     print(get_image_embedding(images[0]).shape)\n#     break\n    # Do whatever you need with the batch of images and targets\n#     print(images.shape)  # Example: (batch_size, channels, height, width)\n#     print(targets)  # Example: tensor([[1, 2, 3, 4], [5, 6, 7, 8], ...])","metadata":{"papermill":{"duration":3.668307,"end_time":"2024-05-20T07:27:00.141288","exception":false,"start_time":"2024-05-20T07:26:56.472981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T20:39:28.324222Z","iopub.execute_input":"2024-05-22T20:39:28.324608Z","iopub.status.idle":"2024-05-22T20:39:36.481211Z","shell.execute_reply.started":"2024-05-22T20:39:28.324578Z","shell.execute_reply":"2024-05-22T20:39:36.479991Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"20000 2000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"train_paths_set = set()\nfor image_path in tqdm(train_dataset):\n    train_paths_set.update(image_path[-1])","metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:32:55.331807Z","iopub.status.busy":"2024-04-12T22:32:55.330913Z","iopub.status.idle":"2024-04-12T22:39:09.295382Z","shell.execute_reply":"2024-04-12T22:39:09.290477Z","shell.execute_reply.started":"2024-04-12T22:32:55.331770Z"},"papermill":{"duration":0.0094,"end_time":"2024-05-20T07:27:00.160171","exception":false,"start_time":"2024-05-20T07:27:00.150771","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"len(train_paths_set)","metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:39:09.298181Z","iopub.status.busy":"2024-04-12T22:39:09.297772Z","iopub.status.idle":"2024-04-12T22:39:09.305166Z","shell.execute_reply":"2024-04-12T22:39:09.303985Z","shell.execute_reply.started":"2024-04-12T22:39:09.298138Z"},"papermill":{"duration":0.009071,"end_time":"2024-05-20T07:27:00.178806","exception":false,"start_time":"2024-05-20T07:27:00.169735","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"test_paths_set = set()\nfor image_path in tqdm(test_dataset):\n    test_paths_set.update(image_path[-1])","metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:39:09.306649Z","iopub.status.busy":"2024-04-12T22:39:09.306324Z","iopub.status.idle":"2024-04-12T22:39:48.711671Z","shell.execute_reply":"2024-04-12T22:39:48.710761Z","shell.execute_reply.started":"2024-04-12T22:39:09.306605Z"},"papermill":{"duration":0.009398,"end_time":"2024-05-20T07:27:00.197509","exception":false,"start_time":"2024-05-20T07:27:00.188111","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"len(test_paths_set)","metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:39:48.714852Z","iopub.status.busy":"2024-04-12T22:39:48.714219Z","iopub.status.idle":"2024-04-12T22:39:48.721948Z","shell.execute_reply":"2024-04-12T22:39:48.720857Z","shell.execute_reply.started":"2024-04-12T22:39:48.714811Z"},"papermill":{"duration":0.009517,"end_time":"2024-05-20T07:27:00.216849","exception":false,"start_time":"2024-05-20T07:27:00.207332","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"len(train_paths_set.intersection(test_paths_set))","metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:39:48.724002Z","iopub.status.busy":"2024-04-12T22:39:48.723483Z","iopub.status.idle":"2024-04-12T22:39:48.733117Z","shell.execute_reply":"2024-04-12T22:39:48.732101Z","shell.execute_reply.started":"2024-04-12T22:39:48.723964Z"},"papermill":{"duration":0.009323,"end_time":"2024-05-20T07:27:00.236020","exception":false,"start_time":"2024-05-20T07:27:00.226697","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(4096*4, 2048)\n        self.fc_agg = nn.Linear(2048, 1024)  # Adjust depending on aggregation method\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, 4)\n\n    def forward(self, x):\n        x = x.view(-1, 4096*4)  # Adjust view based on aggregation method\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc_agg(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n\nmodel = MyModel().to(device)\n# Initialize your model\n# if os.path.exists(\"/kaggle/input/inception-v3-5-layers/model_inception_fc.pt\"):\n#     model.load_state_dict(torch.load(\"/kaggle/input/inception-v3-5-layers/model_inception_fc.pt\"))\n#     model = model.to(device)\n#     print(\"Loaded pretrained model\")\n# else:\n#     print(\"Loaded initial model\")\n\n\n\n# # Split the dataset into train, validation, and test sets\n# train_size = int(0.75 * len(custom_dataset))\n# val_size = int(0.15 * len(custom_dataset))\n# test_size = len(custom_dataset) - train_size - val_size\n# train_dataset, val_dataset, test_dataset = random_split(custom_dataset, [train_size, val_size, test_size])\n\n# Create data loaders for train, validation, and test sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size)\n# for images, targets in tqdm(train_loader):\n#     images = torch.stack([encode_vae(img.to(device)) for img in images])\n# torch.save(train_loader, 'train_loader.pth')\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n# for images, targets in tqdm(test_loader):\n#     images = torch.stack([encode_vae(img.to(device)) for img in images])\n# torch.save(test_loader, 'test_loader.pth')\n# Define your loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nimport numpy as np\nfrom tqdm import tqdm\n\n# Assuming log4pl is defined somewhere in your script\ndef log4pl(x, A, B, C, D):\n    return (((A-D) / (1.0 + ((x/C)**B))) + D)\n\ndef smape(A, F):\n    return 100 / len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n\ndef evaluate(loader, device):\n    model.eval()\n    total_smape_params = np.zeros(4)  # Initialize SMAPE totals for each parameter\n    total_smape_sinusoid = 0\n    num_samples = 0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for inputs, labels, targets, train_sizes, empirical_maps in tqdm(loader):\n            inputs, labels, targets = inputs.to(device),labels.to(device), targets.to(device)\n            empirical_maps = empirical_maps.to(device)  # Empirical mAP values\n            \n            outputs = model(torch.cat((get_image_embedding(inputs[0]),get_image_embedding(labels[0])),dim=1))  # Predicted parameters\n            all_predictions.append(outputs.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n#             # Calculate SMAPE for each parameter separately\n#             outputs = outputs.cpu().numpy() - 10\n#             # Calculate SMAPE for the sinusoid\n#             A, B, C, D = outputs.T  # Transpose to unpack parameters\n# #             print(\"True params:\",targets)\n#             sinusoidal_preds = log4pl(train_sizes.cpu().numpy(), A, B, C, D)\n# #             print(\"sinusoidal_preds\",sinusoidal_preds)\n# #             print(empirical_maps.cpu().numpy(), sinusoidal_preds)\n#             smape_sinusoid = smape(empirical_maps.cpu().numpy()[0], sinusoidal_preds[0])\n# #             print(smape_sinusoid)\n#             total_smape_sinusoid += smape_sinusoid\n            \n#             num_samples += 1  # Counting the batches\n    all_predictions = np.concatenate(all_predictions)\n    all_targets = np.concatenate(all_targets)\n    # Calculate SMAPE for each parameter\n    smapes = []\n    for i in range(all_targets.shape[1]):  # Assuming the second dimension is the parameter dimension\n        smape_value = smape(all_targets[:, i], all_predictions[:, i])\n        smapes.append(smape_value)\n#     avg_smape_sinusoid = total_smape_sinusoid / num_samples\n    return smapes\n\n\n# Replace the printing of MSE with SMAPE in your training loop\nnum_epochs = 10  # Adjust number of epochs as needed\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels, targets, _, _ in tqdm(train_loader):  # Ignoring empirical mAP and sizes here\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        targets = targets.to(device)  # Parameters targets\n        optimizer.zero_grad()\n        outputs = model(torch.cat((get_image_embedding(inputs[0]),get_image_embedding(labels[0])),dim=1))\n        loss = criterion(outputs, targets.float())\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    # Evaluation\n    avg_smape_params = evaluate(test_loader, device)\n    torch.save(model.state_dict(), \"model_incept_v3_fc.pt\")\n    print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}\")\n    for i, smape_value in enumerate(avg_smape_params):\n        print(f\"Validation SMAPE for parameter {i+1}: {smape_value}%\")\n#     print(f\"Validation SMAPE for Sinusoid: {avg_smape_sinusoid}%\")\n\n\nprint(\"Training finished!\")\navg_smape_params = evaluate(test_loader, device)\n# print(f\"Test SMAPE for Parameters: {avg_smape_params}%\")\n# print(f\"Test SMAPE for Sinusoid: {avg_smape_sinusoid}%\")\nfor i, smape_value in enumerate(avg_smape_params, start=1):\n    print(f\"Test SMAPE for parameter {i}: {smape_value}%\")\n","metadata":{"papermill":{"duration":40287.497621,"end_time":"2024-05-20T18:38:27.743475","exception":false,"start_time":"2024-05-20T07:27:00.245854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T20:42:10.609097Z","iopub.execute_input":"2024-05-22T20:42:10.609494Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/20000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n  1%|‚ñè         | 279/20000 [01:18<1:19:55,  4.11it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(2048*4, 2048)\n        self.fc_agg = nn.Linear(2048, 1024)  # Adjust depending on aggregation method\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, 4)\n\n    def forward(self, x):\n        x = x.view(-1, 2048*4)  # Adjust view based on aggregation method\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc_agg(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n\nmodel = MyModel().to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/model_incept_v3_fc/pytorch/1/1/model_incept_v3_fc.pt\"))\n# Initialize your model\n# if os.path.exists(\"/kaggle/input/inception-v3-5-layers/model_inception_fc.pt\"):\n#     model.load_state_dict(torch.load(\"/kaggle/input/inception-v3-5-layers/model_inception_fc.pt\"))\n#     model = model.to(device)\n#     print(\"Loaded pretrained model\")\n# else:\n#     print(\"Loaded initial model\")\n\n\n\n# # Split the dataset into train, validation, and test sets\n# train_size = int(0.75 * len(custom_dataset))\n# val_size = int(0.15 * len(custom_dataset))\n# test_size = len(custom_dataset) - train_size - val_size\n# train_dataset, val_dataset, test_dataset = random_split(custom_dataset, [train_size, val_size, test_size])\n\n# Create data loaders for train, validation, and test sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size)\n# for images, targets in tqdm(train_loader):\n#     images = torch.stack([encode_vae(img.to(device)) for img in images])\n# torch.save(train_loader, 'train_loader.pth')\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n# for images, targets in tqdm(val_loader):\n#     images = torch.stack([encode_vae(img.to(device)) for img in images])\n# torch.save(val_loader, 'val_loader.pth')\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n# for images, targets in tqdm(test_loader):\n#     images = torch.stack([encode_vae(img.to(device)) for img in images])\n# torch.save(test_loader, 'test_loader.pth')\n# Define your loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nimport numpy as np\nfrom tqdm import tqdm\n\n# Assuming log4pl is defined somewhere in your script\ndef log4pl(x, A, B, C, D):\n    return (((A-D) / (1.0 + ((x/C)**B))) + D)\n\ndef smape(A, F):\n    return 100 / len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\ndef mae(y_true, predictions):\n    y_true, predictions = np.array(y_true), np.array(predictions)\n    return np.mean(np.abs(y_true - predictions))\ndef evaluate(loader, device):\n    model.eval()\n    total_smape_params = np.zeros(4)  # Initialize SMAPE totals for each parameter\n    total_smape_sinusoid = 0\n    num_samples = 0\n    all_predictions = []\n    all_targets = []\n    all_true_smape = []\n    all_pred_smape = []\n    b_c_max_min = {\n        \"/kaggle/input/inception-v3-5-layers/feet-14\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]],[[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/fire_smoke-9\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]], [[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/puddle-segmentation-8\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/Coffee-Fruit-Maturity-‚òïüçí-5\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]], [[float('-inf'),float('inf')],[float('-inf'),float('inf')]],\n                                                       [[float('-inf'),float('inf')],[float('-inf'),float('inf')]], [[float('-inf'),float('inf')],[float('-inf'),float('inf')]],\n                                                       [[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/Severstal-steel-defects-1\": [[],[[float('-inf'),float('inf')],[float('-inf'),float('inf')]], [[float('-inf'),float('inf')],[float('-inf'),float('inf')]],\n                                                     [[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/screw-detection-17\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/bolt_111-1\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/affected-leaves-initialD-16\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]],[],[],[[float('-inf'),float('inf')],[float('-inf'),float('inf')]],[],[],\n                                                       [[float('-inf'),float('inf')],[float('-inf'),float('inf')]]],\n        \"/kaggle/input/inception-v3-5-layers/solarpanels_full-1\": [[],[],[[float('-inf'),float('inf')],[float('-inf'),float('inf')]],[]],\n        \"/kaggle/input/inception-v3-5-layers/Pothole-Detection-9\": [[[float('-inf'),float('inf')],[float('-inf'),float('inf')]]]\n    }\n    with torch.no_grad():\n        for inputs, targets, train_sizes, empirical_maps, true_smape, dataset_path, class_index in tqdm(loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            empirical_maps = empirical_maps.to(device)  # Empirical mAP values\n            \n            outputs = model(get_image_embedding(inputs[0]))  # Predicted parameters\n            all_predictions.append(outputs.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n            # Calculate SMAPE for each parameter separately\n            outputs = outputs.cpu().numpy() - 10\n            # Calculate SMAPE for the sinusoid\n            A, B, C, D = outputs.T  # Transpose to unpack parameters\n#             print(\"True params:\",targets)\n            sinusoidal_preds = log4pl(train_sizes.cpu().numpy(), A, B, C, D)\n#             print(\"sinusoidal_preds\",sinusoidal_preds)\n#             print(empirical_maps.cpu().numpy(), sinusoidal_preds)\n            smape_sinusoid = smape(empirical_maps.cpu().numpy()[0], sinusoidal_preds[0])\n#             print(smape_sinusoid)\n            all_true_smape.append(true_smape)\n            all_pred_smape.append(smape_sinusoid)\n#             print(class_index[0])\n#             print(b_c_max_min[dataset_path[0]][class_index][0][0])\n            if B > b_c_max_min[dataset_path[0]][class_index][0][0]:\n                b_c_max_min[dataset_path[0]][class_index][0][0] = B\n            if B < b_c_max_min[dataset_path[0]][class_index][0][1]:\n                b_c_max_min[dataset_path[0]][class_index][0][1] = B\n            if C > b_c_max_min[dataset_path[0]][class_index][1][0]:\n                b_c_max_min[dataset_path[0]][class_index][1][0] = C\n            if C < b_c_max_min[dataset_path[0]][class_index][1][1]:\n                b_c_max_min[dataset_path[0]][class_index][1][1] = C\n            num_samples += 1  # Counting the batches\n    all_predictions = np.concatenate(all_predictions)\n    all_targets = np.concatenate(all_targets)\n    print(\"MAE true_smape vs pred_smape: \",mae(all_true_smape,all_pred_smape))\n    # Calculate SMAPE for each parameter\n    smapes = []\n    for i in range(all_targets.shape[1]):  # Assuming the second dimension is the parameter dimension\n        smape_value = smape(all_targets[:, i], all_predictions[:, i])\n        smapes.append(smape_value)\n#     avg_smape_sinusoid = total_smape_sinusoid / num_samples\n    print(b_c_max_min)\n    return smapes\n\n\n# # Replace the printing of MSE with SMAPE in your training loop\n# num_epochs = 15  # Adjust number of epochs as needed\n# for epoch in range(num_epochs):\n#     model.train()\n#     running_loss = 0.0\n#     for inputs, targets, _, _ in tqdm(train_loader):  # Ignoring empirical mAP and sizes here\n#         inputs = inputs.to(device)\n#         targets = targets.to(device)  # Parameters targets\n#         optimizer.zero_grad()\n#         outputs = model(get_image_embedding(inputs[0]))\n#         loss = criterion(outputs, targets.float())\n#         loss.backward()\n#         optimizer.step()\n#         running_loss += loss.item()\n    \n#     # Evaluation\n#     avg_smape_params = evaluate(val_loader, device)\n#     torch.save(model.state_dict(), \"model_incept_v3_fc.pt\")\n#     print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}\")\n#     for i, smape_value in enumerate(avg_smape_params):\n#         print(f\"Validation SMAPE for parameter {i+1}: {smape_value}%\")\n# #     print(f\"Validation SMAPE for Sinusoid: {avg_smape_sinusoid}%\")\n\n\nprint(\"Training finished!\")\navg_smape_params = evaluate(test_loader, device)\n# print(f\"Test SMAPE for Parameters: {avg_smape_params}%\")\n# print(f\"Test SMAPE for Sinusoid: {avg_smape_sinusoid}%\")\nfor i, smape_value in enumerate(avg_smape_params, start=1):\n    print(f\"Test SMAPE for parameter {i}: {smape_value}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T22:36:48.773395Z","iopub.status.idle":"2024-05-18T22:36:48.773781Z","shell.execute_reply":"2024-05-18T22:36:48.773618Z","shell.execute_reply.started":"2024-05-18T22:36:48.773601Z"},"papermill":{"duration":21.110241,"end_time":"2024-05-20T18:39:10.127727","exception":false,"start_time":"2024-05-20T18:38:49.017486","status":"completed"},"tags":[]}}]}