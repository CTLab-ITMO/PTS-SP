{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbe081b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T14:14:09.040072Z",
     "iopub.status.busy": "2024-01-14T14:14:09.039691Z",
     "iopub.status.idle": "2024-01-14T14:15:28.240796Z",
     "shell.execute_reply": "2024-01-14T14:15:28.239787Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 79.210504,
     "end_time": "2024-01-14T14:15:28.243005",
     "exception": false,
     "start_time": "2024-01-14T14:14:09.032501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-14 14:15:11--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 192.30.255.113\r\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T141511Z&X-Amz-Expires=300&X-Amz-Signature=9b244e5a30bd32528dafd91cd3053915516e20925b4fad35a6365bd10bb57b1f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-14 14:15:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T141511Z&X-Amz-Expires=300&X-Amz-Signature=9b244e5a30bd32528dafd91cd3053915516e20925b4fad35a6365bd10bb57b1f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   285MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-01-14 14:15:12 (285 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Berrybox_Quality_InstanceSeg-6 to yolov8:: 100%|██████████| 299105/299105 [00:09<00:00, 33057.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Berrybox_Quality_InstanceSeg-6 in yolov8:: 100%|██████████| 986/986 [00:00<00:00, 1606.35it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"usdacranberrybreeding\").project(\"berrybox_quality_instanceseg\")\n",
    "dataset = project.version(6).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8d6065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T14:15:28.270687Z",
     "iopub.status.busy": "2024-01-14T14:15:28.270260Z",
     "iopub.status.idle": "2024-01-14T14:15:50.820899Z",
     "shell.execute_reply": "2024-01-14T14:15:50.819714Z"
    },
    "papermill": {
     "duration": 22.567062,
     "end_time": "2024-01-14T14:15:50.823418",
     "exception": false,
     "start_time": "2024-01-14T14:15:28.256356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86869a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T14:15:50.852202Z",
     "iopub.status.busy": "2024-01-14T14:15:50.851888Z",
     "iopub.status.idle": "2024-01-14T14:15:50.877538Z",
     "shell.execute_reply": "2024-01-14T14:15:50.876606Z"
    },
    "papermill": {
     "duration": 0.042262,
     "end_time": "2024-01-14T14:15:50.879535",
     "exception": false,
     "start_time": "2024-01-14T14:15:50.837273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Berrybox_Quality_InstanceSeg-6\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Berrybox_Quality_InstanceSeg-6\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474e4a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T14:15:50.908768Z",
     "iopub.status.busy": "2024-01-14T14:15:50.908437Z",
     "iopub.status.idle": "2024-01-14T14:15:51.014294Z",
     "shell.execute_reply": "2024-01-14T14:15:51.013524Z"
    },
    "papermill": {
     "duration": 0.123258,
     "end_time": "2024-01-14T14:15:51.016516",
     "exception": false,
     "start_time": "2024-01-14T14:15:50.893258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # Корректируем data.yaml файл\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83eed17",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-14T14:15:51.045265Z",
     "iopub.status.busy": "2024-01-14T14:15:51.044967Z",
     "iopub.status.idle": "2024-01-14T16:20:06.505750Z",
     "shell.execute_reply": "2024-01-14T16:20:06.504759Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7455.477155,
     "end_time": "2024-01-14T16:20:06.507926",
     "exception": false,
     "start_time": "2024-01-14T14:15:51.030771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_1/images 28\n",
      "test_1/images 29\n",
      "valid_0/images 34\n",
      "test_0/images 36\n",
      "train/labels 399 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 0 содержит 280 объекта(-ов)\n",
      " Класс 1 содержит 229 объекта(-ов)\n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 280\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 280]\n",
      "\tКол-во директорий для класса 0: 38 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 29, folder 37, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 29\n",
      "temp_0_38/train/images 29 \n",
      "\n",
      "Класс 1\n",
      "\tКол-во train класса 1: 229\n",
      "\tКоличество данных (train) на каждой итерации класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 229]\n",
      "\tКол-во директорий для класса 1: 37 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 28, folder 36, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 28\n",
      "temp_1_37/train/images 28 \n",
      "\n",
      "/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml\n",
      "defaultdict(<class 'int'>, {'0': 38, '1': 37}) defaultdict(<class 'list'>, {'0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 280], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 229]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 22.9MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 95.3MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 33.78it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:01<00:00, 28.08it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.51G      1.392      1.747      4.039     0.8924        294        640: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n",
      "                   all         34       1217     0.0772      0.243     0.0484     0.0318      0.101      0.318     0.0667     0.0436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.94G       1.22      1.189      4.169     0.9124        109        640: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
      "                   all         34       1217     0.0712      0.219     0.0435     0.0282     0.0938      0.289     0.0605     0.0395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.66G      1.318     0.9883      4.108     0.8842         95        640: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
      "                   all         34       1217     0.0657      0.199     0.0395     0.0257     0.0885      0.268     0.0561     0.0367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.72G       1.27      1.172      3.947     0.8391        215        640: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.93it/s]\n",
      "                   all         34       1217     0.0825      0.259     0.0523     0.0345      0.102      0.321      0.068     0.0448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.77G      1.088      1.081      4.099     0.8826         94        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.12it/s]\n",
      "                   all         34       1217     0.0744       0.23     0.0458       0.03     0.0943      0.292      0.061     0.0401\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]\n",
      "                   all         34       1217     0.0831      0.261     0.0528     0.0347      0.103      0.324     0.0685     0.0454\n",
      "                 berry         34       1217     0.0831      0.261     0.0528     0.0347      0.103      0.324     0.0685     0.0454\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 106.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "                   all         36       1095     0.0803      0.289      0.052     0.0345     0.0955      0.344     0.0645     0.0422\n",
      "                 berry         36       1095     0.0803      0.289      0.052     0.0345     0.0955      0.344     0.0645     0.0422\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 44.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.05G       1.28      1.806      4.006     0.8986        166        640: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "                   all         34       1217     0.0956       0.34     0.0664     0.0434      0.122      0.434     0.0897     0.0597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.62G      1.267      1.052      4.045     0.8671        108        640: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "                   all         34       1217     0.0884      0.308     0.0603     0.0391      0.116      0.405     0.0842     0.0554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.47G      1.086     0.8714        4.1       0.89         40        640: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
      "                   all         34       1217     0.0865      0.298     0.0576      0.037      0.113      0.391     0.0801     0.0536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.56G      1.087       1.18      3.895     0.8884         92        640: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]\n",
      "                   all         34       1217      0.101      0.357     0.0717     0.0474      0.123      0.435     0.0914     0.0622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.82G      1.103      1.128      3.864     0.8917         81        640: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
      "                   all         34       1217     0.0975      0.341     0.0688     0.0444       0.12      0.421     0.0888       0.06\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.58it/s]\n",
      "                   all         34       1217      0.101      0.357     0.0717     0.0474      0.123      0.437     0.0919     0.0622\n",
      "                 berry         34       1217      0.101      0.357     0.0717     0.0474      0.123      0.437     0.0919     0.0622\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "                   all         36       1095      0.102      0.416     0.0732     0.0483      0.116      0.473     0.0865     0.0582\n",
      "                 berry         36       1095      0.102      0.416     0.0732     0.0483      0.116      0.473     0.0865     0.0582\n",
      "Speed: 0.1ms preprocess, 9.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 118.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.03G      1.881      1.738      3.912     0.9275        123        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
      "                   all         34       1217      0.105      0.399     0.0742     0.0504      0.121      0.462     0.0894     0.0613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.58G       1.86      2.041      3.741      0.989        102        640: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
      "                   all         34       1217      0.101      0.384     0.0708      0.048      0.117      0.445     0.0854     0.0596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.45G      1.259      1.345      3.943      1.001         28        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]\n",
      "                   all         34       1217     0.0993      0.376     0.0693     0.0469      0.116      0.438      0.084     0.0592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.47G      1.591      1.335      3.853     0.9678         54        640: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
      "                   all         34       1217      0.113      0.435     0.0828     0.0569      0.127      0.491     0.0966     0.0674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.65G      1.685      1.417      3.751     0.9579         68        640: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
      "                   all         34       1217      0.113      0.434     0.0828     0.0562      0.127      0.491     0.0967     0.0679\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217      0.114      0.437     0.0834     0.0572      0.128      0.493     0.0973     0.0679\n",
      "                 berry         34       1217      0.114      0.437     0.0834     0.0572      0.128      0.493     0.0973     0.0679\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                   all         36       1095      0.119      0.532     0.0917     0.0621      0.127      0.569        0.1     0.0675\n",
      "                 berry         36       1095      0.119      0.532     0.0917     0.0621      0.127      0.569        0.1     0.0675\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 44.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.04G       1.85      2.109      3.885     0.9029        329        640: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.04it/s]\n",
      "                   all         34       1217      0.104       0.44     0.0779     0.0526      0.112      0.472     0.0856      0.061\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.99G      1.537      1.331       3.99     0.9381        157        640: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]\n",
      "                   all         34       1217      0.103      0.425     0.0761     0.0515      0.112      0.462     0.0845     0.0601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.7G      1.459      1.123      3.914     0.9136        122        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.90it/s]\n",
      "                   all         34       1217      0.102      0.412     0.0736       0.05      0.111      0.449     0.0823      0.059\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.81G       1.43       1.52      3.811     0.8978        268        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n",
      "                   all         34       1217      0.104      0.418     0.0757     0.0512      0.114      0.458     0.0849     0.0623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.72G      1.313      1.417       3.86     0.9184        126        640: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n",
      "                   all         34       1217      0.111      0.444     0.0818     0.0555      0.119      0.478       0.09     0.0657\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.59it/s]\n",
      "                   all         34       1217       0.11      0.441     0.0812     0.0551      0.119      0.477     0.0896     0.0652\n",
      "                 berry         34       1217       0.11      0.441     0.0812     0.0551      0.119      0.477     0.0896     0.0652\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "                   all         36       1095      0.116      0.547     0.0906     0.0612      0.125      0.591        0.1     0.0677\n",
      "                 berry         36       1095      0.116      0.547     0.0906     0.0612      0.125      0.591        0.1     0.0677\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 43.05it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.03G       1.56      1.871      3.818     0.9057        187        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
      "                   all         34       1217        0.1      0.444     0.0753       0.05      0.105      0.464     0.0799     0.0578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.64G      1.317      1.069      4.071      0.905        122        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
      "                   all         34       1217     0.0979      0.419     0.0708     0.0468      0.104      0.446     0.0768      0.055\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.6G      1.206     0.9293      3.882     0.9079         64        640: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n",
      "                   all         34       1217     0.0941      0.398     0.0669     0.0445      0.102       0.43      0.074     0.0527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.67G      1.258      1.362      3.819     0.9092        126        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "                   all         34       1217      0.101      0.431     0.0753     0.0507      0.107      0.456     0.0811     0.0584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      1.017     0.9515      3.882     0.8472         89        640: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "                   all         34       1217     0.0994      0.422     0.0739     0.0493      0.106      0.451     0.0807     0.0577\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n",
      "                   all         34       1217      0.101      0.431      0.075     0.0506      0.107      0.456      0.081     0.0584\n",
      "                 berry         34       1217      0.101      0.431      0.075     0.0506      0.107      0.456      0.081     0.0584\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "                   all         36       1095      0.115      0.587     0.0958     0.0659      0.123      0.629      0.105     0.0719\n",
      "                 berry         36       1095      0.115      0.587     0.0958     0.0659      0.123      0.629      0.105     0.0719\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 507.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.06G     0.9591      1.234      3.666     0.8479        124        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
      "                   all         34       1217     0.0985      0.455      0.077     0.0508      0.105      0.486     0.0831     0.0583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.24G     0.6527      1.033      3.853     0.8179         80        640: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.15it/s]\n",
      "                   all         34       1217     0.0905      0.412     0.0675     0.0453      0.097      0.442     0.0731     0.0517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.12G     0.7977      1.111      3.738      0.806         89        640: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
      "                   all         34       1217     0.0885      0.397     0.0635     0.0425     0.0947      0.425     0.0691     0.0487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.18G     0.8501     0.9506      3.764     0.8454         54        640: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.11it/s]\n",
      "                   all         34       1217      0.089      0.395     0.0637     0.0418     0.0938      0.417     0.0681     0.0485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.14G          1       1.71      3.792     0.8777        172        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
      "                   all         34       1217      0.089      0.389     0.0634     0.0417     0.0958      0.419     0.0696     0.0499\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.61it/s]\n",
      "                   all         34       1217     0.0985      0.454     0.0769     0.0508      0.105      0.485     0.0829     0.0582\n",
      "                 berry         34       1217     0.0985      0.454     0.0769     0.0508      0.105      0.485     0.0829     0.0582\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                   all         36       1095      0.106      0.604     0.0983     0.0662      0.113      0.644      0.106     0.0748\n",
      "                 berry         36       1095      0.106      0.604     0.0983     0.0662      0.113      0.644      0.106     0.0748\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 57.85it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.93G      1.415      1.807      3.902     0.8957        381        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.88it/s]\n",
      "                   all         34       1217      0.103      0.486     0.0835     0.0523      0.107      0.506      0.088     0.0639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.49G      1.175      1.166      3.902     0.9326        133        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217     0.0924      0.429     0.0698     0.0462     0.0998      0.463     0.0767     0.0543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.68G      1.338      1.428      3.943     0.9038        223        640: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n",
      "                   all         34       1217     0.0868      0.396      0.063     0.0416     0.0955      0.435      0.071     0.0491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.33G      1.247      1.216      3.815      0.924        104        640: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.86it/s]\n",
      "                   all         34       1217      0.086      0.392     0.0611     0.0398     0.0945      0.431     0.0687     0.0479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.64G      1.368      1.516      3.905     0.8996        320        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n",
      "                   all         34       1217      0.087      0.399     0.0624     0.0409     0.0924      0.424     0.0675     0.0481\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.62it/s]\n",
      "                   all         34       1217      0.104      0.489     0.0841     0.0528      0.108      0.509     0.0884     0.0642\n",
      "                 berry         34       1217      0.104      0.489     0.0841     0.0528      0.108      0.509     0.0884     0.0642\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "                   all         36       1095     0.0995      0.584      0.094     0.0608      0.105      0.618     0.0996     0.0697\n",
      "                 berry         36       1095     0.0995      0.584      0.094     0.0608      0.105      0.618     0.0996     0.0697\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 49.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        11G      1.386      1.603      4.035     0.9212       1232        640: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         34       1217     0.0775      0.246     0.0486     0.0322      0.101      0.319     0.0665     0.0434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G      1.552      1.741      4.042     0.9252       1219        640: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n",
      "                   all         34       1217     0.0752      0.235     0.0467     0.0301     0.0973      0.304     0.0636     0.0417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.31G      1.561      1.643      4.056     0.9271       1268        640: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         34       1217     0.0706      0.217      0.043     0.0273     0.0925      0.284     0.0594     0.0389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G      1.166      1.671      4.041     0.9067        884        640: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]\n",
      "                   all         34       1217     0.0655      0.199     0.0393     0.0255     0.0877      0.266     0.0555     0.0361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.8G      1.211      1.406      4.061      0.924        814        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n",
      "                   all         34       1217     0.0609      0.183     0.0361     0.0226     0.0836      0.251     0.0523     0.0332\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217     0.0781      0.248     0.0491     0.0324      0.101      0.322     0.0673     0.0437\n",
      "                 berry         34       1217     0.0781      0.248     0.0491     0.0324      0.101      0.322     0.0673     0.0437\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095     0.0699       0.25     0.0439     0.0293     0.0883      0.316     0.0584     0.0375\n",
      "                 berry         36       1095     0.0699       0.25     0.0439     0.0293     0.0883      0.316     0.0584     0.0375\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 71.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.39G      1.708      1.811      4.034     0.8693        284        640: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n",
      "                   all         34       1217     0.0816      0.281     0.0542     0.0336      0.109      0.376      0.077      0.052\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.93G      1.081      1.075      4.287     0.8258         30        640: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217     0.0835       0.29     0.0562     0.0346      0.109      0.379     0.0774     0.0535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       3.2G      1.378      1.556      3.874     0.8887        142        640: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n",
      "                   all         34       1217      0.083      0.288     0.0557     0.0341      0.109      0.377     0.0771      0.053\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.07G      1.409      1.057       3.75     0.9007         62        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "                   all         34       1217     0.0832      0.288     0.0585     0.0361      0.109      0.376     0.0794     0.0542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.96G      1.541      1.412      3.999     0.8531        105        640: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
      "                   all         34       1217     0.0826      0.285     0.0579     0.0358      0.107      0.371     0.0784     0.0534\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.65it/s]\n",
      "                   all         34       1217     0.0823      0.284     0.0552     0.0342      0.107      0.371     0.0759      0.052\n",
      "                 berry         34       1217     0.0823      0.284     0.0552     0.0342      0.107      0.371     0.0759      0.052\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                   all         36       1095     0.0782      0.306     0.0521     0.0319     0.0948      0.371      0.066     0.0439\n",
      "                 berry         36       1095     0.0782      0.306     0.0521     0.0319     0.0948      0.371      0.066     0.0439\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 58.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      11.2G      1.246      1.349      4.055     0.9135         63        640: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]\n",
      "                   all         34       1217     0.0748      0.234     0.0464       0.03     0.0987      0.309     0.0647     0.0419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.9G      1.445      1.608      4.094      0.917        205        640: 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                   all         34       1217     0.0637      0.193      0.038     0.0246     0.0859       0.26     0.0541     0.0345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.4G      1.272      1.574       3.98     0.9092        241        640: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]\n",
      "                   all         34       1217      0.088      0.279     0.0568     0.0378      0.106      0.338     0.0714     0.0481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.03G      1.252      1.551      3.979     0.9196        136        640: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n",
      "                   all         34       1217      0.126      0.423     0.0937     0.0677      0.139      0.464      0.105     0.0732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G       1.41      1.567      3.739     0.8807        320        640: 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         34       1217      0.198      0.798      0.236      0.179      0.201      0.809       0.24      0.163\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.61it/s]\n",
      "                   all         34       1217      0.199        0.8      0.237      0.179      0.201      0.809      0.241      0.163\n",
      "                 berry         34       1217      0.199        0.8      0.237      0.179      0.201      0.809      0.241      0.163\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                   all         36       1095      0.169      0.768      0.217      0.165      0.171      0.776      0.221      0.147\n",
      "                 berry         36       1095      0.169      0.768      0.217      0.165      0.171      0.776      0.221      0.147\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 30.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.38G      1.296       1.82      3.481     0.8948        406        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n",
      "                   all         34       1217      0.195      0.869      0.278      0.211      0.197      0.878      0.284      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.35G     0.6923      1.341      3.535     0.8935        156        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n",
      "                   all         34       1217      0.194      0.851       0.27      0.204      0.196       0.86      0.275      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.72G     0.9322      1.444      3.602     0.8841        222        640: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n",
      "                   all         34       1217      0.193      0.844      0.267      0.202      0.195      0.853      0.274      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.51G      0.822      1.206      3.428     0.8868        148        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
      "                   all         34       1217      0.195      0.846      0.269      0.203      0.197      0.855      0.277      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.68G     0.9653      1.609       3.49     0.8874        325        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "                   all         34       1217      0.196      0.858      0.287      0.217      0.198      0.866      0.292      0.197\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "                   all         34       1217      0.196       0.86      0.288      0.218      0.198      0.867      0.293      0.197\n",
      "                 berry         34       1217      0.196       0.86      0.288      0.218      0.198      0.867      0.293      0.197\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095       0.17      0.847      0.279      0.212       0.17      0.851      0.283      0.186\n",
      "                 berry         36       1095       0.17      0.847      0.279      0.212       0.17      0.851      0.283      0.186\n",
      "Speed: 0.1ms preprocess, 9.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 53.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.05G      1.475      1.509      3.577     0.8779        332        640: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "                   all         34       1217      0.191       0.89      0.296      0.224      0.192      0.896      0.299      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       3.2G     0.9814     0.9566      3.591     0.8784         71        640: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.53it/s]\n",
      "                   all         34       1217       0.19      0.885      0.291       0.22      0.191      0.889      0.294      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.37G      1.333      1.192      3.418     0.9077        166        640: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n",
      "                   all         34       1217      0.191      0.878      0.281      0.211      0.192      0.887      0.285      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.14G      1.107     0.9398      3.488     0.8837         83        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217      0.192      0.878       0.28      0.211      0.193      0.887      0.284      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.28G      1.395      1.181      3.483     0.8946        162        640: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
      "                   all         34       1217      0.194      0.893       0.31      0.236      0.195      0.899      0.314      0.209\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]\n",
      "                   all         34       1217      0.194      0.893      0.309      0.235      0.195      0.899      0.313      0.209\n",
      "                 berry         34       1217      0.194      0.893      0.309      0.235      0.195      0.899      0.313      0.209\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         36       1095      0.166      0.892      0.311      0.234      0.166      0.895      0.315      0.203\n",
      "                 berry         36       1095      0.166      0.892      0.311      0.234      0.166      0.895      0.315      0.203\n",
      "Speed: 0.2ms preprocess, 10.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 407.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.05G      1.103       1.54      3.381      0.844        321        640: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n",
      "                   all         34       1217      0.175      0.859      0.287      0.212      0.176      0.862      0.288      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.22G     0.8131     0.8541      3.389     0.8821         75        640: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.60it/s]\n",
      "                   all         34       1217      0.178       0.87      0.285       0.21      0.179      0.876      0.286      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.64G     0.8877      1.125      3.394     0.8465        171        640: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.88it/s]\n",
      "                   all         34       1217       0.18      0.874      0.284      0.209      0.181      0.879      0.286      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.24G     0.8028      1.111      3.302     0.8504         94        640: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n",
      "                   all         34       1217       0.18       0.87      0.281      0.206      0.181      0.872      0.282      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.26G      1.072      1.389       3.24      0.857        180        640: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n",
      "                   all         34       1217      0.183      0.889      0.309       0.23      0.183      0.892       0.31       0.21\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "                   all         34       1217      0.183      0.889      0.309      0.229      0.184      0.893       0.31       0.21\n",
      "                 berry         34       1217      0.183      0.889      0.309      0.229      0.184      0.893       0.31       0.21\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "                   all         36       1095      0.156      0.895      0.364      0.267      0.156      0.894      0.366      0.239\n",
      "                 berry         36       1095      0.156      0.895      0.364      0.267      0.156      0.894      0.366      0.239\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 39.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.03G      1.087      1.242      3.668     0.9529        247        640: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.90it/s]\n",
      "                   all         34       1217      0.159      0.814       0.27      0.194      0.159      0.818      0.272      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.14G     0.7464       1.02      3.565      0.887         70        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.91it/s]\n",
      "                   all         34       1217      0.159      0.805      0.261      0.189       0.16       0.81      0.264      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.41G      1.058      1.082      3.396       0.88        127        640: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "                   all         34       1217      0.161      0.816      0.268      0.194      0.162      0.823       0.27      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.21G       0.98      1.007      3.454     0.9272         81        640: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "                   all         34       1217      0.164      0.826       0.27      0.196      0.164      0.828      0.271      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.35G       1.14      1.108      3.669     0.9426        174        640: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
      "                   all         34       1217      0.167      0.843      0.289       0.21      0.168      0.846      0.289      0.194\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.22it/s]\n",
      "                   all         34       1217      0.167      0.844      0.289      0.211      0.167      0.846       0.29      0.195\n",
      "                 berry         34       1217      0.167      0.844      0.289      0.211      0.167      0.846       0.29      0.195\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "                   all         36       1095      0.147      0.889      0.377      0.272      0.148       0.89      0.378      0.247\n",
      "                 berry         36       1095      0.147      0.889      0.377      0.272      0.148       0.89      0.378      0.247\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 47.99it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.15G     0.9562      1.437      3.321      0.883        439        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.82it/s]\n",
      "                   all         34       1217      0.154      0.817      0.303      0.213      0.154      0.818      0.304      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.68G     0.7844      1.328      3.426     0.8785        337        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.40it/s]\n",
      "                   all         34       1217      0.155      0.809      0.281        0.2      0.155      0.811      0.283      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.15G     0.8275      1.397      3.473     0.8822        394        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n",
      "                   all         34       1217      0.156      0.805      0.262      0.188      0.157      0.808      0.264      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      5.32G      0.682      1.236       3.47     0.8745        346        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "                   all         34       1217      0.155       0.79      0.246      0.177      0.155      0.793      0.249      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.95G     0.9073      1.314      3.343     0.8702        450        640: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n",
      "                   all         34       1217      0.161      0.829      0.282      0.205      0.161      0.828      0.284      0.189\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "                   all         34       1217      0.154      0.818      0.304      0.214      0.155       0.82      0.305      0.198\n",
      "                 berry         34       1217      0.154      0.818      0.304      0.214      0.155       0.82      0.305      0.198\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "                   all         36       1095      0.134      0.859      0.381      0.269      0.135      0.861      0.381      0.249\n",
      "                 berry         36       1095      0.134      0.859      0.381      0.269      0.135      0.861      0.381      0.249\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 41.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.78G     0.5751     0.8797       3.15     0.8449        199        640: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n",
      "                   all         34       1217      0.153      0.833      0.337      0.232      0.154      0.835      0.337      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.47G     0.7679      1.019      3.233     0.8778        250        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n",
      "                   all         34       1217      0.152      0.818      0.307      0.216      0.153      0.822      0.309      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.92G      1.077      1.217      3.283     0.8749        275        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n",
      "                   all         34       1217      0.152      0.804      0.286      0.202      0.152      0.807      0.287      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.58G      1.031      1.226       3.34     0.8754        303        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n",
      "                   all         34       1217      0.151      0.794      0.272      0.194      0.152      0.797      0.274      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.26G     0.9346     0.9476      3.189     0.8506        239        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.70it/s]\n",
      "                   all         34       1217      0.156      0.828      0.313      0.224      0.156      0.827      0.313      0.202\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.49it/s]\n",
      "                   all         34       1217      0.153      0.832      0.336      0.232      0.153      0.834      0.336      0.215\n",
      "                 berry         34       1217      0.153      0.832      0.336      0.232      0.153      0.834      0.336      0.215\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         36       1095      0.132      0.866      0.358      0.251      0.133      0.868      0.358      0.228\n",
      "                 berry         36       1095      0.132      0.866      0.358      0.251      0.133      0.868      0.358      0.228\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 54.61it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      11.5G      1.338      1.552      4.076     0.9127        543        640: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         34       1217     0.0672      0.205     0.0406     0.0263     0.0901      0.275     0.0575     0.0372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.1G      1.163      1.478      4.088     0.9067        657        640: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "                   all         34       1217      0.121      0.407     0.0875     0.0605      0.136      0.459      0.102     0.0692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      1.126       1.47        3.8     0.8978        494        640: 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.85it/s]\n",
      "                   all         34       1217      0.202      0.975      0.705      0.584      0.201      0.974      0.703       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      11.2G     0.8923       1.17       2.69     0.8652        736        640: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n",
      "                   all         34       1217       0.85      0.959      0.858      0.701      0.849      0.958      0.857      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.9G     0.7566     0.9743      1.137     0.8356        674        640: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.72it/s]\n",
      "                   all         34       1217      0.853      0.983       0.88      0.717      0.852      0.981      0.879      0.509\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.47it/s]\n",
      "                   all         34       1217      0.853      0.983      0.893      0.723      0.852      0.981      0.891      0.512\n",
      "                 berry         34       1217      0.853      0.983      0.893      0.723      0.852      0.981      0.891      0.512\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "                   all         36       1095      0.795      0.979      0.818      0.631      0.794      0.977      0.817      0.449\n",
      "                 berry         36       1095      0.795      0.979      0.818      0.631      0.794      0.977      0.817      0.449\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 52.04it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.51G     0.6682     0.8208      1.025     0.8184        287        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n",
      "                   all         34       1217      0.855      0.985      0.882      0.707      0.854      0.984      0.879      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       4.9G     0.6748     0.8889     0.9616     0.8488        306        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n",
      "                   all         34       1217      0.855      0.985      0.874      0.704      0.853      0.984      0.873      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.11G     0.7492     0.9604     0.7618      0.836        372        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n",
      "                   all         34       1217      0.853      0.987      0.875      0.708      0.851      0.985      0.874      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.84G     0.7721     0.9658     0.8121     0.8361        345        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.53it/s]\n",
      "                   all         34       1217      0.854      0.985      0.876      0.711      0.853      0.984      0.875      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.57G     0.7335     0.8896      1.045     0.8111        309        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n",
      "                   all         34       1217      0.856      0.982      0.875      0.712      0.855       0.98      0.874      0.513\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "                   all         34       1217      0.854      0.985      0.884      0.716      0.853      0.984      0.883      0.516\n",
      "                 berry         34       1217      0.854      0.985      0.884      0.716      0.853      0.984      0.883      0.516\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "                   all         36       1095      0.794      0.976      0.813      0.628      0.792      0.974      0.811      0.454\n",
      "                 berry         36       1095      0.794      0.976      0.813      0.628      0.792      0.974      0.811      0.454\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 90.32it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.92G     0.6907       0.82     0.7939     0.8052        271        640: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n",
      "                   all         34       1217      0.855      0.984      0.878      0.703      0.853      0.982      0.877      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.44G     0.7693     0.8004     0.9291     0.8075        212        640: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.30it/s]\n",
      "                   all         34       1217      0.854      0.984      0.872      0.701      0.853      0.983      0.871      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.79G     0.6924     0.7909     0.6847     0.8075        255        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n",
      "                   all         34       1217      0.857      0.985      0.872      0.704      0.856      0.984      0.871      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       4.6G     0.6564     0.7469     0.7604     0.8288        176        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]\n",
      "                   all         34       1217      0.858      0.984      0.872      0.704      0.856      0.983      0.871      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.78G      0.801     0.8496     0.8476     0.8325        365        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n",
      "                   all         34       1217      0.859      0.983      0.876       0.71      0.857      0.982      0.875       0.52\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "                   all         34       1217      0.859      0.983      0.873      0.707      0.857      0.982      0.872      0.516\n",
      "                 berry         34       1217      0.859      0.983      0.873      0.707      0.857      0.982      0.872      0.516\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         36       1095      0.798      0.976      0.811      0.624      0.796      0.973      0.809      0.458\n",
      "                 berry         36       1095      0.798      0.976      0.811      0.624      0.796      0.973      0.809      0.458\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 388.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.83G     0.7045     0.8764     0.6959      0.813        259        640: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]\n",
      "                   all         34       1217      0.848      0.975      0.861      0.677      0.846      0.973      0.859      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.47G     0.8242      0.854     0.8154     0.8343        215        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         34       1217      0.849      0.975      0.865      0.685      0.848      0.974      0.863      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.75G      0.775      1.004     0.6708     0.8297        304        640: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n",
      "                   all         34       1217      0.849      0.979      0.865      0.689      0.847      0.977      0.864      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.87G     0.6913     0.9015     0.7091     0.8157        230        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.57it/s]\n",
      "                   all         34       1217       0.85       0.98      0.879      0.707      0.848      0.978      0.877      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.98G     0.8456      1.067     0.8231     0.8265        393        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "                   all         34       1217      0.851      0.981      0.868      0.699       0.85      0.979      0.867      0.522\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]\n",
      "                   all         34       1217       0.85      0.979      0.874      0.703      0.848      0.977      0.872      0.525\n",
      "                 berry         34       1217       0.85      0.979      0.874      0.703      0.848      0.977      0.872      0.525\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         36       1095      0.798      0.958      0.811      0.622      0.796      0.956      0.809      0.469\n",
      "                 berry         36       1095      0.798      0.958      0.811      0.622      0.796      0.956      0.809      0.469\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 477.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.78G     0.6147     0.6963      1.536      0.799        135        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "                   all         34       1217      0.848      0.957      0.866      0.675      0.845      0.954      0.863      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.23G     0.7099     0.8449      1.245     0.8125        149        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n",
      "                   all         34       1217      0.845      0.959       0.86      0.675      0.843      0.958      0.858      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.56G     0.6157     0.6942     0.6897     0.7922        231        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.84it/s]\n",
      "                   all         34       1217      0.844       0.96      0.858      0.676      0.841      0.957      0.856      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.58G     0.5725     0.7084     0.7799     0.8093        143        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n",
      "                   all         34       1217      0.845      0.961      0.859      0.682      0.843       0.96      0.857      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.37G     0.7406     0.8215      1.389     0.8089        206        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "                   all         34       1217      0.846       0.96      0.864       0.69      0.844      0.958      0.863      0.523\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "                   all         34       1217      0.846       0.96       0.87      0.694      0.844      0.958      0.869      0.528\n",
      "                 berry         34       1217      0.846       0.96       0.87      0.694      0.844      0.958      0.869      0.528\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         36       1095      0.791      0.955      0.807      0.617      0.789      0.953      0.804      0.472\n",
      "                 berry         36       1095      0.791      0.955      0.807      0.617      0.789      0.953      0.804      0.472\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 55.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.92G     0.7338     0.8195     0.7981     0.8095        294        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n",
      "                   all         34       1217      0.853      0.938      0.863      0.655      0.849      0.933      0.859      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.71G     0.6229     0.8641      1.021       0.84        303        640: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]\n",
      "                   all         34       1217      0.847      0.942      0.857      0.656      0.841      0.938      0.853      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.75G     0.6807     0.9088     0.7782     0.8357        315        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "                   all         34       1217      0.847      0.944      0.854       0.66      0.842      0.939      0.851      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.92G     0.5992     0.8005      0.922     0.8302        269        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "                   all         34       1217      0.848      0.942      0.861      0.675      0.845      0.939      0.858      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.09G     0.7597     0.8551     0.8875     0.8238        409        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.74it/s]\n",
      "                   all         34       1217      0.847      0.942      0.854      0.672      0.845       0.94      0.853      0.519\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.50it/s]\n",
      "                   all         34       1217      0.848      0.942      0.859      0.673      0.845      0.939      0.857      0.521\n",
      "                 berry         34       1217      0.848      0.942      0.859      0.673      0.845      0.939      0.857      0.521\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         36       1095      0.782      0.961      0.798      0.601      0.783       0.95      0.796      0.467\n",
      "                 berry         36       1095      0.782      0.961      0.798      0.601      0.783       0.95      0.796      0.467\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:01<00:00, 65.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.5G      1.266      1.473      4.026     0.9157         57        640: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         34       1217     0.0615      0.186     0.0365     0.0229     0.0852      0.257     0.0536     0.0342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.58G      1.131      1.537      3.653     0.8868        203        640: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         34       1217       0.85      0.936       0.85      0.706      0.849      0.935      0.849      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.3G     0.7887     0.9942      1.191     0.8328        177        640: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]\n",
      "                   all         34       1217       0.85      0.998      0.909      0.712      0.848      0.994      0.908      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.91G     0.6259     0.6938     0.6282     0.8021         56        640: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]\n",
      "                   all         34       1217      0.883      0.984      0.948      0.807      0.881      0.983      0.947      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.62G     0.6215      0.626     0.6067     0.8051         86        640: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n",
      "                   all         34       1217      0.916      0.974      0.963      0.813      0.915      0.975      0.962      0.583\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "                   all         34       1217      0.916      0.974      0.963      0.813      0.915      0.974      0.963      0.584\n",
      "                 berry         34       1217      0.916      0.974      0.963      0.813      0.915      0.974      0.963      0.584\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "                   all         36       1095      0.863      0.977      0.938      0.774      0.861      0.975      0.937      0.553\n",
      "                 berry         36       1095      0.863      0.977      0.938      0.774      0.861      0.975      0.937      0.553\n",
      "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 108.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.49G     0.6802     0.7016     0.7502     0.8375        210        640: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "                   all         34       1217      0.882      0.988      0.944      0.792      0.882      0.988      0.943      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.46G     0.6587     0.7365     0.7506      0.829        189        640: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217      0.885      0.988      0.948      0.795      0.884      0.987      0.947      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.69G     0.6169     0.6442     0.5891     0.8074        265        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n",
      "                   all         34       1217      0.887      0.987       0.95      0.798      0.886      0.986      0.949      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.86G     0.5392     0.6814     0.6069     0.8215        198        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n",
      "                   all         34       1217      0.888      0.986      0.949        0.8      0.888      0.986      0.948       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.38G     0.6898     0.7132     0.7809     0.8121        236        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.93it/s]\n",
      "                   all         34       1217      0.891      0.985       0.95      0.801       0.89      0.984      0.949      0.581\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n",
      "                   all         34       1217      0.891      0.985      0.949      0.801       0.89      0.984      0.949      0.582\n",
      "                 berry         34       1217      0.891      0.985      0.949      0.801       0.89      0.984      0.949      0.582\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095       0.84      0.986      0.918      0.762      0.839      0.984      0.917      0.546\n",
      "                 berry         36       1095       0.84      0.986      0.918      0.762      0.839      0.984      0.917      0.546\n",
      "Speed: 0.2ms preprocess, 10.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:01<00:00, 66.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      1.302      1.509       4.06     0.9046        370        640: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n",
      "                   all         34       1217     0.0602      0.182     0.0356     0.0223     0.0844      0.255      0.053     0.0334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.4G       1.17      1.551      3.633     0.9034        426        640: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         34       1217      0.858      0.935      0.854      0.705      0.857      0.935      0.853      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        10G     0.7412      0.883       1.12     0.8302        454        640: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "                   all         34       1217      0.859      0.998      0.906      0.738      0.858      0.998      0.905      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.74G     0.6837     0.7174      0.637     0.8146        446        640: 100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n",
      "                   all         34       1217      0.884      0.993      0.944      0.778      0.883      0.992      0.943      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        11G     0.6455     0.6782     0.5891     0.8201        763        640: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         34       1217      0.904      0.992      0.961      0.823      0.903      0.991       0.96      0.603\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]\n",
      "                   all         34       1217      0.904      0.992      0.961      0.823      0.903      0.991      0.961      0.603\n",
      "                 berry         34       1217      0.904      0.992      0.961      0.823      0.903      0.991      0.961      0.603\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "                   all         36       1095      0.837      0.993      0.936      0.779      0.836      0.991      0.935       0.57\n",
      "                 berry         36       1095      0.837      0.993      0.936      0.779      0.836      0.991      0.935       0.57\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 504.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.51G     0.5535     0.5828     0.6185     0.7801        203        640: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.73it/s]\n",
      "                   all         34       1217      0.873      0.998      0.939      0.791      0.872      0.998      0.938      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.51G     0.6592      0.589     0.5328     0.7937        263        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n",
      "                   all         34       1217      0.875      0.997      0.946      0.797      0.875      0.996      0.945      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.95G     0.6123     0.5968     0.5067      0.803        327        640: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n",
      "                   all         34       1217      0.877      0.996      0.948      0.801      0.876      0.995      0.947      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.89G     0.6528     0.5902     0.5062     0.8135        327        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217       0.88      0.996      0.948      0.801      0.879      0.995      0.947      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.65G     0.6017     0.6019     0.4843     0.8004        348        640: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n",
      "                   all         34       1217      0.882      0.995      0.949      0.804      0.882      0.994      0.948      0.601\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n",
      "                   all         34       1217      0.882      0.995       0.95      0.806      0.881      0.994       0.95      0.604\n",
      "                 berry         34       1217      0.882      0.995       0.95      0.806      0.881      0.994       0.95      0.604\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095      0.823      0.995      0.918      0.765      0.821      0.993      0.917      0.566\n",
      "                 berry         36       1095      0.823      0.995      0.918      0.765      0.821      0.993      0.917      0.566\n",
      "Speed: 0.7ms preprocess, 10.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:01<00:00, 71.65it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.5G      1.214      1.478      3.998     0.9115        427        640: 100%|██████████| 5/5 [00:06<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         34       1217     0.0626      0.189     0.0372     0.0235     0.0849      0.256     0.0533     0.0344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G      1.128      1.466       3.63     0.8846        796        640: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217      0.853      0.942      0.852      0.688      0.851      0.939      0.848      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.68G     0.7644     0.9154      1.149     0.8322        755        640: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217      0.837      0.998      0.901      0.745      0.836      0.998        0.9      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.77G     0.6359     0.6738     0.6525     0.8144        698        640: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "                   all         34       1217      0.884      0.988       0.94      0.791      0.883      0.987      0.939      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.9G     0.6538     0.6538     0.5839     0.8129        820        640: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         34       1217      0.904      0.981      0.961      0.816      0.901      0.979       0.96      0.592\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "                   all         34       1217      0.903      0.981       0.96      0.815      0.901      0.979      0.959      0.592\n",
      "                 berry         34       1217      0.903      0.981       0.96      0.815      0.901      0.979      0.959      0.592\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n",
      "                   all         36       1095       0.84      0.983      0.935      0.771      0.838       0.98      0.934       0.56\n",
      "                 berry         36       1095       0.84      0.983      0.935      0.771      0.838       0.98      0.934       0.56\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 585.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.49G     0.5645      0.511      1.003     0.8073        201        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "                   all         34       1217      0.881      0.993      0.944      0.792      0.879      0.991      0.942      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.51G     0.5151     0.4455     0.9507     0.7932        179        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n",
      "                   all         34       1217      0.883      0.993      0.944      0.794      0.881       0.99      0.943      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.59G     0.4769     0.5064     0.9037     0.7898        179        640: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "                   all         34       1217      0.885      0.993      0.946      0.798      0.882       0.99      0.945      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.62G     0.4693      0.482     0.8408     0.7948        192        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.81it/s]\n",
      "                   all         34       1217       0.89      0.992      0.949      0.802      0.888      0.989      0.947      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.42G     0.5429     0.4705        1.1     0.7595        169        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.93it/s]\n",
      "                   all         34       1217      0.891      0.992      0.949      0.801      0.889      0.989      0.948      0.594\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]\n",
      "                   all         34       1217      0.891      0.992      0.949      0.801      0.889      0.989      0.948      0.593\n",
      "                 berry         34       1217      0.891      0.992      0.949      0.801      0.889      0.989      0.948      0.593\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "                   all         36       1095      0.823      0.989      0.917      0.758       0.82      0.986      0.916      0.555\n",
      "                 berry         36       1095      0.823      0.989      0.917      0.758       0.82      0.986      0.916      0.555\n",
      "Speed: 0.1ms preprocess, 9.7ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:01<00:00, 75.03it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      11.8G      1.244      1.377      4.082     0.8984         35        640: 100%|██████████| 6/6 [00:06<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                   all         34       1217      0.132      0.445      0.101     0.0745      0.143      0.482      0.112     0.0765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.65G     0.9986      1.373      2.909     0.8702         27        640: 100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                   all         34       1217      0.854      0.979      0.885      0.723      0.852      0.977      0.884       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.9G     0.7051     0.8032     0.7737     0.8146         64        640: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "                   all         34       1217      0.907      0.972      0.944      0.779      0.904       0.97      0.943      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.7G     0.6524      0.656     0.6167     0.8136         91        640: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         34       1217      0.916      0.979      0.965      0.807      0.914      0.977      0.964      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.75G     0.6452     0.5821     0.5651     0.7991         39        640: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         34       1217      0.944      0.973      0.975       0.82      0.943      0.973      0.975      0.609\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217      0.944      0.974      0.975      0.821      0.943      0.973      0.974      0.608\n",
      "                 berry         34       1217      0.944      0.974      0.975      0.821      0.943      0.973      0.974      0.608\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "                   all         36       1095      0.894      0.964      0.948      0.791      0.893      0.963      0.947      0.572\n",
      "                 berry         36       1095      0.894      0.964      0.948      0.791      0.893      0.963      0.947      0.572\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 95.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.61G     0.5375     0.5334     0.8592     0.7759        233        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n",
      "                   all         34       1217      0.915      0.985      0.967      0.807      0.914      0.984      0.966      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.48G     0.5429     0.5482     0.7917     0.8136        231        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n",
      "                   all         34       1217      0.919      0.985      0.967      0.808      0.918      0.984      0.967      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.73G     0.6486     0.5388     0.5515     0.8204        300        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.80it/s]\n",
      "                   all         34       1217      0.922      0.983      0.968      0.809      0.921      0.982      0.968       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.72G     0.5728     0.5425     0.6081     0.7905        245        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n",
      "                   all         34       1217      0.924      0.982      0.969      0.813      0.924      0.981      0.969      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.48G     0.5882     0.4797     0.8951     0.7847        249        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217      0.929      0.982       0.97      0.814      0.928      0.981      0.969      0.616\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]\n",
      "                   all         34       1217      0.928      0.982       0.97      0.814      0.927      0.981      0.969      0.615\n",
      "                 berry         34       1217      0.928      0.982       0.97      0.814      0.927      0.981      0.969      0.615\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "                   all         36       1095      0.866      0.974      0.935       0.78      0.864      0.973      0.934      0.572\n",
      "                 berry         36       1095      0.866      0.974      0.935       0.78      0.864      0.973      0.934      0.572\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:01<00:00, 74.97it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.6G      1.216      1.409      4.058     0.8987        412        640: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         34       1217     0.0573       0.17     0.0335     0.0207     0.0797      0.237     0.0493     0.0314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.93G     0.9816      1.279      2.859     0.8664        429        640: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                   all         34       1217      0.851      0.983      0.901      0.735       0.85      0.982      0.899      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        11G     0.6696     0.7454     0.7629     0.8169        290        640: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         34       1217      0.862      0.998      0.949      0.764       0.86      0.996      0.948      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.7G     0.6486     0.6268     0.6103     0.8057        371        640: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         34       1217      0.919       0.98      0.968      0.793      0.917      0.977      0.967      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.8G     0.6214     0.6065     0.5686     0.7998        273        640: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         34       1217      0.931      0.978      0.972      0.822      0.929      0.975      0.971       0.59\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "                   all         34       1217      0.931      0.977      0.972      0.823      0.929      0.975      0.971      0.591\n",
      "                 berry         34       1217      0.931      0.977      0.972      0.823      0.929      0.975      0.971      0.591\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
      "                   all         36       1095      0.875      0.974      0.951      0.786      0.874      0.972       0.95      0.562\n",
      "                 berry         36       1095      0.875      0.974      0.951      0.786      0.874      0.972       0.95      0.562\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 35.16it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.16G     0.5668     0.5343     0.6161     0.8074        371        640: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.70it/s]\n",
      "                   all         34       1217      0.913      0.988      0.962      0.807       0.91      0.985      0.961      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.23G     0.6262     0.5992     0.6451     0.8241        392        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n",
      "                   all         34       1217      0.915      0.987      0.963       0.81      0.913      0.985      0.963      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.29G     0.5808     0.4872      0.709     0.8248        389        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]\n",
      "                   all         34       1217      0.917      0.987      0.965      0.812      0.916      0.985      0.964      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.73G     0.5376     0.4885     0.6194     0.8093        352        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]\n",
      "                   all         34       1217      0.918      0.987      0.965      0.813      0.915      0.985      0.964       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.19G     0.7027     0.6476     0.5953     0.8118        465        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n",
      "                   all         34       1217       0.92      0.988      0.966      0.814      0.917      0.985      0.965       0.59\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n",
      "                   all         34       1217      0.919      0.988      0.966      0.814      0.917      0.985      0.965       0.59\n",
      "                 berry         34       1217      0.919      0.988      0.966      0.814      0.917      0.985      0.965       0.59\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "                   all         36       1095      0.864      0.979      0.939      0.772      0.862      0.977      0.938      0.558\n",
      "                 berry         36       1095      0.864      0.979      0.939      0.772      0.862      0.977      0.938      0.558\n",
      "Speed: 0.2ms preprocess, 10.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:01<00:00, 73.41it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.86G      1.256      1.541       4.06     0.9055        862        640: 100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                   all         34       1217     0.0571       0.17     0.0334     0.0204     0.0794      0.237     0.0491     0.0315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.6G      1.014      1.285      2.782     0.8718        809        640: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         34       1217      0.844      0.979      0.879      0.671      0.843      0.978      0.878        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.6G     0.6885     0.7514     0.7752     0.8156        804        640: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         34       1217      0.905      0.975      0.953      0.782      0.901      0.971      0.951      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G     0.6445     0.6121     0.6153       0.81        547        640: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                   all         34       1217      0.928      0.976      0.971      0.791      0.926      0.973       0.97      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.78G     0.6095     0.5879     0.5056     0.8071        673        640: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                   all         34       1217      0.931      0.984      0.973      0.825       0.93      0.983      0.973      0.621\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217      0.931      0.984      0.974      0.825       0.93      0.983      0.973      0.621\n",
      "                 berry         34       1217      0.931      0.984      0.974      0.825       0.93      0.983      0.973      0.621\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n",
      "                   all         36       1095      0.873      0.981      0.953      0.795      0.872      0.979      0.952       0.59\n",
      "                 berry         36       1095      0.873      0.981      0.953      0.795      0.872      0.979      0.952       0.59\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 94.18it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.2G     0.5303     0.7779     0.8965     0.7872        178        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n",
      "                   all         34       1217      0.905      0.994      0.967       0.81      0.904      0.993      0.967      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.31G     0.5755     0.7256     0.8546     0.8052        180        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n",
      "                   all         34       1217       0.91      0.994      0.967      0.811      0.909      0.993      0.967      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.65G     0.5092     0.5427     0.4655     0.7907        247        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.73it/s]\n",
      "                   all         34       1217      0.912      0.994      0.968      0.813      0.911      0.993      0.968      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.66G     0.4838     0.6449     0.5627     0.7927        177        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n",
      "                   all         34       1217      0.917      0.993       0.97      0.818      0.916      0.992       0.97      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.41G     0.6839     0.6591     0.9405     0.7883        226        640: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]\n",
      "                   all         34       1217      0.917      0.993       0.97      0.818      0.916      0.992      0.969      0.626\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "                   all         34       1217      0.917      0.993       0.97      0.817      0.916      0.992      0.969      0.626\n",
      "                 berry         34       1217      0.917      0.993       0.97      0.817      0.916      0.992      0.969      0.626\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "                   all         36       1095      0.851      0.989      0.941      0.789       0.85      0.987       0.94      0.582\n",
      "                 berry         36       1095      0.851      0.989      0.941      0.789       0.85      0.987       0.94      0.582\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:01<00:00, 73.95it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.82G      1.252      1.474      4.065      0.909       1305        640: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                   all         34       1217      0.057      0.169     0.0334     0.0205     0.0797      0.237     0.0493     0.0315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.9G     0.9549      1.259      2.846     0.8642       1001        640: 100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217       0.85      0.988      0.878      0.708       0.85      0.987      0.877      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.9G     0.6394      0.728     0.7368     0.8087       1257        640: 100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                   all         34       1217      0.912      0.969      0.958      0.805      0.911      0.968      0.957       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G     0.6595     0.6368     0.5971     0.8087        939        640: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217      0.913      0.984      0.973      0.825      0.911      0.983      0.972      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G     0.6108     0.5806     0.5766     0.8028        707        640: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217      0.942      0.977      0.978      0.833       0.94      0.975      0.977      0.588\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n",
      "                   all         34       1217      0.942      0.977      0.979      0.834       0.94      0.975      0.978      0.588\n",
      "                 berry         34       1217      0.942      0.977      0.979      0.834       0.94      0.975      0.978      0.588\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                   all         36       1095      0.887      0.971      0.961       0.79      0.888      0.965       0.96      0.558\n",
      "                 berry         36       1095      0.887      0.971      0.961       0.79      0.888      0.965       0.96      0.558\n",
      "Speed: 0.2ms preprocess, 10.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 51.29it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.21G     0.6688     0.6352     0.5061      0.816        293        640: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "                   all         34       1217      0.921      0.984      0.971      0.819      0.919      0.983       0.97      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.84G     0.8013     0.8264     0.5496      0.816        369        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n",
      "                   all         34       1217      0.921      0.983      0.972      0.821       0.92      0.981      0.971       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.35G     0.7297     0.7536     0.6489     0.8413        360        640: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.40it/s]\n",
      "                   all         34       1217      0.926      0.983      0.973      0.824      0.925      0.981      0.972      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.81G     0.8109     0.9172     0.5864     0.8501        328        640: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n",
      "                   all         34       1217      0.929      0.979      0.974      0.824      0.927      0.977      0.973      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.55G      0.676     0.8022     0.4955      0.789        297        640: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n",
      "                   all         34       1217       0.93      0.979      0.974      0.827      0.928      0.978      0.973      0.592\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "                   all         34       1217       0.93      0.979      0.974      0.828      0.929      0.977      0.973      0.593\n",
      "                 berry         34       1217       0.93      0.979      0.974      0.828      0.929      0.977      0.973      0.593\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095      0.869      0.979      0.952      0.786      0.867      0.976      0.951      0.552\n",
      "                 berry         36       1095      0.869      0.979      0.952      0.786      0.867      0.976      0.951      0.552\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:01<00:00, 72.29it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      11.2G      1.223      1.494      4.053     0.9058        352        640: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n",
      "                   all         34       1217      0.138      0.485      0.105      0.075      0.149      0.523      0.117     0.0806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.8G     0.8556      1.074      2.072     0.8498        257        640: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n",
      "                   all         34       1217      0.892      0.932      0.892      0.753      0.891      0.931      0.891      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.66G     0.6818     0.6774     0.6819      0.812        323        640: 100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         34       1217      0.905      0.981      0.972      0.807      0.904      0.982      0.972      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.3G     0.6449     0.5655     0.6655     0.8037        177        640: 100%|██████████| 7/7 [00:07<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "                   all         34       1217      0.914      0.983       0.98      0.824       0.91      0.979      0.978      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      11.3G     0.6478     0.6169     0.5315     0.7974        187        640: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         34       1217      0.935      0.983       0.98      0.834      0.934      0.981      0.979      0.603\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]\n",
      "                   all         34       1217      0.935      0.983       0.98      0.834      0.934      0.981      0.979      0.602\n",
      "                 berry         34       1217      0.935      0.983       0.98      0.834      0.934      0.981      0.979      0.602\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                   all         36       1095      0.896      0.972      0.962      0.808      0.895       0.97      0.961      0.571\n",
      "                 berry         36       1095      0.896      0.972      0.962      0.808      0.895       0.97      0.961      0.571\n",
      "Speed: 0.5ms preprocess, 10.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 68.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.93G     0.5693     0.6074     0.6254     0.7981        493        640: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.30it/s]\n",
      "                   all         34       1217      0.927      0.982      0.973      0.823      0.926      0.981      0.973      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.34G     0.7781      0.686     0.6498     0.7992        598        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.25it/s]\n",
      "                   all         34       1217      0.928      0.982      0.973      0.824      0.927      0.981      0.973      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.83G     0.6585      0.609     0.5711     0.8088        593        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n",
      "                   all         34       1217      0.929      0.983      0.974      0.826      0.928      0.982      0.974      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.71G     0.4336     0.5075     0.5726     0.7986        348        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n",
      "                   all         34       1217      0.929      0.983      0.975      0.826      0.928      0.982      0.974      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.74G      0.484      0.442     0.6013     0.8093        396        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         34       1217      0.931      0.981      0.975      0.826       0.93       0.98      0.975      0.603\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.49it/s]\n",
      "                   all         34       1217      0.931      0.981      0.975      0.826       0.93       0.98      0.975      0.602\n",
      "                 berry         34       1217      0.931      0.981      0.975      0.826       0.93       0.98      0.975      0.602\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         36       1095      0.887      0.973      0.949      0.799      0.886      0.971      0.948      0.564\n",
      "                 berry         36       1095      0.887      0.973      0.949      0.799      0.886      0.971      0.948      0.564\n",
      "Speed: 0.3ms preprocess, 10.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:01<00:00, 73.02it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G      1.268      1.565      4.075     0.9108       1455        640: 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217      0.151      0.539      0.123     0.0887       0.16       0.57      0.132       0.09\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G     0.8083       1.05      2.012     0.8451        936        640: 100%|██████████| 7/7 [00:08<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         34       1217      0.863      0.998      0.914      0.785      0.861      0.997      0.912      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.82G     0.6632      0.688     0.6591     0.8097       1200        640: 100%|██████████| 7/7 [00:07<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                   all         34       1217      0.901      0.984      0.957      0.793      0.899      0.979      0.956      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.75G     0.6333     0.5889     0.5314     0.8053       1020        640: 100%|██████████| 7/7 [00:07<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         34       1217      0.921      0.981      0.969       0.79       0.92      0.979      0.969      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.7G     0.6567     0.5967     0.5425     0.8028        890        640: 100%|██████████| 7/7 [00:07<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                   all         34       1217       0.94      0.983      0.976      0.822      0.939      0.981      0.976      0.577\n",
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]\n",
      "                   all         34       1217      0.939      0.982      0.976      0.822      0.939      0.981      0.976      0.576\n",
      "                 berry         34       1217      0.939      0.982      0.976      0.822      0.939      0.981      0.976      0.576\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                   all         36       1095      0.885      0.969      0.959      0.789      0.883      0.967      0.957      0.545\n",
      "                 berry         36       1095      0.885      0.969      0.959      0.789      0.883      0.967      0.957      0.545\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 66.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.93G       0.52     0.5595     0.5107     0.7969        547        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n",
      "                   all         34       1217      0.908      0.994      0.968      0.809      0.907      0.994      0.968      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.57G     0.6633     0.6914     0.6924     0.8018        612        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]\n",
      "                   all         34       1217      0.913      0.993      0.969      0.811      0.912      0.993      0.969      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.82G     0.5713     0.5059     0.5519     0.7997        605        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n",
      "                   all         34       1217      0.918      0.993       0.97      0.813      0.917      0.993       0.97       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.75G     0.4941     0.4899     0.6416      0.793        406        640: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "                   all         34       1217      0.918      0.993      0.971      0.813      0.917      0.992      0.971      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.73G     0.4898     0.5485     0.5385     0.7982        394        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n",
      "                   all         34       1217      0.921      0.987      0.972      0.815       0.92      0.987      0.972      0.581\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.65it/s]\n",
      "                   all         34       1217      0.921      0.987      0.972      0.815       0.92      0.987      0.972      0.581\n",
      "                 berry         34       1217      0.921      0.987      0.972      0.815       0.92      0.987      0.972      0.581\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "                   all         36       1095      0.855      0.988      0.943      0.775      0.853      0.986      0.941       0.54\n",
      "                 berry         36       1095      0.855      0.988      0.943      0.775      0.853      0.986      0.941       0.54\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:01<00:00, 74.22it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.3G      1.255      1.498      4.069      0.893        355        640: 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         34       1217      0.165      0.614      0.156      0.116      0.171      0.634      0.163      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        11G     0.7774     0.9959      1.773     0.8363        512        640: 100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         34       1217      0.895      0.978      0.948      0.796      0.893      0.975      0.947       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.1G     0.6754     0.6106     0.6319     0.8085        585        640: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         34       1217      0.941      0.981      0.974      0.797      0.939      0.979      0.974      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G     0.6656     0.5769      0.555     0.7995        429        640: 100%|██████████| 8/8 [00:08<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         34       1217      0.949       0.98      0.977      0.791      0.947      0.978      0.977       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.7G     0.6215      0.556      0.526     0.7943        510        640: 100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n",
      "                   all         34       1217      0.947      0.979      0.975      0.811      0.946      0.978      0.975      0.594\n",
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.61it/s]\n",
      "                   all         34       1217      0.941      0.981      0.974      0.797      0.939      0.979      0.974      0.621\n",
      "                 berry         34       1217      0.941      0.981      0.974      0.797      0.939      0.979      0.974      0.621\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         36       1095      0.879      0.979      0.948      0.762      0.877      0.977      0.947       0.58\n",
      "                 berry         36       1095      0.879      0.979      0.948      0.762      0.877      0.977      0.947       0.58\n",
      "Speed: 0.2ms preprocess, 10.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 51.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.7G     0.6371     0.6058     0.5184     0.7867        669        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n",
      "                   all         34       1217      0.933      0.989      0.966      0.798      0.933      0.988      0.966      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.69G     0.6452      0.644     0.4995     0.7794        642        640: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "                   all         34       1217      0.934      0.989      0.966      0.799      0.934      0.988      0.966      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.78G     0.6425     0.6023     0.4477     0.7968        757        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n",
      "                   all         34       1217      0.938      0.988      0.968      0.803      0.937      0.987      0.968      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.21G     0.5708     0.5161     0.5557     0.8164        521        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         34       1217      0.938      0.986      0.969      0.803      0.937      0.985      0.968      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.29G     0.5993     0.5981     0.4869     0.8126        601        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "                   all         34       1217       0.94      0.985       0.97      0.808      0.939      0.984       0.97      0.591\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n",
      "                   all         34       1217       0.94      0.985      0.969      0.808      0.939      0.984      0.969       0.59\n",
      "                 berry         34       1217       0.94      0.985      0.969      0.808      0.939      0.984      0.969       0.59\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n",
      "                   all         36       1095      0.879      0.979      0.947       0.77      0.877      0.977      0.946       0.56\n",
      "                 berry         36       1095      0.879      0.979      0.947       0.77      0.877      0.977      0.946       0.56\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:01<00:00, 70.92it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G      1.149      1.491      3.927     0.8933        133        640: 100%|██████████| 9/9 [00:09<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217      0.846      0.822      0.833      0.695      0.845      0.821      0.831      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.94G     0.7292     0.8408      1.065     0.8201         95        640: 100%|██████████| 9/9 [00:09<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]\n",
      "                   all         34       1217      0.876      0.997      0.956      0.783      0.874      0.995      0.955      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G     0.6551     0.6037     0.5791     0.8019        240        640: 100%|██████████| 9/9 [00:09<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         34       1217       0.94      0.983      0.979      0.814      0.936      0.979      0.977      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G     0.6478     0.5986     0.5977      0.798        118        640: 100%|██████████| 9/9 [00:09<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         34       1217      0.943       0.98      0.979       0.83      0.943      0.979      0.979      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G     0.6439     0.6043     0.5444     0.7947        159        640: 100%|██████████| 9/9 [00:09<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         34       1217      0.941      0.985       0.98      0.833       0.94      0.983       0.98      0.603\n",
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217      0.943       0.98      0.979       0.83      0.943      0.979      0.979      0.623\n",
      "                 berry         34       1217      0.943       0.98      0.979       0.83      0.943      0.979      0.979      0.623\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "                   all         36       1095      0.897      0.966      0.969      0.822      0.895      0.964      0.968        0.6\n",
      "                 berry         36       1095      0.897      0.966      0.969      0.822      0.895      0.964      0.968        0.6\n",
      "Speed: 0.4ms preprocess, 10.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 94.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.76G     0.7103     0.9986     0.6185     0.8082        506        640: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n",
      "                   all         34       1217      0.936      0.984      0.975      0.827      0.934      0.982      0.975      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.41G     0.6487     0.6113     0.5671     0.7907        530        640: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n",
      "                   all         34       1217      0.936      0.984      0.976      0.827      0.934      0.982      0.976      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.77G     0.5636     0.4982     0.5328     0.7779        526        640: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n",
      "                   all         34       1217      0.937      0.983      0.976      0.828      0.935      0.981      0.976      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.55G     0.5639     0.6069     0.5724     0.7861        330        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]\n",
      "                   all         34       1217      0.938      0.984      0.977      0.828      0.936      0.982      0.976      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.06G     0.5658     0.5258      0.497     0.7997        490        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.57it/s]\n",
      "                   all         34       1217       0.94       0.98      0.977      0.828      0.939      0.979      0.977      0.603\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.69it/s]\n",
      "                   all         34       1217      0.938      0.983      0.976      0.828      0.936      0.981      0.976      0.604\n",
      "                 berry         34       1217      0.938      0.983      0.976      0.828      0.936      0.981      0.976      0.604\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "                   all         36       1095      0.885      0.972      0.959      0.797      0.883       0.97      0.958       0.57\n",
      "                 berry         36       1095      0.885      0.972      0.959      0.797      0.883       0.97      0.958       0.57\n",
      "Speed: 0.2ms preprocess, 9.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:01<00:00, 72.88it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.9G      1.185       1.45      3.923     0.8934        680        640: 100%|██████████| 9/9 [00:11<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n",
      "                   all         34       1217      0.849      0.845      0.838      0.688      0.847      0.843      0.836      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.6G      0.741     0.8584     0.9939     0.8238        730        640: 100%|██████████| 9/9 [00:10<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         34       1217      0.888      0.986      0.964       0.79      0.886      0.984      0.964      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.79G     0.6944     0.6303     0.5843     0.8037        721        640: 100%|██████████| 9/9 [00:10<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         34       1217      0.933      0.977      0.971      0.811      0.929      0.973       0.97      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.4G     0.6773     0.5965     0.5603     0.7965       1424        640: 100%|██████████| 9/9 [00:10<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n",
      "                   all         34       1217      0.931      0.983      0.971      0.815      0.928       0.98       0.97       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.84G     0.6219      0.577     0.5181     0.7974       1044        640: 100%|██████████| 9/9 [00:10<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         34       1217      0.934      0.985      0.978      0.827       0.93      0.981      0.975      0.572\n",
      "\n",
      "5 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "                   all         34       1217      0.888      0.986      0.964      0.789      0.886      0.984      0.963      0.613\n",
      "                 berry         34       1217      0.888      0.986      0.964      0.789      0.886      0.984      0.963      0.613\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                   all         36       1095       0.83      0.992      0.943      0.751      0.828      0.989      0.942      0.578\n",
      "                 berry         36       1095       0.83      0.992      0.943      0.751      0.828      0.989      0.942      0.578\n",
      "Speed: 0.2ms preprocess, 10.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 93.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.05G     0.7767     0.6411     0.4656     0.7899        769        640: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         34       1217      0.932      0.987      0.972      0.817      0.929      0.984       0.97      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.91G      0.781     0.6519     0.4602     0.8152        827        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n",
      "                   all         34       1217      0.931      0.987      0.971       0.82      0.929      0.985       0.97      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.15G     0.7774     0.6693     0.4674     0.8033        963        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n",
      "                   all         34       1217      0.932      0.987      0.972      0.821      0.929      0.983       0.97      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.54G     0.6592      0.712     0.4911      0.814        680        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.21it/s]\n",
      "                   all         34       1217      0.933      0.985      0.972       0.82       0.93      0.983       0.97      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.73G     0.7426      0.771     0.4956     0.8271        734        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "                   all         34       1217      0.934      0.984      0.973      0.823      0.931      0.982      0.971      0.576\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.59it/s]\n",
      "                   all         34       1217      0.933      0.985      0.973      0.822      0.931      0.982      0.971      0.577\n",
      "                 berry         34       1217      0.933      0.985      0.973      0.822      0.931      0.982      0.971      0.577\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                   all         36       1095      0.885      0.968      0.955      0.786      0.883      0.966      0.954      0.545\n",
      "                 berry         36       1095      0.885      0.968      0.955      0.786      0.883      0.966      0.954      0.545\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:02<00:00, 74.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.62G        1.1      1.494      3.806     0.8883        567        640: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         34       1217      0.854      0.957      0.857      0.697      0.853      0.955      0.856       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.3G     0.6781     0.7677     0.7375     0.8211        429        640: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         34       1217      0.881      0.996      0.962      0.788      0.877      0.992      0.961      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.2G     0.6887     0.5938     0.5571     0.8021        471        640: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217      0.925      0.981      0.972      0.782      0.923      0.979      0.972      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G     0.6984     0.6014     0.5918      0.798        569        640: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n",
      "                   all         34       1217      0.939      0.981      0.978      0.791      0.936      0.978      0.975      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        10G     0.6516     0.5489     0.4912     0.7959        559        640: 100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         34       1217      0.907      0.979      0.976       0.82      0.905      0.976      0.976      0.582\n",
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "                   all         34       1217      0.907      0.979      0.976      0.821      0.905      0.976      0.976      0.583\n",
      "                 berry         34       1217      0.907      0.979      0.976      0.821      0.905      0.976      0.976      0.583\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                   all         36       1095      0.857      0.967      0.946      0.781      0.857      0.966      0.944      0.552\n",
      "                 berry         36       1095      0.857      0.967      0.946      0.781      0.857      0.966      0.944      0.552\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 44.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.45G     0.6089     0.5821     0.5097     0.8043        813        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "                   all         34       1217      0.918      0.976      0.978      0.828      0.916      0.974      0.977      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.96G     0.6349     0.5476     0.4868     0.8079        662        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.66it/s]\n",
      "                   all         34       1217      0.917      0.976      0.978      0.829      0.915      0.974      0.976      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.55G     0.5609     0.5282     0.4713     0.8031        918        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "                   all         34       1217      0.913      0.977      0.978      0.828      0.911      0.974      0.976      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.33G      0.587     0.5677     0.4686     0.8123        616        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         34       1217      0.913      0.976      0.978      0.827       0.91      0.974      0.976      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.56G     0.5468     0.5011      0.468     0.7957        658        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         34       1217      0.913      0.977      0.978      0.829      0.911      0.975      0.976      0.588\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.62it/s]\n",
      "                   all         34       1217      0.918      0.976      0.978      0.829      0.916      0.974      0.977      0.589\n",
      "                 berry         34       1217      0.918      0.976      0.978      0.829      0.916      0.974      0.977      0.589\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "                   all         36       1095      0.854       0.97      0.941      0.784      0.852      0.968       0.94       0.55\n",
      "                 berry         36       1095      0.854       0.97      0.941      0.784      0.852      0.968       0.94       0.55\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:02<00:00, 71.05it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G       1.06      1.354      3.497     0.8811         12        640: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         34       1217      0.863      0.975      0.862      0.678      0.861      0.973      0.861      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      11.1G     0.6776      0.741      0.708     0.8202        117        640: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         34       1217      0.929      0.976      0.971      0.809      0.924      0.971       0.97      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.9G     0.7081     0.5928     0.6368     0.8036         23        640: 100%|██████████| 11/11 [00:11<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         34       1217      0.946      0.982      0.976       0.82      0.944      0.979      0.975      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        10G     0.7642     0.6367     0.5447     0.7986         42        640: 100%|██████████| 11/11 [00:10<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                   all         34       1217      0.902       0.98      0.971      0.818      0.902      0.978       0.97      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.84G     0.6257     0.5591     0.4732     0.7933        109        640: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217      0.932      0.968      0.983      0.817      0.932      0.964      0.982      0.605\n",
      "\n",
      "5 epochs completed in 0.032 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.61it/s]\n",
      "                   all         34       1217      0.946      0.981      0.976      0.819      0.944      0.978      0.975      0.621\n",
      "                 berry         34       1217      0.946      0.981      0.976      0.819      0.944      0.978      0.975      0.621\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
      "                   all         36       1095       0.88       0.98      0.957      0.808      0.879      0.979      0.957      0.589\n",
      "                 berry         36       1095       0.88       0.98      0.957      0.808      0.879      0.979      0.957      0.589\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 128.88it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.99G     0.5766     0.5121     0.6396     0.7923        468        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n",
      "                   all         34       1217      0.926      0.985      0.972      0.809      0.924      0.984      0.972      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.43G     0.5973     0.4667     0.7935     0.7904        484        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "                   all         34       1217      0.927      0.985      0.972      0.809      0.926      0.984      0.972      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.98G     0.6286     0.5363     0.5621     0.7922        662        640: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.73it/s]\n",
      "                   all         34       1217      0.928      0.984      0.972       0.81      0.926      0.983      0.972      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.83G     0.6533     0.6942     0.6531      0.808        407        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n",
      "                   all         34       1217      0.927      0.984      0.973      0.811      0.926      0.983      0.972      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.69G     0.6754     0.6225     0.5827     0.8305        431        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.25it/s]\n",
      "                   all         34       1217      0.929      0.983      0.974      0.812      0.928      0.981      0.973      0.607\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]\n",
      "                   all         34       1217      0.927      0.985      0.972       0.81      0.926      0.984      0.972      0.611\n",
      "                 berry         34       1217      0.927      0.985      0.972       0.81      0.926      0.984      0.972      0.611\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         36       1095      0.866       0.98       0.94      0.768      0.865      0.979       0.94      0.584\n",
      "                 berry         36       1095      0.866       0.98       0.94      0.768      0.865      0.979       0.94      0.584\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:02<00:00, 73.40it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.62G      1.154      1.468      3.768     0.8947        649        640: 100%|██████████| 11/11 [00:12<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.49it/s]\n",
      "                   all         34       1217      0.856      0.977      0.868      0.689      0.855      0.976      0.867      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        11G     0.7059     0.7377     0.7247     0.8139        877        640: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         34       1217      0.936      0.979      0.975      0.824      0.933      0.976      0.974      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.3G     0.6783     0.5963      0.572     0.8032        718        640: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         34       1217      0.943      0.981      0.972      0.765      0.939      0.977       0.97      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G     0.7171     0.5948      0.544     0.8002        792        640: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                   all         34       1217      0.923      0.979      0.983      0.824      0.923      0.979      0.983      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.2G     0.6405     0.5724     0.4965     0.7952        648        640: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "                   all         34       1217      0.936      0.977      0.985      0.815      0.938      0.976      0.985       0.65\n",
      "\n",
      "5 epochs completed in 0.033 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]\n",
      "                   all         34       1217      0.936      0.977      0.985      0.815      0.936      0.977      0.985       0.65\n",
      "                 berry         34       1217      0.936      0.977      0.985      0.815      0.936      0.977      0.985       0.65\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "                   all         36       1095      0.904      0.951      0.973      0.804      0.904      0.951      0.973      0.623\n",
      "                 berry         36       1095      0.904      0.951      0.973      0.804      0.904      0.951      0.973      0.623\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 82.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.94G     0.5516     0.5349     0.5205     0.7828        494        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n",
      "                   all         34       1217      0.932      0.979      0.978      0.812      0.932      0.979      0.978      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.98G      0.573     0.5788     0.5161     0.8187        590        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n",
      "                   all         34       1217      0.933      0.978      0.979      0.813      0.934      0.976      0.979      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.98G     0.5232     0.4799     0.4441     0.7848        670        640: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n",
      "                   all         34       1217      0.935      0.976       0.98      0.813      0.935      0.976       0.98      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.72G     0.4373     0.4471     0.5062     0.7934        404        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                   all         34       1217      0.936      0.976       0.98      0.815      0.936      0.976       0.98       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.86G     0.5523     0.5093     0.4794     0.8102        430        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "                   all         34       1217      0.937      0.976      0.981      0.812      0.937      0.976      0.981       0.65\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]\n",
      "                   all         34       1217      0.931      0.979      0.978      0.812      0.932      0.978      0.978      0.655\n",
      "                 berry         34       1217      0.931      0.979      0.978      0.812      0.932      0.978      0.978      0.655\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         36       1095       0.88      0.969      0.958      0.805      0.879      0.968      0.958      0.616\n",
      "                 berry         36       1095       0.88      0.969      0.958      0.805      0.879      0.968      0.958      0.616\n",
      "Speed: 0.1ms preprocess, 10.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:02<00:00, 74.83it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.5G      1.047      1.382      3.368     0.8809        446        640: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         34       1217      0.867       0.94      0.874      0.679      0.867      0.939      0.873      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.8G     0.6968     0.6695     0.7148     0.8092        341        640: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                   all         34       1217      0.933      0.983      0.971      0.791      0.931      0.981      0.971      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.7G     0.6886     0.6135     0.5971     0.7994        281        640: 100%|██████████| 12/12 [00:12<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217      0.941      0.975      0.975      0.766      0.939      0.973      0.975      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.1G     0.6965     0.6006       0.53     0.7987        421        640: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         34       1217      0.898      0.986      0.974      0.799      0.899      0.984      0.974      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.7G     0.6585      0.567      0.476     0.7973        265        640: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         34       1217      0.938      0.983      0.983      0.825      0.935      0.979      0.982      0.603\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "                   all         34       1217      0.938      0.983      0.983      0.826      0.935      0.979      0.982      0.603\n",
      "                 berry         34       1217      0.938      0.983      0.983      0.826      0.935      0.979      0.982      0.603\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         36       1095      0.918      0.954      0.974      0.783      0.917      0.953      0.972      0.577\n",
      "                 berry         36       1095      0.918      0.954      0.974      0.783      0.917      0.953      0.972      0.577\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 66.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.51G     0.5228     0.4753     0.5718     0.7922        319        640: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "                   all         34       1217      0.937      0.992      0.976      0.825      0.934      0.989      0.975        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      0.637      0.495     0.9457     0.7678        302        640: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         34       1217      0.937      0.991      0.976      0.827      0.934      0.987      0.975        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.67G     0.5558     0.4565     0.5503     0.7829        382        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n",
      "                   all         34       1217      0.937       0.99      0.977      0.825      0.934      0.987      0.976      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.32G     0.4788     0.4032     0.5903     0.8105        239        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n",
      "                   all         34       1217      0.939       0.99      0.977      0.827      0.936      0.987      0.976      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.61G     0.4933     0.4026     0.4956     0.8193        299        640: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n",
      "                   all         34       1217       0.94       0.99      0.978      0.827      0.936      0.987      0.977        0.6\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]\n",
      "                   all         34       1217       0.94       0.99      0.978      0.827      0.936      0.987      0.977      0.599\n",
      "                 berry         34       1217       0.94       0.99      0.978      0.827      0.936      0.987      0.977      0.599\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n",
      "                   all         36       1095      0.891      0.975      0.963      0.789       0.89      0.974      0.962      0.576\n",
      "                 berry         36       1095      0.891      0.975      0.963      0.789       0.89      0.974      0.962      0.576\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:02<00:00, 73.96it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G     0.9837      1.318      3.314     0.8776        941        640: 100%|██████████| 12/12 [00:15<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         34       1217      0.875      0.938      0.873      0.721      0.874      0.938      0.872      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        11G     0.6586     0.6426     0.6612     0.8099        730        640: 100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n",
      "                   all         34       1217      0.926      0.985      0.973      0.763      0.924      0.985      0.972      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.6G     0.6845     0.6307     0.5785     0.8027       1364        640: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "                   all         34       1217      0.938      0.979      0.982       0.78      0.936      0.978      0.981      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G     0.7092     0.5929     0.5545     0.7991       1082        640: 100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                   all         34       1217      0.917      0.979       0.98      0.794      0.915      0.977       0.98      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.71G     0.6535     0.5454     0.4886     0.7947       1020        640: 100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         34       1217      0.941      0.987      0.985        0.8       0.94      0.986      0.985      0.649\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.71it/s]\n",
      "                   all         34       1217      0.941      0.987      0.985        0.8       0.94      0.986      0.985       0.65\n",
      "                 berry         34       1217      0.941      0.987      0.985        0.8       0.94      0.986      0.985       0.65\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "                   all         36       1095      0.914      0.959      0.978      0.762      0.913      0.959      0.977      0.612\n",
      "                 berry         36       1095      0.914      0.959      0.978      0.762      0.913      0.959      0.977      0.612\n",
      "Speed: 0.2ms preprocess, 10.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 63.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.98G     0.5509     0.5422     0.4786      0.785        513        640: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n",
      "                   all         34       1217       0.94       0.99      0.979       0.79      0.939      0.989      0.979      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.53G     0.6625      0.645     0.5548     0.8033        516        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.57it/s]\n",
      "                   all         34       1217       0.94      0.991       0.98       0.79      0.939       0.99      0.979      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       8.3G      0.686     0.6707     0.4618     0.8043        717        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.61it/s]\n",
      "                   all         34       1217      0.939      0.993       0.98      0.792      0.938      0.993       0.98      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.92G     0.5982     0.6211      0.493     0.8038        432        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         34       1217      0.939      0.993      0.981      0.793      0.938      0.993      0.981      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.11G     0.6122     0.6059      0.465     0.8181        495        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         34       1217      0.939      0.993      0.981      0.798      0.939      0.992      0.981      0.648\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "                   all         34       1217      0.939      0.993      0.981      0.798      0.938      0.992      0.981      0.648\n",
      "                 berry         34       1217      0.939      0.993      0.981      0.798      0.938      0.992      0.981      0.648\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         36       1095       0.91      0.963      0.974      0.772      0.909      0.963      0.973      0.611\n",
      "                 berry         36       1095       0.91      0.963      0.974      0.772      0.909      0.963      0.973      0.611\n",
      "Speed: 0.1ms preprocess, 9.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:02<00:00, 73.14it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        11G     0.9818      1.282      3.122     0.8732        673        640: 100%|██████████| 13/13 [00:15<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                   all         34       1217      0.866      0.965       0.87       0.73      0.865      0.963      0.868       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      11.2G     0.6735      0.648     0.6497      0.806        428        640: 100%|██████████| 13/13 [00:14<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                   all         34       1217      0.923      0.971      0.978      0.818      0.918      0.967      0.976       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.8G     0.6917     0.6136     0.5468     0.7974        529        640: 100%|██████████| 13/13 [00:14<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         34       1217      0.906      0.983      0.972      0.765      0.908      0.981      0.972       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.7G     0.7046     0.5599     0.5337     0.7982        376        640: 100%|██████████| 13/13 [00:14<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         34       1217      0.949      0.979      0.983      0.807      0.947      0.977      0.983      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.6G     0.6218     0.5313     0.4986     0.7936        543        640: 100%|██████████| 13/13 [00:15<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         34       1217      0.937      0.979      0.986      0.827      0.933      0.976      0.985      0.592\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "                   all         34       1217      0.906      0.985      0.972      0.764      0.908      0.981      0.972       0.66\n",
      "                 berry         34       1217      0.906      0.985      0.972      0.764      0.908      0.981      0.972       0.66\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095      0.843      0.968      0.938      0.743      0.843      0.967      0.937      0.622\n",
      "                 berry         36       1095      0.843      0.968      0.938      0.743      0.843      0.967      0.937      0.622\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 56.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G     0.6141     0.5524     0.6399      0.799         61        640: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n",
      "                   all         34       1217      0.946      0.974      0.982      0.824      0.943      0.971       0.98      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.5G     0.6315     0.6683     0.5047     0.8142         62        640: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "                   all         34       1217       0.95      0.972      0.984      0.815      0.949      0.971      0.983      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.38G     0.5979     0.5826     0.5181     0.7854         60        640: 100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         34       1217       0.95      0.973      0.984      0.834      0.949      0.971      0.984      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.31G     0.5926     0.4739     0.5572     0.7944         65        640: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]\n",
      "                   all         34       1217      0.947      0.979      0.984      0.807      0.946      0.977      0.983      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.7G     0.6141     0.4993     0.4692     0.8008         51        640: 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         34       1217      0.951      0.976      0.984      0.829      0.952      0.976      0.984      0.622\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.59it/s]\n",
      "                   all         34       1217       0.95      0.973      0.984      0.833      0.949      0.971      0.984       0.62\n",
      "                 berry         34       1217       0.95      0.973      0.984      0.833      0.949      0.971      0.984       0.62\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "                   all         36       1095      0.928      0.936      0.972      0.813      0.927      0.934      0.969      0.593\n",
      "                 berry         36       1095      0.928      0.936      0.972      0.813      0.927      0.934      0.969      0.593\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 251 images, 0 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:03<00:00, 67.71it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.7G     0.9868      1.256      2.739     0.8651        918        640: 100%|██████████| 16/16 [00:21<00:00,  1.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         34       1217      0.874      0.993      0.946      0.757      0.871      0.991      0.945      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G     0.6983     0.5927     0.6267     0.8044        665        640: 100%|██████████| 16/16 [00:19<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         34       1217      0.935      0.979       0.97      0.805      0.935      0.979       0.97      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.8G     0.7487     0.6024     0.5486     0.8005        874        640: 100%|██████████| 16/16 [00:19<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         34       1217      0.946      0.986      0.977      0.794      0.946      0.986      0.977      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      0.705     0.5694     0.5172     0.8008        710        640: 100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         34       1217       0.93      0.985      0.981      0.738      0.929      0.983       0.98      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.3G     0.6498     0.5226      0.481     0.7927        707        640: 100%|██████████| 16/16 [00:24<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.11it/s]\n",
      "                   all         34       1217      0.949      0.992      0.984      0.854      0.947       0.99      0.982      0.632\n",
      "\n",
      "5 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]\n",
      "                   all         34       1217      0.949      0.992      0.984      0.855      0.947       0.99      0.982      0.632\n",
      "                 berry         34       1217      0.949      0.992      0.984      0.855      0.947       0.99      0.982      0.632\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "                   all         36       1095      0.931      0.963      0.979      0.837       0.93      0.962      0.978      0.606\n",
      "                 berry         36       1095      0.931      0.963      0.979      0.837       0.93      0.962      0.978      0.606\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_38/train/labels... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<00:00, 51.96it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_0_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G     0.6274     0.5491     0.4643     0.7978        998        640: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         34       1217      0.948      0.988      0.976      0.841      0.946      0.986      0.974      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.2G     0.6093     0.5549     0.4738     0.8012        747        640: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         34       1217      0.947      0.989      0.977      0.844      0.945      0.987      0.976      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.3G     0.6004     0.5439       0.45     0.8045       1271        640: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "                   all         34       1217      0.948      0.988      0.979      0.849      0.946      0.987      0.977      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.48G     0.5985     0.5546     0.4227     0.8007        946        640: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "                   all         34       1217      0.947      0.988       0.98      0.849      0.946      0.987      0.979       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      11.1G     0.6091     0.5547     0.4128     0.8018       1026        640: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         34       1217      0.948      0.989      0.981      0.841      0.946      0.988       0.98      0.614\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
      "                   all         34       1217      0.948      0.988      0.979       0.85      0.946      0.987      0.977      0.629\n",
      "                 berry         34       1217      0.948      0.988      0.979       0.85      0.946      0.987      0.977      0.629\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "                   all         36       1095      0.913      0.969      0.973      0.832      0.912      0.968      0.973      0.595\n",
      "                 berry         36       1095      0.913      0.969      0.973      0.832      0.912      0.968      0.973      0.595\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 280 images, 0 backgrounds, 0 corrupt: 100%|██████████| 280/280 [00:04<00:00, 66.20it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_0/labels.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.82G     0.9437      1.174      2.452     0.8642        704        640: 100%|██████████| 18/18 [00:24<00:00,  1.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "                   all         34       1217      0.853      0.999       0.96      0.797      0.853      0.998      0.959      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.87G      0.723     0.6473     0.5878      0.804        698        640: 100%|██████████| 18/18 [00:23<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         34       1217        0.9      0.973      0.972      0.764      0.896       0.97      0.969      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.6G     0.7782     0.6087     0.5738     0.7981        384        640: 100%|██████████| 18/18 [00:27<00:00,  1.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         34       1217      0.946      0.981      0.983      0.818      0.946       0.98      0.983      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.6G     0.7161     0.5502       0.52     0.7981        497        640: 100%|██████████| 18/18 [00:21<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "                   all         34       1217      0.952       0.97      0.986      0.809       0.95      0.967      0.986      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.2G     0.6766     0.5199     0.4667     0.7981        562        640: 100%|██████████| 18/18 [00:27<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                   all         34       1217      0.952      0.988      0.987      0.843      0.949      0.984      0.985      0.603\n",
      "\n",
      "5 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.66it/s]\n",
      "                   all         34       1217      0.946      0.984      0.983      0.818      0.945      0.983      0.983      0.664\n",
      "                 berry         34       1217      0.946      0.984      0.983      0.818      0.945      0.983      0.983      0.664\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_0/labels.cache... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         36       1095      0.928      0.943      0.973      0.827      0.928      0.943      0.973      0.637\n",
      "                 berry         36       1095      0.928      0.943      0.973      0.827      0.928      0.943      0.973      0.637\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.6ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 0: \n",
      " defaultdict(<class 'list'>, {0: [0.04222117151805566, 0.06454937361026782, 0.04580205441796008], 1: [0.058247236319687624, 0.08650369893662646, 0.06454507038705676], 2: [0.06749691243416799, 0.10043927754317075, 0.07587152012791162], 3: [0.06774833002606961, 0.10049071702150944, 0.07766549925813114], 4: [0.07186036392833245, 0.10469857087265788, 0.08204894339894642], 5: [0.07475674355382636, 0.1059332833195429, 0.08843973264446697], 6: [0.03745573342958251, 0.05838554402213461, 0.04080899304818333], 7: [0.14669088544718661, 0.2213653245730803, 0.16673691050071096], 8: [0.18565000139122978, 0.2832048801522213, 0.2085648281872106], 9: [0.20283050322084484, 0.3148964051232078, 0.2250637636829027], 10: [0.23941975553713046, 0.36590017751466297, 0.2752142014866066], 11: [0.24683663116476806, 0.3776377694800298, 0.2867113847456694], 12: [0.24884135219347486, 0.38121327740753863, 0.28857597881268066], 13: [0.4491903602416049, 0.8168674338454872, 0.4089750680899761], 14: [0.45398983826574835, 0.8113734941403874, 0.42155627699379056], 15: [0.4582198405091031, 0.8089827406303743, 0.4362760557376596], 16: [0.46911827704814335, 0.808507220512066, 0.46649310937110955], 17: [0.47202330562374806, 0.8043203265925689, 0.4753333248511164], 18: [0.5529562492472835, 0.9368513146813511, 0.55622660472665], 19: [0.5699667001638326, 0.9354103848699858, 0.5993547526945457], 20: [0.5596846769218865, 0.9342819213960775, 0.5763921964441359], 21: [0.5724011716664197, 0.946964002781038, 0.5959150962644275], 22: [0.5620281486352682, 0.9501956186807141, 0.5645551470641458], 23: [0.5902023662134426, 0.9520635366208277, 0.6346109353663545], 24: [0.5578695526245203, 0.9596615257654747, 0.5478070784552801], 25: [0.5707737449322972, 0.9605640997725484, 0.5803392875149785], 26: [0.5453402999457297, 0.9574119641395804, 0.5238220793901193], 27: [0.5797230010250409, 0.9471384033548604, 0.6181334186124748], 28: [0.5997687436914168, 0.9681053708203824, 0.6592762000072573], 29: [0.5784156918809966, 0.9418430985437255, 0.6179130295616062], 30: [0.5518458819734249, 0.9444865087788062, 0.5504889036264621], 31: [0.5893262090689075, 0.9566875098625617, 0.6404221926889666], 32: [0.6226993752900085, 0.9726576335881865, 0.7017458506298049], 33: [0.577180135522618, 0.9724666502299703, 0.5838384428871294], 34: [0.6119892363397152, 0.977457769519531, 0.675273283592222], 35: [0.6215163869964062, 0.9374871631402221, 0.7259821444720629], 36: [0.6058992970023935, 0.9777800842727011, 0.651842551629809], 37: [0.6365308253642393, 0.9733757307276352, 0.7151974942843553]})\n",
      "Количество данных (train) для класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 280]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABriElEQVR4nO3dd3gUVdsG8Htma3pIb0CQXgRCFZCihqJ+CKiAilJEkaYoFkBFrBQLIjYUQdRXAUVApIoIKhpBkEjvJQgp1PRsPd8fw06ypJBGdrO5f165TKY+W9h59pznnJGEEAJEREREHkJ2dQBERERElYnJDREREXkUJjdERETkUZjcEBERkUdhckNEREQehckNEREReRQmN0RERORRtK4OoKrZ7XacPXsWfn5+kCTJ1eEQERFRKQghkJmZiaioKMhyyW0zNS65OXv2LGrXru3qMIiIiKgcTp8+jZiYmBK3qXHJjZ+fHwDlyfH393dxNERERFQaGRkZqF27tnodL0mNS24cXVH+/v5MboiIiKqZ0pSUsKCYiIiIPAqTGyIiIvIoLk1ufvvtN/Tt2xdRUVGQJAkrV6685j5btmxBmzZtYDAY0KBBAyxatOi6x0lERETVh0uTm+zsbLRq1QoffvhhqbY/ceIE7rzzTtxyyy1ITEzEk08+iUceeQQbNmy4zpESERFRdeHSguLbb78dt99+e6m3nzdvHurVq4d33nkHANC0aVNs3boV7777Lnr37n29wiQiIqJqpFrV3CQkJCA+Pt5pWe/evZGQkFDsPiaTCRkZGU4/RERE5LmqVXKTkpKC8PBwp2Xh4eHIyMhAbm5ukfvMmDEDAQEB6g8n8CMiIvJs1Sq5KY8pU6YgPT1d/Tl9+rSrQyIiIqLrqFpN4hcREYHU1FSnZampqfD394eXl1eR+xgMBhgMhqoIj4iIiNxAtWq56dSpEzZt2uS0bOPGjejUqZOLIiIi8gw5OcBnnwE9egAtWgD9+wNr1wJ2u6sjqzmsVmDRIqBDByAwEIiJAZ57DvjvP1dHVv1IQgjhqpNnZWXh6NGjAIC4uDjMnj0bt9xyC4KCglCnTh1MmTIFZ86cwZdffglAGQreokULjBs3Dg8//DB++eUXPPHEE1izZk2pR0tlZGQgICAA6enpvP0CEbmd7GxAloFiGqOvi+RkJak5fBiQJEAIQKMBbDbgnnuAJUsAbbVq569+zGagXz9g/Xrl9XcklRoN4OsL/PIL0KaNa2MsjYMHlR9fX6BrV6AyO07Kcv12acvNjh07EBcXh7i4OADAxIkTERcXh5deegkAkJycjKSkJHX7evXqYc2aNdi4cSNatWqFd955B5999hmHgRNRtWa3AwsWAM2bKxcFb2+gUydgxYrSH2P7dmDwYGVfnQ5o1w746qvStbwMGgQcP6787vi6a7Mp/1++HHj99bI9Hiq7GTOAn35Sfi/4mtlsQFaWkvhYra6JrTQOHAC6dQOaNgUGDAB69gQiIoC3385/T1Ull7bcuAJbbojcU1ISsGWL8mHeuTPQuLGrI6oaQgCPPAIsXJjfagLkf3t/9VVg6tSSj7FkCTBkiLKP4wLo2H/IEODLL5W/i7Jr17VbBAIDgZSUyv0WTvksFiAqCjh/3rFEQPY2A5KAsGggbDJgk7FypYR+/VwZadGOHVOS6czM/KS4oOefB954o+LnKcv1m8kNEblUejrw6KPAsmXO3/Buu025KEdFuS62qrBiBXD33SVvs2sX0Lp10etSUoA6dZQLZHE+/xwYPlz53Wy1IzUjD8npeUhOz8XSH/Pw09ZcyD550PjnQuuXBwgJlzY3Rfb+aPUYO3YAbduW6aFRKeRZbNi8MwsDR2VAH5oJfVgGdKEZ0Hg7v6BCAFpJA39vGQatBkadDKNOA4NOA4NW+d145f/q3zrnvw1FbqNsV/CYRq0GBp0Mg1Yu1R24H3pISbCLa1mSJOXLS0xMxZ6rsly/2YtKRC5jsQC9eysXzqu/Zv36q9Jn/88/QECAa+KrCh98kF/fAgDawGxo/PIAAQASNBrgjU+ByZOUvyUJkABIkgQJSuIih0jQ2wu0+uhs0PjlQeufC61/Ht74NQ8rsnJxNj0P57NMhZ5r37jCcYX0TYTsY0Lm3zcAYGFxRQkhkJphwoHkDBxIycCB5EwcTM7A8fPZsNkFQu64envl/47cQpIAG2y4lGMDUEImW8kM10iYtJIGP2XKCOilgbDKEFYNhEWGNd0bWbvrAFBaDb/6CpgypcrCZnJDVB2YzcCffyrNvo0bA40aOa//+2/gm2+ACxeA2FjlW/oNN7gi0rJZvhzYtq3odVYrcPKkMoLn6aerNKwqlZgICGMe/JqehU/zMzBEFJ5F/W8A93xc/DEihpZ8DguAfwuMuNFrZEQEGBEZYITO4oU13xlhzTTCluEFa6YRvi3OwL/9CQTdegBa3zxY/m6K5s2v/Q2eFHkWG46kZl1JYjJwMDkTB1IycDmn6KQk0EuHyyf9kXHaD+Y0f1jS/GG54AthlQGNHZLWDllrw5Lv7GjVxoY8ix15VhtMFjvyLDbkWZVlpiv/z7PYYLLYYLJeWV9we6tNXWay2mGyXPnb8bvVDps9P/s1WZXtSuLVpIjn4EygU3JT1SO+mNwQuTEhlG/2r75asD9eadH45BMlkXngAWDlSmU0i+Pb3uuvAy+8oOxXilZl5OYq3SMnTgBBQcoImbCw6/GInH3xRX6rhaSzwqfFf5A0AlmJdSCsGtjtSi1KdUluzp9X6g/8/JTCypKe+2yTFT/tT4HPnWfhG3EO0pWaGGGTYL3snb+hBHh5CUTHKK+vgFD+L5TWgPMXgJxc4EpTj9KsY5WVZCXTC9YMI0SOF5YuNCIq0AuRgUYE++jV7gYhgDYLgL1787sVLv3iD1uWAbVuOQj/DidQp50JWn0rVLPZQ647IQRSMvJwMDkT+5MzcDAlEweSM3DiSmvM1TSyhBtCfNA00h9NIv3QNNIfTSP8Ee5vwLx5EsYuKuIkNg00kgYtmupwT5/S/XuuKIvtSoJUMDm68repQDKVZ7EhI8uOJ5+2QWjskLQ2SFrl/9aM/OF+drtSXFyVWHND5MZeew24MnjQiWN46C23AKtWFd9l8MEHwLhxJZ/jm2+AMWOAjAwlQbLZlOM/9RQwc2bxhaiVIS4O2H3QDL82p+DX9oRaZ2C97IWLm5oh92g4goIkXLhw/WKoDKdPA888A3z/fX73UsOGSnJ5333521ltdmw9eh4rd53Bhn2pyLXkV1/mnQlE9r5o5ByMgj1Xry6XJODdd4EJE4o+96JFwIgRxcem1QJ33AH88EPx2xw7BnTvrgwJd7yXZBnwavofQu7YDcgCXRuG4OMH28LXUDO/E+dZbDicmlkgkVGSmeJaY2p565QkJsIfTa8kMg3CfGHUaYrcXgjgySeBuXOV18xqzS8Kr18f2LwZcNe7Bw0erLTCllRzc+wYUK9exc7DguISMLkhd/TPP8Dq1YDJpBSO9usHXLyoFOAVNfoAcK7TKE5kpHLh1RT9eYpVq1Ds6AtJUiYQmzmz1A+jTFIz8vB/Tx9Hql8SZL3yQCyXvCFp7UpRK4Dc46EIO9MMe/7wvT5BVIKzZ5WRIufOOX+4O0Y+zZ0r0GNABpbv+g8//nsW57PM6jaxwd7oXjcasydEIyfNp1CSqtEoLWmHDysjloqSmws0aACkphb9fpCk/Pqlkly8CMyfr7SmXbyoXFAfewyIbpeGx5f8gxyzDTdGB2Dh8PYI9fPcYVNCCCSn5+HglbqYA8kZamtMEY0x0MgS6of6XElilBaZZpH+CPMzlKoY92p//aW0yh44oLzmgwcrCXJVzntUVvv3KxMP5uUVfg9KkvIF6/33K34eJjclYHJDVe3oUeCjj4B165R/+F27AuPHK60Wly4BAwcCmzYpFzJZVopsQ0OBe+9VPuTsdgCyHcbY8zBEXYass0LS2dQfWWdTmoN1NkgaO+x5OvXHlqvH2JE6NG+oR6C3DoFeOgR6K78HeOnQvo0GBw9Ixc5DodUq3+ZDQirv+Th5Phuf/HYM3+88A7NNuZqb0/yQ/ld95ByMhKS1I6DTUfi3P6HUGkDCo93r4fFbG7plq8EjjygJwdXfWrUBOfBudga+zc9AF5ytLg/y0aNvy0j0j4tG69qBkCQJW7YoSWZmpvIekCTleFFRwIYNyozBJdm/H4iPV14rx7d9R0L72Wf5I6XK69/TlzFi0d+4mG1G3WBvfPlwB9QN9qnYQd2AozVGSWCU/x9MyUR6bsmtMUqLzLVbY2qSnTuBYcOAffvylxmNSpfyK68U/wWrLJjclIDJDVW2jAxlJMAffygXlltvVb5peXsrLSP33qtcbNTRMFe6ft57D1i8WJl87epvO7IMSLIdxjoXYWh0Ft6NUqDxqvwREsIqw5angz1XB3ueHvZcHcxp/jCdqQXT2VqARYtPPlGGapfkxAng00+VDzijEfi//1NqgXwLNLjsO5uOj7ccw9o9yeo34LZ1ayF1c30kfB8Gu935W64hOBsxd+2DNewcACDc34Dn72iKu1pFlesb8fWQk6O0rJhMyt8av1x41U+DT7MzMNa+pG6ngYw7WkVgQFwUujYMhU5TuK8vKwv4+mulcFyjUZKVe+4p/dwyOTnKcNw1a5Rv0G3bKq9bZXVlnDifjaELt+H0xVyE+Orx+fAOuDGmegxjc7TGOJKX/ckZOHiN1pgGob5qXYwjkSlva0xNIYTyeXbggPJvv1cvoDIvs0xuSsDkhirT5s3KN+6srPzaFJtNaelYtEiZv8RiKcsMnQKG6EvwbnoWPk2SofHJ78KwZRmQezwUthz9leGWGtgtyv+FRQthkSHsMmSjRf3Reptx/3AL8uwWpOeacTnHgsu5FlzOMcNiKzkoYQcs5/3RpnYtjLo7CO3q1kJUYOG28fnzgdGjrwxVteV3x4SHKy1S2d4X8dGWo9hy6Jy6zy2NQzH2lgZoHxuEvDzg2WeVFoY8pTcKWq3SHP/BB8DO5FS88uN+JF3MAQB0iA3CK/2ao2lk5f37tduVae8XLVJGdcTEKK0dffqUXHO0/7AV7W6/AGO98/Cqd86phUYIIO9UMPIORmNI9wh89J6u0uJ1lbTMPAxf+Df2J2fAR6/BvIfaomvDUFeH5STXnN8a4yjwLak1JshHr9TERPijSaRSH9MgzBcGLVtj3A2TmxIwuaHKcuKEMl2+yVS4oFejUabAN5sLrhOQvczQeJshe5uh8TFD421SfvcyQfYxwxB5GVr/PPU4tlwdcg5FIvtAJEyngwGR/61RlpVWEpOp6FoLjUb55r90aeF1QggcO2VD01YWSEYzNEYLZC8LND550EemwxhzEdrA3EL7RQUY0S42CO1iaymtLof8EX9bUd1aAj4N0xB08zHIYUoLhiwBd7aMwpju9dEsqvC/vcuXlXoDm02pYQkPz1+XZ7Hhs9+P44PNR5FnsUOWgIduqouJPRsjwFuHzEyl9WzpUqUlrUULpUi6c+fCj/1qubnAXXcBP/+cX8fk+H+vXspINEe9g90usD85A78dOYffD5/H3ycvwlrgq7+wSzCdDUTukXBk74+GLcsIjUaZYXjatGvHUh1k5lnw2Fc78eexC9BpJLw9sBX6tY6+9o6VTAiBs+l5OHA2I78+JiUDJ4tpjdHKEuqH+qJppN+VJMYfTSP8EMrWmGqDyU0JmNxQZXn6aaVryTmxEND4mKCtlQ1dULby/1rZ0AblQBuYDVl37ZnQ7CYtcg5HIPtAJPJOhQD2wk0Hsqx0V3z6qVL0aTY713xoNErrQ0KCUlRcnDvuUO5nU2Ry5JuHoEaX8NiLF5H43yXsT84oNLxVtmmRczoQeaeDlK6s5AB41U9DwE3HoA/LVI4jyRjUPgaPdbsBsSEVq9M4czkX09ccwJo9yQCUb93D4hrj7bG1cea//KHNjtEmTzwBzJlT8vDZUaOU+zoVNeJMloGHRuXh/x45j9+PnMPWI+dxIdvstI3W5IXLB0KRcyIEeadCIEyFW2gOHvSs20mYrDY8/e2/WL1beR1evLMpHumqTKyUmqq0fgUHK1MVVIZcsw2HUpVJ75RJ8JTfM/KKHp4T7KN36k5qwtYYj8DkpgRMbmqWnBxg3jzl5+RJZabbhx5Shjk7ahHsduVb+/79gI8P0Ldv0XMyWCzKxc5RGFevnnJMANCHpyOw2yEYoi9CNpQ8hMmWq4M9Rw9bjgG2HP2V3/Ww5xhgueyNvFPBgE05SWQkMHKkcvO5vPwGHTRqpBSx3nST0r89fbrSamGxKH3cjz4KTJqkFCaX5OBB5RhZWc4JjiMZ+PZbpWYIUOZlSTx9GTtOXsKOUxexK+kyskzF38nPbtIg69+66BFZD8u/NpYcSBn9cfQ8Xl61D0fSsgAA5pQAXPipOczJtQpt++mnxdcMnT+vPMdOo5y0NhhiLsJY7xy8Ys+rSZqDj16DTvWD0a1RKLo2DEXyYW907y7Bbi+cIMmyUnv01VcVerhuyW4XeG3Nfnz+x0kAwD3N6+HQt02xdk1+S17Hjsp789ZbS3dMIQTOXM5VJr0rOG/Mhewiu3a1soQGYb6FEpkwv8p9v5F7YHJTAiY3NUdGhjIPzK5dyt+Od7pGoyQAv/6qdIU8+KBy35OCo0xGjVK+8Ws0Sk3Je+8piYAsK7cLeO455aKVmpGHWt0OwefG/9SEQNgBa4YXrJd8YLnoo/z/kg+sF32Uia2utMRcayi3LCvzpLzwgnL/pQ0blNE0TZoo3S1Xt0ZYLEB2tjKBXFlGJhw6pLRCrV2b/xzFxSkXpT59it/PYhXwjcmAPuoSjDGXYIi5CK1/Hmw5OmTurIfMnbEQZh3691fmwKhsFpsdUxaexLf7j0A2KNlJ1u4YXP6tMYRVA8lggcZoRe0bLPjoMyuyTBZk5lmRmWdBxpX/7z9ixV87rUqNksECSW+FxtsMSVOgq0kAdXwDcFeHEHRrGIq4OrWg1zq3pq1fDwwdqgwH12qV95EQSmL64YeAXg+PJITAJ78dx8x1BwEA2fujcH5NK/U97qhXWrFC6forKMdsxeHUrCsz+OZ3K2UW0xoT4ntVa0yEMlLp6teCPBeTmxIwuak5xo1ThlIXV48SHa00oVsshb9xS5KS9GRnKx/MgHNyZJdsaPh/J5Bb76g6R0v2viikb6sPy0UfZVZRDQrMJFt0jI89psRY8G7QjnPceCPw++/OI46up+RkJckLClImoCuNuDhg9+4CE795m2A3adWWJ1lW7gY8efL1ifmZZ4APPsuDb5dD8L2x8uZ3t2YakHciFLknQ5F3MgRLvtBj4MCS97FYlLmKDhxQkud+/dx30rXK1nHwf0ipuxuSLJB7IgTnVrSFsCjD9iVJICw2F4tWZuLIOeW+SgeTM4ttjdFpHLUxSnGvY/4YT55bh0qHyU0JmNzUDJmZyu0DCnblyN4mdR4YYdEAkNTWmtIT8G6cglo9DqgFt6azgbi4qRnMZwt3ibz9tnKzuKuHglutyqRW48crXRavv65M1AYoycwjjyitNn5+5Xr4Vaak2XElSSmqPn36+t3K4amnlJYRiwXQR11CUPw+GCLTAQB2iwxh0sFu0qJlUx1CArTwM2rhZ9DB30sLP6MO5mwtXnlBB1ueFvYr29rzdLBleEG5j4HyOI4fr7z6EU+TlATUrQsYb0hDaL9/IOttMKUo0wnowzKhD82AbCyuNcagzt7raJGpH8rWGCoak5sSMLmpGbZvV/r7HYx1ziP8/vw7NAqbpEx0Z8qf8M5u0sJu0kKYtbBf+VF+10CYlW+h/h2Ow1jnIgDAmmlE0OnG2PNjNGRZUpMkR3fTq68qo2SOHlUuwGvXKsu7dVOSmjZt8uMTQqnfyctTLqLuPBtpQXY78PDDSv1PwUTRcZ+rJUvya3auh2XLcFWLioBssMJu0ahdI9HRwKlTxXfV3XmnUlRd1NTxWq3SNffjj5UeusfYskXp/gUAfeRlhN37NzTezkXXwiYh1OCHbjfm18U0iWBrDJUNk5sSMLmpGRITlS4Th8DuBxBw0/FKObbdIiNjW31kbL8BfW/XYtAg5d4/O3cq62++WekuKe62Bp7GbleSmPffV+qb9HqlvmLiROcE7nqwWJRWg7S04m89MGuWMo9OcVJSlNfsxAnnVjxZVu6svnWr87B0cvbvv8otQxy0tbLh3+4E7BYNLGlX7nJ90RcLP5NLvAcW0bUwuSkBk5uawWpVvrGnpSl/h97zN7wbpOHCT82RvTdGLSCVjdYCv1sgG6yQ9FbIesf/bQV+t8J0thYu/94ItkwvyLLSarBkiXIOi0W5mGrd7w4BHm3nTuC225xHfDlaz+65R3l9rvWaXL6s1D7Nn6/UYYWHKyOsRo9WRthR8YRQarSOHy++tkyvV2q6goKqNjbyLGW5fvNjmDySVquMaHrmGeVvfYgynNdy3k8pdLRrER7ghZQUoITRzCWOaLLblWHjDrrqPwFttdS2LbB3r3L/rsWLlSSneXNg7FilS6w0dzUPDFSGzk+adN3D9TiSBMyYAQwaVPw2zzzDxIaqFqu2yGM99ZQyS62ks6rFv/ZLSoVumzbKjSyDg4uvxRgzRvkmWtQEcFotUKfO9a0nodKLiVGGrp84oQzH3rJFudiWJrGhihs4UJkI0ccnv5BclvO/ZLz2mqsjpJqG//TJY8my8m3+m9XKRG8aix5336nHypXKzQlbtAC2bVMKSgsmMNHRysRvjpYAxwe148MaUC6mmzaV/qaGRJ7u4YeV+qXPPwdefBGYO1eZqXjWLCaZVPXYLUUeTxusJDcdGvth8TvO6+rWBX74ATh7VhmK7eurFCI7WnMGDVJGgnz+uVLbYTAoydCAAZ47MRtRefn6AsOGuToKIiY3VAMcSVXqbRqFFz8bXlSU8lOU0FClaZ2IiKoHNhaSxzt8JblpEO7mM+IREVGlYHJDHu9wqtIt1Sisiu5jQERELsXkhjxatsmKM5eVkVKN2HJDRFQjMLkhj3YkTWm1CfE1oJYPK4CJiGoCJjfk0UpTTExERJ6FyQ15NEfLDbukiIhqDiY35NEcI6UasuWGiKjGYHJDHu3IlZFSDcPYckNEVFMwuSGPleU0UootN0RENQWTG/JYjmLiUD8DAr05UoqIqKZgckMey9ElxVYbIqKahckNeawjaVeKiVlvQ0RUozC5IY+l3naBw8CJiGoUJjfksTiBHxFRzcTkhjxSZp4FZ9PzALBbioiopmFyQx7JMTNxmJ8BAd46F0dDRERVickNeaT8Lim22hAR1TRMbsgjOYqJedsFIqKah8kNeSTeMJOIqOZickMeiSOliIhqLiY35HEy8ixIvjJSqgFHShER1ThMbsjjOG67EO5vQIAXR0oREdU0TG7I43CkFBFRzcbkhjyOOlKKXVJERDUSkxvyOI4bZrKYmIioZmJyQx7niDrHDVtuiIhqIiY35FHScy1IybhyTym23BAR1UhMbsijHL3SJRUZYIS/kSOliIhqIiY35FEcxcQNwthqQ0RUUzG5IY9ymMPAiYhqPCY35FEcxcQcKUVEVHNpXR0AVX9CAKmpgM0GREQAGo3rYnG03HCkFBFRzcWWGyo3IYBFi4BmzYDISCAmBqhTB3jzTcBqrfp40nMsSMs0AQAasuaGiKjGYnJD5TZlCjBiBHDoUP6ys2eByZOBe+5RWnIcLuRcwNnMs7Dar1/W45i8LyrACD+OlCIiqrHYLUXlsmMHMGuW8rsQzuuEAFatAhYvBgLa/4g3fn8D285sAwAEewVjbPuxmHzzZHjrvAEAdmHHntQ9yDRnon6t+oj0iyx0PovNgmxLNvz0ftDIRfd7HebkfUREBCY3VE6ffAJotfndT7K3CdrAHJhT/QGbBrIMTP3xQ5w8Nh6ylN9AeCH3At74/Q38fPxnbBq6CSsOrsDUzVNx/NJxAIAECX0b98Wc3nNQr1Y9HDx/EG/8/gaW7l0Ki90CP70fHmnzCCbfPBlhPmFOMan1NuySIiKq0ZjcULns2eNcVxPxQAJ0wdkQVhmms4HIS9UhudF8SEIPO8xO+9qFHdvObMPgZYPx4+EfndYJCKw5vAZ/nv4TC/ouwAPLH4DJaoJVKCfLNGdi7ra5WLZ/GRJGJiDaPxpp2WlYsncJ1h0IAlAL4YH26/3wiYjIjUlCXN2p4NkyMjIQEBCA9PR0+Pv7uzqcaqt3b2DjxitdUpJA3efWFrmdgAUm+RDy5L0wywdhlc7BJp2HHdmAVPzxNZIGXjov5FpyYRO2Itf3b9wfrSNb45VfX4Fd2BGVuwgaEYQ0w7OY2P1uvHbLa5CkEk5CRETVRlmu32y5oXIZOBD46Sfld0mX34RzdmFXGKIuw9hlFQx+/tAiGEZ7CxjtLZz2tyMPNukCbNJ5WKULV36/BAELACsEbLBbrDBIVgg4fkywyEmwS5mwCRuWH1yO7w9+DwCQhS80IggAkCedxBu/vwFfvS8m3zy5Sp4PIiJyHy5Pbj788EO89dZbSElJQatWrfD++++jQ4cOxW4/Z84cfPzxx0hKSkJISAjuvfdezJgxA0ajsQqjpvvvB15/HThzBhAGJbkRNgmWc36wX/RHXv1EIOwLwB4Ko/1GGOwtoLfXg0YEQwN/yDBCFtHQiegyn9sqpcEsnYBZPgazfAIW6Tg0IkRdJ6RcAMAbv7+Bxzs8Dh+9T6U9biIicn8uTW6WLl2KiRMnYt68eejYsSPmzJmD3r1749ChQwgLCyu0/TfffIPJkydj4cKF6Ny5Mw4fPozhw4dDkiTMnj3bBY+g5vLxATZvBu64Azh67kpyY9ECkBAcDEwefg8m/rMAkJORJScjCz+p+0rCAB1CINuDlGTH8YNASEILQAsJWkjQKL8LLQANNPCFVkRAK8KgFWHwtndUj6m0+AAWKUldlmXOws/Hf0a/Jv2q4BkhIiJ34dLkZvbs2Xj00UcxYsQIAMC8efOwZs0aLFy4EJMnF+5O+PPPP9GlSxc88MADAIDY2Fjcf//92LZtW5XGTYp69YB9+4BPv7dh5k7AR6/FkiXAgAGAVtcbX52Nw+7U3YVrZiQzbFIKzNKZYo8tQ4YdhQuDJeENvb0e9KIe9Pb60NnrQS/qQoIyr41JPuC0fYYpo+IPlIiIqhWXTeJnNpuxc+dOxMfH5wcjy4iPj0dCQkKR+3Tu3Bk7d+7E9u3bAQDHjx/H2rVrcccddxR7HpPJhIyMDKcfqjyyDNwYp7Tc1I7UYPBgQK8HZEnG+gfXo21UWwCAVtZCJ+sgQYKP3gcr71uJR9s8CqmIqmIJEmRZxp0N73QaRg4AQsqBSbMPmdrVuKB/DynGJ5FkHIizhseRqn8J6drlTts3Cm50nR45ERG5K5e13Jw/fx42mw3h4eFOy8PDw3Hw4MEi93nggQdw/vx53HzzzRBCwGq1YvTo0Xj++eeLPc+MGTPwyiuvVGrs5CzLpCQ3Pgbnt1OYTxj+GvkXtiZtxQ+HfkCeNQ+tI1rj/hb3w0fvg971e8OgNeDjvz+GXdghSzJswoYwnzB8OeBLdKvbDQ8ufxDfH/geWlkLx8A+u7Bjys1TsOHYBiSmJMIGKyzSCVhwQj23LMloHNwYHaKLr98iIiLP5PKC4rLYsmULpk+fjo8++ggdO3bE0aNHMWHCBLz22muYOnVqkftMmTIFEydOVP/OyMhA7dq1qyrkGiH7SnLjayj8dpIkCV3rdkXXul0LrdNpdHj/9vfxQtcXsOrQKmSYMtA4uDFub3g7tLJyrGWDlmHn2Z34es/XOJ9zHnUD6mJE3AjcUOsG3NvsXtz8+c0wWU1OXV8aSQOdRoeF/RZyKDgRUQ3ksuQmJCQEGo0GqampTstTU1MRERFR5D5Tp07FQw89hEceeQQAcOONNyI7OxujRo3CCy+8AFku3MtmMBhgMBgq/wGQypHc+OjL93aK8I3AqLajil3fNqqt2r1VUFxkHLY9sg0v/vIiVh1aBQEBCRL6NOiD1299Ha0jWpcrHiIiqt5cltzo9Xq0bdsWmzZtQv/+/QEAdrsdmzZtwvjx44vcJycnp1ACo9Eo9xmqYXMRupUsk9JqcnW3VFVoEdYCK+9biQs5F5CanYownzCEeIdUeRxEROQ+XNotNXHiRAwbNgzt2rVDhw4dMGfOHGRnZ6ujp4YOHYro6GjMmDEDANC3b1/Mnj0bcXFxarfU1KlT0bdvXzXJoaqX3y3lutcg2DsYwd7BLjs/ERG5D5cmN4MHD8a5c+fw0ksvISUlBa1bt8b69evVIuOkpCSnlpoXX3wRkiThxRdfxJkzZxAaGoq+ffvijTfecNVDIBRfUExEROQKvLcUVdiz3/2L73b+h2d7N8a4Wxq4OhwiIvJAZbl+u2yeG/Ic2ebiR0sRERFVNSY3VGGuLCgmIiK6GpMbqjB3KCgmIiJyYHJDFZaf3OhcHAkRERGTG6oE+aOl2HJDRESux+SGKqyk2y8QERFVNSY3VGHZLCgmIiI3wuSGKsRktcFsswNgckNERO6ByQ1ViKPVBgB89Ky5ISIi12NyQxXiqLcx6mRoNXw7ERGR6/FqRBWSxWJiIiJyM0xuqEKyedNMIiJyM0xuqELUOW70TG6IiMg9MLmhCnEUFLNbioiI3AWTG6qQbM5OTEREbobJDVVIFmtuiIjIzTC5oQrhrReIiMjdMLmhCskys+WGiIjcC5MbqhAOBSciInfD5IYqJH+0FAuKiYjIPTC5oQphQTEREbkbJjdUISwoJiIid8PkhiokmzMUExGRm2FyQxXCbikiInI3TG6oQnj7BSIicjdMbqhCePsFIiJyN0xuqNyEEMg2s6CYiIjcC5MbKrdciw12ofzOmhsiInIXTG6o3BzFxJIEeOvZLUVERO6ByQ2Vm6OY2EevhSRJLo6GiIhIweSGyo3FxERE5I6Y3FC5ZXF2YiIickNMbqjceOsFIiJyR0xuqNw4OzEREbkjJjdUbkxuiIjIHTG5oXJjtxQREbkjJjdUblmOoeAcLUVERG6EyQ2VWza7pYiIyA0xuaFyU7ul9ExuiIjIfTC5oXJjQTEREbkjJjdUbiwoJiIid8TkhspNvbcUkxsiInIjTG6o3LJ4bykiInJDTG6o3LLN7JYiIiL3w+SGyo1DwYmIyB0xuaFy413BiYjIHTG5oXKx2uzIs9gBsOWGiIjcC5MbKpdss039nQXFRETkTpjcULk46m10GgkGLZMbIiJyH0xuqFxYTExERO6KyQ2VizrHDe8rRUREbobJDZWLY3ZijpQiIiJ3w+SGyoWzExMRkbtickPlwpobIiJyV0xuqFx46wUiInJXTG6oXLLYckNERG6KyQ2VSzZvvUBERG6KyQ2Vi2O0FAuKiYjI3TC5oXJhtxQREbkrJjdULll57JYiIiL3xOSGyoWjpYiIyF0xuaFyYbcUERG5K5cnNx9++CFiY2NhNBrRsWNHbN++vcTtL1++jHHjxiEyMhIGgwGNGjXC2rVrqyhacuBoKSIiclcuvTItXboUEydOxLx589CxY0fMmTMHvXv3xqFDhxAWFlZoe7PZjJ49eyIsLAzLli1DdHQ0Tp06hcDAwKoPvobLHy3F5IaIiNyLS69Ms2fPxqOPPooRI0YAAObNm4c1a9Zg4cKFmDx5cqHtFy5ciIsXL+LPP/+ETqcDAMTGxlZlyHRFltpyw6HgRETkXlzWLWU2m7Fz507Ex8fnByPLiI+PR0JCQpH7rFq1Cp06dcK4ceMQHh6OFi1aYPr06bDZbMWex2QyISMjw+mHKkYIwXtLERGR23JZcnP+/HnYbDaEh4c7LQ8PD0dKSkqR+xw/fhzLli2DzWbD2rVrMXXqVLzzzjt4/fXXiz3PjBkzEBAQoP7Url27Uh9HTWSy2mG1CwBMboiIyP24vKC4LOx2O8LCwvDpp5+ibdu2GDx4MF544QXMmzev2H2mTJmC9PR09ef06dNVGLFncrTaAICPnskNERG5F5ddmUJCQqDRaJCamuq0PDU1FREREUXuExkZCZ1OB40mv86jadOmSElJgdlshl6vL7SPwWCAwWCo3OBrOEcxsZdOA40suTgaIiIiZy5rudHr9Wjbti02bdqkLrPb7di0aRM6depU5D5dunTB0aNHYbfb1WWHDx9GZGRkkYkNXR+c44aIiNyZS7ulJk6ciPnz5+OLL77AgQMHMGbMGGRnZ6ujp4YOHYopU6ao248ZMwYXL17EhAkTcPjwYaxZswbTp0/HuHHjXPUQaqT82Yk5UoqIiNyPS796Dx48GOfOncNLL72ElJQUtG7dGuvXr1eLjJOSkiDL+flX7dq1sWHDBjz11FNo2bIloqOjMWHCBEyaNMlVD6FGYssNERG5M0kIIVwdRFXKyMhAQEAA0tPT4e/v7+pwqqXVu89i/De70KFeEL59rOguRCIiospUlut3tRotRe6Bt14gIiJ3xuSGyiyLt14gIiI3xuSGyiybt14gIiI3VubkZv/+/Rg7dizi4uIQGRmJyMhIxMXFYezYsdi/f//1iJHcjHrrBU7gR0REbqhMV6d169ahf//+aNOmDfr166eOakpNTcXGjRvRpk0b/PDDD+jdu/d1CZbcA0dLERGROyvT1Wny5MmYNGkSXn311ULrXn75Zbz88st49tlnmdx4OBYUExGROytTt9Thw4cxZMiQYtfff//9OHLkSIWDIvfGgmIiInJnZUpuYmNjsWbNmmLXr1mzBnXr1q1wUOTe1JobFhQTEZEbKtNX71dffRUPPPAAtmzZgvj4eKeam02bNmH9+vX45ptvrkug5D7yb7/AlhsiInI/Zbo6DRw4ENHR0Zg7dy7eeecdpKSkAAAiIiLQqVMnbNmypdibXpLnYEExERG5szJfnTp37ozOnTtfj1iommBBMRERuTNO4kdllpXHlhsiInJfZUputm/fDpvNpv69evVqdO/eHdHR0WjXrh2+/PLLSg+Q3IvdLpBtdoyWYkExERG5nzIlN506dcKFCxcAAD/++CP69euH2NhYvPDCC4iLi8PIkSOxYsWK6xIouYccS35yy24pIiJyR2W6Ogkh1N/ffPNNPPfcc5gxY4a6rF69enjzzTcxYMCAyouQ3Iqj3kaWAC8dW26IiMj9lLvm5vDhw7j33nudlt1zzz04ePBghYMi91VwpJQkSS6OhoiIqLAy9yvs378fKSkp8PLygt1uL7TearVWSmDknjhSioiI3F2Zr1C33Xab2j31xx9/oH379uq6Xbt2oU6dOpUXHbkdznFDRETurkxXqBMnTjj97evr6/S32WzGpEmTKh4Vua1s3leKiIjcXJmuUNe6b9TQoUMrFAy5v/xuKRYTExGReypTQbHNZsOsWbPQpUsXtG/fHpMnT0Zubu71io3ckNotpWfLDRERuacyJTfTp0/H888/D19fX0RHR+O9997DuHHjrlds5IZYUExERO6uTMnNl19+iY8++ggbNmzAypUr8eOPP+Lrr78uctQUeaZsFhQTEZGbK1Nyk5SUhDvuuEP9Oz4+HpIk4ezZs5UeGLmnLBYUExGRmytTcmO1WmE0Gp2W6XQ6WCyWSg2K3BcLiomIyN2V+fYLw4cPh8FgUJfl5eVh9OjR8PHxUZctX7688iIkt5JlZrcUERG5tzJdoYYNG1Zo2YMPPlhpwZD7Y80NERG5uzJdoT7//PPrFQdVExwtRURE7q7cN868mhAC69atK3QzTfIsLCgmIiJ3V+Hk5sSJE5g6dSrq1KmDAQMGIC8vrzLiIjfFgmIiInJ35fr6bTKZsGzZMixYsABbt26FzWbD22+/jZEjR8Lf37+yYyQ3wpobIiJyd2Vqudm5cyfGjh2LiIgIzJkzB/3798fp06chyzJ69+7NxKYG4O0XiIjI3ZXpCtWxY0c8/vjj+Ouvv9C4cePrFRO5KavNDpNVmY2aBcVEROSuynSFuu2227BgwQKkpaXhoYceQu/evSFJ0vWKjdxM9pViYoDdUkRE5L7K1C21YcMG7Nu3D40bN8aYMWMQGRmJCRMmAACTnBrAMYGfXiNDr620gXZERESVqsxXqNq1a+Oll17CiRMn8NVXX+HcuXPQarXo168fnn/+eezcufN6xEluIL+YmCOliIjIfVXo63fPnj3xzTff4OzZs3jiiSewbt06dOjQobJiIzeTxZFSRERUDZT7KpWXl4fdu3cjLS0NdrsdderUwSuvvIJjx45VZnzkRrLyODsxERG5v3JdpdavX4+hQ4fi/PnzhdZJkoSnnnqqwoGR++EcN0REVB2Uq1vq8ccfx8CBA5GcnAy73e70Y7PZrn0AqpbYLUVERNVBuZKb1NRUTJw4EeHh4ZUdD7kx3nqBiIiqg3IlN/feey+2bNlSyaGQu8s2X7lpJmcnJiIiN1auq9QHH3yAgQMH4vfff8eNN94InU7ntP6JJ56olODIvbBbioiIqoNyXaUWL16Mn376CUajEVu2bHGawE+SJCY3HsrRLeVnZHJDRETuq1xXqRdeeAGvvPIKJk+eDFnmTLU1BVtuiIioOihXZmI2mzF48GAmNjUMh4ITEVF1UK7sZNiwYVi6dGllx0JuznHjTI6WIiIid1aur+A2mw1vvvkmNmzYgJYtWxYqKJ49e3alBEfuRe2W4mgpIiJyY+W6Su3ZswdxcXEAgL179zqt493BPVf+PDdMboiIyH2V6yq1efPmyo6DqgHW3BARUXXAimAqNY6WIiKi6oDJDZWKEEKdoZjdUkRE5M6Y3FCpmKx22OwCAODD0VJEROTGmNxQqTi6pACOliIiIvfG5IZKxVFM7K3XQJY5Io6IiNwXkxsqFRYTExFRdcHkhkolf3ZiJjdEROTemNxQqeTPccNiYiIicm9MbqhUeOsFIiKqLpjcUKnw1gtERFRdMLmhUmFBMRERVRdMbqhUHAXFTG6IiMjduUVy8+GHHyI2NhZGoxEdO3bE9u3bS7XfkiVLIEkS+vfvf30DJGSbHd1SLCgmIiL35vLkZunSpZg4cSKmTZuGf/75B61atULv3r2RlpZW4n4nT57EM888g65du1ZRpDVbZh67pYiIqHpweXIze/ZsPProoxgxYgSaNWuGefPmwdvbGwsXLix2H5vNhiFDhuCVV17BDTfcUIXR1lwsKCYiourCpcmN2WzGzp07ER8fry6TZRnx8fFISEgodr9XX30VYWFhGDly5DXPYTKZkJGR4fRDZZfNgmIiIqomXJrcnD9/HjabDeHh4U7Lw8PDkZKSUuQ+W7duxYIFCzB//vxSnWPGjBkICAhQf2rXrl3huGsijpYiIqLqwuXdUmWRmZmJhx56CPPnz0dISEip9pkyZQrS09PVn9OnT1/nKD0TC4qJiKi6cOnX8JCQEGg0GqSmpjotT01NRURERKHtjx07hpMnT6Jv377qMrvdDgDQarU4dOgQ6tev77SPwWCAwWC4DtHXDH+e/hPv/fUedif3gowIzNk2CwH+Q9A2qq2rQyMiIiqSS1tu9Ho92rZti02bNqnL7HY7Nm3ahE6dOhXavkmTJtizZw8SExPVn7vuugu33HILEhMT2eVUDtnmbHz2z2cYs3oMJqybgA1HN8AulITx3YR30WVhFyw/uBx2ux4A8POJ1Wg/vz0W/LPAlWETEREVy+UFFBMnTsSwYcPQrl07dOjQAXPmzEF2djZGjBgBABg6dCiio6MxY8YMGI1GtGjRwmn/wMBAACi0nK7tp2M/YeB3A5FhyoBO1kFAYO72uWge2hzTb52OiT9NBABY7VbI8AIAWEQWhCQw6sdR6FS7E5qFNnPlQyAiIirE5cnN4MGDce7cObz00ktISUlB69atsX79erXIOCkpCbJcrUqDqoW9aXvRd3FfWG1KLY3FblHXHTp/CA+ueBBaWQur3QoISU1u7FIOAGVU28d/f4z373i/6oMnIiIqgSSEEK4OoiplZGQgICAA6enp8Pf3d3U4LjNi5Qj8b8//lOSlAFn4QWevA52Igc5eGzqh/GhFGAAgyXg3hGQGALQIa4E9Y/ZUeexERFTzlOX67fKWG6pa53POY9t/27Bk3xI1sZFFAILMY2C0t4AGgcXumyP/DQGz+rdG4sgpIiJyP0xuaohMUyYmrJ+Ar3Z/5dRao7VHIcz8MnQiSl1mldJgkZJgkf6DRT6t/C6fhl3KUrfRSBr0adCnSh8DERFRaTC5qQHMNjN6/683tp/ZDpuwqcv19sYIM70EDQJgkVJwQfcuzPIxCCkPMmSIK/9dTYIEjazB6Hajq/JhEBERlQordWuAJXuXIOG/BKfExsvWEeGm6dAgACbpMFIMz8Ck2Qch5QEABATe7f0utLLWqftJI2mg1+ixfNByxAbGVvVDISIiuia23NQAn/3zGWRJVuev8bX2QZBlDCRokCNvx3n9LAjJBADqdm/2fBMTbpqAvo374pMdn2Dzyc2QJAk9b+iJx9o+htoBnFOIiIjcE5ObGiApPUlNbGThjyDLaEjQIFOzDhd1HwOSXd22XWQ7TL55MgY0HQAAuKHWDZjVc5ZL4iYiIioPJjc1QKRfJJLSkyAgYLS1hAQtzNJJXNR9CEhKDU27qHbY8OAG1PKq5epwiYiIKoQ1NzXAiNYj1N+N9lYAgDw5EZCUZQICo9uNZmJDREQegclNDfBgywfRPKw5NJImP7nR/AtAKRC+MexG3N/ifleGSEREVGmY3NQA3jpvbB62GbfVHQidiIKADXnyXkiQcGfDO7F52GZ46bxcHSYREVGlYM1NDRHiHYKRzd/Ecwd2o3awHa/1moeudbqiXq16rg6NiIioUjG5qUH+PHoeANC/ZVMMbdXYxdEQERFdH+yWqiGEEPjj2AUAQOcGwS6OhoiI6PphclNDHE3LwrlMEwxaGW3qcFQUERF5LiY3NcSfV1pt2scGwajj3byJiMhzMbmpIf64Um/DLikiIvJ0TG5qAJtd4K/jV+pt6oe4OBoiIqLri8lNDbD3TDoy8qzwM2pxY3SAq8MhIiK6rpjc1AB/HFO6pG66IRgaWXJxNERERNcX57nxUCarCcv2L8P6Y+vx7/5uAKLQqo7R1WERERFdd0xuPNCh84fQ86ueOJ1xGhoYEJU7ADKASb/1R3T4WxjQdICrQyQiIrpu2C3lYXIsObj1y1txNvMsAEBrawQZBlhxEbn24xi0bBD+Sf7HxVESERFdP0xuPMySvUtwNvMsbMIGAOpdwE2a3RCSAADMTpjtsviIiIiuNyY3HubHQz9CQn7RsCO5yZX/BQBY7Vb8cOgHl8RGRERUFZjceJg8Wx4ElBYarT0KRntTCNiRJ+9StzFZTa4Kj4iI6LpjcuNh4iLioJGU2yv4We8AAOTKO2CTleHgsiSjZXhLl8VHRER0vTG58TCPtnkUAgKSMMDXFg8AyNSuVtfbhR0TOk5wVXhERETXHZMbD1OvVj18dMdH8LH1gAxfWKSzyJN3qXU497W4D0NaDnFxlERERNcPkxsPNKrtKLTyewIAkKVdC0gCzUKbYX7f+fj67q8hS3zZiYjIc3ESPw/098lL+O+igFEn48TkxfAzaqDT6FwdFhERUZVgcuNBssxZyLXkYtGfSQCAAXHRCPLhLReIiKhmYXLjAX479Rte/+11bDy+ERoRhOi8hZCgxT1tQ10dGhERUZVj8UU19+2+b3HLF7fglxO/AAB8rX0gQQuTvA+PrLsdmaZMF0dIRERUtZjcVGPpeekYsXIEhBDK7RaEFr7WPgCADM0a7E3bi+m/T3dxlERERFWLyU019vWer5FrzVVnJPa2dYYWQbDiInI0f8ImbJi3cx4sNouLIyUiIqo6TG6qsX1p+6CV88umHJP2ZWnXA5IVAHA57zLO5ZxzSXxERESuwOSmGvPR+6itNhAyDPamAIAczR9O23lpvao6NCIiIpdhclONDWgyAFa70kKjE3Ugwwt25MAinQag3Eeqa52uqOVVy5VhEhERVSkmN9XYTTE3oXvd7tBIGhjsjQEAJvkIINkBAEIIvNjtRVeGSEREVOWY3FRjkiRhxeAV6Fy7M/T2RgAAq+YIZEmGXqPHwn4L0at+LxdHSUREVLU4iV81V8urFn4d/iu6vrUe/1204+b6MejR+G0MbTUUwd7Brg6PiIioyjG58QBZJivOXFK6oubf8wLC/HjLBSIiqrnYLeUB9vyXDiGA6EAvJjZERFTjMbnxALtOXwYAtK4d6NI4iIiI3AGTGw+QeCW5iasT6NI4iIiI3AGTm2pOCKEmN2y5ISIiYnJT7Z1Nz8O5TBO0soQW0QGuDoeIiMjlmNxUc4lJlwEATSL9YNRpXBsMERGRG2ByU80lnr4EgF1SREREDkxuqrldV1puWtfm/aOIiIgAJjfVmsVmx54z6QDYckNEROTA5KYaO5SSCZPVDn+jFjeE+Lg6HCIiIrfA5KYac0ze16p2IGRZcm0wREREboL3lqqGUlOB778HVpy9DABoHhHo0niIiIjcCVtuqhG7HZg8GYiJAcaPB/anKiOl3pociC++cHFwREREboLJTTXy4ovArFmA1QpAb4EuOBsAcPlYIIYPB5Yvd2l4REREboHJTTVx4QLw9tv5fxsiLwMALJe8Yc81QJKA558HhHBNfERERO6CyU018cMPV1psrjBEXQYAmJMDAShJzaFDwN69VR8bERGRO2FyU01cugTIBV4tXUgmAMCUElBoOyIiopqMyU01Ub8+YLPl/63xNgEAbFkGdZkkAfXqVXVkRERE7oXJTTVxxx1ASIiSwACA7G0GANhzlORGowF69gRq13ZVhERERO6ByU01odcD8+cryY0sAxovCwDAlqOHRgP4+ADvvuviIImIiNwAk5tqpH9/YMMGoE1bobbciDw9+vQBtm0DmjVzbXxERETuwC2Smw8//BCxsbEwGo3o2LEjtm/fXuy28+fPR9euXVGrVi3UqlUL8fHxJW7vaeLjgY1bLJBkZcz3sf06rF4NNGni4sCIiIjchMuTm6VLl2LixImYNm0a/vnnH7Rq1Qq9e/dGWlpakdtv2bIF999/PzZv3oyEhATUrl0bvXr1wpkzZ6o4cte5kK202vgZtKgTo3FxNERERO5FEsK107517NgR7du3xwcffAAAsNvtqF27Nh5//HFMnjz5mvvbbDbUqlULH3zwAYYOHVpovclkgslkUv/OyMhA7dq1kZ6eDn9//8p7IFXo75MXMXBeAuoGe+PXZ29xdThERETXXUZGBgICAkp1/XZpy43ZbMbOnTsRHx+vLpNlGfHx8UhISCjVMXJycmCxWBAUFFTk+hkzZiAgIED9qe0Bw4kuZCktN0E+ehdHQkRE5H5cmtycP38eNpsN4eHhTsvDw8ORkpJSqmNMmjQJUVFRTglSQVOmTEF6err6c/r06QrH7WoXr3RLBTO5ISIiKkTr6gAqYubMmViyZAm2bNkCo9FY5DYGgwEGg6HIddXVxWylm40tN0RERIW5NLkJCQmBRqNBamqq0/LU1FRERESUuO/bb7+NmTNn4ueff0bLli2vZ5hux1FQHOTjWUkbERFRZXBpt5Rer0fbtm2xadMmdZndbsemTZvQqVOnYvd788038dprr2H9+vVo165dVYTqVtgtRUREVDyXd0tNnDgRw4YNQ7t27dChQwfMmTMH2dnZGDFiBABg6NChiI6OxowZMwAAs2bNwksvvYRvvvkGsbGxam2Or68vfH19XfY4qtLFbBYUExERFcflyc3gwYNx7tw5vPTSS0hJSUHr1q2xfv16tcg4KSkJcoHbYX/88ccwm8249957nY4zbdo0vPzyy1UZusuoo6V8mdwQERFdzeXz3FS1soyTd1c3Td+ElIw8/DCuC1rVDnR1OERERNddtZnnhspOCIGLOeyWIiIiKg6Tm2om22yD2WoHAASzW4qIiKgQJjfVzMUr9TZGnQxvvctLpoiIiNwOk5tq5sKVCfyCOccNERFRkZjcVDMcBk5ERFQyJjfVzAUmN0RERCViclPNcHZiIiKikjG5qWbYLUVERFQyJjfVDGcnJiIiKhmTm2rmojpaiskNERFRUZjcVDOObqla3kxuiIiIisLkpppxjJbi7MRERERFY3JTzeQXFHMSPyIioqIwualG8iw25JhtADhaioiIqDhMbqoRR6uNTiPB38j7ShERERWFyU01UrCYWJIkF0dDRETknpjcVCO89QIREdG1MbmpRtQ5bjhSioiIqFhMbqoRdXZijpQiIiIqFpObaoQ3zSQiIro2JjfVCG+aSUREdG0cT+xmDpw7gKMXjyLQGIhOtTtBK+e/RI6C4lpMboiIiIrF5MYFhBDYcnILPvr7I+xM3gkvnRdurn0zdiTvwD/J/6jbRfhG4LVbXsMjbR4BwG4pIiKi0mByc51Z7Vb89d9fSM9LR8Oghkg3peP1317HqsOroJW1sNqtAID95/YX2jclKwWP/vgoMk2ZeKrTU+yWIiIiKgUmN9fRpzs/xUubX0JqdmqR6x2JzbVM2TQFI+JG4ELWlaHgTG6IiIiKxeTmOnnrj7fw3M/PXXtDoYFGBEGDQGhELWhELcjCB9marbDJaQAAs82Mb3YvRUZeDAC23BAREZWEyc11cD7nPJ7/5fkSt9GIWvCz9oef9XbI8C603mhvhTTDNACAVtbi+IVUADGQJCDQm8kNERFRcZjcXAeL9yyGXdjVv7X2KHjbboYEDQAJWhEKH1sPSNABAAQssEmXYMNl2KUseNnbwGhvCUkYICQTbMIGb00YAOW+UhqZ95UiIiIqDpOb6+BU+inIkgy7sEMSeoSZX4ZORBXaLk/eh3Ttd8iTdwCOfEUA0aYF0IpwGO03IlezA7Iko2NUPL7EIXZJERERXQOTm0pks9vw9p9v45Odn6jFwgHW+6ETUbDiInI1CQAEBKzI0STApNlX+CASkCv/Az/b7TDa2iBXswOTu0yG3aZ0XTG5ISIiKhmTm0oihMDIVSPx5b9fQkAAAHT2evC33g0AuKj/ALma7cXuL11puhEQyNXshJ/tdniLdnj6ljp4vuvz+DLhFACOlCIiIroWJjeV5NdTv+KLf7/IXyBkBJsfhwQNsuWtJSY20X7ReLTNo3ikzSM4cvEI9qUewzsrBbT2KDzUfAgkSVJnJ2bLDRERUcmY3FSST3d+6jQpn5+tLwyiEezIwiX9J0XuE+QVhFnxs9QZiAEg2j8aPWJ74NfEBGw/cRG/HjmHh4Lr4mK2MscNkxsiIqKSMbmpJIcvHFYTG0l4IdAyBABwSfc5bNIlAICP1gfLBy/Hf5n/IcwnDL3q94JeU3Sy0r1RqJLcHDqHh26qy9mJiYiISonJTSUJ9gpWR0j52HpAhjcs0mlkaX5StwnzDUOvBr1KdbzujULx1oZDSDh2HmarHReymNwQERGVhuzqADzFAzc+oMxtIwA/6+0AgEztekBSiotlScZDLR8q9fGaRfojxFePbLMNO09dKnDTTEPlB09ERORBmNxUkr6N+yI2MBZeoin04gYImJGt2QQA0EgaBHsFY2z7saU+nixL6NYwFADw6+Fz7JYiIiIqJSY3FZSel44n1j2B2u/WxsnLJ+FtVbqdcjRbIWvyAAANghrg1+G/Itw3vEzH7t5YSW62HErDpZwrLTe+TG6IiIhKwpqbCsgyZ6H7ou7Ym7YXNmGDJHzgbesKAMjUrEW3ut3wYtcX0SO2BySp7LdMuLlBCCQJOJiSqS6rxftKERERlYgtNxUw56852JO2BzZhAwD42m6BDCPM0kmY5IPYfGIz6gTUKVdiAwAGGBCqCchfYNZi9tsyLl+uhOCJiIg8FJObCvh4x8f5N8gUgK9aSLwOkJQi4s/++axcx75wAejYETjyW6i6zJKlxwsvAG3aAGfPVjh8IiIij8TkppzMNjPOZuZnGAZ7M+hFXdiRh2zNZgDKrRSOXjparuOPGQMcOgTkHs9Pbmy5etjtwOnTwLBhFYufiIjIUzG5KSedrINBkz8s2y7lIFvzO7I1v0BIOQCUlpsAQ0BxhyjW2bPA998DNhtgOhsIe55SGmXPUc5ntQI//wwcPlwJD4SIiMjDMLkpJ0mSMLjFYGhlJfGwyCdxXj8LF3UfqdtY7VYMbj64zMfesQOwX+ntgpCReyoEAGDP1Tlt99df5YudiIjIkzG5qYBJXSZBK2shSwWexiu1wxpJg84xnXHbDbeV+bgajfPfmX/Xg+WCD7IPRDkt13KsGxERUSFMbiqgWWgz/PTgTwj1VupidLIOGknJTG674TasfmC1c+JTSp07A4YCExGbzgTh7Gc9kHcyv/5GowF69KhQ+ERERB6J3/0rqGvdrjj91Gn8ePhHJKYkwqg14v8a/R9ahrcs9zFr1QIeeQT4+OMC3VMFaDTAffcBUVGF1xEREdV0khBCuDqIqpSRkYGAgACkp6fD39/f1eEUKy8PuPtuYN06JZmx2fL/37UrsHYt4Ovr6iiJiIiqRlmu32y5cVNGI7B6NbBhA7BwIZCUpLTUDB8O3Hkn622IiIiKw0ukG5Nl4PbblR8iIiIqHRYUExERkUdhckNEREQehckNEREReRQmN0RERORRmNwQERGRR2FyQ0RERB6FyQ0RERF5FCY3RERE5FGY3BAREZFHYXJDREREHqXG3X7BcZ/QjIwMF0dCREREpeW4bpfmft81LrnJzMwEANSuXdvFkRAREVFZZWZmIiAgoMRtJFGaFMiD2O12nD17Fn5+fpAkqVKPnZGRgdq1a+P06dMAUOTv/v7+xW7nuIV7wfXFLSvNNhVdVtxjc8f17hCDu68vjYoeo6bv7w4xuHr/yjpGTVedn8PrFbsQApmZmYiKioIsl1xVU+NabmRZRkxMzHU9R8EX8+rfS7uutMvKu19ZllWn9e4Qg7uvL42KHqOm7+8OMbh6/8o6Rk1XnZ/D6xH7tVpsHFhQTERERB6FyQ0RERF5lBrXLXU9GQwGTJs2DQaDAQCK/b2k7YpaX9Sy0mxT0WUlPTZ3W+8OMbj7+tKo6DFq+v7uEIOr96+sY9R01fk5dIfYa1xBMREREXk2dksRERGRR2FyQ0RERB6FyQ0RERF5FCY3RERE5FGY3FTQjBkz0L59e/j5+SEsLAz9+/fHoUOHAAAzZ86EJElo0qSJOiOy4ycoKAiNGzdGVFQUJEnCihUrMGzYMBiNRnWb8PBwGI1G6HQ6GAwGSJKE999/H02bNoVGo4EkSdDpdPD394dOp4MkSTAYDOjevTtat26tHkuj0cDLy8vp/JIkITQ0FLfeeisiIiLg4+ODoKAgp/N36NAB69atc3q8CQkJuPXWW+Hj46PGNH78eHX9p59+ih49esDf3189zpNPPqmuf/nllwvF4e3tjdzcXABA3759C61v0qSJUwyrVq1CRESEut7Hxwdbt25V18+fPx+RkZGQZRmSJKFhw4bYsWMHACA2NrbQ8SVJQlhYGJKSkhASElLk+nHjxgEAbDYbRowYoT6fsiwjNjYWOTk56vqBAwc6Pd9jx451uhdKZmYmhg4dCm9vb/X1adasGZKSkgAAX3/9NerWrau+xvXr10fXrl3V98rKlStx4MAB3HXXXQgICIC3tzeioqIQFhYGLy8vxMfH48iRI+r5fvvtNzRp0gR6vV59vgpavnw5evXqheDgYEiShMTERKf1v/32G1q2bKm+3pIk4fLlywAAi8WCSZMm4cYbb4SPjw+ioqIwdOhQnD17ttTnf/nll9GkSRP4+PigVq1aiI+Px7Zt25y2eeSRRxAUFKSef+XKlSjO6NGjIUkS5syZU+oYhg8fXug179OnT6n3B+D0mvj4+KB9+/bqa1rScwigyPecJEl46623SnX+rKwsjB8/HjExMfDy8kKzZs0wb948p22eeeYZBAcHq/8uvv76a6f1qampGD58OKKiouDt7Y0+ffqo7yPH55zRaIRer1c/bwo+hry8PIwbNw7BwcHw9fXFPffcg9TUVKdzPPHEE2jbti0MBgNat25dxKvn2Uq6Xjj06NGj0Ptg9OjRTtu44nksTewpKSl46KGH1GtKmzZt8P333zttc/HiRQwZMgT+/v4IDAzEyJEjkZWVVenxMrmpoF9//RXjxo3DX3/9hY0bN8JisaBXr1747bff8NFHH0Gn00GWZXTr1g1GoxH33XcfAODWW2/FiRMncPvttwMAVqxYgWXLluGuu+7C7NmzAQBmsxnvvfceHn74YXTt2hUAMGXKFOTl5eGll17C2rVrER0djdzcXHh7e+O7775D3759sW3bNuzZswcjR47E2rVrMW/ePJjNZsiyjM8++wx//PEHtm7dCh8fH2zZsgVz5szBnj17UK9ePZhMJjz00EMAgK5du6Jfv37Yt28fACWx6dOnD3r16oUFCxYgNDQUderUcbqNRU5ODvr06aMeo3nz5k7P1+nTpyHLMp5//nls2bIFv//+O+bOnatOpW2xWBAeHo7nn38eAHDw4EGnxGXDhg3o378/YmJisHjxYvz888948sknERQUBAC4dOkSnn/+eURERGDKlCkAgIkTJ6JWrVoAgL///hsJCQkIDAzEmDFj8PHHHwMAJkyYAKPRiCeffBLPP/+8ev4VK1YAAAYOHAgAGDduHL744gsMHjwYGzZswLvvvovU1FT1QjJr1iysX78e99xzD2bMmAEA+OKLL/D++++rj+G+++7DN998g379+mHlypUYN24cTp06hUuXLgEA5s6di9zcXDz99NMAgMaNG2P79u149dVXASgfIDfffDOaNGmCLVu2YPz48cjIyMBbb72Fbdu2wcfHB71790ZeXh4AIDs7G6GhoRgyZEiR7+Hs7GzcfPPNmDVrVrHrIyIiMGjQoELrcnJy8M8//2Dq1Kn4559/sHz5chw6dAh33XWX0/4lnb9Ro0b44IMPsGfPHmzduhWxsbHo1asXzp0753Setm3bom/fvkUew2HFihX466+/EBUVVegxlBQDAPTp0wfJycnqz+LFi0u9/7Fjx5xek927d2Pq1KkwGo3q/sU9hwCczpucnIyFCxdCkiTcc889pTr/xIkTsX79evzvf//DgQMH8OSTT2L8+PFYtWqVuk1mZiZatWpV5DGEEOjfvz+OHz+OH374Abt27ULdunURHx+P7Oxs9XNuwoQJGDNmDOrXr6/G5fDUU0/hxx9/xHfffYdff/0VZ8+exd13313oXA8//DAGDx5c5OPwdMVdLwo+jwDw6KOPOr0f3nzzzULHqurnsTSxDx06FIcOHcKqVauwZ88e3H333Rg0aBB27dqlbjNkyBDs27cPGzduxOrVq/Hbb79h1KhRlR+woEqVlpYmAIiYmBgxePBg4e/vLyZMmCDuvPNO8fDDDwshhAAgVqxYIe6++24xZMgQAUAEBgaKt956Sz0OAKHVasXixYuFEEKkp6cLAKJly5bqNocOHRIAxG+//SYAiF9//VXYbDYRHBys/u3QqFEjAUD88ssv6jIfHx/h4+MjPvvsM3VZUFCQeOaZZwQAcenSJVGrVi11fceOHcWLL74oMjMzRcOGDcXGjRtF9+7dxYQJE5yeg8zMTBETEyMAiC5dujitj46OFuHh4cU+f9OmTROtWrUSmzdvVmMoKDIyUtSuXbvY/SdNmiRuvvlmIYQQJ06cEADErl27nLYZPHiwePDBB4UQQkyYMEHUr19f2O12p20c5x89erTT+sDAQNGqVSunbR2voxDC6XV2nP/WW29V1+fk5AhJkkSPHj2cjtGmTRvxwgsviJycHKHRaMTq1aud4nesdzynjvjtdruIiIhweu9cvnxZGAwG9b1TEADh7e1d5HNX3PN19f5FvS4Fbd++XQAQp06dKtP5HRzv9Z9//rnQus8//1z993O1//77T0RHR4u9e/eKunXrinfffbfYx3B1DMOGDRP9+vUrMa6S9i/4nirN/td6Dvv16yduvfXWUp+/efPm4tVXX3Va5njPXM3x3v7f//6nLnN8luzdu1ddZrPZRGhoqJg/f36hY6xYsUIAEKtXrxZCKO85nU4nvvvuO3WbAwcOCAAiISGh0P6Of+c1neN6UfCzuqjP1OK48nksKnYfHx/x5ZdfOm0XFBSkvof2798vAIi///5bXb9u3TohSZI4c+ZMpcbHlptKlp6eDkBpWty9ezf8/PywZs0abN68GV999RVef/11AMCJEyewdetWteXm8uXLiI+PdzpWo0aNkJCQALPZrLYMNGjQAL1790ZYWJj6rc5sNgMAgoKCIMsydDqd+reDY5sBAwagRYsWmDRpEmJjY5Gbm4umTZvCbrdjyZIlyMvLU5s5v//+e2RnZ6NTp05IS0vDtm3bEBYWhhtuuAH//fcfXnvtNfXxFjRu3DjcdNNNhZanpaXhzJkzuHTpEvR6PTQaDcLCwgo1Wx45cgT33nsvAOUbjKNpPy0tDcnJyahfv77avO7r64vnnntO3XfVqlVo164dBg4ciHbt2gFQul0c7HY71qxZg0aNGqFnz56YO3cuTCYTfvjhh6JeTnz77bd4+OGHIUkS0tLScPnyZZw+fRpxcXEIDw9H27ZtsXnzZvV17Ny5MzZt2oTDhw+rx0hMTFTXm81mCCFQt25d9XXs2LEjcnJysHXrVlitVthsNvUbv4OXl5fagrVz5040atQIvXv3RkhICFJSUqDRaNRtAwIC0LFjRyQkJBT5mK639PR0SJKEwMDAMu9rNpvx6aefIiAgAK1atSr1fna7HQ899BCeffbZQq2FpbVlyxaEhYWhcePGGDNmDC5cuFDqczveUwVf05K6zkqSmpqKNWvWYOTIkaXep3Pnzli1ahXOnDkDIQQ2b96Mw4cPo1evXqXa32QyAYDT+06WZRgMBqeWUwfHt3VHi+jOnTthsVicPsOaNGmCOnXquOx9WB04Pj8LflYDStd0SEgIWrRogSlTpqjd3u6kqNg7d+6MpUuX4uLFi07XlB49egCA2mru+GwGgPj4eMiyXKgrusIqNVWq4Ww2m4iLixPe3t4iNzdXGAwGIUmSaNeundixY4fo3bu3+q0NgJg+fboQIv+b3NmzZ9VjARBNmjQRWq1WSJIkwsPDBQCh1+vF7Nmzxa5du8Trr78uAIigoCDRsWNHYTKZxPTp09WWIIfU1FSh0+lESEiIWLZsmTAYDGrLUFxcnPq7v7+/mDdvnjAajQKA8Pf3F2vWrBFCCJGQkCAACB8fHxEdHS0SEhLEk08+KSRJEsOGDVPPtXjxYtGiRQuxYcOGQi03jmP4+vqKV155RXzwwQciMjJSABD//POPEEKItWvXim+//VZ89tlnAoBo3769qFOnjsjIyFD3ByDuvPNO8c0334jbbrtNABAzZ84UQghhMBiEwWAQU6ZMEatXrxYAhMFgEIsWLRJCCJGcnKx+8x06dKjQaDRiypQpQpIksWXLFvVxOL7dajQa9RuF4/xGo1FIkiS0Wq26zeHDh9X3wKRJk5zWjx8/Xj2u4/yyLItp06aJHTt2iEGDBgkAaotUp06dRPfu3cVff/0lAIjXX39dyLKstr454p89e7bakgHAKf6BAweKQYMGFXqPOvYtSmW03OTm5oo2bdqIBx54oNj9izr/jz/+KHx8fIQkSSIqKkps3769yP2La7mZPn266Nmzp9rCVtaWm8WLF4sffvhB7N69W6xYsUI0bdpUtG/fXlit1mvuX/A95fi3OWPGjELvqYL7l/Qczpo1S9SqVUvk5uaWOv68vDwxdOhQ9d+yXq8XX3zxRZH7F9VyYzabRZ06dcTAgQPFxYsXhclkEjNnzhQARK9evZz2t9ls4qabbnJ6DF9//bXQ6/WFztW+fXvx3HPPFVrOlhvlebzzzjtFly5dnJZ/8sknYv369WL37t3if//7n4iOjhYDBgwo8hiueh6Li/3SpUuiV69eTteUDRs2qOvfeOMN0ahRo0LHCw0NFR999FGlxsjkphI9+OCDQpZl8dNPPwkhhNDpdGq31OLFi0VMTIya4EyYMEEEBQWJRYsWFZvcdOzYUdx+++0iISFB3HfffeqygiIiIoQkSepFtnbt2sLLy0vt9khPTxdhYWHCaDSK48ePC5PJJI4cOSI+/vhjdZ8FCxaIxMRE8fLLLwt/f381QXryySdFSEiI2Ldvn/jjjz/UD9V///1XPb+Pj49o166dEEKIpKQkERYWJv7991/1A7RgcuM4xpQpU9T9L126JGRZFrfffrvT43Lsf/LkSeHv7y8+++wzdf/o6GinbYODg0VUVJT6nHfq1EkIkX+xvu+++8RNN90khBDizJkzAoC4//77Ra9evcT//d//CSGE6Nu3r7jvvvsKnb93797qMsf5/fz8xOLFi8Xu3bvFl19+KTQajbjzzjuFEEJ9nRcvXizWrVsnAIiAgAA1uXKcPzQ0VH3+27dvL6Kjo4W/v78QQoijR4+Kbt26qe+L5s2biyFDhogmTZqoy+6//36nmHr27OkUvyuSG7PZLPr27Svi4uJEenp6sfsXdf6srCxx5MgRkZCQIB5++GERGxsrUlNTC21XVHKzY8cOER4e7tSsXdbk5mrHjh0rtmvs6v0LvqcKuvo9VXD/kpKbxo0bOyXEpYn/rbfeEo0aNRKrVq0S//77r3j//feFr6+v2LhxY6H9i0puhFCex1atWqnvy969e4vbb79d9OnTx2m70aNHq1+2mNyU3+jRo0XdunXF6dOnS9xu06ZNAoA4evRooXWueh6Li338+PGiQ4cO4ueff1avKQEBAWL37t1CCCY31dK4cePUWheNRiM0Go36IeZIPubOnSs++ugj9cP5tddeE40bN1a3K3hRASCaNWsmnnjiCSGEECaTSQDONTfjxo0Tfn5+ok2bNuLy5cvi4YcfFjExMaJVq1Zi7NixIiMjQ4SHhwuDwSAOHDjgFO/u3bvV1qFRo0apy2+77TbRt29f9YPrtttuE6NGjRLHjx9X43Q8voKPUaPRiO+//179XZZlp8ev0WjE0aNHBQDx1VdfOcVSq1Yt0axZM6dlBWtu2rVrJyZPnqzG0L17d6dt27RpI7y8vIQQQtSpU0eMHDlSCJF/sZ4yZYqa/JhMJqHVasXTTz8tZFkWK1euFEII8dxzz4nOnTurx1y8eLEAIL7++mt1meP8Q4cOdTp/ixYt1MQkJiZGfPDBB07nHzt2rGjcuLHT+V977TWRlZWlJrSNGzd2am0TQoh9+/ap74tBgwaJO+64Q231ee2114QQ+RfhYcOGOcXfrVs39b1T0PVKbsxms+jfv79o2bKlOH/+fIn7XyuxEEKIBg0aqC2bBRWV3Lz77rvqe6zg+1KWZVG3bt1yxxASEiLmzZt3zf0LvqYFXf2eKrh/ccmNo34uMTGx2LiuPn9OTo7Q6XRq/YvDyJEjnZJzh+KSG4fLly+LtLQ0IYQQHTp0EGPHjlXXjRs3TsTExIhvvvnG6TE4LsBXP6Y6deqI2bNnFzpHTU9uHM/j8ePHr7ltVlaWACDWr19faJ0rnsfiYnd8vhes2xJCuaY89thjQgghFixYUOhzzmKxCI1GI5YvX16pcbLmpoKEEBg/fjxWrFiBjRs3Ys+ePUhMTFTrLHx9fTFkyBAEBARAq9U61WJoNBrY7XYAQGBgIDZt2uR07MOHD6NTp04AAL1eD0Dp5yx4zo4dO6JRo0Z44YUXsH79eixcuBB79uzBbbfdhoYNG+LSpUvYvn17oeHUjup1rVar9rdfHROg1BOYTCbExsYiIiICo0aNUh9fYmIivLy80Lx5cyQmJqJnz57q4//ss88AAHFxcRgyZAgSExNxww03ICoqymn4YFZWFjIyMgqNbim4/tixY4iMjERsbCy8vLxw/Phxp21Onz6t9vt26dKl0PDEpKQk1K1bV30e27dvj59++glhYWG488471efasQ0ArF+/HgCcahYcw8gLjuIBgAsXLqg1Lzk5OerILwdZltXn1HH+Q4cOwcfHB5GRkbh06RKOHTuGhg0bOu3n7e0NAMjIyMCGDRvQr18/AEDDhg3Vx1ivXj1ERERgx44davwZGRnYtm2b+t653iwWCwYNGoQjR47g559/RnBwcIWP6XjflcZDDz2E3bt3O70vo6Ki8Oyzz2LDhg3lOv9///2HCxcuIDIy8prbFnxNC7r6PVUaCxYsQNu2bctUb2SxWGCxWAq9767+t1xaAQEBCA0NxZEjR7Bjxw7069fP6TPnl19+KfS8tG3bFjqdzukz7NChQ0hKSqqy92F1cPXzWK9evWvu45iaoTTvxevpWrE76oJKeh926tQJly9fxs6dO9X1v/zyC+x2Ozp27FjpAVMFjBkzRgQEBIgtW7aI5ORk9ScnJ0ds375dSJIkOnXqJPr27Sv8/PyETqcTAMSDDz4ofH19xb333qvWkPj4+IiXXnpJfPnll2r3xzfffCPmzp0r7rrrLvXbaNu2bYWvr6944oknhCRJokOHDsLX11dMmzZNxMTEiJ49e4qQkBAhy7L4+uuvxerVq8WYMWPEXXfdJRYtWiQ+/fRTER0drX7DnTt3rjh69Kjo0qWLACCGDx8uAIghQ4YISZLEsmXLhBDKN2R/f3/x3XffiSNHjogXX3xRSJIkhg8frj4fycnJYteuXWL+/PkCgGjdurV44IEHxIULF4QQQvTo0UN4e3uLDz/8UCxdulTUq1dPABDbtm0TQijNnfPnzxczZswQAES7du1EYGCgOHTokBBCiKeeekrtAvj5559F//79BQDxzjvvCCGUkTparVaMHz9ejcFgMIg33nhDJCcnCyGEWLZsmQAg+vTpI44cOSLef/99odFoxO+//y6Sk5PFzp07RVBQkACUkWi7du1S42/fvr2QJElMnjxZbN68WX39HK1fw4YNE5GRkWLu3Lli4cKF6us4fPhw9fxTp04VGo1GTJ8+XXz++eciOjpaABCbN28WQgjx3XffiQ8++EAsWLBAAEotToMGDdRurhEjRgitVitmzJghjhw5or43ZsyYIXbv3i369esn6tWrp9ZsZGZmirVr14olS5YIQKnbWrJkiVi7dq3IzMwUFy5cELt27RJr1qwRAMSSJUvErl271HgzMzPFxo0b1f0BiAULFoi1a9eKlJQUcdddd4mYmBiRmJjo9G/AZDJd8/wpKSliypQpIiEhQZw8eVLs2LFDjBgxQhgMBqdvgPv37xdLliwRo0ePFgDE008/LZYsWSL2799f5L/Lq7ulSoohOTlZPPPMMyIhIUGcOHFC/Pzzz6JNmzaiYcOGIi8vr1TP4fLly4VOpxOffvppoffUtZ5Dx3srPT1deHt7i48//rjQ47nW+bt37y6aN28uNm/eLI4fPy4+//xzYTQanZr6jx49KpYsWSKmTp0qAKUWbMmSJWo387fffis2b94sjh07JlauXCnq1q0r7r77bqfPue+//15s3LhRvP322wKA2Lhxo/rvY/To0aJOnTril19+ETt27BCdOnVSu4gdjhw5Inbt2iUee+wx0ahRI7Fr1y6xa9cu9b3i6Uq6XgihvEavvvqq2LFjhzhx4oT44YcfxA033CC6devmdBxXPI/Xit1sNosGDRqIrl27im3btomjR4+Kt99+W0iSpNZuCiFEnz59RFxcnNi2bZvYunWraNiwYaEu3crA5KaCHB9UV/98/vnnQgilyyI4OFgtLnWXH29vb9GhQwfRpUsXERYWJry9vdVC4uIeixBCzJgxQ8TExAhvb2/RqVMn0bp1a6dhi9OmTSvxGIMHDxZ+fn5qd1VwcLBYsmSJun/z5s2vGcPQoUPV59PLy0s8++yzTq/JhAkTijzGtGnThBBCLXauU6eOMBqNolWrVmr31LXiz8jIEJ07d1YTQ4PBIIYOHap+qGRkZIiePXuWeP6lS5eqNTcARHBwsFP315gxY0r1Gvr5+Qmj0ShatmwpBg0apHZB3nbbbWoyKER+N0RRP5s3b3YqSi4q3pL2f+utt0o89rX237BhgxgwYICIiooSer1eREZGirvuuqtQQfHVxfiOn6K6XYQonNyUFMP69etFr169RGhoqNDpdKJu3bri0UcfFSkpKaV+DoVQmtwbNGhQ6D11rf0d761PPvlEeHl5icuXLxd6PNc6f3Jyshg+fLiIiooSRqNRNG7cWLzzzjtOUxwMGzasyP0dRaHvvfeeiImJETqdTtSpU0e8+OKL6vv6Wu/Fzz//XOTm5oqxY8eKWrVqCW9vbzFgwAA1QXbo3r17kfufOHGiyNfR01zrPZCUlCS6desmgoKChMFgEA0aNBDPPvtsoRo2VzyP14pdCCEOHz4s7r77bvWa0rJly0JDwy9cuCDuv/9+4evrK/z9/cWIESNEZmZmpccrXQmaiIiIyCOw5oaIiIg8CpMbIiIi8ihMboiIiMijMLkhIiIij8LkhoiIiDwKkxsiIiLyKExuiIiIyKMwuSEiIiKPwuSGiNyCEAKjRo1CUFAQJElCYmIievTogSeffFLdJjY2FnPmzLmucWzatAlNmzaFzWa7LscfPnw4+vfvX+rtzWYzYmNjsWPHjusSD5EnYnJDVAMNHz4ckiRh5syZTstXrlwJSZJcEtP69euxaNEirF69GsnJyWjRogWWL1+O1157rUrjeO655/Diiy+qN0N9+eWX0bp160o7/nvvvYdFixaVenu9Xo9nnnkGkyZNqrQYiDwdkxuiGspoNGLWrFm4dOmSq0MBAPXu7507d0ZERAS0Wi2CgoLg5+dXZTFs3boVx44dwz333FPmfS0WS6m2CwgIQGBgYJmOPWTIEGzduhX79u0rc1xENRGTG6IaKj4+HhEREZgxY0ax2xTVajFnzhzExsaqfzu6WaZPn47w8HAEBgbi1VdfhdVqxbPPPougoCDExMTg888/L/Y8w4cPx+OPP46kpCRIkqQe/+puqatdvnwZjzzyCEJDQ+Hv749bb70V//77r7r+33//xS233AI/Pz/4+/ujbdu2JXbvLFmyBD179oTRaAQALFq0CK+88gr+/fdfSJIESZLUVhdJkvDxxx/jrrvugo+PD9544w3YbDaMHDkS9erVg5eXFxo3boz33nuv0GMt2C3Vo0cPPPHEE3juuecQFBSEiIgIvPzyy0771KpVC126dMGSJUuKjZ2I8mldHQARuYZGo8H06dPxwAMP4IknnkBMTEy5j/XLL78gJiYGv/32G/744w+MHDkSf/75J7p164Zt27Zh6dKleOyxx9CzZ88iz/Pee++hfv36+PTTT/H333+rXULXMnDgQHh5eWHdunUICAjAJ598gttuuw2HDx9GUFAQhgwZgri4OHz88cfQaDRITEyETqcr9ni///47HnjgAfXvwYMHY+/evVi/fj1+/vlnAErLi8PLL7+MmTNnYs6cOdBqtbDb7YiJicF3332H4OBg/Pnnnxg1ahQiIyMxaNCgYs/7xRdfYOLEidi2bRsSEhIwfPhwdOnSBT179lS36dChA37//fdSPS9ENR2TG6IabMCAAWjdujWmTZuGBQsWlPs4QUFBmDt3LmRZRuPGjfHmm28iJycHzz//PABgypQpmDlzJrZu3Yr77ruv0P4BAQHw8/ODRqNBREREqc65detWbN++HWlpaTAYDACAt99+GytXrsSyZcswatQoJCUl4dlnn0WTJk0AAA0bNizxmKdOnUJUVJT6t5eXF3x9faHVaouM64EHHsCIESOclr3yyivq7/Xq1UNCQgK+/fbbEpObli1bYtq0aWqMH3zwATZt2uSU3ERFReHUqVMlxk9ECnZLEdVws2bNwhdffIEDBw6U+xjNmzeHLOd/nISHh+PGG29U/9ZoNAgODkZaWlqFYi3o33//RVZWFoKDg+Hr66v+nDhxAseOHQMATJw4EY888gji4+Mxc+ZMdXlxcnNz1S6p0mjXrl2hZR9++CHatm2L0NBQ+Pr64tNPP0VSUlKJx2nZsqXT35GRkYWeKy8vL+Tk5JQ6NqKajMkNUQ3XrVs39O7dG1OmTCm0TpZlCCGclhVVOHt1V48kSUUus9vtlRCxIisrC5GRkUhMTHT6OXToEJ599lkASrfRvn37cOedd+KXX35Bs2bNsGLFimKPGRISUqYCax8fH6e/lyxZgmeeeQYjR47ETz/9hMTERIwYMQJms7nE45Tmubp48SJCQ0NLHRtRTcZuKSLCzJkz0bp1azRu3NhpeWhoKFJSUiCEUIeIJyYmuiDCwtq0aYOUlBRotVqnAuerNWrUCI0aNcJTTz2F+++/H59//jkGDBhQ5LZxcXHYv3+/0zK9Xl/qOW/++OMPdO7cGWPHjlWXXau1qLT27t2LuLi4SjkWkadjyw0R4cYbb8SQIUMwd+5cp+U9evTAuXPn8Oabb+LYsWP48MMPsW7dOhdF6Sw+Ph6dOnVC//798dNPP+HkyZP4888/8cILL2DHjh3Izc3F+PHjsWXLFpw6dQp//PEH/v77bzRt2rTYY/bu3Rtbt251WhYbG4sTJ04gMTER58+fh8lkKnb/hg0bYseOHdiwYQMOHz6MqVOn4u+//66Ux/v777+jV69elXIsIk/H5IaIAACvvvpqoa6Qpk2b4qOPPsKHH36IVq1aYfv27XjmmWdcFKEzSZKwdu1adOvWDSNGjECjRo1w33334dSpUwgPD4dGo8GFCxcwdOhQNGrUCIMGDcLtt9/uVPB7tSFDhmDfvn04dOiQuuyee+5Bnz59cMsttyA0NBSLFy8udv/HHnsMd999NwYPHoyOHTviwoULTq045ZWQkID09HTce++9FT4WUU0gias71ImIarBnn30WGRkZ+OSTT1wdimrw4MFo1aqVOvqMiErGlhsiogJeeOEF1K1bt1KLnyvCbDbjxhtvxFNPPeXqUIiqDbbcEBERkUdhyw0RERF5FCY3RERE5FGY3BAREZFHYXJDREREHoXJDREREXkUJjdERETkUZjcEBERkUdhckNEREQehckNEREReZT/B+NkCgURegCHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('0', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40234c7c",
   "metadata": {
    "papermill": {
     "duration": 0.749273,
     "end_time": "2024-01-14T16:20:08.004702",
     "exception": false,
     "start_time": "2024-01-14T16:20:07.255429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab7646f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.77343,
     "end_time": "2024-01-14T16:20:09.586486",
     "exception": false,
     "start_time": "2024-01-14T16:20:08.813056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a70ecb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.751413,
     "end_time": "2024-01-14T16:20:11.090966",
     "exception": false,
     "start_time": "2024-01-14T16:20:10.339553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6aaaf3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.743764,
     "end_time": "2024-01-14T16:20:12.638383",
     "exception": false,
     "start_time": "2024-01-14T16:20:11.894619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791beaa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.804927,
     "end_time": "2024-01-14T16:20:14.208385",
     "exception": false,
     "start_time": "2024-01-14T16:20:13.403458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594d8a3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.744844,
     "end_time": "2024-01-14T16:20:15.710850",
     "exception": false,
     "start_time": "2024-01-14T16:20:14.966006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7576.859891,
   "end_time": "2024-01-14T16:20:22.622241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-14T14:14:05.762350",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
