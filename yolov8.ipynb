{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491c8dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:01:16.983495Z",
     "iopub.status.busy": "2023-12-01T15:01:16.982734Z",
     "iopub.status.idle": "2023-12-01T15:02:21.910998Z",
     "shell.execute_reply": "2023-12-01T15:02:21.909943Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 64.936943,
     "end_time": "2023-12-01T15:02:21.913083",
     "exception": false,
     "start_time": "2023-12-01T15:01:16.976140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\r\n",
      "pytoolconfig 1.2.6 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\r\n",
      "tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m--2023-12-01 15:02:12--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.113.3\r\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231201T150213Z&X-Amz-Expires=300&X-Amz-Signature=0a5a2edcb903db8093d933633258dbcdbddb2ee2f433debfd90259e4b2b88414&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-12-01 15:02:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231201T150213Z&X-Amz-Expires=300&X-Amz-Signature=0a5a2edcb903db8093d933633258dbcdbddb2ee2f433debfd90259e4b2b88414&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: ‚Äòyolov8m-seg.pt‚Äô\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   246MB/s    in 0.2s    \r\n",
      "\r\n",
      "2023-12-01 15:02:13 (246 MB/s) - ‚Äòyolov8m-seg.pt‚Äô saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.221, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in puddle-segmentation-8 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48211/48211 [00:01<00:00, 41157.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to puddle-segmentation-8 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4847/4847 [00:00<00:00, 8803.44it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"hanyang-university-bd2kb\").project(\"puddle-segmentation\")\n",
    "dataset = project.version(8).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1627364e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:02:21.928902Z",
     "iopub.status.busy": "2023-12-01T15:02:21.928436Z",
     "iopub.status.idle": "2023-12-01T15:02:21.960356Z",
     "shell.execute_reply": "2023-12-01T15:02:21.959474Z"
    },
    "papermill": {
     "duration": 0.04254,
     "end_time": "2023-12-01T15:02:21.962522",
     "exception": false,
     "start_time": "2023-12-01T15:02:21.919982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/puddle-segmentation-8\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/puddle-segmentation-8\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe86057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:02:21.979523Z",
     "iopub.status.busy": "2023-12-01T15:02:21.979208Z",
     "iopub.status.idle": "2023-12-01T15:02:22.083807Z",
     "shell.execute_reply": "2023-12-01T15:02:22.083045Z"
    },
    "papermill": {
     "duration": 0.115963,
     "end_time": "2023-12-01T15:02:22.085998",
     "exception": false,
     "start_time": "2023-12-01T15:02:21.970035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): –ø—É—Ç—å –¥–æ –≤–µ—Å–æ–≤ yolov8.pt\n",
    "            path_to_yaml (str): –ø—É—Ç—å –¥–æ data.yaml —Ñ–∞–π–ª–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "            train_perc (float): –¥–æ–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö \n",
    "            test_perc (float): –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            val_perc (float): –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, '–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è train –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —á–∞—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö\n",
    "            iters (int): –∫–æ–ª-–≤–æ –∏–Ω—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "        Returns:\n",
    "            YOLO: —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        \"\"\"        \n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —á–∞—Å—Ç—è—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏ –ø—Ä–æ—Å–∞–¥–∫–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —á–∞—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö\n",
    "            iters (int): –∫–æ–ª-–≤–æ –∏–Ω—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "        Returns:\n",
    "            YOLO: —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # —Å–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫—É—Å–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–æ –Ω–∞—à–µ–≥–æ folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # –∫–æ–ø–∏—Ä—É–µ–º –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –∫—É—Å–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–ø–∫—É retrain\n",
    "        for path in source_pathes:\n",
    "            # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∏ train/test/val. –£–¥–∞–ª–µ–Ω–∏–µ 1-keep_perc –¥–æ–ª–∏ –¥–∞–Ω–Ω—ã—Ö \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å\n",
    "        \"\"\"        \n",
    "        # —Å–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã\n",
    "            allfiles = os.listdir(path)\n",
    "            # –∏—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º, —á—Ç–æ–±—ã –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –∏—Ö –≤ –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –∫ label —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # –ö–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞,\n",
    "                # –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - {empty_count}\")\n",
    "        # –û—Å—Ç–∞–≤–ª—è–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∏–º–µ–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤ –∏ –±—ã–ª —É–∂–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º train, test, val —Å —É—á–µ—Ç–æ–º —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ —Ä–∞–≤–Ω—ã–µ –¥–æ–ª–µ piece_perc –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): –¥–æ–ª—è —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –∫ label —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # –ö–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞,\n",
    "                # –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"–ö–ª–∞—Å—Å {key} —Å–æ–¥–µ—Ä–∂–∏—Ç {value} –æ–±—ä–µ–∫—Ç–∞(-–æ–≤)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # –†–∞–∑–¥–µ–ª–∏—Ç—å —Å–Ω–∞—á–∞–ª–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º, –∞ –ø–æ—Ç–æ–º –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"–ö–ª–∞—Å—Å {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\t–ö–æ–ª-–≤–æ train –∫–ª–∞—Å—Å–∞ {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\t–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∞ {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\t–ö–æ–ª-–≤–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "            color_dict (dict): —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAM –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # –¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/—Ç–µ—Å—Ç–æ–≤—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # –ø—É—Ç—å –∫ –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–º –≤–µ—Å–∞–º yolov8 –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –ø–æ–Ω–∏–∂–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ \n",
    "        for cls in cls_tl_dict.keys():\n",
    "            result_dict = defaultdict(list)\n",
    "            # —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "            color_dict = defaultdict(str)\n",
    "            # –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ map –≤ —Ü–µ–ª—è—Ö –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∏ –ø—Ä–æ—Å–∞–¥–æ–∫ –º–µ—Ç—Ä–∏–∫–∏\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "                model = self.train(folder_name, iters)\n",
    "                # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–µ—Ç—Ä–∏–∫–∞ —É–ª—É—á—à–∞–µ—Ç—Å—è\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ) –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: \\n {result_dict}\")\n",
    "            print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "\n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # –¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/—Ç–µ—Å—Ç–æ–≤—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # –ø—É—Ç—å –∫ –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–º –≤–µ—Å–∞–º yolov8 –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –ø–æ–Ω–∏–∂–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "            metrics = self.test(model)\n",
    "            # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–±–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219f497b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:02:22.102165Z",
     "iopub.status.busy": "2023-12-01T15:02:22.101860Z",
     "iopub.status.idle": "2023-12-01T16:06:40.832639Z",
     "shell.execute_reply": "2023-12-01T16:06:40.831505Z"
    },
    "papermill": {
     "duration": 3858.741436,
     "end_time": "2023-12-01T16:06:40.835101",
     "exception": false,
     "start_time": "2023-12-01T15:02:22.093665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1712_jpeg_jpg.rf.6743aa15f86650f685950f10335cf521.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1448_jpeg_jpg.rf.3f5fe2090c8f83954eb4f85fd33640e2.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image338_jpeg_jpg.rf.07290b77d8614388be0b6c5b477f26a0.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1448_jpeg_jpg.rf.1fac25f8cfc0311e0760a5ed6eac65ff.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image19_jpeg_jpg.rf.24a170542d199cfbc933b873efd7927c.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image338_jpeg_jpg.rf.f9c964dba32479debf57bfd0ce1347ba.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image792_jpeg_jpg.rf.8c58f9581d896f6750687b056b28b03d.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230426_113303172_04_jpg.rf.414a8956b61140c1970b8eafa8295ca6.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230303_155124767_05_jpg.rf.462d7aa0eea136c4312720cdd11ca6ce.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image88_jpeg_jpg.rf.253074927d14756c8d4973890e49988d.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1712_jpeg_jpg.rf.cd253201a1e39224af7ac10a51f12418.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230426_113303172_04_jpg.rf.84776f54da07a3a109e2a92b854a78c2.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1262_jpeg_jpg.rf.96c564b12ee68002c5df0c945a013755.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230112_175920520_mp4-1_jpg.rf.04d9f2e8993ecb9e8302e106c7aa5294.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1262_jpeg_jpg.rf.f6a8e4b4c0eb096527a742a41303d802.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1804_jpeg_jpg.rf.d5363ee6e9d102616061d5e9cd21c9b3.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image19_jpeg_jpg.rf.5b1c01c0e5778c81a7002d3c74a700ab.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image88_jpeg_jpg.rf.0321e07f5c0ce99e1d79187fd033cd2b.txt\n",
      "–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - 18\n",
      "valid_0/images 240\n",
      "test_0/images 241\n",
      "train/labels 1920 \n",
      "\n",
      "–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - 0\n",
      "–ö–ª–∞—Å—Å 0 —Å–æ–¥–µ—Ä–∂–∏—Ç 1920 –æ–±—ä–µ–∫—Ç–∞(-–æ–≤)\n",
      "\n",
      "–ö–ª–∞—Å—Å 0\n",
      "\t–ö–æ–ª-–≤–æ train –∫–ª–∞—Å—Å–∞ 0: 1920\n",
      "\t–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∞ 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1920]\n",
      "\t–ö–æ–ª-–≤–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: 43 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 500, folder 40, cls 0\n",
      "\tnum_to_mv_train 500, folder 41, cls 0\n",
      "\tnum_to_mv_train 419, folder 42, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 500\n",
      "temp_0_41/train/images 500 \n",
      "\n",
      "temp_0_42/train/labels 500\n",
      "temp_0_42/train/images 500 \n",
      "\n",
      "temp_0_43/train/labels 419\n",
      "temp_0_43/train/images 419 \n",
      "\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 14.5MB/s]\n",
      "2023-12-01 15:02:27,630\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-01 15:02:28,953\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 74.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 154.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 897.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/valid_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      1.59G      1.942      2.922      4.514      1.775          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0565      0.108     0.0219     0.0078     0.0399     0.0777     0.0128    0.00369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G      2.805      11.19       6.57      2.628          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0579       0.11     0.0223    0.00773     0.0402     0.0801     0.0127    0.00366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.59G      1.706      8.392       6.81      1.764          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0594      0.113     0.0222    0.00758     0.0403     0.0829     0.0128    0.00358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.59G      1.382       6.36      6.292       2.38          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0575       0.11     0.0213    0.00746     0.0415     0.0856     0.0132    0.00367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.59G      2.383      10.54      7.826      2.904          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.052       0.11      0.021    0.00728     0.0416     0.0884     0.0128     0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0563      0.108     0.0219    0.00781     0.0395     0.0773      0.013     0.0037\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÜ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñÉ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.38298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 7.82598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.90364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 10.53503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.87078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.19191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.77475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_150245-tzxuwy2g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_150245-tzxuwy2g/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<00:00, 895.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/test_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0697       0.14     0.0275    0.00957      0.045     0.0795     0.0134    0.00448\n",
      "Speed: 1.2ms preprocess, 27.9ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 754.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.74G      1.708      5.543      3.419      1.958         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0382      0.127     0.0165    0.00538     0.0232     0.0497    0.00628    0.00169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.57G      2.361      7.627      5.819      2.559          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0421      0.141     0.0169    0.00551      0.018     0.0497    0.00633     0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.49G      2.133      5.479      4.521      2.615          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0393      0.116     0.0163     0.0054     0.0169     0.0497    0.00586    0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.52G      2.433       5.85      4.116      2.296         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0374      0.113     0.0163    0.00539     0.0211     0.0525    0.00584    0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      2.252      5.314      3.917      2.404          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0377      0.119     0.0161     0.0054     0.0191     0.0442    0.00565    0.00162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0429      0.144     0.0174    0.00557     0.0182     0.0497    0.00636     0.0017\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñà‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñà‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñá‚ñÖ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñà‚ñÜ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.14365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.25226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.9174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.40421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.3141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.97188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.29094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.47597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_150552-llaluvat\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_150552-llaluvat/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0477      0.109     0.0197    0.00681     0.0311     0.0712     0.0087    0.00244\n",
      "Speed: 1.3ms preprocess, 28.4ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1797.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.66G      2.411      7.067      3.766      2.431         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0562      0.119     0.0218    0.00793      0.043     0.0967     0.0133    0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.96G      2.445      8.473      4.669      2.357          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0563      0.113     0.0221    0.00787     0.0443     0.0939     0.0133    0.00371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.99G      2.498       8.19      4.231      2.379         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0593      0.127     0.0217     0.0077     0.0404     0.0884     0.0127    0.00356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.97G      2.645      7.026      3.888      2.796         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0573      0.122     0.0215    0.00747     0.0395     0.0967      0.013    0.00355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.99G      1.744      5.795      4.453      2.001         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.056      0.127     0.0213    0.00739     0.0378     0.0967     0.0131    0.00361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0574      0.122     0.0218    0.00795     0.0433     0.0967     0.0134    0.00375\n",
      "Speed: 1.2ms preprocess, 13.7ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñá‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÜ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.09669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.74429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.45287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.00115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.7949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.87505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.19147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.78635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_150753-8nigrux2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_150753-8nigrux2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0679       0.13     0.0267    0.00922     0.0448     0.0738     0.0137    0.00441\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 823.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.77G     0.9203      6.619      2.703      1.497          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0422      0.141     0.0171    0.00557     0.0201     0.0525    0.00565     0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      2.014      5.872      3.665      2.543          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0384      0.119     0.0164    0.00555     0.0221     0.0359     0.0061    0.00171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.48G      1.388      5.378      3.794      1.942          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0375      0.105     0.0163    0.00543     0.0205      0.047    0.00595    0.00171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.48G      1.228      7.115      2.669       1.82          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0406      0.113     0.0167    0.00564     0.0241     0.0414    0.00611    0.00179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      2.512      6.627      6.928      3.154          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0359     0.0994     0.0163    0.00559     0.0254     0.0442    0.00586    0.00178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0399      0.113     0.0166    0.00562     0.0225     0.0387    0.00609    0.00179\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÅ‚ñÜ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.5117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 6.92826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 3.1539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.62672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.24359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.39518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_151147-hypvomez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_151147-hypvomez/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0502      0.137     0.0213    0.00724     0.0349     0.0763    0.00931    0.00257\n",
      "Speed: 1.4ms preprocess, 29.8ms inference, 0.0ms loss, 7.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 873.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.44G      2.028      6.223      4.603       2.17         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0551      0.113     0.0221    0.00795     0.0417     0.0884     0.0135    0.00378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.96G       1.95      7.674      4.373      2.184         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0605      0.124     0.0223    0.00809     0.0459     0.0967     0.0137    0.00388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.83G      1.637      6.153       4.38      2.003         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0617      0.127     0.0232    0.00818     0.0434     0.0939     0.0137    0.00377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.88G      1.771      5.126      3.696      2.087         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0617      0.127     0.0224    0.00781     0.0418     0.0939     0.0132    0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.86G      1.688      7.122       4.18      1.918         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0583      0.122     0.0219    0.00781     0.0431      0.102     0.0133    0.00364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0615      0.127     0.0231    0.00813     0.0435     0.0939     0.0136     0.0038\n",
      "Speed: 1.3ms preprocess, 13.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÑ‚ñà‚ñá‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÅ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÉ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.09392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.18014\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.91776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 7.12209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.84483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.83438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.17993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.75019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_151348-ahjj6mwv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_151348-ahjj6mwv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0712      0.132     0.0274    0.00961      0.046     0.0763     0.0143    0.00481\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 3964.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.78G      1.134      3.557      4.218      1.523          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0418      0.171     0.0168    0.00538     0.0247     0.0304     0.0057    0.00163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      1.132      4.539      4.937      1.821          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0392      0.144     0.0158    0.00503     0.0189     0.0414    0.00542    0.00154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.47G      1.155      3.799      6.569       1.09          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0402      0.155     0.0167    0.00534     0.0201     0.0387    0.00537    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.48G       1.91      3.425       8.19      1.535          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0409      0.149     0.0166    0.00547     0.0191     0.0442     0.0054    0.00152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.46G     0.7907      5.665      5.445      1.538          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0413      0.152     0.0168    0.00544     0.0183     0.0608     0.0057    0.00152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0411      0.169     0.0167    0.00535     0.0227     0.0276    0.00572    0.00163\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÅ‚ñá‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÅ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñà‚ñÅ‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.16851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.02762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.79074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.44545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.66529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.98253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.30011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.49671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_151745-igvu3sok\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_151745-igvu3sok/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393      0.046      0.127     0.0189     0.0065     0.0354     0.0712    0.00791    0.00219\n",
      "Speed: 1.3ms preprocess, 29.7ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 11945.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.64G      1.583      5.148      4.082       1.98         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0548      0.116     0.0221    0.00786     0.0378     0.0801      0.013    0.00372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.66G      1.728      4.908      4.421      1.878         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0602      0.124      0.022    0.00792     0.0418     0.0884     0.0134    0.00374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.56G      2.094      6.667      3.761      2.241         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0602      0.127      0.022    0.00788     0.0415     0.0912     0.0133    0.00371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.54G      1.856      5.111       4.88       2.08         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0576      0.127     0.0217    0.00774     0.0405     0.0912      0.013    0.00357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.54G      1.974        6.3      4.352       2.24         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0576      0.119     0.0218    0.00757     0.0394     0.0967     0.0123    0.00344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0567      0.116     0.0222    0.00793     0.0392     0.0801     0.0131    0.00369\n",
      "Speed: 1.2ms preprocess, 13.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñà‚ñá‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÖ‚ñÅ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.97384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.35186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.23984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.29978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.84482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.17997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.74894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_151946-qfbb1yfj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_151946-qfbb1yfj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0666      0.127     0.0271    0.00941     0.0477     0.0738     0.0141    0.00457\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 620.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.78G      1.473      6.496      3.347      2.039          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0412      0.146      0.017    0.00539     0.0196      0.047    0.00565    0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.57G      2.087      6.426      4.442      2.504          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0393      0.138     0.0161    0.00541     0.0197     0.0497    0.00556     0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.6G      2.847      5.092      4.874      3.137          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0391      0.149     0.0161    0.00537     0.0201      0.058    0.00598    0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.6G     0.9912      5.576      2.935      1.698          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0393      0.138     0.0166    0.00577     0.0196     0.0608    0.00635    0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       1.6G       2.58      5.516      8.074      2.615          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0377      0.116      0.017    0.00596      0.017     0.0442    0.00608    0.00171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0373      0.127     0.0171    0.00591     0.0177      0.047    0.00626    0.00173\n",
      "Speed: 0.8ms preprocess, 13.7ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñá‚ñá‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÉ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.57989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 8.07429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.61511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.51597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.98308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.29593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.24323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.42208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_152342-6gdtyqer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_152342-6gdtyqer/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0526      0.122     0.0216    0.00714     0.0378     0.0585    0.00836    0.00235\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1443.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         5G       1.65      5.137      4.465      1.963         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.055      0.116     0.0227    0.00808      0.038     0.0801     0.0138    0.00386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.41G      1.753      5.485      4.336      1.996         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0585      0.119      0.022    0.00783     0.0436     0.0912     0.0135    0.00373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.33G      1.888      5.782      3.746      2.023         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0577      0.119     0.0214    0.00768     0.0417     0.0884     0.0133    0.00364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.22G      1.488      3.859      4.544       1.71         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.057      0.119     0.0216    0.00765     0.0402     0.0856     0.0129     0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.27G       1.76      6.403      4.383      2.131         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0537       0.11     0.0211     0.0075     0.0407     0.0967     0.0126    0.00348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0538      0.111     0.0225    0.00802      0.041     0.0893     0.0134    0.00374\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñà‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñá‚ñÜ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.76024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.38291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.13101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.4031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.83492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.18409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.74933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_152546-fw7hx9km\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_152546-fw7hx9km/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0661       0.13     0.0274    0.00965     0.0502     0.0814     0.0146    0.00466\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1843.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.92G      2.105      6.512       3.64      2.433          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0391      0.152     0.0164     0.0052     0.0187     0.0414    0.00573    0.00168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      2.175      5.676      4.822       2.38          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0393      0.144     0.0163    0.00542     0.0229     0.0552      0.006    0.00168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      2.113      6.453      4.143      2.292          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0399      0.133     0.0163    0.00544     0.0205      0.047    0.00592    0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.05G      2.671      4.914      4.859      2.717          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0411      0.138     0.0171    0.00564     0.0239     0.0552    0.00625    0.00174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.09G      2.256      4.826       3.63      1.994         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0381      0.127     0.0174    0.00576     0.0236     0.0552    0.00648    0.00176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0396      0.119     0.0172    0.00579     0.0227     0.0525    0.00648    0.00176\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñá‚ñÉ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÉ‚ñá‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.0227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.25573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.62967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.99402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.82581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.9707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.27525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.39618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_152943-szwjsxbn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_152943-szwjsxbn/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0517      0.122     0.0219    0.00715     0.0289     0.0712    0.00881    0.00247\n",
      "Speed: 1.3ms preprocess, 29.9ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 992.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.9G      1.825      5.353      4.048      2.105         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0547      0.113      0.022    0.00792     0.0428     0.0939     0.0133     0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.12G      1.692      5.184      3.999      1.943         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0549      0.113     0.0216    0.00784     0.0418     0.0912     0.0137    0.00373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.02G       1.92      6.208      4.116      2.173         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0578      0.124     0.0216    0.00773     0.0402     0.0884     0.0132    0.00368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      6.99G      1.697      5.392      4.016      1.956         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0587      0.124     0.0211    0.00771     0.0405     0.0912      0.013    0.00363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      6.96G      1.728      5.733      5.119      2.192         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0551      0.113     0.0207    0.00737     0.0383     0.0967     0.0125    0.00343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0557      0.113     0.0221    0.00799     0.0385     0.0801     0.0134    0.00363\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñá‚ñÖ‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÅ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.72822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.11882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.1921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.73291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.83585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.18532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.75207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_153147-3b0irwec\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_153147-3b0irwec/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0649      0.125     0.0266     0.0094     0.0467     0.0763     0.0137    0.00451\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 7644.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.87G      2.703       4.79      5.917      2.371          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0443      0.166     0.0175    0.00555     0.0217     0.0497    0.00568    0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.14G      2.446      4.775      4.947      2.071          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.041      0.152     0.0169    0.00556     0.0208     0.0522    0.00569    0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.14G       2.41      5.213      7.525      2.336          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0404      0.133     0.0168    0.00538     0.0235     0.0552    0.00574     0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.15G      3.374       5.25      8.595      2.448          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0385      0.124     0.0171    0.00553     0.0207      0.047    0.00566    0.00172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.16G      1.909       5.72      4.595      2.162          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0382      0.133     0.0165     0.0054      0.021     0.0414    0.00602    0.00176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0432      0.157     0.0172    0.00544     0.0199     0.0497    0.00566    0.00168\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÉ‚ñÑ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñà‚ñÅ‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÖ‚ñÉ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñÅ‚ñÜ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñÖ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñá‚ñà‚ñÜ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.15746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.90874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.59495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.16205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.72008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.18495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.37582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_153550-ynv1nrin\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_153550-ynv1nrin/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0448       0.14      0.019    0.00655     0.0367     0.0687    0.00797    0.00221\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 1111.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.37G      2.108      5.323      4.005      2.123         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0573      0.113     0.0226    0.00812       0.04     0.0829     0.0136    0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.23G      2.175      5.141      4.172      2.231         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0551      0.113     0.0219    0.00807     0.0396     0.0829     0.0136    0.00374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.11G      1.751      4.765      4.395      2.002         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0555       0.11     0.0217    0.00788     0.0427     0.0912     0.0133    0.00365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.09G      1.815      4.434      4.817      1.961         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0636       0.13     0.0219    0.00782     0.0412     0.0912     0.0132    0.00368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.11G      2.032      6.042      4.884      2.141         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0593      0.113     0.0216    0.00768     0.0409     0.0967     0.0125    0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.057      0.113     0.0225    0.00811     0.0396     0.0801     0.0135    0.00368\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñÅ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÉ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.03222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.88415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.14131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.04173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.8337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.17714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.73934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_153752-cvt0oddg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_153752-cvt0oddg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0665      0.132     0.0274    0.00962     0.0469     0.0789     0.0146    0.00474\n",
      "Speed: 1.5ms preprocess, 28.6ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1060.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.66G      2.091       4.91      4.837      2.483          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0401      0.141      0.017    0.00543     0.0217      0.047    0.00574    0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.14G      2.446      7.355      5.222      2.265          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0391      0.116     0.0162    0.00529     0.0232     0.0359     0.0056    0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      2.254      6.345      6.182      2.453          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362       0.04      0.105     0.0157     0.0051     0.0232     0.0359    0.00548    0.00158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      2.505      6.565      5.568      2.575          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0426      0.144      0.017    0.00537     0.0249     0.0331    0.00531    0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.05G      2.045      5.224      4.428      2.081          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362       0.04      0.119      0.016    0.00536     0.0262     0.0331    0.00543    0.00168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0403      0.141     0.0171    0.00547     0.0218      0.047    0.00578    0.00166\n",
      "Speed: 1.2ms preprocess, 13.6ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÑ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÖ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñá‚ñÉ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñá‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.14088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.04504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.42792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.08079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.22416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.99679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.1819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.41246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_154155-z4v36wi0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_154155-z4v36wi0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0468      0.135     0.0194    0.00656     0.0337     0.0687    0.00786    0.00223\n",
      "Speed: 1.2ms preprocess, 29.8ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 1240.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.34G      1.925      5.974      4.932      2.024          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0579      0.119     0.0211    0.00751     0.0405     0.0884     0.0128    0.00354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.53G      2.287      5.422      4.862      2.335          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0585      0.127     0.0211    0.00733     0.0371     0.0939     0.0125    0.00346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.43G      1.655      5.887      3.542      2.003         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0556      0.119     0.0205     0.0073     0.0369     0.0994     0.0122    0.00327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.14G      1.579      5.436      4.489      1.932          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.052       0.13     0.0195    0.00689     0.0353     0.0912     0.0116    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.57G      1.765      5.976      3.817      1.915         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0515      0.119     0.0191    0.00682      0.036     0.0801      0.011     0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0578      0.122      0.021    0.00753     0.0393     0.0856     0.0127    0.00354\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñà‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñá‚ñà‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñà‚ñÅ‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÅ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.7655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.81739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.91546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.97576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.79386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.21314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.8326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_154356-n3z89fje\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_154356-n3z89fje/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0645       0.14     0.0266    0.00928     0.0433     0.0712     0.0138    0.00446\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1270.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.1G     0.8557      4.359      2.393      1.369          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.033      0.119      0.014    0.00466     0.0216     0.0359    0.00475    0.00142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.978      5.911      4.094      2.293          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0353      0.108     0.0142    0.00479     0.0182     0.0442    0.00494    0.00145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      1.422      6.265      2.874      2.176          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0342      0.102     0.0144    0.00501     0.0206     0.0497    0.00518    0.00149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      1.625      4.783       5.02       2.25          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0343      0.105      0.015    0.00515     0.0246     0.0497    0.00521    0.00154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G      2.078      7.093      2.909      2.104         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0368      0.102     0.0148    0.00517     0.0271     0.0525    0.00553    0.00157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.037       0.11     0.0147    0.00517     0.0277     0.0525    0.00548    0.00156\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÜ‚ñÇ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñà‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÖ‚ñÜ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.1105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.07841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.9088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.10449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 7.09292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.01983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.13341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.53054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_154801-2rkwcagf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_154801-2rkwcagf/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0404      0.148     0.0181      0.006     0.0244     0.0865    0.00663    0.00202\n",
      "Speed: 1.3ms preprocess, 29.9ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 1063.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.998      5.377      4.352      2.067         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0567      0.122     0.0218    0.00799     0.0436     0.0967     0.0136    0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.56G      1.897      4.951      4.253      2.104         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0584      0.127     0.0217    0.00791     0.0422     0.0994     0.0131    0.00362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.37G      1.908      6.004      4.594       2.15         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0569      0.122     0.0208    0.00762     0.0388     0.0884     0.0121    0.00346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.09G        1.8      5.513      4.118      2.044         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0571      0.127     0.0208     0.0074     0.0411     0.0941     0.0121    0.00332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.991      6.058      4.534      2.176         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0559      0.122     0.0216    0.00763     0.0423     0.0939     0.0132    0.00364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0578      0.124     0.0218    0.00801     0.0411     0.0884     0.0136    0.00375\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñá‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÜ‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÜ‚ñà‚ñÅ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÉ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñÅ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñá‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.0884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.99147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.53423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.17569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.05815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.82522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.19701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.80549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_155009-r1mev75p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_155009-r1mev75p/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0685       0.14      0.027    0.00965     0.0482     0.0789     0.0142    0.00469\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 3708.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.89G      1.136      3.442      3.688      1.358         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0396       0.16     0.0169    0.00584     0.0208     0.0387    0.00604    0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.422      5.086      4.016      1.915          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0387      0.135     0.0164    0.00582     0.0256     0.0414    0.00622     0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G      1.518      4.482      3.722      1.625          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0402      0.119     0.0171    0.00598     0.0289     0.0442    0.00634    0.00189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      1.427       5.43      4.011      1.964          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0401       0.11     0.0177    0.00604     0.0293      0.047     0.0065     0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.11G       1.81      5.096       3.57      1.977         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0361      0.102     0.0175    0.00616     0.0325     0.0525    0.00688    0.00203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0397       0.11     0.0181    0.00625     0.0328     0.0525    0.00687    0.00204\n",
      "Speed: 0.8ms preprocess, 14.0ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÖ‚ñÅ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñà‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñá‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñá‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.1105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.80987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.56993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.9766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.09633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.98484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.22356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.41851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_155414-2baez60i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_155414-2baez60i/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0539       0.13     0.0238    0.00785     0.0356     0.0814     0.0103    0.00286\n",
      "Speed: 1.3ms preprocess, 29.8ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 997.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.3G      1.676      5.147      3.972      1.872         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0554      0.113     0.0218    0.00797     0.0401     0.0856     0.0135    0.00373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.54G      2.104       4.84      4.568      2.158         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0589      0.119     0.0219    0.00774     0.0401     0.0912      0.013    0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.13G      1.922      5.984      4.305      2.199         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0533      0.108     0.0211    0.00736     0.0379     0.0994     0.0124    0.00332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.11G      1.836      4.925      3.817      1.973         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0569      0.135     0.0209    0.00761     0.0415       0.11     0.0123    0.00336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.2G      1.607      5.682      3.834      1.883         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.057      0.138     0.0223    0.00799     0.0445      0.108     0.0143     0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0571      0.138     0.0224    0.00803     0.0446      0.108     0.0142    0.00386\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÑ‚ñà‚ñÅ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÑ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñá‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00803\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.13812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.60745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.83366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.88331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.68188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.83353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.20239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.79161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_155619-yqb326ol\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_155619-yqb326ol/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0616      0.112     0.0265    0.00977     0.0569     0.0862     0.0157    0.00527\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1455.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.99G      2.289      4.633      4.412      2.266          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0413      0.141     0.0189    0.00602       0.02     0.0801    0.00622    0.00183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.15G      2.545      7.149      6.388      3.067          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362      0.044      0.152     0.0194     0.0064     0.0196     0.0663    0.00631    0.00183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      2.008      7.101      4.915      2.212          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0421      0.124     0.0189    0.00643     0.0185     0.0497     0.0061    0.00187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      3.006      5.796      7.082      2.802          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0454      0.149     0.0198    0.00667     0.0198     0.0552    0.00659    0.00196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.03G       1.93      5.006      4.262      1.998          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0507      0.141     0.0203    0.00669     0.0182     0.0497     0.0067    0.00209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0517      0.144     0.0206     0.0068     0.0179      0.047    0.00672    0.00212\n",
      "Speed: 1.2ms preprocess, 13.5ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñá‚ñÉ‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñà‚ñÅ‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñÖ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÇ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñà‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.14365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.92996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.99788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.00603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.22374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.40414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_160027-d47e12io\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_160027-d47e12io/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0631      0.127     0.0249     0.0086     0.0453     0.0814     0.0113    0.00325\n",
      "Speed: 1.3ms preprocess, 29.7ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 911.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G      1.899      5.912      4.185      2.141         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0545       0.11     0.0216    0.00793      0.038     0.0801     0.0138     0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.22G      2.142      5.483      4.283      2.241         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362       0.06      0.124     0.0216    0.00791      0.041     0.0884     0.0134    0.00366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.11G      2.193      5.847      4.459      2.238         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0566       0.11     0.0213    0.00773     0.0439      0.105     0.0131     0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.5G      1.718      4.731      4.045      1.912         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0546      0.119      0.021    0.00764      0.041      0.108     0.0125    0.00336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.59G      1.939      5.586      3.998      2.086         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0522      0.119     0.0206    0.00743     0.0469      0.113     0.0129    0.00351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        362     0.0545       0.11     0.0217    0.00795     0.0382     0.0801     0.0137    0.00376\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñá‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñà‚ñÅ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñá‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.1105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.93916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.99773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.08626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.58567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.81465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.20501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.81155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231201_160232-x907z6s6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231201_160232-x907z6s6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        393     0.0659      0.135      0.026    0.00933     0.0455     0.0712      0.014    0.00465\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = -9.764551451191001e-05\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ) –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: \n",
      " defaultdict(<class 'list'>, {0: [0.004483440910335405, 0.013405030671893529, 0.002456630851443803], 1: [0.004408753342371934, 0.013681059639167872, 0.0023795640323929276], 2: [0.004812679352400212, 0.014319684393537115, 0.0027644011510728397], 3: [0.00457497644891839, 0.014096892963215113, 0.0026031562573165623], 4: [0.004664364567190202, 0.014564947009862645, 0.002386459010725156], 5: [0.004509816179810896, 0.013702340727541614, 0.0022927111684810757], 6: [0.00474401747846947, 0.014601093644854792, 0.0026285740914272038], 7: [0.004457833736611151, 0.013819795429612099, 0.002350192927403418], 8: [0.004686592402222403, 0.014221380068211125, 0.002543003783764032], 9: [0.005274145753817551, 0.01565894446938744, 0.0028788948613696188], 10: [0.00465189746576357, 0.014046429948168834, 0.002412107566755037]})\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1920]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/puddle-segmentation-8/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 10\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbe1a2",
   "metadata": {
    "papermill": {
     "duration": 0.336021,
     "end_time": "2023-12-01T16:06:41.508219",
     "exception": false,
     "start_time": "2023-12-01T16:06:41.172198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd9dad",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.366004,
     "end_time": "2023-12-01T16:06:42.273894",
     "exception": false,
     "start_time": "2023-12-01T16:06:41.907890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64d422",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.352061,
     "end_time": "2023-12-01T16:06:42.998366",
     "exception": false,
     "start_time": "2023-12-01T16:06:42.646305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b215ea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.344994,
     "end_time": "2023-12-01T16:06:43.678220",
     "exception": false,
     "start_time": "2023-12-01T16:06:43.333226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7738ab",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.354521,
     "end_time": "2023-12-01T16:06:44.370320",
     "exception": false,
     "start_time": "2023-12-01T16:06:44.015799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"–ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4a0e2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.427891,
     "end_time": "2023-12-01T16:06:45.173806",
     "exception": false,
     "start_time": "2023-12-01T16:06:44.745915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3939.022036,
   "end_time": "2023-12-01T16:06:52.094176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-01T15:01:13.072140",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
