{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install roboflow\n!pip install ultralytics\n! pip install ruamel.yaml\n! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n\nfrom roboflow import Roboflow\nimport sys\nimport ruamel.yaml\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport os\nfrom collections import defaultdict\nimport copy\nimport math\nimport shutil\nimport numpy as np\nimport psutil\nimport gc\nimport matplotlib.pyplot as plt\nimport locale\nfrom IPython.display import clear_output\nimport ctypes\nimport ctypes.util\nimport torch\n\n\n\nrf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\nproject = rf.workspace(\"roboarm\").project(\"feet-qevah\")\ndataset = project.version(10).download(\"yolov8\")\n\n\n%cd /kaggle/working/feet-10\n\ngc.enable()\n\nlibc = ctypes.CDLL(ctypes.util.find_library('c'))\nlibc.malloc_trim(ctypes.c_int(0))\n\ntorch.set_num_threads(1)\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\n","metadata":{"id":"tKyXaYbpvLMm","outputId":"421a4599-fff2-4e30-9da2-d15013fbe64d","execution":{"iopub.status.busy":"2023-10-28T16:19:20.518856Z","iopub.execute_input":"2023-10-28T16:19:20.519171Z","iopub.status.idle":"2023-10-28T16:20:40.063331Z","shell.execute_reply.started":"2023-10-28T16:19:20.519144Z","shell.execute_reply":"2023-10-28T16:20:40.062288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class YoloModel:\n    def __init__(self, path_to_model: str, path_to_yaml: str,\n                 train_perc: float, test_perc: float, val_perc: float,):\n        \"\"\"Инициализация переменных\n\n        Args:\n            path_to_model (str): путь до весов yolov8.pt\n            path_to_yaml (str): путь до data.yaml файла датасета\n            train_perc (float): доля тренировочных данных \n            test_perc (float): доля тестовых данных\n            val_perc (float): доля валидационных данных\n        \"\"\"        \n        self.path_to_model = path_to_model\n        self.path_to_yaml = path_to_yaml\n        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n        self.train_perc = train_perc\n        self.test_perc = test_perc\n        self.val_perc = val_perc\n        \n        self.ttvs_flag = 0\n        self.tp_flag = 0\n        \n        self.ram_usage = []\n        \n        assert self.train_path != None, 'Директория train отсутствует'\n        if (self.val_path == None):\n            os.mkdir(\"valid\", mode=0o777)\n            os.mkdir(\"valid/images\", mode=0o777)\n            os.mkdir(\"valid/labels\", mode=0o777)\n            self.val_path = Path(\"valid\")\n        if (self.test_path == None):\n            os.mkdir(\"test\", mode=0o777)\n            os.mkdir(\"test/images\", mode=0o777)\n            os.mkdir(\"test/labels\", mode=0o777)\n            self.test_path = Path(\"test\")\n    \n    def get_ram_usage(self,):\n        \"\"\"Gets the current RAM usage of the system.\n\n        Returns:\n            float: RAM usage in GB.\n        \"\"\"\n        return psutil.virtual_memory().used / 1e9\n\n    def train(self, folder_name: str, iters: int) -> YOLO: \n        \"\"\"Инициализация модели и обучение\n\n        Args:\n            folder_name (str): название директории с частью данных\n            iters (int): кол-во интераций\n\n        Returns:\n            YOLO: экземпляр обученной модели\n        \"\"\"        \n        # Корректируем data.yaml файл\n        yaml = ruamel.yaml.YAML()\n        # yaml.preserve_quotes = True\n        with open('data.yaml', 'r+') as fp:\n            data = yaml.load(fp)\n            for elem in data:\n                if elem == 'train':\n                    data[elem] = './'+folder_name+'/train/images'\n                elif elem == 'val':\n                    data[elem] = './'+folder_name+'/valid/images'\n                elif elem == 'test':\n                    data[elem] = './temp/images'\n            fp.truncate(0)\n            fp.seek(0)\n            yaml.dump(data, fp)\n        self.ram_usage.append(self.get_ram_usage())\n        model = YOLO(self.path_to_model)\n        model.train(data=self.path_to_yaml, pretrained=self.path_to_model,\n                    exist_ok=True, epochs=iters,)\n        return model\n    \n    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n\n        Args:\n            folder_name (str): название директории с частью данных\n            iters (int): кол-во интераций\n\n        Returns:\n            YOLO: экземпляр обученной модели\n        \"\"\"        \n        os.mkdir(\"retrain\", mode=0o777)\n        os.mkdir(\"retrain/train\", mode=0o777)\n        os.mkdir(\"retrain/valid\", mode=0o777)\n        os.mkdir(\"retrain/train/images\", mode=0o777)\n        os.mkdir(\"retrain/train/labels\", mode=0o777)\n        os.mkdir(\"retrain/valid/images\", mode=0o777)\n        os.mkdir(\"retrain/valid/labels\", mode=0o777)\n\n        # собираем список всех кусков данных до нашего folder_name\n        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n        source_pathes = [f\"temp_{i}\" for i in folder_num]\n\n        # копируем все собранные куски данных в папку retrain\n        for path in source_pathes:\n            # собираем все файлы\n            all_images_train = os.listdir(path+\"/train/images\")\n            all_labels_train = os.listdir(path+\"/train/labels\")\n\n            all_images_valid = os.listdir(path+\"/valid/images\")\n            all_labels_valid = os.listdir(path+\"/valid/labels\")\n\n            for image in all_images_train:\n                shutil.copyfile(path+\"/train/images/\" + image,\n                                \"retrain/train/images/\" + image)\n            for label in all_labels_train:\n                shutil.copyfile(path+\"/train/labels/\" + label,\n                                \"retrain/train/labels/\" + label)\n            for image in all_images_valid:\n                shutil.copyfile(path+\"/valid/images/\" + image,\n                                \"retrain/valid/images/\" + image)\n            for label in all_labels_valid:\n                shutil.copyfile(path+\"/valid/labels/\" + label,\n                                \"retrain/valid/labels/\" + label)\n\n        # Корректируем data.yaml файл\n        yaml = ruamel.yaml.YAML()\n        with open('data.yaml', 'r+') as fp:\n            data = yaml.load(fp)\n            for elem in data:\n                if elem == 'train':\n                    data[elem] = 'retrain/train/images'\n                elif elem == 'val':\n                    data[elem] = 'retrain/valid/images'\n                elif elem == 'test':\n                    data[elem] = './temp/images'\n            fp.truncate(0)\n            fp.seek(0)\n            yaml.dump(data, fp)\n        \n        self.ram_usage.append(self.get_ram_usage())\n        # load a pretrained model (recommended for training)\n        model = YOLO(self.path_to_model)\n        model.train(data=self.path_to_yaml, pretrained=self.path_to_model,\n                    exist_ok=True, epochs=iters,)\n        return model\n    \n    def test(self, model: YOLO):\n        \"\"\"Тестирование модели\n\n        Args:\n            model (YOLO): экземпляр обученной модели\n\n        Returns:\n            _type_: _description_\n        \"\"\"        \n        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n        return metrics\n    \n    def train_test_val_split(self, keep_perc: float):\n        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n\n        Args:\n            keep_perc (float): доля данных, которую нужно оставить\n        \"\"\"        \n        # создаем директории для объединения всех файлов\n        os.mkdir(\"temp\", mode=0o777)\n        os.mkdir(\"temp/images\", mode=0o777)\n        os.mkdir(\"temp/labels\", mode=0o777)\n            \n        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n                        self.test_path / 'images', self.test_path / 'labels',\\\n                        self.val_path / 'images', self.val_path / 'labels',)\n        destination = Path('temp')\n\n        for path in source_pathes:\n            # собираем все файлы\n            allfiles = os.listdir(path)\n            # итерируем по всем файлам, чтобы переместить их в папку назначения\n            sub_folder = path.name # images or labels\n            for f in allfiles:\n                src_path = os.path.join(path, f)\n                dst_path = os.path.join(destination / sub_folder, f)\n                os.rename(src_path, dst_path)\n        total_num = len(allfiles)\n        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n        classes = defaultdict(set)\n        empty_count = 0\n        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n            with txt_path.open() as f:\n                text = f.read()\n                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n                # а остальное - координаты сегментации\n                for obj in text.split('\\n'):\n                    if len(obj) > 0:\n                        classes[obj.split()[0]].add(txt_path)\n                    else:\n                        print(f\"Пустой файл: {txt_path}\")\n                        empty_count += 1\n        print(f\"Кол-во пустых файлов - {empty_count}\")\n        # Оставляем указанный процент данных\n        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n            num_files = len(pathes)\n            num_to_del = num_files*(1-keep_perc)\n            for i, file_path in enumerate(pathes.copy()):\n                if i+1 >= num_to_del:\n                    break\n                f = file_path.name.split('.')[:-1]\n                f.append('jpg')\n                try:\n                    Path(\"temp\",'images',\".\".join(f)).unlink()\n                    file_path.unlink()\n                except OSError as e:\n                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n                    pass\n                classes[cls].remove(file_path)\n\n        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n        class_copy = copy.deepcopy(classes)\n        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n            num_files = len(class_copy[cls])\n            num_to_mv_train = int(num_files * self.train_perc)\n            num_to_mv_test = int(num_files * self.test_perc)\n            num_to_mv_val = int(num_files * self.val_perc)\n            # print(num_files, num_to_mv, len(pathes))\n            temp_dict_name = \"train\"\n            for i, file_path in enumerate(pathes.copy()):\n                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n                    temp_dict_name = \"valid\"\n                elif i+1 > num_to_mv_val + num_to_mv_train:\n                    temp_dict_name = \"test\"\n                f = file_path.name.split('.')[:-1]\n                f.append('jpg')\n                try:\n                    os.replace(Path(\"temp\",\"images\",\".\".join(f)), Path(temp_dict_name,\"images\").joinpath(Path(\"temp\",\"images\",\".\".join(f)).name))\n                    os.replace(file_path, Path(temp_dict_name,\"labels\").joinpath(file_path.name))\n                except OSError as e:\n                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n                    pass\n                classes[cls].remove(file_path)\n        shutil.rmtree(\"temp\")\n\n    def take_piece(self, piece_perc: float):\n        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n\n        Args:\n            piece_perc (float): доля части данных, на которые нужно поделить датасет\n        \"\"\"        \n        # создаем директории для объединения всех файлов\n        os.mkdir(\"temp\", mode=0o777)\n        os.mkdir(\"temp/images\", mode=0o777)\n        os.mkdir(\"temp/labels\", mode=0o777)\n\n        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\n                        self.test_path / 'images', self.test_path / 'labels',\n                        self.val_path / 'images', self.val_path / 'labels',)\n        destination = Path('temp')\n\n        for path in source_pathes:\n            # собираем все файлы\n            allfiles = os.listdir(path)\n            # итерируем по всем файлам, чтобы переместить их в папку назначения\n            sub_folder = path.name  # images or labels\n            for f in allfiles:\n                src_path = os.path.join(path, f)\n                dst_path = os.path.join(destination / sub_folder, f)\n                os.rename(src_path, dst_path)\n        total_num = len(allfiles)\n        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n        classes = defaultdict(set)\n        empty_count = 0\n        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n            with txt_path.open() as f:\n                text = f.read()\n                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n                # а остальное - координаты сегментации\n                for obj in text.split('\\n'):\n                    if len(obj) > 0:\n                        classes[obj.split()[0]].add(txt_path)\n                    else:\n                        print(f\"Пустой файл: {txt_path}\")\n                        empty_count += 1\n        print(f\"Кол-во пустых файлов - {empty_count}\")\n        self.num_folders = 1 / piece_perc\n        for folder in range(int(self.num_folders)):\n            os.mkdir(f\"temp_{folder+1}\", mode=0o777)\n\n            os.mkdir(f\"temp_{folder+1}/train\", mode=0o777)\n            os.mkdir(f\"temp_{folder+1}/valid\", mode=0o777)\n\n            os.mkdir(f\"temp_{folder+1}/train/labels\", mode=0o777)\n            os.mkdir(f\"temp_{folder+1}/train/images\", mode=0o777)\n            os.mkdir(f\"temp_{folder+1}/valid/labels\", mode=0o777)\n            os.mkdir(f\"temp_{folder+1}/valid/images\", mode=0o777)\n        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n        class_copy = copy.deepcopy(classes)\n        for folder in range(int(self.num_folders)):\n            folder_name = f\"temp_{folder+1}\"\n            for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n                num_files = len(class_copy[cls])\n                num_to_mv_train = int(num_files * self.train_perc * piece_perc)\n                num_to_mv_val = int(num_files * self.val_perc * piece_perc)\n                # print(num_files, num_to_mv, len(pathes))\n                temp_dict_name = \"train\"\n                for i, file_path in enumerate(pathes.copy()):\n                    if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n                        temp_dict_name = \"valid\"\n                    if i+1 >= num_to_mv_val + num_to_mv_train + 3:  # останавливаем только если это последняя папка\n                        break\n                    f = file_path.name.split('.')[:-1]\n                    f.append('jpg')\n                    try:\n                        os.replace(Path(\"temp\", \"images\", \".\".join(f)), Path(\n                            folder_name, temp_dict_name, \"images\").joinpath(Path(\"temp\", \"images\", \".\".join(f)).name))\n                        os.replace(file_path, Path(\n                            folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n                    except OSError as e:\n                        # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n                        pass\n                    classes[cls].remove(file_path)\n    \n    def plot_result(self, result_dict: dict, color_dict: dict):\n        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n\n        Args:\n            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n            color_dict (dict): словарь с индикаторами повторного обучения\n        '''\n        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n        for i, metric in enumerate(metrics_names):\n            plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=list(color_dict.values()), zorder=1)\n            plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n            plt.ylabel(metric)\n            plt.xlabel(\"Keep percent (%)\")\n            plt.show()\n        \n    def plot_ram_usage(self,):\n        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n        plt.xlabel('Iteration')\n        plt.ylabel('RAM Usage (GB)')\n        plt.title('RAM Usage During Training')\n        plt.show()\n    \n    def increm_learning(self, keep_perc: float, piece_perc: float, iters: int):\n        os.environ['WANDB_DISABLED'] = 'true'\n        # делим датасет на тренировочную/тестовую/валидационную выборку\n        if self.ttvs_flag == 0:\n            self.train_test_val_split(keep_perc)\n            self.ttvs = 1\n        if self.tp_flag == 0:\n            self.take_piece(piece_perc)\n            self.tp = 1\n        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n        native_path_to_model = self.path_to_model\n        # словарь с метриками {доля данных: массив метрик}\n        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n        # словарь с индикаторами повторного обучения\n        color_dict = defaultdict(str)\n        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n        max_map = 0\n        \n        # Инкрементальное обучение \n        for folder in range(int(self.num_folders)):\n            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n            libc.malloc_trim(ctypes.c_int(0))\n\n            torch.set_num_threads(1)\n            folder_name = f\"temp_{folder+1}\"\n            # дообучаем модель\n            model = self.train(folder_name, iters)\n            # тестируем модель\n            metrics = self.test(model)\n            # проверяем, что метрика улучшается\n            if metrics.seg.map > max_map:\n                max_map = metrics.seg.map\n                # заносим метрики в словарь\n                result_dict[folder].append(metrics.seg.map)\n                result_dict[folder].append(metrics.seg.map50)\n                result_dict[folder].append(metrics.seg.map75)\n                color_dict[folder] = \"green\"\n                clear_output(wait=True)\n                del(model)\n                del(metrics)\n                gc.collect()\n                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n            else:\n                self.path_to_model = native_path_to_model\n                # дообучаем модель\n                model = self.retrain(folder_name, iters)\n                # тестируем модель\n                metrics = self.test(model)\n                if metrics.seg.map > max_map:\n                    max_map = metrics.seg.map\n                # заносим метрики в словарь\n                result_dict[folder].append(metrics.seg.map)\n                result_dict[folder].append(metrics.seg.map50)\n                result_dict[folder].append(metrics.seg.map75)\n                color_dict[folder] = \"red\"\n                clear_output(wait=True)\n                del(model)\n                del(metrics)\n                gc.collect()\n                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n                shutil.rmtree(\"retrain\")\n                \n        print(f\"Итоговый результат: \\n {result_dict}\")\n        self.plot_result(result_dict, color_dict)","metadata":{"execution":{"iopub.status.busy":"2023-10-28T16:20:40.065351Z","iopub.execute_input":"2023-10-28T16:20:40.065757Z","iopub.status.idle":"2023-10-28T16:20:40.137203Z","shell.execute_reply.started":"2023-10-28T16:20:40.065728Z","shell.execute_reply":"2023-10-28T16:20:40.136193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locale.getpreferredencoding = lambda: \"UTF-8\"\n\nPATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\nPATH_TO_YAML = \"/kaggle/working/feet-10/data.yaml\"\nTRAIN_PERC = 0.8\nTEST_PERC = 0.1\nVAL_PERC = 0.1\nKEEP_PERC = 1.0\nPIECE_PERC = 0.1\nITERS = 5\n\nexp_1 = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\nexp_1.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)","metadata":{"execution":{"iopub.status.busy":"2023-10-28T16:20:40.138612Z","iopub.execute_input":"2023-10-28T16:20:40.139024Z","iopub.status.idle":"2023-10-28T16:57:53.738398Z","shell.execute_reply.started":"2023-10-28T16:20:40.138984Z","shell.execute_reply":"2023-10-28T16:57:53.736258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_folders = 1 / PIECE_PERC\nfor folder in range(int(num_folders)):\n    dir_path = f\"temp_{folder+1}/train/labels\"\n    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n    dir_path = f\"temp_{folder+1}/train/images\"\n    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n    dir_path = f\"temp_{folder+1}/valid/labels\"\n    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n    dir_path = f\"temp_{folder+1}/valid/images\"\n    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T16:57:53.743168Z","iopub.status.idle":"2023-10-28T16:57:53.743534Z","shell.execute_reply.started":"2023-10-28T16:57:53.743340Z","shell.execute_reply":"2023-10-28T16:57:53.743357Z"},"trusted":true},"execution_count":null,"outputs":[]}]}