{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66505ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T10:00:40.135033Z",
     "iopub.status.busy": "2024-01-16T10:00:40.134285Z",
     "iopub.status.idle": "2024-01-16T10:01:54.625325Z",
     "shell.execute_reply": "2024-01-16T10:01:54.624127Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 74.499577,
     "end_time": "2024-01-16T10:01:54.627429",
     "exception": false,
     "start_time": "2024-01-16T10:00:40.127852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-16 10:01:42--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 192.30.255.113\r\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240116T100142Z&X-Amz-Expires=300&X-Amz-Signature=fbb880f5ff65d8aea53b02acd975f9d42898e5624f5590d4a676a53fa1135440&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-16 10:01:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240116T100142Z&X-Amz-Expires=300&X-Amz-Signature=fbb880f5ff65d8aea53b02acd975f9d42898e5624f5590d4a676a53fa1135440&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   296MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-01-16 10:01:43 (296 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Coffee-Fruit-Maturity-â˜•ðŸ’-5 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147374/147374 [00:04<00:00, 36604.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Coffee-Fruit-Maturity-â˜•ðŸ’-5 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4732/4732 [00:00<00:00, 6619.33it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"ciencia-cafeto\").project(\"coffee-fruit-maturity-befkg\")\n",
    "dataset = project.version(5).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6e71da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T10:01:54.649765Z",
     "iopub.status.busy": "2024-01-16T10:01:54.649360Z",
     "iopub.status.idle": "2024-01-16T10:02:17.010759Z",
     "shell.execute_reply": "2024-01-16T10:02:17.009761Z"
    },
    "papermill": {
     "duration": 22.375219,
     "end_time": "2024-01-16T10:02:17.013178",
     "exception": false,
     "start_time": "2024-01-16T10:01:54.637959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a2a3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T10:02:17.035778Z",
     "iopub.status.busy": "2024-01-16T10:02:17.035459Z",
     "iopub.status.idle": "2024-01-16T10:02:17.059434Z",
     "shell.execute_reply": "2024-01-16T10:02:17.058456Z"
    },
    "papermill": {
     "duration": 0.0375,
     "end_time": "2024-01-16T10:02:17.061345",
     "exception": false,
     "start_time": "2024-01-16T10:02:17.023845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadaed48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T10:02:17.084632Z",
     "iopub.status.busy": "2024-01-16T10:02:17.084329Z",
     "iopub.status.idle": "2024-01-16T10:02:17.191548Z",
     "shell.execute_reply": "2024-01-16T10:02:17.190726Z"
    },
    "papermill": {
     "duration": 0.121538,
     "end_time": "2024-01-16T10:02:17.193449",
     "exception": false,
     "start_time": "2024-01-16T10:02:17.071911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ…\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): Ð¿ÑƒÑ‚ÑŒ Ð´Ð¾ Ð²ÐµÑÐ¾Ð² yolov8.pt\n",
    "            path_to_yaml (str): Ð¿ÑƒÑ‚ÑŒ Ð´Ð¾ data.yaml Ñ„Ð°Ð¹Ð»Ð° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°\n",
    "            train_perc (float): Ð´Ð¾Ð»Ñ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… \n",
    "            test_perc (float): Ð´Ð¾Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            val_perc (float): Ð´Ð¾Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ train Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ Ñ‡Ð°ÑÑ‚ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            iters (int): ÐºÐ¾Ð»-Ð²Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹\n",
    "\n",
    "        Returns:\n",
    "            YOLO: ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "        \"\"\"        \n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð²ÑÐµÑ… Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… Ñ‡Ð°ÑÑ‚ÑÑ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ Ð¿Ñ€Ð¾ÑÐ°Ð´ÐºÐ¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ Ñ‡Ð°ÑÑ‚ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            iters (int): ÐºÐ¾Ð»-Ð²Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹\n",
    "\n",
    "        Returns:\n",
    "            YOLO: ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÐºÑƒÑÐºÐ¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ Ð½Ð°ÑˆÐµÐ³Ð¾ folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ ÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ðµ ÐºÑƒÑÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð¿Ð°Ð¿ÐºÑƒ retrain\n",
    "        for path in source_pathes:\n",
    "            # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ð° Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð»Ð¸ train/test/val. Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ 1-keep_perc Ð´Ð¾Ð»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð½ÑƒÐ¶Ð½Ð¾ Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ\n",
    "        \"\"\"        \n",
    "        # ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð²ÑÐµÑ… Ñ„Ð°Ð¹Ð»Ð¾Ð²\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "            allfiles = os.listdir(path)\n",
    "            # Ð¸Ñ‚ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»Ð°Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÑÑ‚Ð¸Ñ‚ÑŒ Ð¸Ñ… Ð² Ð¿Ð°Ð¿ÐºÑƒ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ, Ð³Ð´Ðµ ÐºÐ»ÑŽÑ‡ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¿ÑƒÑ‚ÐµÐ¹ Ðº label Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # ÐšÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð´Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ°, Ð³Ð´Ðµ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°,\n",
    "                # Ð° Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ - ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ„Ð°Ð¹Ð»: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - {empty_count}\")\n",
    "        # ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ (ÑÐºÐ¾Ñ€ÐµÐµ Ð²ÑÐµÐ³Ð¾ Ð¸Ð¼ÐµÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð¸ Ð±Ñ‹Ð» ÑƒÐ¶Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼ train, test, val Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¹\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸ Ñ€Ð°Ð²Ð½Ñ‹Ðµ Ð´Ð¾Ð»Ðµ piece_perc Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼ temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): Ð´Ð¾Ð»Ñ Ñ‡Ð°ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ð¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ, Ð³Ð´Ðµ ÐºÐ»ÑŽÑ‡ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¿ÑƒÑ‚ÐµÐ¹ Ðº label Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # ÐšÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð´Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ°, Ð³Ð´Ðµ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°,\n",
    "                # Ð° Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ - ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ„Ð°Ð¹Ð»: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"ÐšÐ»Ð°ÑÑ {key} ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ {value} Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼, Ð° Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐºÐ»Ð°ÑÑÐ° Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð¿Ð¾ __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"ÐšÐ»Ð°ÑÑ {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¾Ñ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "            color_dict (dict): ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ RAM Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        # Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "            color_dict = defaultdict(str)\n",
    "            # Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ map Ð² Ñ†ÐµÐ»ÑÑ… Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾ÑÐ°Ð´Ð¾Ðº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                model = self.train(folder_name, iters)\n",
    "                # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ÑÑ\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: \\n {result_dict}\")\n",
    "            print(f\"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        # Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "        color_dict = defaultdict(str)\n",
    "        # Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ map Ð² Ñ†ÐµÐ»ÑÑ… Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾ÑÐ°Ð´Ð¾Ðº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            model = self.train(folder_name, iters)\n",
    "            # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ÑÑ\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: \\n {result_dict}\")\n",
    "        print(f\"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            metrics = self.test(model)\n",
    "            # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð±Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0a5c45",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-16T10:02:17.217063Z",
     "iopub.status.busy": "2024-01-16T10:02:17.216456Z",
     "iopub.status.idle": "2024-01-16T12:27:25.696343Z",
     "shell.execute_reply": "2024-01-16T12:27:25.695397Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 8708.55142,
     "end_time": "2024-01-16T12:27:25.755548",
     "exception": false,
     "start_time": "2024-01-16T10:02:17.204128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - 0\n",
      "valid_4/images 205\n",
      "test_4/images 207\n",
      "valid_3/images 55\n",
      "test_3/images 56\n",
      "valid_2/images 66\n",
      "test_2/images 68\n",
      "valid_0/images 36\n",
      "test_0/images 37\n",
      "valid_1/images 27\n",
      "test_1/images 29\n",
      "train/labels 1999 \n",
      "\n",
      "ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - 0\n",
      "ÐšÐ»Ð°ÑÑ 4 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 1752 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 3 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 520 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 2 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 611 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 0 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 341 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 1 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 263 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 4\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 4: 1752\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 4: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1752]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 4: 43 \n",
      "\tnum_to_mv_train 2, folder 0, cls 4\n",
      "\tnum_to_mv_train 2, folder 1, cls 4\n",
      "\tnum_to_mv_train 2, folder 2, cls 4\n",
      "\tnum_to_mv_train 2, folder 3, cls 4\n",
      "\tnum_to_mv_train 2, folder 4, cls 4\n",
      "\tnum_to_mv_train 3, folder 5, cls 4\n",
      "\tnum_to_mv_train 3, folder 6, cls 4\n",
      "\tnum_to_mv_train 3, folder 7, cls 4\n",
      "\tnum_to_mv_train 3, folder 8, cls 4\n",
      "\tnum_to_mv_train 3, folder 9, cls 4\n",
      "\tnum_to_mv_train 3, folder 10, cls 4\n",
      "\tnum_to_mv_train 3, folder 11, cls 4\n",
      "\tnum_to_mv_train 5, folder 12, cls 4\n",
      "\tnum_to_mv_train 5, folder 13, cls 4\n",
      "\tnum_to_mv_train 5, folder 14, cls 4\n",
      "\tnum_to_mv_train 5, folder 15, cls 4\n",
      "\tnum_to_mv_train 5, folder 16, cls 4\n",
      "\tnum_to_mv_train 5, folder 17, cls 4\n",
      "\tnum_to_mv_train 5, folder 18, cls 4\n",
      "\tnum_to_mv_train 5, folder 19, cls 4\n",
      "\tnum_to_mv_train 5, folder 20, cls 4\n",
      "\tnum_to_mv_train 5, folder 21, cls 4\n",
      "\tnum_to_mv_train 5, folder 22, cls 4\n",
      "\tnum_to_mv_train 5, folder 23, cls 4\n",
      "\tnum_to_mv_train 5, folder 24, cls 4\n",
      "\tnum_to_mv_train 5, folder 25, cls 4\n",
      "\tnum_to_mv_train 10, folder 26, cls 4\n",
      "\tnum_to_mv_train 10, folder 27, cls 4\n",
      "\tnum_to_mv_train 10, folder 28, cls 4\n",
      "\tnum_to_mv_train 10, folder 29, cls 4\n",
      "\tnum_to_mv_train 10, folder 30, cls 4\n",
      "\tnum_to_mv_train 10, folder 31, cls 4\n",
      "\tnum_to_mv_train 10, folder 32, cls 4\n",
      "\tnum_to_mv_train 10, folder 33, cls 4\n",
      "\tnum_to_mv_train 10, folder 34, cls 4\n",
      "\tnum_to_mv_train 10, folder 35, cls 4\n",
      "\tnum_to_mv_train 50, folder 36, cls 4\n",
      "\tnum_to_mv_train 50, folder 37, cls 4\n",
      "\tnum_to_mv_train 100, folder 38, cls 4\n",
      "\tnum_to_mv_train 100, folder 39, cls 4\n",
      "\tnum_to_mv_train 500, folder 40, cls 4\n",
      "\tnum_to_mv_train 500, folder 41, cls 4\n",
      "\tnum_to_mv_train 251, folder 42, cls 4\n",
      "temp_4_1/train/labels 2\n",
      "temp_4_1/train/images 2 \n",
      "\n",
      "temp_4_2/train/labels 2\n",
      "temp_4_2/train/images 2 \n",
      "\n",
      "temp_4_3/train/labels 2\n",
      "temp_4_3/train/images 2 \n",
      "\n",
      "temp_4_4/train/labels 2\n",
      "temp_4_4/train/images 2 \n",
      "\n",
      "temp_4_5/train/labels 2\n",
      "temp_4_5/train/images 2 \n",
      "\n",
      "temp_4_6/train/labels 3\n",
      "temp_4_6/train/images 3 \n",
      "\n",
      "temp_4_7/train/labels 3\n",
      "temp_4_7/train/images 3 \n",
      "\n",
      "temp_4_8/train/labels 3\n",
      "temp_4_8/train/images 3 \n",
      "\n",
      "temp_4_9/train/labels 3\n",
      "temp_4_9/train/images 3 \n",
      "\n",
      "temp_4_10/train/labels 3\n",
      "temp_4_10/train/images 3 \n",
      "\n",
      "temp_4_11/train/labels 3\n",
      "temp_4_11/train/images 3 \n",
      "\n",
      "temp_4_12/train/labels 3\n",
      "temp_4_12/train/images 3 \n",
      "\n",
      "temp_4_13/train/labels 5\n",
      "temp_4_13/train/images 5 \n",
      "\n",
      "temp_4_14/train/labels 5\n",
      "temp_4_14/train/images 5 \n",
      "\n",
      "temp_4_15/train/labels 5\n",
      "temp_4_15/train/images 5 \n",
      "\n",
      "temp_4_16/train/labels 5\n",
      "temp_4_16/train/images 5 \n",
      "\n",
      "temp_4_17/train/labels 5\n",
      "temp_4_17/train/images 5 \n",
      "\n",
      "temp_4_18/train/labels 5\n",
      "temp_4_18/train/images 5 \n",
      "\n",
      "temp_4_19/train/labels 5\n",
      "temp_4_19/train/images 5 \n",
      "\n",
      "temp_4_20/train/labels 5\n",
      "temp_4_20/train/images 5 \n",
      "\n",
      "temp_4_21/train/labels 5\n",
      "temp_4_21/train/images 5 \n",
      "\n",
      "temp_4_22/train/labels 5\n",
      "temp_4_22/train/images 5 \n",
      "\n",
      "temp_4_23/train/labels 5\n",
      "temp_4_23/train/images 5 \n",
      "\n",
      "temp_4_24/train/labels 5\n",
      "temp_4_24/train/images 5 \n",
      "\n",
      "temp_4_25/train/labels 5\n",
      "temp_4_25/train/images 5 \n",
      "\n",
      "temp_4_26/train/labels 5\n",
      "temp_4_26/train/images 5 \n",
      "\n",
      "temp_4_27/train/labels 10\n",
      "temp_4_27/train/images 10 \n",
      "\n",
      "temp_4_28/train/labels 10\n",
      "temp_4_28/train/images 10 \n",
      "\n",
      "temp_4_29/train/labels 10\n",
      "temp_4_29/train/images 10 \n",
      "\n",
      "temp_4_30/train/labels 10\n",
      "temp_4_30/train/images 10 \n",
      "\n",
      "temp_4_31/train/labels 10\n",
      "temp_4_31/train/images 10 \n",
      "\n",
      "temp_4_32/train/labels 10\n",
      "temp_4_32/train/images 10 \n",
      "\n",
      "temp_4_33/train/labels 10\n",
      "temp_4_33/train/images 10 \n",
      "\n",
      "temp_4_34/train/labels 10\n",
      "temp_4_34/train/images 10 \n",
      "\n",
      "temp_4_35/train/labels 10\n",
      "temp_4_35/train/images 10 \n",
      "\n",
      "temp_4_36/train/labels 10\n",
      "temp_4_36/train/images 10 \n",
      "\n",
      "temp_4_37/train/labels 50\n",
      "temp_4_37/train/images 50 \n",
      "\n",
      "temp_4_38/train/labels 50\n",
      "temp_4_38/train/images 50 \n",
      "\n",
      "temp_4_39/train/labels 100\n",
      "temp_4_39/train/images 100 \n",
      "\n",
      "temp_4_40/train/labels 100\n",
      "temp_4_40/train/images 100 \n",
      "\n",
      "temp_4_41/train/labels 500\n",
      "temp_4_41/train/images 500 \n",
      "\n",
      "temp_4_42/train/labels 500\n",
      "temp_4_42/train/images 500 \n",
      "\n",
      "temp_4_43/train/labels 251\n",
      "temp_4_43/train/images 251 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 3\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 3: 520\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 3: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 520]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 3: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 3\n",
      "\tnum_to_mv_train 2, folder 1, cls 3\n",
      "\tnum_to_mv_train 2, folder 2, cls 3\n",
      "\tnum_to_mv_train 2, folder 3, cls 3\n",
      "\tnum_to_mv_train 2, folder 4, cls 3\n",
      "\tnum_to_mv_train 3, folder 5, cls 3\n",
      "\tnum_to_mv_train 3, folder 6, cls 3\n",
      "\tnum_to_mv_train 3, folder 7, cls 3\n",
      "\tnum_to_mv_train 3, folder 8, cls 3\n",
      "\tnum_to_mv_train 3, folder 9, cls 3\n",
      "\tnum_to_mv_train 3, folder 10, cls 3\n",
      "\tnum_to_mv_train 3, folder 11, cls 3\n",
      "\tnum_to_mv_train 5, folder 12, cls 3\n",
      "\tnum_to_mv_train 5, folder 13, cls 3\n",
      "\tnum_to_mv_train 5, folder 14, cls 3\n",
      "\tnum_to_mv_train 5, folder 15, cls 3\n",
      "\tnum_to_mv_train 5, folder 16, cls 3\n",
      "\tnum_to_mv_train 5, folder 17, cls 3\n",
      "\tnum_to_mv_train 5, folder 18, cls 3\n",
      "\tnum_to_mv_train 5, folder 19, cls 3\n",
      "\tnum_to_mv_train 5, folder 20, cls 3\n",
      "\tnum_to_mv_train 5, folder 21, cls 3\n",
      "\tnum_to_mv_train 5, folder 22, cls 3\n",
      "\tnum_to_mv_train 5, folder 23, cls 3\n",
      "\tnum_to_mv_train 5, folder 24, cls 3\n",
      "\tnum_to_mv_train 5, folder 25, cls 3\n",
      "\tnum_to_mv_train 10, folder 26, cls 3\n",
      "\tnum_to_mv_train 10, folder 27, cls 3\n",
      "\tnum_to_mv_train 10, folder 28, cls 3\n",
      "\tnum_to_mv_train 10, folder 29, cls 3\n",
      "\tnum_to_mv_train 10, folder 30, cls 3\n",
      "\tnum_to_mv_train 10, folder 31, cls 3\n",
      "\tnum_to_mv_train 10, folder 32, cls 3\n",
      "\tnum_to_mv_train 10, folder 33, cls 3\n",
      "\tnum_to_mv_train 10, folder 34, cls 3\n",
      "\tnum_to_mv_train 10, folder 35, cls 3\n",
      "\tnum_to_mv_train 50, folder 36, cls 3\n",
      "\tnum_to_mv_train 50, folder 37, cls 3\n",
      "\tnum_to_mv_train 100, folder 38, cls 3\n",
      "\tnum_to_mv_train 100, folder 39, cls 3\n",
      "\tnum_to_mv_train 19, folder 40, cls 3\n",
      "temp_3_1/train/labels 2\n",
      "temp_3_1/train/images 2 \n",
      "\n",
      "temp_3_2/train/labels 2\n",
      "temp_3_2/train/images 2 \n",
      "\n",
      "temp_3_3/train/labels 2\n",
      "temp_3_3/train/images 2 \n",
      "\n",
      "temp_3_4/train/labels 2\n",
      "temp_3_4/train/images 2 \n",
      "\n",
      "temp_3_5/train/labels 2\n",
      "temp_3_5/train/images 2 \n",
      "\n",
      "temp_3_6/train/labels 3\n",
      "temp_3_6/train/images 3 \n",
      "\n",
      "temp_3_7/train/labels 3\n",
      "temp_3_7/train/images 3 \n",
      "\n",
      "temp_3_8/train/labels 3\n",
      "temp_3_8/train/images 3 \n",
      "\n",
      "temp_3_9/train/labels 3\n",
      "temp_3_9/train/images 3 \n",
      "\n",
      "temp_3_10/train/labels 3\n",
      "temp_3_10/train/images 3 \n",
      "\n",
      "temp_3_11/train/labels 3\n",
      "temp_3_11/train/images 3 \n",
      "\n",
      "temp_3_12/train/labels 3\n",
      "temp_3_12/train/images 3 \n",
      "\n",
      "temp_3_13/train/labels 5\n",
      "temp_3_13/train/images 5 \n",
      "\n",
      "temp_3_14/train/labels 5\n",
      "temp_3_14/train/images 5 \n",
      "\n",
      "temp_3_15/train/labels 5\n",
      "temp_3_15/train/images 5 \n",
      "\n",
      "temp_3_16/train/labels 5\n",
      "temp_3_16/train/images 5 \n",
      "\n",
      "temp_3_17/train/labels 5\n",
      "temp_3_17/train/images 5 \n",
      "\n",
      "temp_3_18/train/labels 5\n",
      "temp_3_18/train/images 5 \n",
      "\n",
      "temp_3_19/train/labels 5\n",
      "temp_3_19/train/images 5 \n",
      "\n",
      "temp_3_20/train/labels 5\n",
      "temp_3_20/train/images 5 \n",
      "\n",
      "temp_3_21/train/labels 5\n",
      "temp_3_21/train/images 5 \n",
      "\n",
      "temp_3_22/train/labels 5\n",
      "temp_3_22/train/images 5 \n",
      "\n",
      "temp_3_23/train/labels 5\n",
      "temp_3_23/train/images 5 \n",
      "\n",
      "temp_3_24/train/labels 5\n",
      "temp_3_24/train/images 5 \n",
      "\n",
      "temp_3_25/train/labels 5\n",
      "temp_3_25/train/images 5 \n",
      "\n",
      "temp_3_26/train/labels 5\n",
      "temp_3_26/train/images 5 \n",
      "\n",
      "temp_3_27/train/labels 10\n",
      "temp_3_27/train/images 10 \n",
      "\n",
      "temp_3_28/train/labels 10\n",
      "temp_3_28/train/images 10 \n",
      "\n",
      "temp_3_29/train/labels 10\n",
      "temp_3_29/train/images 10 \n",
      "\n",
      "temp_3_30/train/labels 10\n",
      "temp_3_30/train/images 10 \n",
      "\n",
      "temp_3_31/train/labels 10\n",
      "temp_3_31/train/images 10 \n",
      "\n",
      "temp_3_32/train/labels 10\n",
      "temp_3_32/train/images 10 \n",
      "\n",
      "temp_3_33/train/labels 10\n",
      "temp_3_33/train/images 10 \n",
      "\n",
      "temp_3_34/train/labels 10\n",
      "temp_3_34/train/images 10 \n",
      "\n",
      "temp_3_35/train/labels 10\n",
      "temp_3_35/train/images 10 \n",
      "\n",
      "temp_3_36/train/labels 10\n",
      "temp_3_36/train/images 10 \n",
      "\n",
      "temp_3_37/train/labels 50\n",
      "temp_3_37/train/images 50 \n",
      "\n",
      "temp_3_38/train/labels 50\n",
      "temp_3_38/train/images 50 \n",
      "\n",
      "temp_3_39/train/labels 100\n",
      "temp_3_39/train/images 100 \n",
      "\n",
      "temp_3_40/train/labels 100\n",
      "temp_3_40/train/images 100 \n",
      "\n",
      "temp_3_41/train/labels 19\n",
      "temp_3_41/train/images 19 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 2\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 2: 611\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 2: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 611]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 2: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 2\n",
      "\tnum_to_mv_train 2, folder 1, cls 2\n",
      "\tnum_to_mv_train 2, folder 2, cls 2\n",
      "\tnum_to_mv_train 2, folder 3, cls 2\n",
      "\tnum_to_mv_train 2, folder 4, cls 2\n",
      "\tnum_to_mv_train 3, folder 5, cls 2\n",
      "\tnum_to_mv_train 3, folder 6, cls 2\n",
      "\tnum_to_mv_train 3, folder 7, cls 2\n",
      "\tnum_to_mv_train 3, folder 8, cls 2\n",
      "\tnum_to_mv_train 3, folder 9, cls 2\n",
      "\tnum_to_mv_train 3, folder 10, cls 2\n",
      "\tnum_to_mv_train 3, folder 11, cls 2\n",
      "\tnum_to_mv_train 5, folder 12, cls 2\n",
      "\tnum_to_mv_train 5, folder 13, cls 2\n",
      "\tnum_to_mv_train 5, folder 14, cls 2\n",
      "\tnum_to_mv_train 5, folder 15, cls 2\n",
      "\tnum_to_mv_train 5, folder 16, cls 2\n",
      "\tnum_to_mv_train 5, folder 17, cls 2\n",
      "\tnum_to_mv_train 5, folder 18, cls 2\n",
      "\tnum_to_mv_train 5, folder 19, cls 2\n",
      "\tnum_to_mv_train 5, folder 20, cls 2\n",
      "\tnum_to_mv_train 5, folder 21, cls 2\n",
      "\tnum_to_mv_train 5, folder 22, cls 2\n",
      "\tnum_to_mv_train 5, folder 23, cls 2\n",
      "\tnum_to_mv_train 5, folder 24, cls 2\n",
      "\tnum_to_mv_train 5, folder 25, cls 2\n",
      "\tnum_to_mv_train 10, folder 26, cls 2\n",
      "\tnum_to_mv_train 10, folder 27, cls 2\n",
      "\tnum_to_mv_train 10, folder 28, cls 2\n",
      "\tnum_to_mv_train 10, folder 29, cls 2\n",
      "\tnum_to_mv_train 10, folder 30, cls 2\n",
      "\tnum_to_mv_train 10, folder 31, cls 2\n",
      "\tnum_to_mv_train 10, folder 32, cls 2\n",
      "\tnum_to_mv_train 10, folder 33, cls 2\n",
      "\tnum_to_mv_train 10, folder 34, cls 2\n",
      "\tnum_to_mv_train 10, folder 35, cls 2\n",
      "\tnum_to_mv_train 50, folder 36, cls 2\n",
      "\tnum_to_mv_train 50, folder 37, cls 2\n",
      "\tnum_to_mv_train 100, folder 38, cls 2\n",
      "\tnum_to_mv_train 100, folder 39, cls 2\n",
      "\tnum_to_mv_train 110, folder 40, cls 2\n",
      "temp_2_1/train/labels 2\n",
      "temp_2_1/train/images 2 \n",
      "\n",
      "temp_2_2/train/labels 2\n",
      "temp_2_2/train/images 2 \n",
      "\n",
      "temp_2_3/train/labels 2\n",
      "temp_2_3/train/images 2 \n",
      "\n",
      "temp_2_4/train/labels 2\n",
      "temp_2_4/train/images 2 \n",
      "\n",
      "temp_2_5/train/labels 2\n",
      "temp_2_5/train/images 2 \n",
      "\n",
      "temp_2_6/train/labels 3\n",
      "temp_2_6/train/images 3 \n",
      "\n",
      "temp_2_7/train/labels 3\n",
      "temp_2_7/train/images 3 \n",
      "\n",
      "temp_2_8/train/labels 3\n",
      "temp_2_8/train/images 3 \n",
      "\n",
      "temp_2_9/train/labels 3\n",
      "temp_2_9/train/images 3 \n",
      "\n",
      "temp_2_10/train/labels 3\n",
      "temp_2_10/train/images 3 \n",
      "\n",
      "temp_2_11/train/labels 3\n",
      "temp_2_11/train/images 3 \n",
      "\n",
      "temp_2_12/train/labels 3\n",
      "temp_2_12/train/images 3 \n",
      "\n",
      "temp_2_13/train/labels 5\n",
      "temp_2_13/train/images 5 \n",
      "\n",
      "temp_2_14/train/labels 5\n",
      "temp_2_14/train/images 5 \n",
      "\n",
      "temp_2_15/train/labels 5\n",
      "temp_2_15/train/images 5 \n",
      "\n",
      "temp_2_16/train/labels 5\n",
      "temp_2_16/train/images 5 \n",
      "\n",
      "temp_2_17/train/labels 5\n",
      "temp_2_17/train/images 5 \n",
      "\n",
      "temp_2_18/train/labels 5\n",
      "temp_2_18/train/images 5 \n",
      "\n",
      "temp_2_19/train/labels 5\n",
      "temp_2_19/train/images 5 \n",
      "\n",
      "temp_2_20/train/labels 5\n",
      "temp_2_20/train/images 5 \n",
      "\n",
      "temp_2_21/train/labels 5\n",
      "temp_2_21/train/images 5 \n",
      "\n",
      "temp_2_22/train/labels 5\n",
      "temp_2_22/train/images 5 \n",
      "\n",
      "temp_2_23/train/labels 5\n",
      "temp_2_23/train/images 5 \n",
      "\n",
      "temp_2_24/train/labels 5\n",
      "temp_2_24/train/images 5 \n",
      "\n",
      "temp_2_25/train/labels 5\n",
      "temp_2_25/train/images 5 \n",
      "\n",
      "temp_2_26/train/labels 5\n",
      "temp_2_26/train/images 5 \n",
      "\n",
      "temp_2_27/train/labels 10\n",
      "temp_2_27/train/images 10 \n",
      "\n",
      "temp_2_28/train/labels 10\n",
      "temp_2_28/train/images 10 \n",
      "\n",
      "temp_2_29/train/labels 10\n",
      "temp_2_29/train/images 10 \n",
      "\n",
      "temp_2_30/train/labels 10\n",
      "temp_2_30/train/images 10 \n",
      "\n",
      "temp_2_31/train/labels 10\n",
      "temp_2_31/train/images 10 \n",
      "\n",
      "temp_2_32/train/labels 10\n",
      "temp_2_32/train/images 10 \n",
      "\n",
      "temp_2_33/train/labels 10\n",
      "temp_2_33/train/images 10 \n",
      "\n",
      "temp_2_34/train/labels 10\n",
      "temp_2_34/train/images 10 \n",
      "\n",
      "temp_2_35/train/labels 10\n",
      "temp_2_35/train/images 10 \n",
      "\n",
      "temp_2_36/train/labels 10\n",
      "temp_2_36/train/images 10 \n",
      "\n",
      "temp_2_37/train/labels 50\n",
      "temp_2_37/train/images 50 \n",
      "\n",
      "temp_2_38/train/labels 50\n",
      "temp_2_38/train/images 50 \n",
      "\n",
      "temp_2_39/train/labels 100\n",
      "temp_2_39/train/images 100 \n",
      "\n",
      "temp_2_40/train/labels 100\n",
      "temp_2_40/train/images 100 \n",
      "\n",
      "temp_2_41/train/labels 110\n",
      "temp_2_41/train/images 110 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 0\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 0: 341\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 341]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 0: 39 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 40, folder 38, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 40\n",
      "temp_0_39/train/images 40 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 1\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 1: 263\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 263]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 1: 38 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 50, folder 36, cls 1\n",
      "\tnum_to_mv_train 12, folder 37, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 50\n",
      "temp_1_37/train/images 50 \n",
      "\n",
      "temp_1_38/train/labels 12\n",
      "temp_1_38/train/images 12 \n",
      "\n",
      "/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml\n",
      "defaultdict(<class 'int'>, {'4': 43, '3': 41, '2': 41, '0': 39, '1': 38}) defaultdict(<class 'list'>, {'4': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1752], '3': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 520], '2': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 611], '0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 341], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 263]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 22.1MB/s]\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 92.4MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 189.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<00:00, 821.82it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.28G     0.6386      1.887      4.107      1.172          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.79it/s]\n",
      "                   all         66        399      0.129      0.338      0.104     0.0721      0.137      0.331      0.106     0.0697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G     0.6316      1.382      3.376      1.153          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.128      0.138        0.1     0.0701      0.136       0.14      0.105      0.068\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G      0.777     0.9761      4.221      1.205          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.118      0.203     0.0957     0.0665      0.129      0.178     0.0988     0.0646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.3G       0.57      1.667      4.345     0.9749          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.116      0.323     0.0908      0.063      0.126       0.17     0.0943     0.0611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.28G     0.7748       1.41      3.948      1.202          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399     0.0718      0.682     0.0881     0.0615     0.0964      0.561     0.0919     0.0596\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n",
      "                   all         66        399      0.131      0.316      0.104     0.0722      0.138      0.333      0.107     0.0698\n",
      "                  ripe         66        399      0.131      0.316      0.104     0.0722      0.138      0.333      0.107     0.0698\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<00:00, 851.42it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.54it/s]\n",
      "                   all         68        365     0.0987     0.0936      0.096     0.0667      0.126     0.0959      0.105     0.0643\n",
      "                  ripe         68        365     0.0987     0.0936      0.096     0.0667      0.126     0.0959      0.105     0.0643\n",
      "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 648.87it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.02G      1.379      3.011      3.624      1.288        115        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399     0.0293      0.847     0.0946     0.0656     0.0296      0.832     0.0968     0.0647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.47G       1.18      2.553      3.487      1.455         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399     0.0296      0.852     0.0947     0.0647     0.0293      0.842     0.0965     0.0641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.45G      1.037      2.566      3.586      1.309         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0293      0.842     0.0944     0.0653      0.029      0.835     0.0966     0.0646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.79G      1.118      2.594      3.843      1.182         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0298       0.83     0.0933     0.0645     0.0297      0.827     0.0957     0.0644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.44G     0.9741      2.848      3.739       1.36         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0331      0.797     0.0924     0.0639     0.0406      0.774     0.0961      0.064\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399     0.0293      0.847     0.0945     0.0655     0.0296      0.832     0.0967     0.0646\n",
      "                  ripe         66        399     0.0293      0.847     0.0945     0.0655     0.0296      0.832     0.0967     0.0646\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.69it/s]\n",
      "                   all         68        365      0.119      0.216     0.0851     0.0588      0.138      0.222     0.0921     0.0571\n",
      "                  ripe         68        365      0.119      0.216     0.0851     0.0588      0.138      0.222     0.0921     0.0571\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1207.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.24G      1.154      2.951      3.935      1.423         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.032      0.882      0.104     0.0725      0.133      0.381      0.107       0.07\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.26G     0.9284      2.325      3.571      1.141         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399       0.12      0.496      0.101     0.0702      0.131      0.366      0.104      0.068\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.07G     0.7878       1.93      3.616      1.173         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.123      0.226     0.0976     0.0678      0.132      0.153     0.0999     0.0654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.93G      0.976      2.068      3.551      1.144         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.121      0.129     0.0946     0.0659      0.125      0.108     0.0981     0.0637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.15G       1.18      2.655      3.663      1.201         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.119      0.401     0.0935     0.0647      0.131      0.143     0.0964     0.0632\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.032      0.885      0.104     0.0726      0.132      0.381      0.106       0.07\n",
      "                  ripe         66        399      0.032      0.885      0.104     0.0726      0.132      0.381      0.106       0.07\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.43it/s]\n",
      "                   all         68        365      0.121      0.334     0.0974     0.0675      0.126     0.0849      0.106      0.065\n",
      "                  ripe         68        365      0.121      0.334     0.0974     0.0675      0.126     0.0849      0.106      0.065\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 631.05it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G     0.9687       2.41       3.42      1.162         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399     0.0294      0.847     0.0932     0.0655     0.0294      0.847     0.0957     0.0644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.4G     0.9231      1.488      3.453      1.109         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399     0.0295      0.845     0.0932     0.0649     0.0294      0.842     0.0951     0.0642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.37G      1.044      1.831      3.543      1.262         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399     0.0291       0.83     0.0933     0.0646     0.0291       0.83     0.0954     0.0641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.43G        1.2      2.473      3.613      1.485         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0338      0.797      0.091     0.0628     0.0337      0.794     0.0933     0.0625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.39G      0.927      1.893      3.692      1.161         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399     0.0407      0.762     0.0886     0.0612     0.0743      0.607     0.0922     0.0615\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399     0.0294      0.847     0.0931     0.0655     0.0294      0.847     0.0957     0.0644\n",
      "                  ripe         66        399     0.0294      0.847     0.0931     0.0655     0.0294      0.847     0.0957     0.0644\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.54it/s]\n",
      "                   all         68        365      0.127      0.247     0.0871     0.0604      0.136      0.219     0.0933     0.0586\n",
      "                  ripe         68        365      0.127      0.247     0.0871     0.0604      0.136      0.219     0.0933     0.0586\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 758.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.18G     0.9942      2.256      3.671      1.233         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.128      0.411      0.107     0.0741      0.136      0.391      0.109     0.0715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.61G     0.9656      2.522      3.539      1.266         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.124      0.148      0.104      0.072      0.138      0.138      0.107     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       5.3G      1.009      2.259      3.454      1.198         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.128      0.198     0.0997      0.069      0.133      0.135      0.103     0.0671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.99G     0.7311      1.401       3.76      1.176         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.126      0.266      0.095      0.066      0.133      0.159     0.0981     0.0636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.39G      1.272      2.682      3.559      1.327         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399       0.12      0.401     0.0941     0.0653      0.124      0.416     0.0971     0.0635\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399      0.131      0.376      0.107      0.074      0.142      0.221      0.109     0.0715\n",
      "                  ripe         66        399      0.131      0.376      0.107      0.074      0.142      0.221      0.109     0.0715\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.55it/s]\n",
      "                   all         68        365     0.0999     0.0967     0.0985      0.069      0.127      0.112      0.107     0.0663\n",
      "                  ripe         68        365     0.0999     0.0967     0.0985      0.069      0.127      0.112      0.107     0.0663\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1257.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.48G     0.8512      1.731      3.409      1.201         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.98it/s]\n",
      "                   all         66        399     0.0295      0.847     0.0931     0.0648     0.0294      0.845      0.095     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.37G     0.9288      1.938      3.786      1.325         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0296      0.847     0.0932     0.0642     0.0295      0.845     0.0942     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G     0.6145      1.064      4.014      1.145          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399     0.0295       0.84     0.0874     0.0605      0.029      0.825     0.0892       0.06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.34G     0.6683      2.069      3.643      1.098         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0298      0.842     0.0875     0.0604     0.0295      0.832     0.0902     0.0604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.32G     0.6323      1.581      3.839      1.215          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399     0.0296      0.837     0.0884     0.0615     0.0293      0.827     0.0928     0.0611\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399     0.0295      0.847     0.0928     0.0647     0.0294      0.845      0.095     0.0638\n",
      "                  ripe         66        399     0.0295      0.847     0.0928     0.0647     0.0294      0.845      0.095     0.0638\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.58it/s]\n",
      "                   all         68        365      0.115      0.181     0.0843     0.0582      0.127      0.192     0.0909     0.0568\n",
      "                  ripe         68        365      0.115      0.181     0.0843     0.0582      0.127      0.192     0.0909     0.0568\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 793.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.81G      1.047      2.293      3.749      1.184        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.99it/s]\n",
      "                   all         66        399     0.0322      0.885      0.106     0.0733      0.136      0.351      0.108     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.69G       0.96      2.519       3.62       1.27         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399       0.13      0.195      0.102     0.0711      0.127      0.154      0.105     0.0688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.31G     0.8212      1.952      3.679      1.163         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.126      0.185     0.0987      0.068      0.127      0.143      0.103     0.0663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      6.72G      1.067      2.489      3.642      1.244         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.125      0.223     0.0969     0.0671      0.126      0.143        0.1      0.065\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      6.34G      1.083      2.418      3.737      1.349         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.114      0.429     0.0944     0.0651      0.131      0.301     0.0969     0.0638\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399     0.0322      0.885      0.106     0.0733      0.136      0.351      0.108     0.0708\n",
      "                  ripe         66        399     0.0322      0.885      0.106     0.0733      0.136      0.351      0.108     0.0708\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.62it/s]\n",
      "                   all         68        365      0.126      0.378     0.0977     0.0678      0.128       0.11      0.107     0.0654\n",
      "                  ripe         68        365      0.126      0.378     0.0977     0.0678      0.128       0.11      0.107     0.0654\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 758.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.47G      1.424      3.006      4.142      1.553         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0298      0.852     0.0949     0.0665     0.0295      0.845     0.0969     0.0655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.4G      1.127      3.296      3.847      1.324         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0301      0.855     0.0941     0.0648     0.0295      0.837     0.0946     0.0642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.32G      1.155      4.567      3.838      1.416          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0303       0.85     0.0936     0.0636     0.0296      0.832     0.0941     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.39G      1.117      3.109      3.799      1.277         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0305      0.852     0.0925     0.0634     0.0311      0.835     0.0948     0.0631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.37G      1.454      3.542       3.88      1.646         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0301      0.837     0.0893     0.0602     0.0297      0.827     0.0912     0.0594\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399     0.0298      0.852     0.0947     0.0664     0.0295      0.845     0.0966     0.0654\n",
      "                  ripe         66        399     0.0298      0.852     0.0947     0.0664     0.0295      0.845     0.0966     0.0654\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.55it/s]\n",
      "                   all         68        365      0.122      0.219     0.0867     0.0602      0.129      0.184     0.0936     0.0586\n",
      "                  ripe         68        365      0.122      0.219     0.0867     0.0602      0.129      0.184     0.0936     0.0586\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 770.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.61G     0.8956      2.102      3.652       1.22         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399     0.0315      0.895      0.105     0.0735      0.134      0.383      0.107      0.071\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.65G       0.98      2.547      3.668      1.228        111        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.129      0.326      0.103     0.0713      0.133      0.216      0.106      0.069\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.44G      1.085      2.694      3.848      1.325        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.127      0.168      0.101     0.0681      0.131      0.173      0.103     0.0666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.39G      1.126      2.736      3.743      1.431         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.127      0.243     0.0954     0.0653      0.126       0.16     0.0984     0.0637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.37G     0.9871      2.656       3.73      1.255         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.119      0.328     0.0913     0.0629      0.129      0.288     0.0953     0.0622\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399     0.0315      0.895      0.106     0.0737      0.135      0.386      0.107     0.0711\n",
      "                  ripe         66        399     0.0315      0.895      0.106     0.0737      0.135      0.386      0.107     0.0711\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.49it/s]\n",
      "                   all         68        365      0.126      0.373     0.0983     0.0676      0.129      0.113      0.106     0.0653\n",
      "                  ripe         68        365      0.126      0.373     0.0983     0.0676      0.129      0.113      0.106     0.0653\n",
      "Speed: 0.4ms preprocess, 14.6ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1515.47it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.34G     0.5994      2.021      3.637      1.039         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399     0.0298       0.85     0.0924     0.0639     0.0295      0.842     0.0933     0.0631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.6567      1.251      4.019       1.16         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0299      0.847     0.0899     0.0621     0.0295      0.835     0.0913     0.0614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.88G     0.5631      1.567      3.863      1.122          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0298      0.842     0.0897     0.0606     0.0293       0.83     0.0906     0.0604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.84G     0.8194       1.25      4.047      1.119          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0291       0.82     0.0855     0.0587     0.0292      0.822     0.0877     0.0581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G     0.6623      1.119      3.312      1.062         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0292      0.815     0.0812     0.0553     0.0294       0.82     0.0846     0.0547\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399     0.0299      0.852     0.0927      0.064     0.0295      0.842     0.0936     0.0633\n",
      "                  ripe         66        399     0.0299      0.852     0.0927      0.064     0.0295      0.842     0.0936     0.0633\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.119      0.205     0.0847     0.0584      0.122      0.178      0.091      0.057\n",
      "                  ripe         68        365      0.119      0.205     0.0847     0.0584      0.122      0.178      0.091      0.057\n",
      "Speed: 0.3ms preprocess, 14.5ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 765.93it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.95G     0.9891      2.287      3.584       1.25         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399     0.0314      0.895      0.105     0.0727      0.134      0.348      0.106     0.0702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         9G     0.8947      2.049      3.699      1.211        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.126      0.351      0.103     0.0713      0.135      0.343      0.105     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.03G      1.076       2.41      3.808      1.217        161        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.131      0.208     0.0997     0.0683      0.129      0.173      0.102     0.0666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.72G     0.8079      1.829      3.692      1.164         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.127      0.273     0.0956     0.0661      0.126       0.15     0.0995     0.0644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.71G     0.6807      1.588      3.449      1.142         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.123      0.343     0.0941     0.0647      0.132      0.301     0.0971     0.0631\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399     0.0314      0.895      0.105     0.0728      0.135      0.351      0.107     0.0703\n",
      "                  ripe         66        399     0.0314      0.895      0.105     0.0728      0.135      0.351      0.107     0.0703\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.57it/s]\n",
      "                   all         68        365      0.125      0.373     0.0979     0.0676      0.123     0.0815      0.106     0.0655\n",
      "                  ripe         68        365      0.125      0.373     0.0979     0.0676      0.123     0.0815      0.106     0.0655\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 647.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.34G     0.9739      1.687      3.391      1.247         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399     0.0294      0.842     0.0938      0.066     0.0293       0.84     0.0955     0.0649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.95G      0.736      1.566      3.282      1.206         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0307      0.852     0.0938     0.0654     0.0302      0.837     0.0949     0.0642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.94G     0.6935      1.785      3.561      1.251         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0299      0.845     0.0927     0.0647     0.0296      0.837     0.0941     0.0635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G     0.8251      1.625       3.27      1.212         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399       0.03       0.85     0.0916     0.0639     0.0298      0.842     0.0927     0.0628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.9G     0.8901      2.226      3.497      1.282         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0297      0.835     0.0906     0.0639     0.0294      0.827     0.0941     0.0631\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n",
      "                   all         66        399     0.0295      0.845     0.0942      0.066     0.0293       0.84     0.0955     0.0649\n",
      "                  ripe         66        399     0.0295      0.845     0.0942      0.066     0.0293       0.84     0.0955     0.0649\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.53it/s]\n",
      "                   all         68        365      0.115      0.186     0.0867     0.0604      0.123        0.2     0.0935     0.0588\n",
      "                  ripe         68        365      0.115      0.186     0.0867     0.0604      0.123        0.2     0.0935     0.0588\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 952.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G     0.9816      2.111      3.539      1.268        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399     0.0315      0.895      0.105      0.073      0.135      0.381      0.107     0.0707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.61G     0.8475      1.805      3.598      1.113        124        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.111      0.614      0.102     0.0708      0.134      0.196      0.105     0.0686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G     0.9671      2.285      3.618      1.249        175        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.129      0.201     0.0988     0.0682      0.127      0.168      0.101     0.0662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G     0.8156      2.095      3.641      1.153        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.124      0.266      0.096     0.0663      0.128      0.143     0.0985     0.0644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G     0.8854      1.846      3.538       1.25        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.122      0.343     0.0933     0.0638      0.132      0.298     0.0964     0.0623\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399     0.0322      0.887      0.105      0.073      0.135      0.381      0.107     0.0707\n",
      "                  ripe         66        399     0.0322      0.887      0.105      0.073      0.135      0.381      0.107     0.0707\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365       0.11     0.0986     0.0984     0.0676      0.119     0.0932      0.106     0.0652\n",
      "                  ripe         68        365       0.11     0.0986     0.0984     0.0676      0.119     0.0932      0.106     0.0652\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 669.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.65G     0.7726       1.67      3.364     0.9873         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0295      0.847     0.0923     0.0649     0.0294      0.842     0.0941     0.0636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.98G     0.8203      2.102      3.548      1.014         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0299      0.852     0.0918     0.0642     0.0295      0.842     0.0921     0.0628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.87G     0.7783       2.22      3.627      1.032         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399     0.0299      0.847     0.0893     0.0627     0.0292      0.827     0.0896     0.0616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.02G     0.8356      1.723      3.325      0.933         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399     0.0298      0.837     0.0902     0.0623     0.0297      0.835     0.0916     0.0618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.02G     0.7047      1.589      3.065     0.9681         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399     0.0337      0.782     0.0878     0.0615     0.0341      0.792     0.0898     0.0609\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399     0.0295      0.847     0.0924     0.0649     0.0292       0.84     0.0943     0.0636\n",
      "                  ripe         66        399     0.0295      0.847     0.0924     0.0649     0.0292       0.84     0.0943     0.0636\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.52it/s]\n",
      "                   all         68        365      0.122      0.255     0.0861     0.0594      0.129      0.173      0.092     0.0579\n",
      "                  ripe         68        365      0.122      0.255     0.0861     0.0594      0.129      0.173      0.092     0.0579\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 769.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.41G     0.8247      1.868      3.235      1.221         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.137      0.316      0.104     0.0721      0.137      0.145      0.106     0.0696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G     0.8664      1.703      3.568      1.092         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.128      0.206     0.0969     0.0668      0.129       0.18     0.0994     0.0649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.8999      2.094      3.512      1.278         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399     0.0612      0.739      0.103     0.0719      0.141      0.368      0.106     0.0704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.8985      1.979      3.463      1.207         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399     0.0616      0.752      0.111     0.0781     0.0622       0.76      0.114     0.0761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G     0.9106      1.885      3.485      1.234         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399       0.18      0.426      0.137      0.098      0.183      0.434       0.14     0.0946\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399       0.18      0.426      0.137     0.0981      0.182      0.431       0.14     0.0945\n",
      "                  ripe         66        399       0.18      0.426      0.137     0.0981      0.182      0.431       0.14     0.0945\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.56it/s]\n",
      "                   all         68        365       0.14     0.0832      0.127     0.0884      0.158     0.0942      0.134     0.0847\n",
      "                  ripe         68        365       0.14     0.0832      0.127     0.0884      0.158     0.0942      0.134     0.0847\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 799.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.56G      1.307      2.075      3.295      1.319         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399      0.178      0.376       0.13      0.095      0.188      0.376      0.134      0.092\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.96G      1.285      2.539       3.28      1.467         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.174      0.378      0.127     0.0927      0.177      0.386      0.131       0.09\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.82G      1.266      2.406      3.325      1.507         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.171      0.388      0.124     0.0903      0.176      0.398      0.129     0.0882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G     0.9825      2.092      3.414      1.349         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.157      0.444      0.121     0.0881       0.16      0.454      0.126     0.0859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.01G      1.353      2.347       3.34      1.455         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.161      0.411      0.121     0.0884      0.163      0.416      0.126      0.085\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399      0.184      0.368      0.129     0.0948      0.187      0.376      0.134     0.0917\n",
      "                  ripe         66        399      0.184      0.368      0.129     0.0948      0.187      0.376      0.134     0.0917\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.52it/s]\n",
      "                   all         68        365      0.146      0.112      0.121     0.0849      0.154      0.118      0.125     0.0804\n",
      "                  ripe         68        365      0.146      0.112      0.121     0.0849      0.154      0.118      0.125     0.0804\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 849.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.4G     0.9506      2.198      3.633      1.279         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.127      0.449      0.104     0.0721      0.131      0.358      0.106     0.0696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G     0.9248      1.925      3.385      1.188         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.132      0.313     0.0985      0.068      0.127      0.175      0.102     0.0663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G      0.896      2.383      3.636      1.213         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399     0.0944      0.639     0.0997     0.0697      0.119      0.539      0.103     0.0678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8431      2.081      3.528      1.141         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0318      0.877      0.111      0.078      0.136      0.544      0.114     0.0764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G     0.8134      1.818      3.361      1.168         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.174      0.541      0.148      0.106      0.186      0.496      0.151      0.101\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]\n",
      "                   all         66        399      0.175      0.541      0.149      0.106      0.187      0.496      0.151      0.101\n",
      "                  ripe         66        399      0.175      0.541      0.149      0.106      0.187      0.496      0.151      0.101\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.52it/s]\n",
      "                   all         68        365      0.152     0.0877      0.142     0.0976      0.166     0.0959      0.148     0.0942\n",
      "                  ripe         68        365      0.152     0.0877      0.142     0.0976      0.166     0.0959      0.148     0.0942\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 788.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.58G     0.8696      1.468      3.404      1.204         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.98it/s]\n",
      "                   all         66        399      0.187      0.336      0.134     0.0981      0.193      0.346      0.138     0.0942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.81G      1.103        2.1       3.77      1.342         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.175      0.368      0.129     0.0941      0.181      0.381      0.134     0.0907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.89G     0.6268      1.312      3.638      1.001          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399      0.171      0.404      0.128     0.0942      0.182      0.306      0.133     0.0903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G     0.9111      1.749      3.452      1.187         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.177      0.336      0.129     0.0946      0.183      0.323      0.135     0.0909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.07G      1.312      2.684      3.858      1.409         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.178      0.282      0.124     0.0911      0.185      0.292      0.129     0.0877\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]\n",
      "                   all         66        399      0.185      0.333      0.134     0.0976      0.191      0.343      0.138      0.094\n",
      "                  ripe         66        399      0.185      0.333      0.134     0.0976      0.191      0.343      0.138      0.094\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.55it/s]\n",
      "                   all         68        365      0.175      0.134      0.132     0.0917      0.183      0.134      0.137      0.087\n",
      "                  ripe         68        365      0.175      0.134      0.132     0.0917      0.183      0.134      0.137      0.087\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 832.07it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.4G     0.9441       2.23      3.513      1.183        113        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.126      0.446      0.104      0.072      0.143      0.327      0.107     0.0696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.53G     0.7433      1.788      3.581      1.112         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.117       0.14     0.0984     0.0678      0.128      0.133      0.101      0.066\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      1.038      2.294      3.629      1.284        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.133      0.388      0.102     0.0704      0.138      0.358      0.104     0.0685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.9341      2.142      3.591      1.202         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.139      0.504      0.117     0.0812      0.143      0.516      0.121       0.08\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.43G       0.99      2.219      3.461      1.188        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.184      0.431      0.149      0.105      0.185      0.433      0.152      0.101\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399      0.183      0.428      0.149      0.105      0.184       0.43      0.152      0.101\n",
      "                  ripe         66        399      0.183      0.428      0.149      0.105      0.184       0.43      0.152      0.101\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365      0.178      0.118      0.144     0.0986      0.203      0.134      0.151     0.0945\n",
      "                  ripe         68        365      0.178      0.118      0.144     0.0986      0.203      0.134      0.151     0.0945\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 826.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G       1.95      3.254       3.54      1.853         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.183      0.288      0.143      0.103      0.187      0.293      0.147        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G      1.552      3.604      4.094      1.705         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.182      0.273      0.142      0.103      0.185      0.278      0.146     0.0996\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.97G      1.909      3.344      3.617      1.898         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.176      0.274      0.139        0.1      0.181      0.281      0.143     0.0965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G       1.81      3.169      4.023      1.972         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.185      0.301      0.138     0.0997       0.19      0.308      0.142     0.0952\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.93G      1.587       3.42        3.9      1.648         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.189      0.291      0.138     0.0987      0.193      0.296      0.141     0.0945\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399      0.182      0.286      0.143      0.104      0.185      0.291      0.147        0.1\n",
      "                  ripe         66        399      0.182      0.286      0.143      0.104      0.185      0.291      0.147        0.1\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365      0.176       0.14      0.138     0.0973      0.189      0.151      0.142     0.0918\n",
      "                  ripe         68        365      0.176       0.14      0.138     0.0973      0.189      0.151      0.142     0.0918\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 861.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.41G     0.9502      2.096      3.727      1.218         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.117      0.554      0.103     0.0715      0.135      0.338      0.106     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G     0.9602      2.169       3.65      1.239         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.126      0.238     0.0968     0.0669      0.125      0.173     0.0995     0.0648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.44G     0.9625      2.137       3.59      1.256         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399     0.0887      0.584     0.0922     0.0628     0.0894      0.589     0.0958     0.0623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      1.083      2.403      3.584      1.289        135        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0478      0.799      0.114     0.0785     0.0827      0.734      0.116     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.44G       1.11      2.361      3.513      1.308        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.184      0.343      0.142     0.0983      0.183      0.341      0.143     0.0943\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.184      0.343      0.143     0.0987      0.183      0.341      0.142     0.0944\n",
      "                  ripe         66        399      0.184      0.343      0.143     0.0987      0.183      0.341      0.142     0.0944\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365      0.166      0.115      0.138     0.0951      0.174      0.121      0.144     0.0899\n",
      "                  ripe         68        365      0.166      0.115      0.138     0.0951      0.174      0.121      0.144     0.0899\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1107.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.56G     0.9331      1.777      2.754      1.172         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399       0.17      0.366      0.125     0.0909      0.175      0.378      0.131     0.0871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.8657      1.608      3.664      1.186          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.165      0.363      0.124     0.0905      0.171      0.376       0.13     0.0861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.83G     0.6666      1.459      2.918      1.113         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.173      0.256      0.124     0.0896      0.181      0.268      0.129     0.0859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G     0.7362      1.742      3.265      1.108         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.169      0.218      0.122     0.0887      0.175      0.226      0.127     0.0849\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.94G      1.073      2.817      3.553      1.361         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.162      0.434      0.122     0.0887      0.179      0.253      0.124      0.084\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.167      0.383      0.125     0.0911      0.173      0.396      0.131     0.0872\n",
      "                  ripe         66        399      0.167      0.383      0.125     0.0911      0.173      0.396      0.131     0.0872\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365      0.166      0.142      0.127     0.0887      0.166      0.142      0.133     0.0832\n",
      "                  ripe         68        365      0.166      0.142      0.127     0.0887      0.166      0.142      0.133     0.0832\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:00<00:00, 881.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.29G      1.087      2.245      3.631      1.297        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.128      0.361      0.104     0.0717      0.131      0.169      0.106     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.32G      0.853      1.926      3.444      1.139        140        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.128      0.208      0.098     0.0676      0.124       0.15      0.101     0.0656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      1.087       2.51      3.601       1.26        240        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399     0.0607      0.727     0.0918     0.0634      0.119      0.439     0.0971     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.24G     0.9599      2.141      3.509      1.205        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.064      0.782       0.12     0.0824      0.137      0.561      0.122     0.0802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G     0.8709      1.842      3.485      1.212        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.202      0.311      0.164      0.114      0.204      0.313      0.165      0.109\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.186      0.185      0.164      0.114      0.189      0.188      0.165      0.109\n",
      "                  ripe         66        399      0.186      0.185      0.164      0.114      0.189      0.188      0.165      0.109\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.58it/s]\n",
      "                   all         68        365      0.174      0.129      0.155      0.107      0.193      0.142      0.161      0.102\n",
      "                  ripe         68        365      0.174      0.129      0.155      0.107      0.193      0.142      0.161      0.102\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 965.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.47G      0.585      1.178      3.214      1.122         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.99it/s]\n",
      "                   all         66        399      0.197      0.238      0.152       0.11      0.199      0.241      0.156      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.07G     0.7897      1.536      3.197      1.252         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.175      0.266      0.151      0.109      0.182      0.276      0.156      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.05G     0.7789      1.894      3.012       1.23         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.179      0.253      0.151      0.109      0.185       0.26      0.155      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.01G     0.7307      1.428      2.984      1.102         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.183      0.249      0.147      0.107      0.191      0.259      0.152      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.01G     0.6408      1.182      3.075      1.056         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399       0.19      0.321      0.148      0.109      0.193      0.326      0.154      0.103\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399      0.199       0.24      0.152       0.11      0.201      0.243      0.156      0.105\n",
      "                  ripe         66        399      0.199       0.24      0.152       0.11      0.201      0.243      0.156      0.105\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.168      0.154      0.143      0.101      0.174      0.156      0.147      0.095\n",
      "                  ripe         68        365      0.168      0.154      0.143      0.101      0.174      0.156      0.147      0.095\n",
      "Speed: 0.3ms preprocess, 14.6ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:00<00:00, 825.33it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.32G     0.8301       1.97        3.4      1.185         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.129      0.308      0.101     0.0699      0.134      0.321      0.103     0.0676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      1.019      2.145      3.724      1.279         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.96it/s]\n",
      "                   all         66        399     0.0781      0.692      0.101     0.0705      0.132      0.439      0.104     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.46G     0.9693      2.018      3.391      1.269         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399      0.215      0.273      0.173      0.126      0.223      0.283      0.175       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G     0.8839      1.711      3.025      1.171         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.328      0.637      0.303       0.22      0.331      0.642      0.304      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.9096      1.973      2.552      1.192         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.356      0.757      0.352      0.253       0.36      0.767       0.35      0.236\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.356      0.757      0.352      0.253      0.359      0.759      0.351      0.236\n",
      "                  ripe         66        399      0.356      0.757      0.352      0.253      0.359      0.759      0.351      0.236\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n",
      "                   all         68        365      0.336      0.668      0.334      0.237      0.338      0.671      0.333       0.22\n",
      "                  ripe         68        365      0.336      0.668      0.334      0.237      0.338      0.671      0.333       0.22\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 729.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_14/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.58G     0.7998      1.715      2.199      1.164         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.345      0.749      0.334      0.247      0.349      0.762      0.337      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.08G     0.9863      2.058      2.302      1.254         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.349       0.75      0.338      0.249      0.354      0.764      0.341      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.91G      1.161      2.393      2.477      1.399         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.349      0.747      0.336      0.248      0.353      0.757      0.339      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.87G      1.342      2.317      2.696      1.636         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.345      0.739      0.336      0.247       0.35      0.749      0.338      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.87G      1.098      2.012      3.023       1.38         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.346      0.727      0.338      0.248       0.35      0.742       0.34      0.233\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.347      0.749      0.338      0.249      0.352      0.762      0.341      0.235\n",
      "                  ripe         66        399      0.347      0.749      0.338      0.249      0.352      0.762      0.341      0.235\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.61it/s]\n",
      "                   all         68        365      0.312      0.704       0.32      0.228      0.325      0.658      0.319      0.213\n",
      "                  ripe         68        365      0.312      0.704       0.32      0.228      0.325      0.658      0.319      0.213\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 830.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.9645      2.246      3.604      1.237        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.81it/s]\n",
      "                   all         66        399      0.134      0.291      0.101     0.0695      0.135      0.271      0.104     0.0672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.32G     0.9302      2.224      3.505      1.266         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.148      0.488      0.119     0.0844      0.148      0.486      0.122     0.0817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      1.037      2.239      3.495      1.236         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.209       0.28      0.176      0.126      0.217       0.29      0.179       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.8G     0.9534      1.959      2.912      1.204         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.313      0.614       0.29      0.206      0.314      0.617      0.289      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G     0.9363      1.925      2.523      1.189         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.348      0.749      0.343      0.242      0.349      0.762      0.339      0.227\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.348       0.75      0.343      0.242      0.348       0.76      0.339      0.227\n",
      "                  ripe         66        399      0.348       0.75      0.343      0.242      0.348       0.76      0.339      0.227\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.64it/s]\n",
      "                   all         68        365      0.322      0.636      0.307      0.217       0.32       0.63      0.306      0.202\n",
      "                  ripe         68        365      0.322      0.636      0.307      0.217       0.32       0.63      0.306      0.202\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 768.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      0.674      1.244      2.122      1.082         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399       0.33      0.734      0.317      0.229      0.334      0.734      0.318      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.07G     0.8462      2.148      2.729       1.26         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.328      0.734      0.315      0.227      0.334       0.74      0.316      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.8227       2.29      2.501      1.265         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.323      0.724      0.314      0.226      0.332      0.729      0.314      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.8776      2.806       3.22      1.193         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.323      0.717      0.311      0.225      0.328      0.727      0.313      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.17G     0.8878      1.736       1.71      1.072         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.326      0.714       0.31      0.223       0.33      0.722      0.311       0.21\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.329      0.732      0.316      0.228      0.333      0.734      0.316      0.213\n",
      "                  ripe         66        399      0.329      0.732      0.316      0.228      0.333      0.734      0.316      0.213\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.297      0.685      0.288      0.203      0.297      0.685      0.287      0.191\n",
      "                  ripe         68        365      0.297      0.685      0.288      0.203      0.297      0.685      0.287      0.191\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 856.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.18G     0.9251      2.044      3.494      1.203         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.124      0.208      0.101     0.0694      0.132      0.191      0.104     0.0675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.21G     0.9254      2.013      3.584      1.227        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.037      0.822     0.0924      0.063      0.131      0.291     0.0968     0.0622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.24G     0.9633      2.086      3.422      1.209        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.209      0.163        0.2      0.146      0.212      0.165      0.203      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G     0.9738      1.972      3.007       1.23        165        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.343      0.689       0.34      0.252      0.346      0.697       0.34      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.36G     0.9099      1.857      2.453       1.19         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399       0.38      0.784      0.402        0.3      0.383      0.789      0.399      0.279\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399       0.38      0.784      0.404      0.301      0.383      0.789      0.401       0.28\n",
      "                  ripe         66        399       0.38      0.784      0.404      0.301      0.383      0.789      0.401       0.28\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.377      0.647      0.384      0.281      0.375      0.644      0.381      0.261\n",
      "                  ripe         68        365      0.377      0.647      0.384      0.281      0.375      0.644      0.381      0.261\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 811.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G     0.7157      1.274      2.094      1.084         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399      0.365      0.792      0.403      0.309      0.367      0.799      0.404       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.88G     0.7271      1.445      2.998      1.095         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.366      0.792      0.402      0.307      0.371      0.802      0.402      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G      1.066      2.144      2.011      1.223         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.367      0.787      0.399      0.304      0.371      0.797      0.399      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G     0.9962        2.1      3.557      1.322         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.366      0.782      0.396      0.303      0.369      0.796      0.397      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G       1.08      1.853      2.131      1.269         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.369      0.784      0.398      0.303      0.371      0.799      0.398      0.284\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399      0.364      0.794      0.404      0.309      0.367      0.801      0.405       0.29\n",
      "                  ripe         66        399      0.364      0.794      0.404      0.309      0.367      0.801      0.405       0.29\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.58it/s]\n",
      "                   all         68        365      0.355      0.679       0.37      0.274      0.358      0.685      0.369      0.256\n",
      "                  ripe         68        365      0.355      0.679       0.37      0.274      0.358      0.685      0.369      0.256\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 903.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.6G     0.9559       2.09      3.559      1.194         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.134      0.286     0.0992     0.0688      0.131      0.208      0.102     0.0669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      1.012      2.214      3.558      1.306         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.194      0.338      0.154      0.109      0.198      0.346      0.156      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.46G     0.9085      1.839      3.097      1.225         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.372      0.744      0.389      0.289      0.373      0.739      0.387      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8749      1.737      2.023      1.144         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.444      0.793      0.528      0.406      0.445      0.796      0.525      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G     0.7885      1.991      2.071      1.124         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.459      0.789      0.542      0.422      0.462      0.794      0.542      0.401\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.459      0.789      0.542      0.423      0.461      0.794      0.542      0.402\n",
      "                  ripe         66        399      0.459      0.789      0.542      0.423      0.461      0.794      0.542      0.402\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.67it/s]\n",
      "                   all         68        365      0.399      0.784      0.466       0.36      0.403      0.781      0.466      0.343\n",
      "                  ripe         68        365      0.399      0.784      0.466       0.36      0.403      0.781      0.466      0.343\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 890.13it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.75G      1.682      4.357      1.642      1.778         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.473      0.727      0.524      0.409      0.478      0.734      0.525      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.11G      2.154      4.596      1.845      2.041         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.474      0.722      0.527      0.411      0.478      0.729      0.528      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.89G     0.4207      1.102      1.669      1.022         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.467      0.727      0.522      0.407      0.472      0.727      0.523      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.5809      1.508      1.861        1.1         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.473      0.714      0.526       0.41      0.478      0.719      0.527      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.88G     0.7733      1.959      2.124      1.244         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.446      0.767      0.523      0.408      0.483      0.713      0.523      0.388\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.473      0.721      0.524      0.409      0.478      0.728      0.525       0.39\n",
      "                  ripe         66        399      0.473      0.721      0.524      0.409      0.478      0.728      0.525       0.39\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.392      0.792      0.445      0.343      0.392       0.79      0.444      0.326\n",
      "                  ripe         68        365      0.392      0.792      0.445      0.343      0.392       0.79      0.444      0.326\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:00<00:00, 871.21it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G      1.053      2.294      3.493      1.285         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.128      0.278     0.0968      0.067      0.126      0.143        0.1      0.065\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      1.119      2.469      3.612      1.321         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.185      0.261      0.151      0.105      0.187      0.263      0.153        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G      1.092      2.257      2.985      1.311         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.321      0.724       0.32      0.225      0.319      0.733      0.314      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G     0.8203       1.74      2.224      1.176         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.468      0.786      0.544       0.43      0.478      0.777      0.544      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G     0.8818      1.773        1.8      1.159         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.476      0.799      0.559      0.443       0.48      0.802       0.56      0.419\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.476      0.799       0.56      0.443      0.479      0.802       0.56      0.419\n",
      "                  ripe         66        399      0.476      0.799       0.56      0.443      0.479      0.802       0.56      0.419\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365      0.425      0.734      0.481      0.373      0.427      0.737       0.48      0.353\n",
      "                  ripe         68        365      0.425      0.734      0.481      0.373      0.427      0.737       0.48      0.353\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 799.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.28G     0.9094      1.965      1.596      1.246         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.471      0.782      0.545      0.433      0.473      0.782      0.546       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.01G     0.8849      1.962      2.184      1.288         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.469      0.777      0.545      0.432      0.469      0.777      0.546      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.03G      0.862      2.082      2.496      1.274         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.468      0.777      0.546      0.433      0.472      0.779      0.547      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G      1.027      1.938      2.932       1.37         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.472      0.779      0.547      0.435      0.473      0.782      0.548      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.02G     0.9317      1.791      1.796      1.285         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.481      0.757       0.55      0.436      0.483      0.757      0.551      0.413\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399       0.48      0.754      0.549      0.436      0.484      0.754       0.55      0.412\n",
      "                  ripe         66        399       0.48      0.754      0.549      0.436      0.484      0.754       0.55      0.412\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.49it/s]\n",
      "                   all         68        365      0.422      0.745      0.479      0.371      0.422      0.745      0.477       0.35\n",
      "                  ripe         68        365      0.422      0.745      0.479      0.371      0.422      0.745      0.477       0.35\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:00<00:00, 845.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.6G     0.9796      2.191      3.529      1.235         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.132      0.316     0.0989     0.0682      0.131      0.168      0.102     0.0664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G     0.9848      2.217      3.663      1.283         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.185      0.516      0.153      0.109      0.185      0.516      0.155      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G     0.9615      2.042      2.931      1.228        111        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.367      0.787      0.403      0.296      0.368      0.787        0.4      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G      0.914      2.007      2.168      1.173         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.451       0.88      0.562      0.439      0.452      0.867      0.562      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G     0.8536       1.76      1.622      1.121         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.489      0.808      0.576      0.453      0.492      0.813      0.578      0.428\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.489      0.807      0.575      0.451      0.492      0.812      0.576      0.426\n",
      "                  ripe         66        399      0.489      0.807      0.575      0.451      0.492      0.812      0.576      0.426\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.417      0.792      0.492      0.383       0.42      0.797      0.492      0.363\n",
      "                  ripe         68        365      0.417      0.792      0.492      0.383       0.42      0.797      0.492      0.363\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 923.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.77G     0.8452      1.755      2.509       1.21         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.459      0.845      0.555      0.438      0.468      0.835      0.556      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G     0.8531      1.825      2.722      1.112         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.458      0.871      0.556      0.438      0.467      0.837      0.558      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G     0.5961       1.51      2.853        1.1          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.456      0.874      0.559       0.44      0.483      0.793       0.56      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G     0.8261      1.415      2.286      1.104         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.479      0.784      0.558      0.439      0.483      0.792      0.559      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       3.9G     0.8249      1.486      2.134      1.119         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.479      0.815       0.56      0.442      0.484      0.822      0.562      0.419\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.481      0.815       0.56      0.441      0.485      0.822      0.562      0.419\n",
      "                  ripe         66        399      0.481      0.815       0.56      0.441      0.485      0.822      0.562      0.419\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.426      0.767      0.482      0.375       0.43      0.773      0.483      0.354\n",
      "                  ripe         68        365      0.426      0.767      0.482      0.375       0.43      0.773      0.483      0.354\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<00:00, 902.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.49G     0.9583      2.307      3.626      1.283         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.84it/s]\n",
      "                   all         66        399      0.121      0.313      0.094     0.0649      0.131      0.206     0.0963      0.063\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.53G     0.9317      2.069      3.298       1.23         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.97it/s]\n",
      "                   all         66        399      0.268      0.501      0.243       0.17      0.271      0.506      0.242      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      1.022      2.084      2.331      1.295         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.451      0.739      0.534      0.413      0.432      0.817      0.536       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8358      1.875       1.63      1.153         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.494      0.747      0.573      0.451      0.503      0.757      0.574      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G       0.98      1.732      1.631      1.214         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.516      0.749      0.606      0.482      0.534      0.735      0.608      0.455\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.517      0.749      0.608      0.483      0.521      0.754      0.609      0.456\n",
      "                  ripe         66        399      0.517      0.749      0.608      0.483      0.521      0.754      0.609      0.456\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365      0.417      0.722      0.505      0.394      0.426      0.703      0.507      0.375\n",
      "                  ripe         68        365      0.417      0.722      0.505      0.394      0.426      0.703      0.507      0.375\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 797.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G     0.7422       1.72      1.535      1.129         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399       0.51      0.734       0.57      0.447      0.517      0.744      0.573      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.09G      1.272      2.545       2.08      1.493         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.509      0.742      0.573       0.45      0.516      0.752      0.576      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.06G      1.283      2.656      1.768      1.537         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.509      0.746      0.574       0.45      0.516      0.749      0.576       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.05G      1.376      2.838      2.163      1.503         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.498      0.764      0.579      0.456      0.517      0.757      0.582      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.99G      1.083      2.308      1.897      1.296         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399       0.49      0.781       0.58      0.457      0.521      0.744      0.584      0.438\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399       0.49      0.782       0.58      0.456      0.522      0.744      0.583      0.437\n",
      "                  ripe         66        399       0.49      0.782       0.58      0.456      0.522      0.744      0.583      0.437\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.57it/s]\n",
      "                   all         68        365      0.461      0.611      0.495      0.385      0.464      0.614      0.496      0.367\n",
      "                  ripe         68        365      0.461      0.611      0.495      0.385      0.464      0.614      0.496      0.367\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:00<00:00, 912.99it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      1.092       2.31      3.523      1.321         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.122      0.311     0.0973     0.0672      0.133      0.278        0.1     0.0653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.62G     0.9811      2.097      3.296      1.252         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.318      0.644      0.302      0.214      0.316      0.642      0.299      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G     0.9379      2.006      2.347      1.265         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.449      0.862      0.551       0.43      0.456      0.855      0.551      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.9284      2.029       1.65      1.226         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.493      0.793      0.576      0.453      0.499      0.802      0.578       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.7901      1.529      1.565      1.103         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399       0.53      0.761      0.618      0.486      0.532      0.767      0.618      0.461\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399       0.53      0.761      0.617      0.485      0.533      0.767      0.617       0.46\n",
      "                  ripe         66        399       0.53      0.761      0.617      0.485      0.533      0.767      0.617       0.46\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.71it/s]\n",
      "                   all         68        365       0.43      0.805      0.524      0.411      0.438      0.767      0.524      0.387\n",
      "                  ripe         68        365       0.43      0.805      0.524      0.411      0.438      0.767      0.524      0.387\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 756.08it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G      1.129      1.993      1.259       1.28         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399       0.51      0.799      0.583      0.457      0.518      0.812      0.589      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.88G      1.003      1.956      1.582      1.217         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.513      0.802      0.586      0.458      0.521      0.815      0.591      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G     0.6885       1.25      3.218      1.076         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.515      0.797      0.588      0.461      0.523      0.808      0.593      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G      0.583      1.012      3.456     0.9819          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.513      0.799      0.589      0.461       0.52      0.812      0.593      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.95G     0.7027       1.23      2.351      1.036         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.513      0.794      0.592      0.464      0.521      0.807      0.597      0.444\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.513      0.795      0.592      0.464      0.522      0.809      0.597      0.443\n",
      "                  ripe         66        399      0.513      0.795      0.592      0.464      0.522      0.809      0.597      0.443\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.69it/s]\n",
      "                   all         68        365      0.429      0.811      0.524      0.408      0.428      0.808      0.523      0.385\n",
      "                  ripe         68        365      0.429      0.811      0.524      0.408      0.428      0.808      0.523      0.385\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 890.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      1.102      2.483      3.514      1.311        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.124      0.316     0.0955     0.0662      0.132      0.248     0.0981     0.0641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G     0.9454      2.134       3.29      1.222        118        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.307      0.624      0.287      0.204      0.308      0.624      0.285      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G     0.9025        1.8      2.313      1.233        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.441      0.852      0.559      0.444      0.447      0.853      0.562       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G     0.9075      1.802      1.768      1.186        124        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.456      0.833      0.571      0.456      0.455      0.851      0.574      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G     0.9086      1.801      1.646      1.172        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.507      0.737      0.596      0.475      0.504      0.747      0.596       0.45\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399      0.508      0.732      0.595      0.475      0.505      0.747      0.596       0.45\n",
      "                  ripe         66        399      0.508      0.732      0.595      0.475      0.505      0.747      0.596       0.45\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.69it/s]\n",
      "                   all         68        365      0.422      0.789      0.517      0.408      0.424      0.787      0.519      0.383\n",
      "                  ripe         68        365      0.422      0.789      0.517      0.408      0.424      0.787      0.519      0.383\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 931.28it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G     0.7085      1.113      1.528      1.021         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.487      0.787      0.576      0.458      0.507      0.752       0.58      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.87G     0.6292      1.196      2.069      1.078         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.491      0.786      0.578      0.459      0.497      0.795      0.582       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G     0.6626      1.074      2.051     0.9335         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.489      0.782       0.58      0.461      0.496      0.787      0.585      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G     0.6361      1.255      2.661      1.055         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.486      0.777      0.579       0.46      0.496      0.792      0.584      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.8911      1.271      2.798      1.037         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.484      0.777      0.583      0.464      0.494      0.789      0.587      0.443\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.484      0.778      0.583      0.464      0.494      0.788      0.587      0.443\n",
      "                  ripe         66        399      0.484      0.778      0.583      0.464      0.494      0.788      0.587      0.443\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.422      0.764      0.513      0.402      0.435      0.742      0.513      0.378\n",
      "                  ripe         68        365      0.422      0.764      0.513      0.402      0.435      0.742      0.513      0.378\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 938.86it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.51G     0.9694      2.322      3.553      1.214         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0794      0.694      0.101     0.0697      0.134      0.388      0.103      0.068\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.65G      1.058      2.295      3.161      1.312          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.347      0.772      0.349      0.251      0.345      0.767      0.346      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.39G     0.9298      1.967      2.012       1.24         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.463      0.845      0.567      0.446      0.468      0.855      0.571      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.39G     0.8227      1.742      1.839      1.136         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.494      0.819      0.593      0.468        0.5      0.829      0.597      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G     0.7977      1.472      1.691      1.086          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.512      0.836      0.605      0.471      0.516      0.832      0.608      0.442\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.511       0.83      0.605       0.47      0.517      0.832      0.608      0.442\n",
      "                  ripe         66        399      0.511       0.83      0.605       0.47      0.517      0.832      0.608      0.442\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.71it/s]\n",
      "                   all         68        365      0.479        0.8      0.572      0.445      0.481      0.803       0.57       0.41\n",
      "                  ripe         68        365      0.479        0.8      0.572      0.445      0.481      0.803       0.57       0.41\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 779.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.59G     0.3956     0.8232      1.241      0.911         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.504       0.81      0.599      0.469      0.504       0.82      0.601      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.08G     0.7574      1.319      1.578      1.191         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.503      0.808        0.6      0.469      0.503      0.823      0.601      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.08G     0.5384      1.364      1.457      1.045         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.509      0.804        0.6      0.469      0.508      0.829      0.601      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G     0.6319      1.339      1.487      1.085         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.536      0.767        0.6      0.468      0.542      0.774      0.601      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.12G     0.4855      0.937      1.091     0.9935         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.536      0.769      0.601       0.47      0.542      0.777      0.603      0.446\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.535      0.769      0.601       0.47      0.542      0.777      0.603      0.447\n",
      "                  ripe         66        399      0.535      0.769      0.601       0.47      0.542      0.777      0.603      0.447\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.53it/s]\n",
      "                   all         68        365      0.468      0.795      0.571      0.444      0.467      0.792      0.564      0.409\n",
      "                  ripe         68        365      0.468      0.795      0.571      0.444      0.467      0.792      0.564      0.409\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 740.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.32G     0.9377        2.2      3.473      1.227         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.032       0.89      0.106     0.0745      0.143      0.439      0.109     0.0722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G      1.005      2.189      3.208      1.247         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.328      0.764      0.336      0.239      0.328      0.764      0.335      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.8262      1.599      2.184      1.167         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.94it/s]\n",
      "                   all         66        399      0.473      0.812      0.572      0.454      0.478       0.82      0.575      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.5G     0.8991       1.74      1.649       1.19         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.485      0.835      0.614      0.487      0.483      0.845      0.616       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G     0.8793      1.768      1.421      1.181         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.516      0.832      0.644      0.507      0.521       0.83       0.65      0.479\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.517      0.832      0.644      0.507      0.534      0.791       0.65      0.478\n",
      "                  ripe         66        399      0.517      0.832      0.644      0.507      0.534      0.791       0.65      0.478\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365      0.457      0.805      0.559      0.441      0.464      0.814      0.561      0.413\n",
      "                  ripe         68        365      0.457      0.805      0.559      0.441      0.464      0.814      0.561      0.413\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1089.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.38G     0.5619       1.01      1.909     0.9701         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.509      0.827      0.618      0.485      0.513       0.84      0.625      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.01G     0.5124      1.159      1.839       1.05         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.519      0.805      0.617      0.485      0.515      0.812      0.626       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G     0.7525      1.753      3.057      1.242         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.523      0.799      0.618      0.485      0.527      0.805      0.627      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G     0.7612      1.447      2.158      1.152         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.522      0.802       0.62      0.486      0.526      0.807      0.627      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.6056      1.233       2.89      1.064         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.526      0.804      0.624      0.488      0.529      0.809      0.631      0.466\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.523      0.812      0.625      0.489      0.529       0.81       0.63      0.467\n",
      "                  ripe         66        399      0.523      0.812      0.625      0.489      0.529       0.81       0.63      0.467\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.42it/s]\n",
      "                   all         68        365      0.447      0.847      0.553      0.435      0.447      0.849      0.552      0.407\n",
      "                  ripe         68        365      0.447      0.847      0.553      0.435      0.447      0.849      0.552      0.407\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:00<00:00, 855.63it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      1.019      2.207      3.532      1.272        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.115      0.654      0.118     0.0834       0.14      0.516      0.118     0.0799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G      0.846      1.808      3.097      1.182         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.379      0.805      0.397      0.288      0.379      0.802      0.396      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.34G     0.8224      1.737       1.95      1.162         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.474       0.84      0.571       0.45      0.476      0.842      0.572      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.36G     0.7408      1.554      1.607        1.1         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.533      0.797      0.613      0.481      0.534      0.789      0.613      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G     0.7697      1.533       1.41      1.091         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.608      0.771      0.652       0.51      0.612      0.776      0.655      0.485\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.608      0.769      0.652      0.509      0.612      0.774      0.656      0.485\n",
      "                  ripe         66        399      0.608      0.769      0.652      0.509      0.612      0.774      0.656      0.485\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.62it/s]\n",
      "                   all         68        365      0.477      0.761      0.578      0.458      0.478      0.764      0.578      0.433\n",
      "                  ripe         68        365      0.477      0.761      0.578      0.458      0.478      0.764      0.578      0.433\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 824.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.39G     0.5887      1.282      1.492      1.117         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399      0.573      0.787      0.641        0.5      0.588      0.764      0.643      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.09G      1.081       2.09      1.651      1.354         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.578      0.794      0.643      0.502      0.585      0.782      0.645      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.09G       0.97      1.653      1.371      1.349         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.579      0.783      0.645      0.502      0.585       0.79      0.649       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      1.097      1.869      1.346      1.362         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.584      0.773      0.648      0.504      0.591      0.769      0.651      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.03G      1.022      1.726      1.449      1.248         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.588      0.772      0.651      0.508      0.594       0.77      0.655      0.484\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399      0.588      0.772      0.651      0.507      0.594       0.78      0.654      0.484\n",
      "                  ripe         66        399      0.588      0.772      0.651      0.507      0.594       0.78      0.654      0.484\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365       0.48      0.775       0.58      0.454       0.48      0.775      0.577      0.431\n",
      "                  ripe         68        365       0.48      0.775       0.58      0.454       0.48      0.775      0.577      0.431\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:00<00:00, 827.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G     0.9318      2.192      3.562      1.279        124        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399     0.0367      0.822     0.0922     0.0638      0.121      0.388     0.0952     0.0624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.61G     0.9059      1.972      3.107      1.217        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.365      0.827      0.399       0.29       0.38      0.779      0.396      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G     0.8713      1.726      1.907      1.172        117        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.478      0.812      0.574      0.457      0.483       0.82      0.577      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.53G     0.7955      1.659      1.607      1.106        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.509      0.781      0.601      0.467      0.489      0.835      0.596      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.51G     0.7975       1.53      1.533      1.127        113        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.588      0.751      0.651      0.508      0.581      0.764       0.65      0.478\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]\n",
      "                   all         66        399      0.589      0.752       0.65      0.507      0.583      0.758       0.65      0.478\n",
      "                  ripe         66        399      0.589      0.752       0.65      0.507      0.583      0.758       0.65      0.478\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.63it/s]\n",
      "                   all         68        365      0.453      0.789      0.578      0.459      0.455      0.791      0.579      0.432\n",
      "                  ripe         68        365      0.453      0.789      0.578      0.459      0.455      0.791      0.579      0.432\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 555.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.31G      1.012      1.959      1.858      1.128         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399       0.56      0.787      0.628      0.491      0.564      0.769      0.628      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.09G     0.8678      1.567      1.519      1.144         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.563      0.777       0.63      0.493      0.567      0.782      0.633      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.14G     0.9789      1.837      1.555      1.325         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.567      0.777      0.632      0.495       0.57      0.782      0.636       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       3.9G      1.145      2.012      1.665      1.404         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.564      0.779      0.634      0.496      0.566      0.782      0.637      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.13G     0.7731      1.827      1.575      1.139         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.564      0.774      0.639      0.502      0.565      0.777      0.642      0.476\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.564      0.776      0.639      0.502      0.566      0.779      0.642      0.476\n",
      "                  ripe         66        399      0.564      0.776      0.639      0.502      0.566      0.779      0.642      0.476\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.62it/s]\n",
      "                   all         68        365      0.465      0.765      0.568      0.447      0.465      0.765      0.567      0.423\n",
      "                  ripe         68        365      0.465      0.765      0.568      0.447      0.465      0.765      0.567      0.423\n",
      "Speed: 0.3ms preprocess, 14.4ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 914.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.41G     0.9914      2.166      3.538      1.237         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                   all         66        399     0.0471      0.789      0.105     0.0731     0.0958      0.662      0.108     0.0714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.56G     0.8704      1.761      2.764      1.183         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.467      0.752      0.541      0.424      0.471      0.756      0.544      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.8635      1.706      1.706      1.185         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.491      0.828      0.589      0.464      0.491      0.819      0.591      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8166      1.609      1.528      1.129         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.536      0.782      0.629      0.498      0.541      0.776      0.631      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.7999       1.55      1.416      1.105         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399        0.6      0.751      0.655      0.499      0.603      0.763      0.653      0.467\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]\n",
      "                   all         66        399      0.599      0.752      0.654      0.498      0.603      0.761      0.652      0.466\n",
      "                  ripe         66        399      0.599      0.752      0.654      0.498      0.603      0.761      0.652      0.466\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365      0.505      0.811      0.622      0.489      0.513      0.786      0.622      0.455\n",
      "                  ripe         68        365      0.505      0.811      0.622      0.489      0.513      0.786      0.622      0.455\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 828.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.1G     0.7526      1.425      1.271      1.157        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.587      0.764      0.643      0.494      0.614      0.737      0.642      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.5677       1.25      1.396      1.078         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.597      0.754      0.643      0.494      0.599      0.755      0.643      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.14G     0.7975      1.586      1.316      1.095        149        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.599      0.757      0.643      0.495      0.598      0.749      0.643      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      1.083      1.991       1.11      1.183         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.597      0.754      0.645      0.495      0.603      0.742      0.645      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.9631      1.811      1.248      1.225        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.597      0.747      0.646      0.496      0.604      0.749      0.646      0.468\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.596      0.747      0.646      0.496      0.606      0.745      0.645      0.468\n",
      "                  ripe         66        399      0.596      0.747      0.646      0.496      0.606      0.745      0.645      0.468\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.67it/s]\n",
      "                   all         68        365      0.505       0.84      0.625      0.489      0.505       0.84      0.624      0.457\n",
      "                  ripe         68        365      0.505       0.84      0.625      0.489      0.505       0.84      0.624      0.457\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 757.86it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.24G     0.8964      1.739      1.199      1.064        193        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.583      0.764      0.615      0.468      0.587      0.769      0.618      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.22G     0.9832      2.022      1.233      1.098        176        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.591      0.742       0.62      0.472      0.595      0.747      0.623      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.28G     0.7281       1.36      1.121     0.9704        150        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399       0.59      0.742      0.621      0.473      0.594      0.747      0.624      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.9222      2.045      1.586       1.29         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.609      0.732      0.625      0.475      0.613      0.737      0.627       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.27G     0.9295      1.858      1.357       1.15        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.613      0.722      0.627      0.476      0.618      0.727      0.629      0.449\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.611      0.722      0.628      0.477      0.616      0.727       0.63       0.45\n",
      "                  ripe         66        399      0.611      0.722      0.628      0.477      0.616      0.727       0.63       0.45\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.72it/s]\n",
      "                   all         68        365      0.514      0.797      0.622      0.486       0.51      0.792      0.619      0.456\n",
      "                  ripe         68        365      0.514      0.797      0.622      0.486       0.51      0.792      0.619      0.456\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:00<00:00, 898.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      1.062      2.335      3.453       1.31         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
      "                   all         66        399      0.174       0.13      0.161      0.112      0.177      0.133      0.163      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.71G     0.9466      1.961       2.36      1.242         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.486      0.746      0.571      0.456      0.492      0.756      0.575      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.46G     0.7636      1.484      1.513      1.109         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.496      0.859      0.616      0.478      0.544      0.751      0.612       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.5G     0.8037      1.541      1.294       1.09         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.603      0.747       0.64      0.479      0.602      0.744      0.636      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G     0.7336      1.367      1.096      1.036        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.622       0.82      0.707      0.539      0.628      0.816      0.707      0.508\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.619       0.82      0.708      0.539      0.623      0.817      0.708      0.508\n",
      "                  ripe         66        399      0.619       0.82      0.708      0.539      0.623      0.817      0.708      0.508\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.71it/s]\n",
      "                   all         68        365      0.561      0.759      0.673       0.53      0.561      0.759      0.671      0.495\n",
      "                  ripe         68        365      0.561      0.759      0.673       0.53      0.561      0.759      0.671      0.495\n",
      "Speed: 0.3ms preprocess, 14.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 864.47it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.42G      1.599      2.642       1.16      1.268        179        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.614      0.825      0.683      0.523       0.61       0.82      0.681      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.349      2.443      1.279      1.296        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.622      0.825      0.686      0.525       0.62      0.817      0.684      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       7.2G       1.29      2.422      1.291      1.239        138        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.619      0.822      0.686      0.526      0.625       0.81      0.686        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.7234      1.675      1.922      1.077         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.621      0.835      0.691      0.528      0.618       0.83      0.688      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.181      2.503      1.483      1.244         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.624      0.832      0.692      0.528      0.623       0.83      0.691      0.501\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.625      0.832      0.692      0.528      0.624       0.83      0.691      0.502\n",
      "                  ripe         66        399      0.625      0.832      0.692      0.528      0.624       0.83      0.691      0.502\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.69it/s]\n",
      "                   all         68        365      0.604      0.698      0.665      0.523      0.604      0.698      0.664      0.488\n",
      "                  ripe         68        365      0.604      0.698      0.665      0.523      0.604      0.698      0.664      0.488\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:00<00:00, 843.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.59G      1.047      2.354      3.496      1.319         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.84it/s]\n",
      "                   all         66        399      0.266      0.387      0.254       0.18      0.271      0.394      0.254      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G     0.8602      1.813      2.084      1.202         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.474       0.83      0.565      0.447      0.489      0.827      0.567      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G     0.8337      1.507      1.379      1.116         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                   all         66        399      0.577      0.747      0.654      0.495      0.577      0.743      0.652      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.8949      1.684      1.318      1.111         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.609       0.76      0.689       0.51      0.608      0.758      0.686      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.8033      1.501      1.108      1.066         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.646      0.802      0.754      0.576      0.641      0.805      0.747      0.544\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.644      0.802      0.753      0.576      0.641      0.807      0.747      0.544\n",
      "                  ripe         66        399      0.644      0.802      0.753      0.576      0.641      0.807      0.747      0.544\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.67it/s]\n",
      "                   all         68        365      0.582      0.718      0.684      0.535      0.582      0.718      0.681      0.499\n",
      "                  ripe         68        365      0.582      0.718      0.684      0.535      0.582      0.718      0.681      0.499\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 803.48it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.84G     0.9316      1.488      1.284      1.084         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.608       0.83      0.729      0.562      0.628      0.805      0.725      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      0.676       1.44      1.563     0.9753         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.614      0.832      0.733      0.567      0.629      0.809      0.729      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G     0.8468      1.528      1.444     0.9888         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.617       0.83      0.736      0.569      0.629      0.811      0.732      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.4185     0.7922      1.393      0.893         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.632      0.822       0.74      0.572       0.63      0.817      0.736      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.5603      1.154      1.593     0.9429         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.634      0.823      0.743      0.574      0.634      0.816      0.739      0.544\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.633      0.818      0.743      0.574      0.632      0.815      0.739      0.543\n",
      "                  ripe         66        399      0.633      0.818      0.743      0.574      0.632      0.815      0.739      0.543\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.60it/s]\n",
      "                   all         68        365      0.552      0.784      0.666       0.52       0.55      0.781      0.664      0.486\n",
      "                  ripe         68        365      0.552      0.784      0.666       0.52       0.55      0.781      0.664      0.486\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [00:00<00:00, 830.52it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      1.005       2.25      3.515      1.273        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.282      0.363      0.255      0.186      0.284      0.366      0.256      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G     0.8942      1.837      2.169      1.219        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.494      0.827      0.598       0.47       0.51      0.807      0.599       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G     0.8701      1.746       1.44      1.157        123        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.586      0.752      0.648      0.499       0.59      0.757      0.646      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G     0.8217      1.537      1.249      1.086         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.598      0.842      0.693      0.533        0.6      0.837       0.69      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G     0.7508      1.443      1.146      1.047        117        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.662      0.857      0.727      0.542      0.659      0.852      0.721      0.514\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.662      0.857      0.727      0.543      0.659       0.85      0.722      0.515\n",
      "                  ripe         66        399      0.662      0.857      0.727      0.543      0.659       0.85      0.722      0.515\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.586      0.819      0.694      0.548      0.588      0.822      0.695      0.516\n",
      "                  ripe         68        365      0.586      0.819      0.694      0.548      0.588      0.822      0.695      0.516\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 811.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.71G      0.976      1.468      1.035      1.146         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.626       0.86      0.699       0.53      0.628      0.862      0.698      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.8265      1.327     0.9959      1.099         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.629      0.857      0.701      0.532      0.631       0.86      0.699      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      0.872      1.284      0.942      1.082         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.626      0.857      0.701      0.532      0.628       0.86        0.7      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.6864      1.127     0.8961      1.127         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.625      0.864      0.703      0.533      0.627      0.867      0.703      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.7739       1.24      1.016      1.115         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.628      0.861      0.704      0.533      0.628      0.862      0.704      0.508\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.628       0.86      0.703      0.533       0.63      0.862      0.704      0.508\n",
      "                  ripe         66        399      0.628       0.86      0.703      0.533       0.63      0.862      0.704      0.508\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.70it/s]\n",
      "                   all         68        365      0.584      0.832      0.685      0.542      0.586      0.833      0.684      0.513\n",
      "                  ripe         68        365      0.584      0.832      0.685      0.542      0.586      0.833      0.684      0.513\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:00<00:00, 893.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G      1.012      2.173      3.407       1.27         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.338      0.627      0.329      0.241      0.339      0.623      0.328      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.72G     0.8633      1.665      1.859      1.158         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.519      0.782      0.607      0.482      0.522      0.782      0.609      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.51G     0.7759       1.49      1.381      1.083         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.583      0.807      0.671      0.521      0.585      0.809      0.672      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.7459      1.418       1.15      1.023         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.642      0.837      0.745      0.549      0.634      0.827      0.726      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.51G     0.7894       1.51      1.052       1.06         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.655      0.839      0.767      0.578      0.657      0.841      0.764      0.546\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]\n",
      "                   all         66        399      0.654       0.84      0.766      0.578      0.656      0.842      0.763      0.546\n",
      "                  ripe         66        399      0.654       0.84      0.766      0.578      0.656      0.842      0.763      0.546\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.74it/s]\n",
      "                   all         68        365      0.605       0.77      0.727      0.575      0.604      0.762      0.726      0.529\n",
      "                  ripe         68        365      0.605       0.77      0.727      0.575      0.604      0.762      0.726      0.529\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 921.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       6.9G     0.3805     0.7433      0.898     0.9139         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.582      0.857      0.704      0.549      0.597      0.845      0.704      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G     0.6165       1.35     0.9549      1.042         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.584      0.853      0.708      0.552      0.612       0.82      0.708      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.6151      1.098      1.143       1.07         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.592      0.847      0.712      0.555      0.597      0.847      0.711      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.8218      1.828      1.594      1.282         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.597      0.852      0.713      0.555      0.613      0.815      0.712      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.6393      1.468       1.52       1.16         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.597       0.85      0.715      0.555      0.614      0.817      0.714      0.527\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         66        399      0.595      0.852      0.715      0.556      0.615      0.817      0.714      0.528\n",
      "                  ripe         66        399      0.595      0.852      0.715      0.556      0.615      0.817      0.714      0.528\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.70it/s]\n",
      "                   all         68        365      0.562      0.847      0.699       0.55       0.56      0.844      0.698      0.512\n",
      "                  ripe         68        365      0.562      0.847      0.699       0.55       0.56      0.844      0.698      0.512\n",
      "Speed: 0.3ms preprocess, 14.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 161/161 [00:00<00:00, 898.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.9883       2.23      3.294      1.274         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]\n",
      "                   all         66        399      0.341      0.797      0.348      0.244       0.34      0.797      0.341      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G     0.8772        1.7      1.743      1.173          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.96it/s]\n",
      "                   all         66        399      0.526      0.787      0.628      0.488      0.531      0.792      0.631      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.53G     0.8036      1.474      1.219      1.084         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.609      0.845      0.699      0.514      0.609      0.845      0.699      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.8G     0.7307      1.297       1.07      1.022          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.659      0.832      0.729      0.546      0.664       0.82      0.725      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G     0.6889      1.227     0.9955      1.019         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.722      0.833       0.77      0.584      0.721       0.83      0.765      0.549\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         66        399      0.722      0.834       0.77      0.584       0.72       0.83      0.765      0.548\n",
      "                  ripe         66        399      0.722      0.834       0.77      0.584       0.72       0.83      0.765      0.548\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.715      0.803      0.806      0.638      0.717      0.796      0.801      0.595\n",
      "                  ripe         68        365      0.715      0.803      0.806      0.638      0.717      0.796      0.801      0.595\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 823.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.1G     0.9898      1.494     0.9021      1.177         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.673      0.837      0.737      0.561      0.673      0.837      0.737      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.7549      1.249     0.8891      0.987        123        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.672      0.837       0.74      0.562      0.672      0.837      0.736      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.6853      1.162     0.8361     0.9931         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.664      0.852      0.742      0.564      0.664      0.852      0.738      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.5135     0.9583     0.8246     0.9642         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.663      0.852      0.744      0.564      0.663      0.852       0.74      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.12G     0.7286      1.345      1.061      1.035         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.667       0.86      0.744      0.565      0.667       0.86       0.74      0.535\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.668       0.86      0.745      0.566      0.668       0.86      0.742      0.535\n",
      "                  ripe         66        399      0.668       0.86      0.745      0.566      0.668       0.86      0.742      0.535\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.72it/s]\n",
      "                   all         68        365      0.671       0.83      0.774      0.611      0.673      0.833      0.772      0.575\n",
      "                  ripe         68        365      0.671       0.83      0.774      0.611      0.673      0.833      0.772      0.575\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:00<00:00, 846.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.59G     0.9693      2.147       3.38       1.27         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]\n",
      "                   all         66        399      0.383      0.844      0.411      0.305      0.385      0.853      0.408      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G     0.8138      1.633      1.706      1.131         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                   all         66        399      0.515      0.789      0.608      0.479      0.519      0.796      0.612      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.5G     0.7615      1.421      1.367      1.078         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.582       0.82      0.683       0.51      0.577      0.834      0.669      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G      0.751      1.354      1.063       1.04         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.627      0.897      0.733      0.555      0.623      0.892      0.721      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.7481      1.386     0.9921      1.031         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.672      0.867      0.757      0.576      0.674      0.861      0.752      0.539\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.672      0.867      0.757      0.576      0.674      0.857      0.752      0.538\n",
      "                  ripe         66        399      0.672      0.867      0.757      0.576      0.674      0.857      0.752      0.538\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.75it/s]\n",
      "                   all         68        365      0.631      0.822      0.755      0.594      0.631      0.822      0.755       0.56\n",
      "                  ripe         68        365      0.631      0.822      0.755      0.594      0.631      0.822      0.755       0.56\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 681.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       6.1G     0.7581      1.303      1.373      1.055         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399      0.625       0.86      0.696      0.539      0.627      0.857      0.695      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.04G     0.8159      1.469       1.89     0.9671         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.628      0.862      0.699      0.542      0.628      0.862      0.696       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G     0.8289      1.627      1.148     0.9665         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.624      0.876      0.705      0.546      0.624      0.876      0.703      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      0.809      1.408      1.124     0.9909         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.626      0.878      0.708      0.549      0.626      0.878      0.705      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.04G     0.6094      1.249      1.004     0.9402         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.629      0.881      0.709      0.549      0.629      0.881      0.705      0.516\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         66        399      0.627      0.877      0.708      0.549      0.627      0.877      0.705      0.516\n",
      "                  ripe         66        399      0.627      0.877      0.708      0.549      0.627      0.877      0.705      0.516\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.80it/s]\n",
      "                   all         68        365      0.621       0.83      0.714      0.556      0.619      0.827       0.71      0.526\n",
      "                  ripe         68        365      0.621       0.83      0.714      0.556      0.619      0.827       0.71      0.526\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181/181 [00:00<00:00, 867.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.32G      1.027      2.277      3.282      1.328         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.386      0.842      0.438      0.324      0.391      0.855      0.438      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G     0.8312      1.637      1.615      1.138         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.464      0.807      0.497      0.365      0.458      0.797      0.484      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G     0.7852       1.46      1.319      1.061         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.577      0.842      0.627      0.452      0.568      0.835      0.604      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.7582      1.377       1.09      1.035         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.636       0.89      0.758      0.567      0.634      0.887      0.752      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.6865      1.299     0.9257     0.9981         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.696      0.852      0.791      0.606      0.676      0.882      0.789      0.569\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         66        399      0.697      0.852      0.791      0.606      0.676      0.882      0.789      0.569\n",
      "                  ripe         66        399      0.697      0.852      0.791      0.606      0.676      0.882      0.789      0.569\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.72it/s]\n",
      "                   all         68        365       0.69      0.814       0.79      0.626       0.69      0.814      0.788      0.587\n",
      "                  ripe         68        365       0.69      0.814       0.79      0.626       0.69      0.814      0.788      0.587\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 910.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.11G      0.751      1.253      1.258      1.007         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.669      0.887      0.769      0.586      0.667       0.88      0.766      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.7859      1.544      1.096      1.014         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399       0.67      0.887       0.77      0.586      0.666      0.882      0.766      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.6642      1.272     0.9417     0.9558         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.675      0.892      0.773      0.589      0.671      0.887      0.768      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      0.832      1.556     0.7834      1.021         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.678      0.892      0.773      0.589      0.674      0.887      0.768      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.6643      1.186      1.199     0.9618         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.677      0.874      0.776      0.592       0.68      0.855      0.769      0.553\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.679      0.869      0.776      0.591      0.679      0.855      0.769      0.554\n",
      "                  ripe         66        399      0.679      0.869      0.776      0.591      0.679      0.855      0.769      0.554\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.58it/s]\n",
      "                   all         68        365        0.7      0.827      0.775      0.608      0.698      0.824      0.771      0.571\n",
      "                  ripe         68        365        0.7      0.827      0.775      0.608      0.698      0.824      0.771      0.571\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [00:00<00:00, 878.97it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.33G      0.999      2.166      3.249      1.269         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                   all         66        399      0.435      0.792      0.531      0.418       0.44      0.799      0.532      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G     0.8276      1.618      1.546      1.132        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399       0.57      0.764      0.649      0.511      0.578      0.768      0.653      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.42G     0.7845      1.462      1.154      1.078        205        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399      0.595      0.885      0.718      0.559      0.592       0.88      0.714      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.43G     0.7779      1.405      1.082      1.037         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.88it/s]\n",
      "                   all         66        399      0.654      0.885      0.755      0.575      0.657       0.88      0.747       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.68G     0.7131       1.28      1.007      1.016        164        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.685      0.882      0.784       0.59      0.694      0.879       0.77      0.551\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]\n",
      "                   all         66        399      0.683      0.882      0.784      0.591      0.691       0.88       0.77      0.551\n",
      "                  ripe         66        399      0.683      0.882      0.784      0.591      0.691       0.88       0.77      0.551\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n",
      "                   all         68        365      0.671      0.814      0.746      0.584      0.671      0.814      0.744      0.542\n",
      "                  ripe         68        365      0.671      0.814      0.746      0.584      0.671      0.814      0.744      0.542\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 816.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.03G     0.4476      1.004     0.6648     0.9197        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.653      0.911      0.764      0.577      0.651      0.908      0.756      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G     0.4575     0.9261     0.6407     0.9208         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.656      0.904      0.764      0.578      0.654      0.901      0.756      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.6042       1.11     0.6824      0.984         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.662      0.905      0.767      0.581       0.66      0.902      0.758      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.5219       1.05     0.7686     0.9627         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.667      0.902      0.768      0.582      0.664        0.9       0.76      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.13G      0.632      1.231     0.8498      1.079         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.677      0.882      0.767      0.582      0.675      0.878      0.757      0.544\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]\n",
      "                   all         66        399      0.666      0.902      0.767      0.581      0.664        0.9      0.758      0.544\n",
      "                  ripe         66        399      0.666      0.902      0.767      0.581      0.664        0.9      0.758      0.544\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.73it/s]\n",
      "                   all         68        365      0.649      0.847      0.734      0.572      0.646      0.851      0.733      0.533\n",
      "                  ripe         68        365      0.649      0.847      0.734      0.572      0.646      0.851      0.733      0.533\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 857.87it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.38G     0.9383       2.05      3.102      1.241        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                   all         66        399       0.43      0.803      0.516      0.397      0.433      0.808      0.516      0.373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G      0.859      1.671      1.528      1.142         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "                   all         66        399      0.537      0.769      0.635      0.498      0.542      0.767      0.639       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.7373      1.367      1.156       1.04         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.585      0.892      0.703      0.543      0.625      0.817      0.702      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.7459      1.347          1      1.017         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n",
      "                   all         66        399       0.69      0.813      0.761      0.582      0.692      0.815      0.754      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.8009      1.413     0.9341      1.038         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:11<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n",
      "                   all         66        399      0.675      0.897      0.776      0.593      0.671      0.892      0.769       0.56\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         66        399      0.676      0.899      0.776      0.593      0.672      0.894      0.769      0.559\n",
      "                  ripe         66        399      0.676      0.899      0.776      0.593      0.672      0.894      0.769      0.559\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.48it/s]\n",
      "                   all         68        365       0.71       0.83      0.799      0.636      0.708      0.827      0.795      0.588\n",
      "                  ripe         68        365       0.71       0.83      0.799      0.636      0.708      0.827      0.795      0.588\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 874.16it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_37/train/images/1_20211205_103917_jpg.rf.5424179cbe37666c6b48566dd120847e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.94G     0.9056      1.741      1.442      1.072          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399       0.68       0.87      0.738      0.568       0.68       0.87      0.736       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       8.9G     0.5727      1.135      1.115     0.9784          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.697      0.842      0.748      0.575      0.698       0.84      0.742       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.01G     0.8313       1.59      1.023      1.096          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.676      0.868      0.743      0.573      0.699       0.84      0.738      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         9G     0.8858      1.557       1.02      1.066         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.685      0.832      0.746       0.58      0.694      0.835      0.746      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5         9G      0.865      1.491     0.9771       1.07         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.678      0.855       0.75      0.585      0.691       0.84      0.751       0.55\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]\n",
      "                   all         66        399      0.678      0.855       0.75      0.585      0.693      0.842      0.751       0.55\n",
      "                  ripe         66        399      0.678      0.855       0.75      0.585      0.693      0.842      0.751       0.55\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.74it/s]\n",
      "                   all         68        365      0.703      0.836      0.799      0.632        0.7      0.833      0.792      0.587\n",
      "                  ripe         68        365      0.703      0.836      0.799      0.632        0.7      0.833      0.792      0.587\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 251 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:00<00:00, 855.70it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.5424179cbe37666c6b48566dd120847e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.53G     0.9974      2.072      2.908      1.252         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:14<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.478      0.799      0.583      0.467      0.482      0.807      0.587      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.69G     0.7829      1.486       1.33      1.107         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         66        399       0.61      0.832       0.69      0.539      0.615      0.837      0.694      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.71G     0.7514      1.363      1.105      1.042         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.642       0.88      0.724      0.568      0.653      0.868      0.729      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.62G     0.7171      1.285     0.9079      1.015         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.694      0.863      0.788      0.602      0.718       0.83      0.787      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.62G     0.7194      1.227     0.7977      1.011         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n",
      "                   all         66        399      0.742       0.88      0.821      0.629      0.751       0.87      0.821      0.585\n",
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         66        399      0.742       0.88      0.821      0.629      0.751       0.87      0.821      0.585\n",
      "                  ripe         66        399      0.742       0.88      0.821      0.629      0.751       0.87      0.821      0.585\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.55it/s]\n",
      "                   all         68        365       0.72      0.849      0.838      0.662       0.72      0.849      0.835      0.619\n",
      "                  ripe         68        365       0.72      0.849      0.838      0.662       0.72      0.849      0.835      0.619\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 829.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_38/train/images/1_20211204_100335_jpg.rf.e07ef7271b3a6f5b617d0e16ead502df.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_38/train/images/1_20211204_104004_jpg.rf.16c7458f11a080c35c74f36193508d5a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.88G     0.8648      1.513      1.038      1.089         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.734      0.885      0.811      0.623      0.735      0.875      0.811       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         9G      0.908      1.583      1.089      1.136         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n",
      "                   all         66        399      0.755      0.872      0.818      0.638      0.763       0.87      0.818      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5         9G     0.7412      1.346     0.9217      1.099          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n",
      "                   all         66        399      0.746      0.865      0.815      0.641      0.752      0.873      0.816      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         9G      0.827      1.353      1.392      1.018          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n",
      "                   all         66        399      0.764       0.82      0.826      0.643      0.771      0.827      0.829        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5         9G     0.7284      1.223     0.8254      1.033          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399       0.75      0.832      0.822      0.637      0.778      0.818      0.823      0.592\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         66        399      0.764       0.82      0.826      0.643      0.771      0.827      0.829      0.599\n",
      "                  ripe         66        399      0.764       0.82      0.826      0.643      0.771      0.827      0.829      0.599\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.74it/s]\n",
      "                   all         68        365      0.748      0.805       0.82      0.651      0.748      0.805      0.817      0.603\n",
      "                  ripe         68        365      0.748      0.805       0.82      0.651      0.748      0.805      0.817      0.603\n",
      "Speed: 0.3ms preprocess, 14.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301/301 [00:00<00:00, 852.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.e07ef7271b3a6f5b617d0e16ead502df.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.16c7458f11a080c35c74f36193508d5a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.5424179cbe37666c6b48566dd120847e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G     0.9347      1.967      2.671      1.215        140        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:16<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         66        399      0.451      0.845      0.509      0.385      0.455      0.847      0.508      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.69G     0.7849      1.445      1.318      1.069        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:16<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.595      0.794      0.715      0.569      0.615      0.784      0.718       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.72G     0.7652      1.424      1.003       1.04         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:16<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
      "                   all         66        399      0.704      0.842       0.78      0.602      0.706      0.845       0.77      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.59G     0.7456      1.307     0.9159      1.022        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:16<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
      "                   all         66        399      0.711      0.869      0.819      0.628      0.711      0.865      0.813      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.61G      0.732      1.294     0.8029      1.003         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:16<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n",
      "                   all         66        399      0.785      0.852      0.823       0.64      0.781      0.857      0.821      0.598\n",
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]\n",
      "                   all         66        399      0.784      0.852      0.823       0.64      0.781      0.857      0.821      0.598\n",
      "                  ripe         66        399      0.784      0.852      0.823       0.64      0.781      0.857      0.821      0.598\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.61it/s]\n",
      "                   all         68        365      0.684      0.858      0.809      0.644      0.684      0.858      0.808      0.599\n",
      "                  ripe         68        365      0.684      0.858      0.809      0.644      0.684      0.858      0.808      0.599\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 807.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_39/train/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_39/train/images/1_20211204_104004_jpg.rf.0bd3f7118ef676a8c09bdaa922a527bf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.09G     0.8217      1.396     0.9077      1.018         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         66        399      0.758      0.862      0.836       0.65      0.759      0.865      0.831      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.01G     0.9476       1.67     0.8824      1.113         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n",
      "                   all         66        399      0.759      0.887      0.843      0.657      0.759      0.887      0.835      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.02G     0.9277      1.599     0.8729      1.082         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]\n",
      "                   all         66        399      0.759      0.907      0.868      0.678      0.783      0.879      0.863       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         9G     0.9022      1.521     0.7987       1.05         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n",
      "                   all         66        399       0.79      0.887      0.877      0.677      0.802      0.867      0.872      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.04G     0.7778      1.361     0.8686      1.012         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.768       0.91      0.874      0.677      0.761      0.907      0.864      0.633\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.767      0.912      0.874      0.677      0.763      0.907      0.864      0.633\n",
      "                  ripe         66        399      0.767      0.912      0.874      0.677      0.763      0.907      0.864      0.633\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.76it/s]\n",
      "                   all         68        365      0.793      0.784      0.844       0.66      0.793      0.784      0.843      0.613\n",
      "                  ripe         68        365      0.793      0.784      0.844       0.66      0.793      0.784      0.843      0.613\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 401 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401/401 [00:00<00:00, 875.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.e07ef7271b3a6f5b617d0e16ead502df.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.0bd3f7118ef676a8c09bdaa922a527bf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.16c7458f11a080c35c74f36193508d5a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.5424179cbe37666c6b48566dd120847e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.64G     0.8796      1.784      2.325      1.174          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:22<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                   all         66        399      0.546      0.742      0.611      0.486      0.548      0.739      0.618      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.77G     0.7656      1.398      1.191      1.046          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:22<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.588      0.892      0.599      0.436      0.585      0.887       0.59      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G     0.8421      1.501          1      1.051         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:22<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n",
      "                   all         66        399      0.735      0.852      0.797      0.612      0.729      0.865      0.796      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.51G     0.8753      1.459      1.036      1.049          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:21<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n",
      "                   all         66        399      0.755      0.875       0.84      0.655      0.756       0.85      0.834      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G     0.7673      1.293     0.8984      0.999         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:22<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.763       0.84      0.836       0.66      0.763      0.845      0.841      0.603\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]\n",
      "                   all         66        399      0.754      0.875       0.84      0.655      0.757       0.85      0.834      0.616\n",
      "                  ripe         66        399      0.754      0.875       0.84      0.655      0.757       0.85      0.834      0.616\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.79it/s]\n",
      "                   all         68        365      0.698      0.874      0.829      0.658      0.701      0.868      0.828      0.608\n",
      "                  ripe         68        365      0.698      0.874      0.829      0.658      0.701      0.868      0.828      0.608\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 797.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.06G     0.9914      1.598       1.16      1.083         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.754      0.825      0.839      0.661      0.768       0.82      0.845      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.12G      0.796      1.333      0.848      1.021         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
      "                   all         66        399      0.794       0.89      0.885      0.703      0.793      0.886      0.888      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.01G     0.8219      1.387     0.7751      1.046         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.804      0.875      0.883      0.703      0.806      0.877      0.883       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.99G     0.9266      1.499     0.7447      1.048         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]\n",
      "                   all         66        399      0.799       0.88      0.872      0.695      0.808       0.88      0.873      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.03G     0.8493      1.401     0.7338       1.02         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.791      0.902      0.882      0.705      0.791      0.902      0.884       0.66\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]\n",
      "                   all         66        399      0.791      0.902      0.882      0.704      0.791      0.902      0.884       0.66\n",
      "                  ripe         66        399      0.791      0.902      0.882      0.704      0.791      0.902      0.884       0.66\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.65it/s]\n",
      "                   all         68        365      0.782      0.885      0.892      0.716      0.776      0.888      0.889      0.671\n",
      "                  ripe         68        365      0.782      0.885      0.892      0.716      0.776      0.888      0.889      0.671\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_41/train/labels... 110 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [00:00<00:00, 832.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_41/train/images/1_20211204_100335_jpg.rf.6863e47f53970092bbe2cf450d32f6d1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_41/train/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_41/train/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_2_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.82G     0.7331      1.309     0.8188      1.004        157        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         66        399      0.759        0.9      0.868      0.686      0.761      0.902      0.869      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.98G     0.8288      1.385     0.7854      1.016         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.782      0.861      0.864      0.662      0.777      0.856      0.859      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.99G     0.7865      1.334     0.7396      1.008        150        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         66        399      0.816      0.837       0.89      0.697      0.818       0.84      0.889      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.99G      0.774      1.315     0.7305      1.026        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                   all         66        399      0.828      0.842      0.888      0.701      0.832      0.845      0.889      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.01G     0.7593      1.281     0.7061     0.9935        173        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.847      0.832      0.901      0.705      0.842       0.83      0.894      0.659\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.43it/s]\n",
      "                   all         66        399      0.846      0.832      0.901      0.704      0.843       0.83      0.893       0.66\n",
      "                  ripe         66        399      0.846      0.832      0.901      0.704      0.843       0.83      0.893       0.66\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.81it/s]\n",
      "                   all         68        365      0.783      0.858      0.887      0.715       0.78      0.855       0.88      0.669\n",
      "                  ripe         68        365      0.783      0.858      0.887      0.715       0.78      0.855       0.88      0.669\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 611 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 611/611 [00:00<00:00, 855.70it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.6863e47f53970092bbe2cf450d32f6d1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.e07ef7271b3a6f5b617d0e16ead502df.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.0bd3f7118ef676a8c09bdaa922a527bf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.16c7458f11a080c35c74f36193508d5a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.5424179cbe37666c6b48566dd120847e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/labels.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_2/images/1_20211204_100335_jpg.rf.f575eff61c78628eae9fc651d66fd029.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.42G     0.9004      1.774      1.965      1.164         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:34<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399       0.67      0.767       0.72      0.572      0.666      0.769      0.718      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.59G     0.8333      1.491      1.055      1.046         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:33<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         66        399      0.734      0.877      0.795      0.614      0.735      0.877      0.792      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.63G     0.7897      1.344     0.8923      1.013         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:33<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n",
      "                   all         66        399      0.778      0.872      0.863      0.672      0.783      0.875      0.859      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G      0.826        1.4     0.8022      1.026         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:33<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n",
      "                   all         66        399      0.831      0.875      0.898       0.68      0.804      0.895      0.893      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.7617      1.274     0.7363      1.003         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:33<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]\n",
      "                   all         66        399      0.859      0.914      0.918      0.716      0.854       0.91      0.909      0.677\n",
      "\n",
      "5 epochs completed in 0.054 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]\n",
      "                   all         66        399      0.859      0.913      0.917      0.717      0.854       0.91      0.909      0.678\n",
      "                  ripe         66        399      0.859      0.913      0.917      0.717      0.854       0.91      0.909      0.678\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211204_104004_jpg.rf.d73e945cec81409862cb3eb363729ecd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.593d08b75b7e29c980d06857840d1657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_2/images/1_20211205_103917_jpg.rf.78fc52361a683340c51c0f304426f5fc.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.82it/s]\n",
      "                   all         68        365      0.755      0.896      0.874      0.695      0.757      0.899      0.874      0.651\n",
      "                  ripe         68        365      0.755      0.896      0.874      0.695      0.757      0.899      0.874      0.651\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 2: \n",
      " defaultdict(<class 'list'>, {0: [0.06428346978561376, 0.10510348116731151, 0.06915527417968158], 1: [0.06502848810070382, 0.10573590834270281, 0.06947555435343768], 2: [0.06632467960400874, 0.10660761512309457, 0.07089794722022365], 3: [0.06539158486120906, 0.10651148381969418, 0.06959408202275562], 4: [0.06532804116017743, 0.10633702587989917, 0.06971757742264001], 5: [0.06549767923507557, 0.10610799058186675, 0.07022049114254324], 6: [0.06517626812518376, 0.1057627858268293, 0.0697264710669174], 7: [0.08474269817241362, 0.13359707493486137, 0.09120157139232357], 8: [0.0942463750626468, 0.1483007595362178, 0.10088717998155818], 9: [0.09449175712895354, 0.15063746659126767, 0.10112459152627183], 10: [0.08994366335342552, 0.14428459896419682, 0.09819226280580215], 11: [0.10194865055227476, 0.16059114132108818, 0.10943497968036872], 12: [0.22037979601733643, 0.33304178977935844, 0.23913101389296731], 13: [0.20200814728661576, 0.3062535170314191, 0.2175274064763726], 14: [0.26140669218442936, 0.381255923820467, 0.2854057104782408], 15: [0.34324609918390303, 0.46643797825076605, 0.38736972710902284], 16: [0.35333169072476983, 0.4803972069824206, 0.4001741727259559], 17: [0.36272604071330405, 0.4923577099401724, 0.41205166299055607], 18: [0.37542046897228243, 0.5074410484956973, 0.4232987390005021], 19: [0.38713919584943024, 0.5242494087050363, 0.43978399855231026], 20: [0.38308302062805555, 0.5187878563936148, 0.43523930103241415], 21: [0.4095248117936444, 0.5702021744576211, 0.4523384584217697], 22: [0.41267081300377706, 0.5606567631942765, 0.46738971314206124], 23: [0.4327995667407517, 0.577609905270944, 0.48607755203925274], 24: [0.4320527561964532, 0.5794138814553911, 0.49027624799519676], 25: [0.4550839947584211, 0.6223452506164999, 0.5103340599937674], 26: [0.45682972296999524, 0.6238444890356337, 0.5018408145109254], 27: [0.4951385880608309, 0.6708755905596946, 0.549702889925845], 28: [0.4991031245174618, 0.6809113828305362, 0.5518216533158236], 29: [0.5159468708182532, 0.6951936557724256, 0.5610453232238022], 30: [0.5290186606513547, 0.7260166184996313, 0.5890699330016917], 31: [0.59476522642522, 0.8013761816598605, 0.6705765386868654], 32: [0.5601249432029896, 0.7552714826597982, 0.6207887604720157], 33: [0.5873255966945193, 0.7877533675874974, 0.6576067374963497], 34: [0.5419801414984413, 0.7444393518824233, 0.6040143534631943], 35: [0.5880173166089369, 0.7948186162671224, 0.6580496667592464], 36: [0.6186688862487523, 0.8351874102432519, 0.7004530673783985], 37: [0.5985845977944334, 0.808199900274875, 0.6680194176258925], 38: [0.6084115905271821, 0.8279458534635777, 0.6784006640478818], 39: [0.6711499413427768, 0.8887769807140071, 0.7489788532142728], 40: [0.6514792458660785, 0.8736793167568638, 0.7540814674753213]})\n",
      "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 2: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 611]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('2', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d00d3c",
   "metadata": {
    "papermill": {
     "duration": 1.023917,
     "end_time": "2024-01-16T12:27:27.811563",
     "exception": false,
     "start_time": "2024-01-16T12:27:26.787646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ Ð¸ Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce79c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 1.03675,
     "end_time": "2024-01-16T12:27:29.940437",
     "exception": false,
     "start_time": "2024-01-16T12:27:28.903687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05169f16",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 1.028886,
     "end_time": "2024-01-16T12:27:32.079429",
     "exception": false,
     "start_time": "2024-01-16T12:27:31.050543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83982d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 1.058212,
     "end_time": "2024-01-16T12:27:34.253829",
     "exception": false,
     "start_time": "2024-01-16T12:27:33.195617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d19042",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 1.025642,
     "end_time": "2024-01-16T12:27:36.301663",
     "exception": false,
     "start_time": "2024-01-16T12:27:35.276021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e84363",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 1.027217,
     "end_time": "2024-01-16T12:27:38.419775",
     "exception": false,
     "start_time": "2024-01-16T12:27:37.392558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8829.781223,
   "end_time": "2024-01-16T12:27:46.545024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-16T10:00:36.763801",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
