{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac85b046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:39:05.190416Z",
     "iopub.status.busy": "2024-05-14T11:39:05.189587Z",
     "iopub.status.idle": "2024-05-14T11:40:09.932339Z",
     "shell.execute_reply": "2024-05-14T11:40:09.931324Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 64.752422,
     "end_time": "2024-05-14T11:40:09.934734",
     "exception": false,
     "start_time": "2024-05-14T11:39:05.182312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.20.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\r\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\r\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.9\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.9:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.9\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\r\n",
      "--2024-05-14 11:40:02--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.121.3\r\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240514T114002Z&X-Amz-Expires=300&X-Amz-Signature=06d33cf9c78a0626bf436429686e27602dc0ee01ef972ca085f3af2b62433e91&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-05-14 11:40:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240514T114002Z&X-Amz-Expires=300&X-Amz-Signature=06d33cf9c78a0626bf436429686e27602dc0ee01ef972ca085f3af2b62433e91&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   269MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-05-14 11:40:03 (269 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "# rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "# project = rf.workspace(\"kafrelsheikh-university\").project(\"strawberry_diseases\")\n",
    "# dataset = project.version(2).download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e12c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T22:40:46.477540Z",
     "iopub.status.busy": "2024-05-11T22:40:46.476591Z",
     "iopub.status.idle": "2024-05-11T22:40:50.787038Z",
     "shell.execute_reply": "2024-05-11T22:40:50.785701Z",
     "shell.execute_reply.started": "2024-05-11T22:40:46.477505Z"
    },
    "papermill": {
     "duration": 0.007477,
     "end_time": "2024-05-14T11:40:09.950428",
     "exception": false,
     "start_time": "2024-05-14T11:40:09.942951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! rm -rf /kaggle/working/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff068af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:09.966859Z",
     "iopub.status.busy": "2024-05-14T11:40:09.966200Z",
     "iopub.status.idle": "2024-05-14T11:40:14.187865Z",
     "shell.execute_reply": "2024-05-14T11:40:14.186931Z"
    },
    "papermill": {
     "duration": 4.232623,
     "end_time": "2024-05-14T11:40:14.190423",
     "exception": false,
     "start_time": "2024-05-14T11:40:09.957800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/dataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copytree(\"/kaggle/input/isaid-class-9\",\"/kaggle/working/dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea932724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T16:37:42.950780Z",
     "iopub.status.busy": "2024-05-12T16:37:42.950402Z",
     "iopub.status.idle": "2024-05-12T16:37:44.070466Z",
     "shell.execute_reply": "2024-05-12T16:37:44.069165Z",
     "shell.execute_reply.started": "2024-05-12T16:37:42.950747Z"
    },
    "papermill": {
     "duration": 0.00768,
     "end_time": "2024-05-14T11:40:14.206736",
     "exception": false,
     "start_time": "2024-05-14T11:40:14.199056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! rm -rf /kaggle/working/dataset/isaid_class_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742e7f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T22:42:43.683356Z",
     "iopub.status.busy": "2024-05-11T22:42:43.682974Z",
     "iopub.status.idle": "2024-05-11T22:42:44.654950Z",
     "shell.execute_reply": "2024-05-11T22:42:44.653727Z",
     "shell.execute_reply.started": "2024-05-11T22:42:43.683322Z"
    },
    "papermill": {
     "duration": 0.007575,
     "end_time": "2024-05-14T11:40:14.221981",
     "exception": false,
     "start_time": "2024-05-14T11:40:14.214406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! mv /kaggle/working/dataset/isaid_class_0/train/data.yaml /kaggle/working/dataset/isaid_class_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92678e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:14.238269Z",
     "iopub.status.busy": "2024-05-14T11:40:14.237961Z",
     "iopub.status.idle": "2024-05-14T11:40:37.509550Z",
     "shell.execute_reply": "2024-05-14T11:40:37.508416Z"
    },
    "papermill": {
     "duration": 23.282474,
     "end_time": "2024-05-14T11:40:37.512006",
     "exception": false,
     "start_time": "2024-05-14T11:40:14.229532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.1.2\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb77296e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:37.530239Z",
     "iopub.status.busy": "2024-05-14T11:40:37.529566Z",
     "iopub.status.idle": "2024-05-14T11:40:37.553724Z",
     "shell.execute_reply": "2024-05-14T11:40:37.552674Z"
    },
    "papermill": {
     "duration": 0.035312,
     "end_time": "2024-05-14T11:40:37.555717",
     "exception": false,
     "start_time": "2024-05-14T11:40:37.520405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/dataset/isaid_class_9\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/dataset/isaid_class_9\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3901c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:37.574024Z",
     "iopub.status.busy": "2024-05-14T11:40:37.573760Z",
     "iopub.status.idle": "2024-05-14T11:40:37.711697Z",
     "shell.execute_reply": "2024-05-14T11:40:37.711004Z"
    },
    "papermill": {
     "duration": 0.149682,
     "end_time": "2024-05-14T11:40:37.713578",
     "exception": false,
     "start_time": "2024-05-14T11:40:37.563896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float, learn_cls: str = None):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read().strip()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        print(text)\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        if learn_cls == None:\n",
    "            for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "                num_files = len(pathes)\n",
    "                num_to_del = num_files*(1-keep_perc)\n",
    "                for i, file_path in enumerate(pathes.copy()):\n",
    "                    if i+1 >= num_to_del:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    try:\n",
    "                        Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                        file_path.unlink()\n",
    "                    except OSError as e:\n",
    "                        # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                        pass\n",
    "                    classes[cls].remove(file_path)\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            pathes = classes[cls]\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('png')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        if learn_cls == None:\n",
    "            for cls in classes.keys():\n",
    "    #             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "    #              # Корректируем data.yaml файл\n",
    "    #             yaml = ruamel.yaml.YAML()\n",
    "    #             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "    #                 data = yaml.load(fp)\n",
    "    #                 data['names'] = [data['names'][int(cls)]]\n",
    "    #                 data['nc'] = 1\n",
    "    #                 fp.truncate(0)\n",
    "    #                 fp.seek(0)\n",
    "    #                 yaml.dump(data, fp)\n",
    "                os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "                os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "                os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        if learn_cls == None:\n",
    "            for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "                num_files = len(class_copy[cls])\n",
    "                num_to_mv_train = int(num_files * self.train_perc)\n",
    "                num_to_mv_test = int(num_files * self.test_perc)\n",
    "                num_to_mv_val = int(num_files * self.val_perc)\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(pathes.copy()):\n",
    "                    if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                        temp_dict_name = f\"valid_{cls}\"\n",
    "                    elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                        temp_dict_name = f\"test_{cls}\"\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                    Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    if temp_dict_name != \"train\":\n",
    "                        # remove another classes in label file\n",
    "                        orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                        new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                        with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                            print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "                dir_path = f\"valid_{cls}/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"test_{cls}/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('png')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False, learn_cls: str = None) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read().strip()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        if learn_cls == None:\n",
    "            for cls in classes.keys():\n",
    "                print(f\"Класс {cls}\")\n",
    "                total_num = len(classes[cls])\n",
    "                print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "                if fib_flag == True:\n",
    "                    n = total_num\n",
    "                    train_list = self.__train_set_of(n)\n",
    "                    files_in_folder = []\n",
    "                    for i in range(len(train_list)):\n",
    "                        if i == 0:\n",
    "                            files_in_folder.append(train_list[i])\n",
    "                            continue\n",
    "                        files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                    print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                    cls_tl_dict[cls] = train_list\n",
    "                    cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "                if fib_flag == True:\n",
    "                    self.num_folders = len(files_in_folder)\n",
    "                    print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "                else:\n",
    "                    self.num_folders = 1 / piece_perc\n",
    "                for folder in range(int(self.num_folders)):\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "\n",
    "                # Распределяем данные по директориям  \n",
    "                class_copy = copy.deepcopy(classes)\n",
    "                for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                    folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                    num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                    print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                    # print(num_files, num_to_mv, len(pathes))\n",
    "                    temp_dict_name = \"train\"\n",
    "                    for i, file_path in enumerate(classes[cls].copy()):\n",
    "                        if i+1 > num_to_mv_train:\n",
    "                            break\n",
    "                        f = file_path.name.split('.')[:-1]\n",
    "                        f.append('png')\n",
    "                        shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                        Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                        shutil.copyfile(file_path,\n",
    "                                        Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                        # remove another classes in label file\n",
    "                        orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                        new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                        with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                            print(*new_lines, sep='\\n', file=fp)\n",
    "                        classes[cls].remove(file_path)\n",
    "                for folder in range(int(self.num_folders)):\n",
    "                    dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                    dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "\n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        shutil.rmtree(\"train\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc,learn_cls)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag, learn_cls)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c91bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:37.730329Z",
     "iopub.status.busy": "2024-05-14T11:40:37.730028Z",
     "iopub.status.idle": "2024-05-14T13:41:54.067608Z",
     "shell.execute_reply": "2024-05-14T13:41:54.066637Z"
    },
    "papermill": {
     "duration": 7276.348267,
     "end_time": "2024-05-14T13:41:54.069682",
     "exception": false,
     "start_time": "2024-05-14T11:40:37.721415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_9/images 27\n",
      "test_9/images 28\n",
      "train/labels 216 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 9 содержит 216 объекта(-ов)\n",
      " Класс 13 содержит 117 объекта(-ов)\n",
      " Класс 0 содержит 6 объекта(-ов)\n",
      " Класс 14 содержит 4 объекта(-ов)\n",
      " Класс 8 содержит 93 объекта(-ов)\n",
      " Класс 7 содержит 56 объекта(-ов)\n",
      " Класс 10 содержит 1 объекта(-ов)\n",
      " Класс 5 содержит 1 объекта(-ов)\n",
      " Класс 12 содержит 1 объекта(-ов)\n",
      " Класс 1 содержит 4 объекта(-ов)\n",
      "\n",
      "Класс 9\n",
      "\tКол-во train класса 9: 216\n",
      "\tКоличество данных (train) на каждой итерации класса 9: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 216]\n",
      "\tКол-во директорий для класса 9: 37 \n",
      "\tnum_to_mv_train 2, folder 0, cls 9\n",
      "\tnum_to_mv_train 2, folder 1, cls 9\n",
      "\tnum_to_mv_train 2, folder 2, cls 9\n",
      "\tnum_to_mv_train 2, folder 3, cls 9\n",
      "\tnum_to_mv_train 2, folder 4, cls 9\n",
      "\tnum_to_mv_train 3, folder 5, cls 9\n",
      "\tnum_to_mv_train 3, folder 6, cls 9\n",
      "\tnum_to_mv_train 3, folder 7, cls 9\n",
      "\tnum_to_mv_train 3, folder 8, cls 9\n",
      "\tnum_to_mv_train 3, folder 9, cls 9\n",
      "\tnum_to_mv_train 3, folder 10, cls 9\n",
      "\tnum_to_mv_train 3, folder 11, cls 9\n",
      "\tnum_to_mv_train 5, folder 12, cls 9\n",
      "\tnum_to_mv_train 5, folder 13, cls 9\n",
      "\tnum_to_mv_train 5, folder 14, cls 9\n",
      "\tnum_to_mv_train 5, folder 15, cls 9\n",
      "\tnum_to_mv_train 5, folder 16, cls 9\n",
      "\tnum_to_mv_train 5, folder 17, cls 9\n",
      "\tnum_to_mv_train 5, folder 18, cls 9\n",
      "\tnum_to_mv_train 5, folder 19, cls 9\n",
      "\tnum_to_mv_train 5, folder 20, cls 9\n",
      "\tnum_to_mv_train 5, folder 21, cls 9\n",
      "\tnum_to_mv_train 5, folder 22, cls 9\n",
      "\tnum_to_mv_train 5, folder 23, cls 9\n",
      "\tnum_to_mv_train 5, folder 24, cls 9\n",
      "\tnum_to_mv_train 5, folder 25, cls 9\n",
      "\tnum_to_mv_train 10, folder 26, cls 9\n",
      "\tnum_to_mv_train 10, folder 27, cls 9\n",
      "\tnum_to_mv_train 10, folder 28, cls 9\n",
      "\tnum_to_mv_train 10, folder 29, cls 9\n",
      "\tnum_to_mv_train 10, folder 30, cls 9\n",
      "\tnum_to_mv_train 10, folder 31, cls 9\n",
      "\tnum_to_mv_train 10, folder 32, cls 9\n",
      "\tnum_to_mv_train 10, folder 33, cls 9\n",
      "\tnum_to_mv_train 10, folder 34, cls 9\n",
      "\tnum_to_mv_train 10, folder 35, cls 9\n",
      "\tnum_to_mv_train 15, folder 36, cls 9\n",
      "temp_9_1/train/labels 2\n",
      "temp_9_1/train/images 2 \n",
      "\n",
      "temp_9_2/train/labels 2\n",
      "temp_9_2/train/images 2 \n",
      "\n",
      "temp_9_3/train/labels 2\n",
      "temp_9_3/train/images 2 \n",
      "\n",
      "temp_9_4/train/labels 2\n",
      "temp_9_4/train/images 2 \n",
      "\n",
      "temp_9_5/train/labels 2\n",
      "temp_9_5/train/images 2 \n",
      "\n",
      "temp_9_6/train/labels 3\n",
      "temp_9_6/train/images 3 \n",
      "\n",
      "temp_9_7/train/labels 3\n",
      "temp_9_7/train/images 3 \n",
      "\n",
      "temp_9_8/train/labels 3\n",
      "temp_9_8/train/images 3 \n",
      "\n",
      "temp_9_9/train/labels 3\n",
      "temp_9_9/train/images 3 \n",
      "\n",
      "temp_9_10/train/labels 3\n",
      "temp_9_10/train/images 3 \n",
      "\n",
      "temp_9_11/train/labels 3\n",
      "temp_9_11/train/images 3 \n",
      "\n",
      "temp_9_12/train/labels 3\n",
      "temp_9_12/train/images 3 \n",
      "\n",
      "temp_9_13/train/labels 5\n",
      "temp_9_13/train/images 5 \n",
      "\n",
      "temp_9_14/train/labels 5\n",
      "temp_9_14/train/images 5 \n",
      "\n",
      "temp_9_15/train/labels 5\n",
      "temp_9_15/train/images 5 \n",
      "\n",
      "temp_9_16/train/labels 5\n",
      "temp_9_16/train/images 5 \n",
      "\n",
      "temp_9_17/train/labels 5\n",
      "temp_9_17/train/images 5 \n",
      "\n",
      "temp_9_18/train/labels 5\n",
      "temp_9_18/train/images 5 \n",
      "\n",
      "temp_9_19/train/labels 5\n",
      "temp_9_19/train/images 5 \n",
      "\n",
      "temp_9_20/train/labels 5\n",
      "temp_9_20/train/images 5 \n",
      "\n",
      "temp_9_21/train/labels 5\n",
      "temp_9_21/train/images 5 \n",
      "\n",
      "temp_9_22/train/labels 5\n",
      "temp_9_22/train/images 5 \n",
      "\n",
      "temp_9_23/train/labels 5\n",
      "temp_9_23/train/images 5 \n",
      "\n",
      "temp_9_24/train/labels 5\n",
      "temp_9_24/train/images 5 \n",
      "\n",
      "temp_9_25/train/labels 5\n",
      "temp_9_25/train/images 5 \n",
      "\n",
      "temp_9_26/train/labels 5\n",
      "temp_9_26/train/images 5 \n",
      "\n",
      "temp_9_27/train/labels 10\n",
      "temp_9_27/train/images 10 \n",
      "\n",
      "temp_9_28/train/labels 10\n",
      "temp_9_28/train/images 10 \n",
      "\n",
      "temp_9_29/train/labels 10\n",
      "temp_9_29/train/images 10 \n",
      "\n",
      "temp_9_30/train/labels 10\n",
      "temp_9_30/train/images 10 \n",
      "\n",
      "temp_9_31/train/labels 10\n",
      "temp_9_31/train/images 10 \n",
      "\n",
      "temp_9_32/train/labels 10\n",
      "temp_9_32/train/images 10 \n",
      "\n",
      "temp_9_33/train/labels 10\n",
      "temp_9_33/train/images 10 \n",
      "\n",
      "temp_9_34/train/labels 10\n",
      "temp_9_34/train/images 10 \n",
      "\n",
      "temp_9_35/train/labels 10\n",
      "temp_9_35/train/images 10 \n",
      "\n",
      "temp_9_36/train/labels 10\n",
      "temp_9_36/train/images 10 \n",
      "\n",
      "temp_9_37/train/labels 15\n",
      "temp_9_37/train/images 15 \n",
      "\n",
      "/kaggle/working/dataset/isaid_class_9/data.yaml\n",
      "defaultdict(<class 'int'>, {'9': 37}) defaultdict(<class 'list'>, {'9': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 216]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 41.6MB/s]\n",
      "2024-05-14 11:40:45.572095: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-14 11:40:45.572225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-14 11:40:45.699795: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 167MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 111.33it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<00:00, 174.61it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.28G       2.79      3.025      6.768      1.191         37        640: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         27        107      0.236     0.0841     0.0769     0.0403      0.054      0.271      0.055     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.37G       3.02      3.171      5.748      1.633         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.255     0.0841     0.0761     0.0399     0.0527      0.252     0.0556     0.0202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.38G      3.096      1.941      5.102      1.412         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107       0.27     0.0748     0.0757     0.0399      0.202     0.0561     0.0535     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.34G      2.605      3.133      6.644      1.383         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.272     0.0748     0.0731     0.0391     0.0493      0.224     0.0544     0.0173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.35G      2.851      3.287      5.926      1.232         31        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.272     0.0748     0.0708     0.0386      0.201     0.0561     0.0513     0.0163\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27        107      0.235     0.0841     0.0767     0.0401     0.0537      0.271     0.0549     0.0205\n",
      "            Helicopter         27        107      0.235     0.0841     0.0767     0.0401     0.0537      0.271     0.0549     0.0205\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 141.74it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/test_9/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263     0.0803      0.141     0.0589     0.0279     0.0651      0.114     0.0397     0.0136\n",
      "            Helicopter         28        263     0.0803      0.141     0.0589     0.0279     0.0651      0.114     0.0397     0.0136\n",
      "Speed: 0.2ms preprocess, 16.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 240.93it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.14G      1.907      3.825      4.003      1.748         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         27        107      0.185     0.0561     0.0531     0.0287      0.156     0.0467     0.0428     0.0141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.29G      1.531      3.395       4.93      1.882          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.188     0.0561     0.0561     0.0304      0.157     0.0467     0.0453     0.0149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.2G      1.737      3.926      4.888      2.049          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.183     0.0561     0.0577     0.0303      0.152     0.0467     0.0431      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.31G      2.288      4.217      5.197       1.99          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.19     0.0561     0.0581     0.0308       0.16     0.0467     0.0447     0.0156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.29G      1.526       3.56      5.186      1.978          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.212     0.0561     0.0608     0.0328       0.18     0.0467     0.0464     0.0165\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.214     0.0561     0.0607     0.0328      0.179     0.0467     0.0464     0.0164\n",
      "            Helicopter         27        107      0.214     0.0561     0.0607     0.0328      0.179     0.0467     0.0464     0.0164\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n",
      "                   all         28        263     0.0654      0.144     0.0507     0.0227     0.0448     0.0989     0.0306      0.012\n",
      "            Helicopter         28        263     0.0654      0.144     0.0507     0.0227     0.0448     0.0989     0.0306      0.012\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 201.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.09G      3.068      3.662      6.441      1.909         44        640: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         27        107     0.0651      0.336     0.0768     0.0394     0.0542       0.28     0.0565     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.78G      2.164      3.144      6.127      1.707         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.241     0.0748     0.0779     0.0404     0.0545      0.271     0.0559     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.79G      2.573      3.077      6.619      1.535         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.241     0.0841     0.0772     0.0401     0.0504      0.243     0.0546      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.59G      2.192      2.807      5.284      1.391         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107       0.22     0.0935     0.0767     0.0395     0.0497      0.234     0.0552     0.0187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.74G       2.55      2.919      5.355      1.624         40        640: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.286     0.0748     0.0742     0.0382      0.214     0.0561     0.0537     0.0175\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27        107     0.0659      0.327      0.078     0.0406     0.0546      0.271     0.0567     0.0208\n",
      "            Helicopter         27        107     0.0659      0.327      0.078     0.0406     0.0546      0.271     0.0567     0.0208\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263     0.0852      0.148     0.0617     0.0289     0.0655      0.114     0.0398     0.0135\n",
      "            Helicopter         28        263     0.0852      0.148     0.0617     0.0289     0.0655      0.114     0.0398     0.0135\n",
      "Speed: 0.3ms preprocess, 15.6ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 196.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.36G      2.214      6.131      5.296       1.71         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.182     0.0561      0.055     0.0298      0.154     0.0467     0.0417     0.0143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.31G      2.512      6.843      6.028      2.166          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.214     0.0654     0.0652     0.0335       0.16     0.0467     0.0459     0.0162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.33G      2.369       6.59      5.604      2.088          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.189     0.0561     0.0676     0.0375       0.16     0.0467     0.0526     0.0176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.36G      2.191       5.66      5.251      1.764         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.261     0.0748     0.0724     0.0369      0.169     0.0467     0.0532     0.0179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.42G      2.546      7.168      5.269      1.814         20        640: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107       0.25     0.0748     0.0627     0.0335      0.206     0.0561      0.047     0.0168\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.263     0.0748     0.0724     0.0369      0.169     0.0467     0.0532      0.018\n",
      "            Helicopter         27        107      0.263     0.0748     0.0724     0.0369      0.169     0.0467     0.0532      0.018\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         28        263     0.0594      0.122     0.0434     0.0197     0.0371      0.076     0.0249    0.00842\n",
      "            Helicopter         28        263     0.0594      0.122     0.0434     0.0197     0.0371      0.076     0.0249    0.00842\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 144.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.81G      2.389      4.834      5.521      1.962         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.233     0.0841     0.0758     0.0394     0.0516      0.262     0.0563     0.0205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.06G      2.066      2.864      6.886      1.307         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.222     0.0959     0.0784     0.0404     0.0545      0.271     0.0589     0.0201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.79G      2.766      3.358      5.278      1.819         41        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.203      0.103     0.0797     0.0418     0.0539      0.262     0.0594     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       4.8G      2.349      4.452      4.998      1.918         34        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.202      0.112     0.0774     0.0406     0.0492      0.234     0.0565     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       4.9G      2.515      5.305      5.307      1.851         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.126      0.103     0.0802     0.0424     0.0512      0.234     0.0592       0.02\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27        107      0.136      0.103     0.0791     0.0421     0.0495      0.224     0.0581     0.0196\n",
      "            Helicopter         27        107      0.136      0.103     0.0791     0.0421     0.0495      0.224     0.0581     0.0196\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         28        263     0.0898      0.144     0.0601     0.0294     0.0709      0.114     0.0411     0.0122\n",
      "            Helicopter         28        263     0.0898      0.144     0.0601     0.0294     0.0709      0.114     0.0411     0.0122\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 8.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 240.64it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      1.837      2.892      4.191      1.164         38        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.193     0.0654     0.0588     0.0302      0.143     0.0467     0.0438     0.0141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.35G      1.569      3.405      4.129      1.319          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.197     0.0654     0.0617     0.0314      0.142     0.0467     0.0447     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.35G      1.827      4.161      4.517      1.359         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.187     0.0654     0.0616     0.0315      0.135     0.0467     0.0473     0.0155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.44G      1.869      3.632      4.194      1.156         27        640: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.202     0.0748     0.0598     0.0308      0.138     0.0467     0.0456     0.0152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.33G      1.789      4.096      4.627      1.438          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.198     0.0748     0.0571     0.0282       0.14     0.0467     0.0432     0.0145\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27        107      0.186     0.0654     0.0614     0.0318      0.134     0.0467     0.0471     0.0155\n",
      "            Helicopter         27        107      0.186     0.0654     0.0614     0.0318      0.134     0.0467     0.0471     0.0155\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263      0.062      0.144     0.0532     0.0232     0.0408     0.0951      0.029    0.00994\n",
      "            Helicopter         28        263      0.062      0.144     0.0532     0.0232     0.0408     0.0951      0.029    0.00994\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 168.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.37G      2.013      3.541      4.889      1.435         77        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.238     0.0728     0.0757     0.0396     0.0497      0.262      0.054     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.23G       2.18      3.706      4.914        1.5         63        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.247     0.0748     0.0765     0.0393     0.0513      0.262     0.0552       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.32G      2.156      4.735      5.107      1.835         41        640: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.246     0.0748     0.0767     0.0397     0.0519      0.262     0.0564     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      6.23G       2.38      3.338      4.663      1.659         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.254     0.0748     0.0744     0.0394      0.191     0.0561     0.0538     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      6.16G      1.879      4.233      5.467      1.711         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.261     0.0654     0.0755     0.0395      0.193     0.0467      0.054     0.0174\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27        107      0.247     0.0748     0.0767     0.0411     0.0519      0.262     0.0569     0.0199\n",
      "            Helicopter         27        107      0.247     0.0748     0.0767     0.0411     0.0519      0.262     0.0569     0.0199\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         28        263     0.0857      0.152     0.0589     0.0295     0.0685      0.122     0.0415     0.0136\n",
      "            Helicopter         28        263     0.0857      0.152     0.0589     0.0295     0.0685      0.122     0.0415     0.0136\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 176.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.33G      2.329      6.927      4.105      1.683         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107       0.21     0.0748     0.0626     0.0328      0.165     0.0561     0.0476     0.0144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.3G       1.82       6.94      4.149      1.615          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.203     0.0748      0.067     0.0341      0.164     0.0561     0.0493     0.0151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G      2.042      5.621      5.084      1.802          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.236     0.0748     0.0699     0.0371      0.178     0.0561     0.0512     0.0168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.42G      2.474      6.043      4.599       2.07         21        640: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.233     0.0748      0.074     0.0389      0.181     0.0561     0.0561     0.0174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.31G      1.706      6.712      4.251      1.695          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.277     0.0748     0.0752      0.039      0.199     0.0561     0.0565     0.0177\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.272     0.0748      0.075      0.039      0.201     0.0561     0.0564     0.0177\n",
      "            Helicopter         27        107      0.272     0.0748      0.075      0.039      0.201     0.0561     0.0564     0.0177\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263     0.0609      0.144     0.0481     0.0228     0.0449      0.106     0.0302    0.00844\n",
      "            Helicopter         28        263     0.0609      0.144     0.0481     0.0228     0.0449      0.106     0.0302    0.00844\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 158.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.61G      2.034      6.007       4.13        1.6         46        640: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.228     0.0748      0.076     0.0401     0.0511      0.271     0.0567     0.0197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.41G      2.257      4.703      4.751      1.492         83        640: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107       0.24     0.0748     0.0793     0.0418     0.0518      0.271     0.0592     0.0201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.37G      2.552      4.571      5.805       1.89         56        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.258     0.0748     0.0781     0.0409     0.0505      0.252     0.0571     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.37G      2.142      4.606      4.715      1.768         58        640: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.254     0.0841     0.0782     0.0412     0.0511      0.252     0.0581     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.38G      1.892      4.513      5.565      1.603         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.221      0.103     0.0779     0.0401     0.0512      0.243     0.0578     0.0185\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27        107       0.24     0.0748     0.0773     0.0406     0.0499      0.262     0.0566     0.0195\n",
      "            Helicopter         27        107       0.24     0.0748     0.0773     0.0406     0.0499      0.262     0.0566     0.0195\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263     0.0882      0.156     0.0623     0.0291     0.0753      0.133     0.0455     0.0147\n",
      "            Helicopter         28        263     0.0882      0.156     0.0623     0.0291     0.0753      0.133     0.0455     0.0147\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 164.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      2.123      4.783      4.956      1.505         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all         27        107      0.209     0.0748     0.0634     0.0339      0.183     0.0561     0.0481     0.0147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.86G      1.814      4.852      6.055      1.724          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.207     0.0654     0.0658     0.0347      0.153     0.0467     0.0488     0.0154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.88G      1.769      5.009      4.991      1.687          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.222     0.0719      0.066     0.0349      0.152     0.0467     0.0522     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.88G      2.297       5.25      4.809      1.566         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.202     0.0654     0.0611     0.0334      0.157     0.0467     0.0516     0.0153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      2.725      4.591      5.111      1.719         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.211     0.0654     0.0643     0.0346      0.186     0.0554     0.0537     0.0164\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.204     0.0654     0.0638     0.0344      0.184      0.055     0.0534     0.0165\n",
      "            Helicopter         27        107      0.204     0.0654     0.0638     0.0344      0.184      0.055     0.0534     0.0165\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         28        263     0.0565      0.125     0.0437      0.019     0.0428     0.0951     0.0281    0.00962\n",
      "            Helicopter         28        263     0.0565      0.125     0.0437      0.019     0.0428     0.0951     0.0281    0.00962\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 157.32it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.94G        2.6      5.482      5.646      1.988         53        640: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.233     0.0825     0.0749     0.0394     0.0519      0.262     0.0556     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.01G      2.129      4.456       5.01      1.744         48        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.245     0.0654     0.0771     0.0412     0.0485      0.243     0.0568     0.0193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.2G      1.952      5.205      4.616      1.687         55        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.264     0.0748     0.0767     0.0402     0.0507      0.252     0.0572     0.0191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       8.7G       2.03       5.18      5.371      2.079         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.259     0.0748     0.0796     0.0412     0.0491      0.243     0.0572     0.0193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.19G      1.887      3.912      5.058      1.486         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107       0.27     0.0654     0.0757     0.0398        0.2     0.0467     0.0549     0.0177\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27        107       0.27     0.0748     0.0781     0.0412      0.049      0.243     0.0564     0.0192\n",
      "            Helicopter         27        107       0.27     0.0748     0.0781     0.0412      0.049      0.243     0.0564     0.0192\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263     0.0911      0.156     0.0637     0.0311       0.08      0.137     0.0467     0.0144\n",
      "            Helicopter         28        263     0.0911      0.156     0.0637     0.0311       0.08      0.137     0.0467     0.0144\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 155.52it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.36G      2.103      4.532      10.62      1.401          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.189     0.0748     0.0642     0.0333      0.147     0.0467     0.0475     0.0147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.88G      2.699      2.918      8.835      1.917          2        640: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.193     0.0654     0.0657     0.0348      0.148     0.0467     0.0499     0.0157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.86G      1.497      4.756      8.806      1.187          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.167     0.0561      0.062     0.0339      0.145     0.0467     0.0518     0.0157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.87G      0.937       3.15      7.338      1.052          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.192     0.0654     0.0598     0.0328      0.172     0.0561     0.0499     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.86G      2.949      6.124      12.57       1.43          3        640: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.227     0.0748     0.0604     0.0316      0.177     0.0561     0.0468     0.0152\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27        107      0.192     0.0654     0.0633      0.033      0.148     0.0467     0.0475     0.0151\n",
      "            Helicopter         27        107      0.192     0.0654     0.0633      0.033      0.148     0.0467     0.0475     0.0151\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         28        263     0.0622      0.141     0.0529     0.0226     0.0471      0.106     0.0347     0.0113\n",
      "            Helicopter         28        263     0.0622      0.141     0.0529     0.0226     0.0471      0.106     0.0347     0.0113\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 159.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      2.321      3.278      5.043      1.543         68        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107       0.24     0.0799     0.0787     0.0405     0.0561       0.29      0.058      0.021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      2.106      4.828      5.513      1.609         52        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.243     0.0841      0.078     0.0409     0.0521      0.262     0.0575     0.0198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.25G      2.627      3.708      5.901      1.662         85        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107       0.24     0.0841     0.0795     0.0415     0.0535      0.262     0.0593     0.0207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.22G      2.084        4.2      5.193      1.684         54        640: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107       0.23     0.0841     0.0783     0.0417     0.0539      0.262     0.0588     0.0202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.21G      2.201      4.999      5.007      1.673         72        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.21      0.103     0.0761     0.0408     0.0489      0.234     0.0562     0.0189\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27        107       0.24     0.0841     0.0792     0.0415     0.0531      0.262      0.059     0.0206\n",
      "            Helicopter         27        107       0.24     0.0841     0.0792     0.0415     0.0531      0.262      0.059     0.0206\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                   all         28        263     0.0963       0.16      0.066     0.0316      0.078      0.129     0.0459     0.0154\n",
      "            Helicopter         28        263     0.0963       0.16      0.066     0.0316      0.078      0.129     0.0459     0.0154\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 161.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      2.263      3.181       5.38      1.255         53        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.183     0.0654     0.0603     0.0317      0.141     0.0467     0.0445     0.0143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.93G      1.547      3.545       3.85       1.12         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.194     0.0654     0.0631     0.0333      0.148     0.0467     0.0462      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       3.1G      1.746      2.806      4.218      1.246         36        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.173     0.0561     0.0606     0.0329      0.154     0.0467     0.0474     0.0156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         3G      1.971      2.773      4.405      1.258         23        640: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.173     0.0561     0.0588     0.0316      0.161     0.0467     0.0449      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.86G      1.531      3.226       4.79      1.016         20        640: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107        0.2     0.0654     0.0585     0.0318      0.163     0.0467     0.0447      0.015\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107      0.203     0.0654     0.0643     0.0332      0.156     0.0467     0.0472     0.0156\n",
      "            Helicopter         27        107      0.203     0.0654     0.0643     0.0332      0.156     0.0467     0.0472     0.0156\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         28        263     0.0609      0.137     0.0496     0.0224     0.0423     0.0951      0.031    0.00981\n",
      "            Helicopter         28        263     0.0609      0.137     0.0496     0.0224     0.0423     0.0951      0.031    0.00981\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 154.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      2.522       3.23      5.542      1.475         12        640: 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.226     0.0748     0.0783     0.0404     0.0533      0.271     0.0576       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.51G      2.351      4.197      4.973      1.738         18        640: 100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.242     0.0654     0.0737      0.039      0.173     0.0467     0.0537     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.23G      2.052      3.678      4.755      1.446         49        640: 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.087      0.439      0.104     0.0558     0.0759      0.383     0.0833     0.0293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G      2.002      3.908      5.106      1.843          4        640: 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107     0.0888      0.439      0.103     0.0567     0.0775      0.383     0.0835      0.031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      1.766      3.335      4.599      1.304         43        640: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.108       0.57       0.19      0.109     0.0995      0.523      0.169     0.0645\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27        107      0.109       0.57      0.191       0.11     0.0998      0.523      0.169     0.0646\n",
      "            Helicopter         27        107      0.109       0.57      0.191       0.11     0.0998      0.523      0.169     0.0646\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                   all         28        263      0.192      0.354      0.156     0.0784      0.184      0.338       0.14     0.0524\n",
      "            Helicopter         28        263      0.192      0.354      0.156     0.0784      0.184      0.338       0.14     0.0524\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 164.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.44G      2.112      3.588      5.883      1.557          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                   all         27        107      0.221      0.131      0.112     0.0636      0.186     0.0654     0.0934     0.0355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.92G      2.802      3.619      5.014      1.531         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.239     0.0841      0.118      0.065      0.186     0.0654     0.0949     0.0372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.86G      2.104      3.974      9.429      1.891          2        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.227     0.0841      0.116     0.0631      0.179     0.0654      0.091     0.0368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.89G       2.49      4.137      6.154       1.27         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.262     0.0841      0.114     0.0624      0.209     0.0654      0.093     0.0365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.93G      3.246      2.845      5.452      1.331         34        640: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.264     0.0935      0.113     0.0634      0.197     0.0654     0.0931     0.0373\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.245     0.0841      0.117     0.0637      0.191     0.0654     0.0932      0.037\n",
      "            Helicopter         27        107      0.245     0.0841      0.117     0.0637      0.191     0.0654     0.0932      0.037\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263      0.117      0.274     0.0862       0.04      0.102       0.24     0.0703     0.0279\n",
      "            Helicopter         28        263      0.117      0.274     0.0862       0.04      0.102       0.24     0.0703     0.0279\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<00:00, 152.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      2.146      3.771      4.834      1.398         73        640: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.231     0.0786     0.0785     0.0401     0.0548      0.271     0.0579       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G       2.08      4.146      5.371      1.504         10        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.258     0.0779     0.0782     0.0404     0.0516      0.252     0.0581     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.22G      1.895      3.739      4.824      1.521         50        640: 100%|██████████| 2/2 [00:01<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.286     0.0748     0.0758     0.0399      0.217     0.0493     0.0554     0.0177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.21G      2.001      4.399      5.452      1.516         13        640: 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107     0.0891       0.43      0.108     0.0588     0.0795      0.383     0.0875     0.0324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      2.224      3.451      4.768      1.438         58        640: 100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.104      0.505       0.13     0.0727      0.096      0.467      0.114     0.0429\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27        107      0.103      0.505      0.131      0.072     0.0952      0.467      0.112     0.0423\n",
      "            Helicopter         27        107      0.103      0.505      0.131      0.072     0.0952      0.467      0.112     0.0423\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         28        263      0.169      0.293      0.118     0.0576      0.149      0.259     0.0985     0.0358\n",
      "            Helicopter         28        263      0.169      0.293      0.118     0.0576      0.149      0.259     0.0985     0.0358\n",
      "Speed: 0.6ms preprocess, 15.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 138.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      2.228      4.675      4.255      1.563         42        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.192     0.0748     0.0829     0.0467      0.232     0.0654     0.0696     0.0253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.95G      1.979      3.334      3.862      1.257         24        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.207     0.0748     0.0869     0.0489      0.183     0.0654      0.076     0.0271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.94G      2.009      4.118      4.255      1.788         20        640: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.197     0.0748     0.0878     0.0497      0.182     0.0654     0.0767      0.027\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.01G      2.049      4.569      3.968      1.723         32        640: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.206     0.0748     0.0898     0.0508      0.183     0.0654     0.0784     0.0277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.98G      2.234      3.667      3.915      1.489         40        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.166     0.0935     0.0885     0.0487      0.188     0.0654     0.0754     0.0267\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27        107      0.206     0.0748     0.0898     0.0507      0.183     0.0654     0.0784     0.0278\n",
      "            Helicopter         27        107      0.206     0.0748     0.0898     0.0507      0.183     0.0654     0.0784     0.0278\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263     0.0821      0.175      0.059     0.0254     0.0661      0.141     0.0417     0.0156\n",
      "            Helicopter         28        263     0.0821      0.175      0.059     0.0254     0.0661      0.141     0.0417     0.0156\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 146.52it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      2.285      3.589      4.769      1.489         77        640: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.231     0.0748     0.0778     0.0407     0.0532      0.271     0.0563     0.0204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      2.066      3.476      4.955      1.439         41        640: 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.255     0.0841     0.0758     0.0401     0.0501      0.243     0.0562     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.21G      2.086      3.943      5.206      1.565         66        640: 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.293     0.0748     0.0748     0.0396      0.229     0.0561     0.0552     0.0177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.21G      2.315      3.898      5.125      1.637         55        640: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107     0.0917      0.121     0.0773     0.0406     0.0532      0.187     0.0573     0.0186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.31G      2.208      3.659      4.899      1.418         73        640: 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107     0.0916      0.449      0.105     0.0569      0.084      0.411     0.0882     0.0303\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27        107     0.0881       0.43      0.102     0.0565     0.0824      0.402     0.0874     0.0302\n",
      "            Helicopter         27        107     0.0881       0.43      0.102     0.0565     0.0824      0.402     0.0874     0.0302\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263      0.139       0.24     0.0923     0.0435      0.119      0.205     0.0724     0.0277\n",
      "            Helicopter         28        263      0.139       0.24     0.0923     0.0435      0.119      0.205     0.0724     0.0277\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 131.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.77G      3.191      6.172      5.926      2.365         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         27        107      0.224     0.0935     0.0742     0.0388      0.197     0.0654     0.0608      0.021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.86G      2.842       6.11      5.734       2.45         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.221     0.0935     0.0739     0.0393      0.186     0.0654     0.0623     0.0216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.85G      2.595      5.855      6.737      2.675          3        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.222     0.0935     0.0753     0.0386      0.185     0.0654     0.0627     0.0226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.87G      2.851      4.949      6.935      1.784          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.239     0.0935     0.0791     0.0416      0.206     0.0748     0.0663     0.0239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      2.745      5.193      5.089      1.567         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.249     0.0935     0.0794     0.0418      0.201     0.0654     0.0614     0.0233\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27        107      0.238     0.0935     0.0785     0.0412      0.205     0.0748     0.0655     0.0239\n",
      "            Helicopter         27        107      0.238     0.0935     0.0785     0.0412      0.205     0.0748     0.0655     0.0239\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263     0.0813      0.175     0.0606     0.0254     0.0636      0.137     0.0405     0.0158\n",
      "            Helicopter         28        263     0.0813      0.175     0.0606     0.0254     0.0636      0.137     0.0405     0.0158\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 144.63it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      1.798      3.053      5.282      1.228         20        640: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.243     0.0748     0.0768     0.0404     0.0511      0.262     0.0549     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      1.927      3.246      4.754      1.345         68        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.257     0.0748     0.0769     0.0407     0.0516      0.252     0.0577     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.21G      1.957      4.172      4.646      1.529         79        640: 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.228     0.0841      0.079     0.0409      0.233     0.0467      0.057     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.21G      1.957      3.877      5.133      1.556        127        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107     0.0893      0.187      0.093     0.0492     0.0697      0.327     0.0745      0.025\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.31G      2.201       3.58      4.814      1.465         90        640: 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.103      0.514      0.132     0.0732     0.0957      0.477      0.115     0.0423\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.104      0.514      0.132     0.0734     0.0968      0.477      0.116     0.0425\n",
      "            Helicopter         27        107      0.104      0.514      0.132     0.0734     0.0968      0.477      0.116     0.0425\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263      0.181      0.319      0.127     0.0615      0.164      0.289      0.109     0.0413\n",
      "            Helicopter         28        263      0.181      0.319      0.127     0.0615      0.164      0.289      0.109     0.0413\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 137.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.42G      1.883      3.544      3.254      1.608         31        640: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.195     0.0935      0.085     0.0488      0.274     0.0654     0.0705     0.0266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.96G      1.679      2.877      3.465      1.369         35        640: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.239     0.0841     0.0871     0.0506      0.404     0.0633     0.0736     0.0278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.94G      1.459      3.599      3.443      1.633         21        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107       0.26     0.0841     0.0918     0.0499      0.382     0.0654     0.0746     0.0283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.9G      2.207      3.677      4.001      2.029         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.277     0.0841     0.0945     0.0496      0.403     0.0654     0.0766      0.031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.92G      1.972      3.403      4.124      1.305         47        640: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107        0.3     0.0841     0.0908     0.0473      0.345     0.0654     0.0741     0.0298\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.268     0.0841     0.0936     0.0494      0.401     0.0654     0.0764     0.0308\n",
      "            Helicopter         27        107      0.268     0.0841     0.0936     0.0494      0.401     0.0654     0.0764     0.0308\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                   all         28        263     0.0953      0.224     0.0739     0.0297     0.0743      0.175     0.0478     0.0178\n",
      "            Helicopter         28        263     0.0953      0.224     0.0739     0.0297     0.0743      0.175     0.0478     0.0178\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 125.28it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      2.128      4.254      4.806      1.655         56        640: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.247     0.0654     0.0739     0.0389     0.0498      0.252     0.0545     0.0189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G      2.091      3.898      4.929      1.453        128        640: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.291     0.0748     0.0777     0.0411      0.052      0.252     0.0584     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.22G      2.047      4.172      4.625      1.467        136        640: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.229     0.0935     0.0793     0.0415     0.0498      0.234     0.0581     0.0193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.21G      2.017      3.725      4.508      1.472        120        640: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.105      0.523      0.127     0.0691      0.096      0.477      0.108     0.0385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G      1.925      3.571      4.476      1.387         77        640: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.113       0.57      0.143     0.0789      0.102      0.514      0.125     0.0471\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.115      0.579      0.144     0.0791      0.104      0.523      0.126     0.0455\n",
      "            Helicopter         27        107      0.115      0.579      0.144     0.0791      0.104      0.523      0.126     0.0455\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263      0.176      0.323       0.13     0.0635      0.167      0.308      0.117     0.0442\n",
      "            Helicopter         28        263      0.176      0.323       0.13     0.0635      0.167      0.308      0.117     0.0442\n",
      "Speed: 0.3ms preprocess, 15.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 181.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G       1.62      4.224      5.203      1.467         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         27        107      0.212      0.103     0.0869     0.0467      0.246     0.0654     0.0703     0.0269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.04G      1.785      4.595      6.337      1.711          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107       0.22      0.103     0.0867     0.0473      0.229     0.0654     0.0713     0.0277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.04G       1.59      4.799      7.505      1.384          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.243      0.103     0.0976     0.0521      0.231     0.0654     0.0784     0.0296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      1.839      5.703      5.797      1.526          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.236      0.103      0.103     0.0538      0.231     0.0654     0.0814     0.0301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.05G      2.003      4.343      9.072       1.45          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.254      0.103      0.107     0.0556     0.0837      0.178     0.0849     0.0312\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27        107      0.255      0.103      0.108     0.0559     0.0836      0.178      0.085     0.0308\n",
      "            Helicopter         27        107      0.255      0.103      0.108     0.0559     0.0836      0.178      0.085     0.0308\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         28        263      0.103       0.24     0.0739     0.0346     0.0817       0.19     0.0519     0.0225\n",
      "            Helicopter         28        263      0.103       0.24     0.0739     0.0346     0.0817       0.19     0.0519     0.0225\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 7.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 134.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.49G      2.161      4.574      9.657      1.437          3        640: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.245     0.0748     0.0777      0.041     0.0514      0.252     0.0564     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G      2.024      3.647      4.857      1.466         29        640: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         27        107      0.259     0.0841      0.084      0.045     0.0573      0.271     0.0654     0.0228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      2.011      3.975      4.489      1.589         21        640: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.097      0.514      0.135     0.0737     0.0899      0.477      0.117     0.0454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      2.238      3.717      4.621      1.536         50        640: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.215      0.458      0.229      0.121      0.193      0.411      0.199      0.074\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G      1.928      3.261      4.085      1.337         17        640: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.551      0.345      0.358      0.186      0.506      0.316      0.319      0.118\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.549      0.346      0.358      0.186      0.507      0.318      0.319      0.118\n",
      "            Helicopter         27        107      0.549      0.346      0.358      0.186      0.507      0.318      0.319      0.118\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                   all         28        263      0.507      0.407       0.39      0.192      0.433      0.433      0.346      0.132\n",
      "            Helicopter         28        263      0.507      0.407       0.39      0.192      0.433      0.433      0.346      0.132\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 163.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      1.646      2.361      3.123      1.344         37        640: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.313      0.271      0.249       0.13      0.273      0.232      0.203     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G      1.907      3.343      3.787      1.556         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.338       0.28      0.253      0.132       0.29      0.234      0.208     0.0762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      1.477      2.834      3.229      1.312         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.361       0.28      0.261      0.138      0.313      0.243      0.218      0.083\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      1.719      2.737      3.942      1.636         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.359       0.29      0.266      0.138      0.314      0.252      0.221     0.0814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.84G      1.221      2.299      2.774      1.219         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107       0.36       0.29       0.27      0.141       0.31      0.252      0.226     0.0821\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.357       0.29      0.269      0.141      0.306      0.252      0.226      0.082\n",
      "            Helicopter         27        107      0.357       0.29      0.269      0.141      0.306      0.252      0.226      0.082\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263       0.31      0.471      0.265      0.124      0.276      0.441      0.225     0.0868\n",
      "            Helicopter         28        263       0.31      0.471      0.265      0.124      0.276      0.441      0.225     0.0868\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 127.97it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      2.213      4.033      5.248      1.531         95        640: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.245     0.0748     0.0781     0.0408     0.0506      0.252      0.057     0.0195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.49G       1.98      3.754      4.766        1.5         78        640: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.257     0.0841     0.0782     0.0412      0.112     0.0935     0.0587     0.0194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      2.069      3.727      4.945       1.35         86        640: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.192      0.103        0.1     0.0534      0.102      0.121      0.079     0.0302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      2.234      3.614      4.603      1.481         55        640: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.319      0.252      0.231      0.119      0.285      0.224      0.207     0.0745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G       1.75      3.825       4.49      1.465         19        640: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.346      0.355      0.266      0.133      0.318      0.327      0.226     0.0835\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27        107      0.345      0.355      0.266      0.134      0.318      0.327      0.226     0.0834\n",
      "            Helicopter         27        107      0.345      0.355      0.266      0.134      0.318      0.327      0.226     0.0834\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263      0.406      0.483      0.298      0.137      0.329      0.433      0.235     0.0852\n",
      "            Helicopter         28        263      0.406      0.483      0.298      0.137      0.329      0.433      0.235     0.0852\n",
      "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 174.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      1.665      3.397      6.796      1.412          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         27        107      0.242      0.355      0.214      0.103      0.196      0.299      0.167      0.064\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.99G      1.962      3.106      8.915      1.255          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.249      0.364      0.219      0.104      0.203      0.299      0.167     0.0635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.05G      2.102      4.867      7.013      1.485          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.248      0.336      0.218      0.106      0.199       0.28      0.173     0.0654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      1.938      3.295      6.944      1.291          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.248      0.336      0.222      0.107      0.193      0.271      0.172     0.0664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.05G      2.024      3.455      5.943      1.647          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.258      0.345      0.228      0.111      0.213       0.29       0.18     0.0677\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.255      0.339      0.227       0.11      0.206       0.28      0.176     0.0658\n",
      "            Helicopter         27        107      0.255      0.339      0.227       0.11      0.206       0.28      0.176     0.0658\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         28        263      0.158      0.559      0.193     0.0855      0.123      0.494      0.148      0.051\n",
      "            Helicopter         28        263      0.158      0.559      0.193     0.0855      0.123      0.494      0.148      0.051\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 150.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.82G      1.888      3.835      4.492      1.436        104        640: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.249     0.0841     0.0808     0.0428     0.0527      0.262     0.0604       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.24G      2.139      3.884       5.14      1.493        127        640: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107     0.0814      0.402     0.0968     0.0534      0.072      0.355     0.0802     0.0272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G      1.888      3.463      4.311      1.425         90        640: 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107     0.0944      0.579      0.127     0.0683     0.0837      0.514       0.11     0.0386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      1.929      3.327      4.302      1.358         73        640: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.364      0.316      0.255       0.13      0.335      0.287      0.217     0.0777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      1.834      3.258      3.751       1.39         53        640: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.649      0.311      0.411      0.215       0.61      0.292      0.346      0.137\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27        107      0.649      0.311      0.412      0.216       0.61      0.292      0.348      0.139\n",
      "            Helicopter         27        107      0.649      0.311      0.412      0.216       0.61      0.292      0.348      0.139\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263      0.593      0.445      0.457      0.218      0.537      0.403      0.403      0.159\n",
      "            Helicopter         28        263      0.593      0.445      0.457      0.218      0.537      0.403      0.403      0.159\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 184.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.48G      1.914      3.019      5.592      1.341         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         27        107      0.367      0.383       0.32      0.163      0.371      0.308      0.283      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G      1.999      3.619      6.013      1.452         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.371      0.392      0.328      0.164      0.322      0.336      0.288       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.05G       2.11      4.812      10.76      1.113         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.389      0.393      0.341      0.172      0.352      0.346        0.3      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.99G      3.393      2.957       16.2      1.462         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.394      0.393      0.355      0.178      0.376       0.36      0.316      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      2.215      3.435      5.786      1.491         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107        0.4      0.393      0.363      0.181      0.362      0.355      0.311      0.116\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.394      0.393      0.362       0.18      0.363      0.355       0.31      0.116\n",
      "            Helicopter         27        107      0.394      0.393      0.362       0.18      0.363      0.355       0.31      0.116\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         28        263      0.441      0.369      0.335      0.155      0.416      0.335      0.292      0.105\n",
      "            Helicopter         28        263      0.441      0.369      0.335      0.155      0.416      0.335      0.292      0.105\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 156.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      2.066      3.775      5.755      1.502          8        640: 100%|██████████| 4/4 [00:02<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.243     0.0782     0.0768     0.0397     0.0492      0.243     0.0562     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G      2.431      3.807      8.479      1.369          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.106      0.523      0.135     0.0729     0.0928      0.458      0.112     0.0417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.34G       2.03      3.505      4.705      1.485          6        640: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.493      0.346      0.389      0.216      0.456      0.318      0.333      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G      1.905       3.45      4.153      1.327         12        640: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107       0.54      0.477      0.501      0.293      0.499      0.439      0.459      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G      1.847      3.445      3.263       1.35          8        640: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.613      0.488      0.532      0.314      0.565      0.462      0.494      0.226\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.614       0.49      0.532      0.316      0.567      0.465      0.494      0.225\n",
      "            Helicopter         27        107      0.614       0.49      0.532      0.316      0.567      0.465      0.494      0.225\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         28        263      0.724      0.654      0.737      0.375      0.731       0.65      0.725      0.306\n",
      "            Helicopter         28        263      0.724      0.654      0.737      0.375      0.731       0.65      0.725      0.306\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 158.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.02G      1.893      4.036      6.857      1.473         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all         27        107      0.755      0.346      0.488      0.285      0.745      0.336       0.44      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.93G      1.953      2.872      21.37      1.604          2        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.753      0.346      0.493      0.287      0.752      0.336      0.444      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      2.626      4.305      4.835      1.496         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.761      0.346      0.499      0.295      0.742      0.336      0.447       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      1.909      3.656      5.427      1.582         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.766      0.346      0.504        0.3      0.745      0.336       0.46      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.01G      2.327      3.626      5.008      1.437         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107       0.47      0.477      0.508      0.302      0.743      0.336      0.464      0.213\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27        107      0.469      0.479      0.509      0.301      0.746      0.336      0.464      0.211\n",
      "            Helicopter         27        107      0.469      0.479      0.509      0.301      0.746      0.336      0.464      0.211\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263      0.836      0.574      0.716      0.347       0.82      0.567      0.683      0.286\n",
      "            Helicopter         28        263      0.836      0.574      0.716      0.347       0.82      0.567      0.683      0.286\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<00:00, 153.87it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      1.915      3.326      5.396      1.339         18        640: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.266     0.0748     0.0791     0.0417     0.0524      0.252     0.0599     0.0198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      1.934      3.816      4.761      1.359         49        640: 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107     0.0876      0.196      0.095     0.0501     0.0694      0.206      0.077     0.0262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G      2.018      3.653      4.632      1.389         41        640: 100%|██████████| 4/4 [00:03<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.228       0.28        0.2      0.103      0.217      0.243      0.173     0.0645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      1.981      3.168      3.988      1.412         75        640: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.755      0.318      0.504      0.243      0.703      0.299      0.444      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G       1.82      3.018      2.979      1.319         39        640: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.562      0.467      0.542      0.252      0.493      0.436      0.447      0.178\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.562      0.467      0.543      0.255      0.491       0.43      0.448      0.177\n",
      "            Helicopter         27        107      0.562      0.467      0.543      0.255      0.491       0.43      0.448      0.177\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                   all         28        263      0.705      0.689      0.745      0.365      0.734      0.597      0.684       0.24\n",
      "            Helicopter         28        263      0.705      0.689      0.745      0.365      0.734      0.597      0.684       0.24\n",
      "Speed: 0.2ms preprocess, 16.6ms inference, 0.0ms loss, 7.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 250.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.11G      2.844      3.989      8.723      1.442          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.458      0.491      0.491      0.226      0.399       0.43      0.395      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.99G      1.663      2.793      5.734      1.646          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.467      0.467      0.493      0.228      0.388      0.445      0.393      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G      1.946      2.667       8.17      1.327          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.457      0.495      0.504      0.235      0.403      0.439      0.408       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.05G      2.057      3.558       6.12      1.807          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.471      0.467        0.5      0.233      0.421      0.421      0.413      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.04G      2.241       3.84      6.983      2.118          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.485      0.458      0.503      0.235      0.372      0.498      0.412      0.153\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.486      0.458      0.503      0.233      0.356      0.542      0.414      0.157\n",
      "            Helicopter         27        107      0.486      0.458      0.503      0.233      0.356      0.542      0.414      0.157\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "                   all         28        263      0.745      0.632       0.73      0.349      0.718       0.61      0.679       0.23\n",
      "            Helicopter         28        263      0.745      0.632       0.73      0.349      0.718       0.61      0.679       0.23\n",
      "Speed: 0.2ms preprocess, 16.5ms inference, 0.0ms loss, 10.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<00:00, 155.18it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      2.122      4.158       5.25      1.556         56        640: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.236     0.0841     0.0804     0.0419     0.0549      0.271     0.0606     0.0205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      2.008      3.986      4.753      1.491         45        640: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.126       0.14     0.0981     0.0514     0.0893      0.112     0.0806     0.0282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      1.926      3.682      5.226      1.505         26        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.32      0.308      0.239      0.125        0.3       0.29      0.197     0.0776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      2.085      3.309       3.86      1.398         84        640: 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.577      0.411      0.431      0.214      0.584      0.346      0.343      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G      1.865      3.249      4.084      1.286         74        640: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.598      0.458       0.49      0.237      0.537      0.411      0.395      0.152\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107      0.595      0.458      0.486      0.233      0.536      0.411      0.393      0.151\n",
      "            Helicopter         27        107      0.595      0.458      0.486      0.233      0.536      0.411      0.393      0.151\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263      0.764      0.678      0.722       0.36      0.747      0.608      0.638      0.213\n",
      "            Helicopter         28        263      0.764      0.678      0.722       0.36      0.747      0.608      0.638      0.213\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 158.79it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.57G      2.029      4.442      3.091      1.702         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         27        107      0.522      0.469      0.435        0.2      0.457      0.411      0.339      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.93G       1.75       3.45      2.337      1.285         37        640: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         27        107      0.558      0.458      0.467      0.208      0.467      0.383      0.337      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.85G      1.929      3.428      3.133      1.498         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.537      0.486      0.475      0.216      0.444      0.402      0.343       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.16G      1.645      2.969      2.015      1.237         59        640: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.601       0.43      0.478      0.223      0.526      0.364      0.356      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.69G       2.04      4.926      2.916      1.408         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.644      0.421       0.49      0.228      0.543      0.336      0.361      0.147\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.643      0.421       0.49      0.228      0.543      0.336      0.362      0.147\n",
      "            Helicopter         27        107      0.643      0.421       0.49      0.228      0.543      0.336      0.362      0.147\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         28        263      0.825      0.608      0.691      0.326      0.745      0.555      0.588      0.183\n",
      "            Helicopter         28        263      0.825      0.608      0.691      0.326      0.745      0.555      0.588      0.183\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 155.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G       1.94      3.894      5.077      1.439          8        640: 100%|██████████| 5/5 [00:03<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.279     0.0654     0.0769     0.0406      0.203     0.0467     0.0573      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.49G      2.123      4.178      5.225      1.582         13        640: 100%|██████████| 5/5 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.163      0.103      0.121     0.0645     0.0882       0.28     0.0997     0.0367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      1.821      3.207      3.889       1.37         13        640: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.487      0.402      0.411      0.208      0.475      0.393      0.379      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      1.824      3.114      3.346       1.42          3        640: 100%|██████████| 5/5 [00:03<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.748      0.449      0.592      0.327      0.652      0.449      0.525      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G      1.746      3.072       3.16      1.212          2        640: 100%|██████████| 5/5 [00:03<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.692      0.486      0.614      0.349      0.881      0.393      0.552      0.246\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.693      0.485      0.614      0.349       0.88      0.393      0.552       0.25\n",
      "            Helicopter         27        107      0.693      0.485      0.614      0.349       0.88      0.393      0.552       0.25\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         28        263      0.816      0.725      0.819      0.424      0.834      0.673      0.768      0.294\n",
      "            Helicopter         28        263      0.816      0.725      0.819      0.424      0.834      0.673      0.768      0.294\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 8.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 153.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      1.716      2.957      2.664       1.26         25        640: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         27        107      0.526      0.533      0.585      0.338      0.838      0.374       0.53      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G      1.804      3.367       4.09      1.536         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.505       0.57      0.598      0.346      0.806      0.374      0.549      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      1.891      3.455      3.828       1.75         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.522      0.579      0.605      0.347      0.507      0.551      0.558      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G      1.598      3.703      3.936      1.547         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.536       0.57      0.613      0.352      0.505      0.533      0.546      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      1.739      3.598      4.117      1.458         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.527      0.607      0.615      0.352      0.547      0.507      0.547      0.249\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.527      0.607      0.615      0.352      0.547      0.507      0.547      0.249\n",
      "            Helicopter         27        107      0.527      0.607      0.615      0.352      0.547      0.507      0.547      0.249\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         28        263      0.765      0.719      0.778      0.393      0.813      0.646       0.74      0.269\n",
      "            Helicopter         28        263      0.765      0.719      0.778      0.393      0.813      0.646       0.74      0.269\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 7.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 151.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      2.022      3.952      5.116      1.456         36        640: 100%|██████████| 5/5 [00:03<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.148      0.103       0.08     0.0413     0.0531      0.252     0.0601     0.0201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      2.157      3.768      4.886      1.435         50        640: 100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.101      0.654      0.189      0.103     0.0899      0.579      0.161     0.0608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      1.958        3.6      4.242      1.446         24        640: 100%|██████████| 5/5 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.437      0.514      0.452       0.25      0.381      0.486      0.391      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      1.878      2.899      3.248      1.277         27        640: 100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.586      0.489      0.486      0.269      0.486      0.495      0.419      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      1.646      3.074      2.688      1.329         19        640: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.737      0.477       0.57      0.312      0.685      0.439      0.488      0.208\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.736      0.477      0.571      0.314      0.685      0.439      0.489      0.208\n",
      "            Helicopter         27        107      0.736      0.477      0.571      0.314      0.685      0.439      0.489      0.208\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263      0.767      0.532      0.654      0.349      0.756      0.525       0.62      0.245\n",
      "            Helicopter         28        263      0.767      0.532      0.654      0.349      0.756      0.525       0.62      0.245\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 204.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      2.025      3.102      2.755       1.13         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         27        107      0.528      0.523      0.508      0.271      0.478      0.472      0.448      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G       1.75      3.076      2.871      1.349         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.555      0.505      0.509      0.272      0.492      0.449      0.448      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.88G      1.898      3.917      2.961       1.27         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107       0.56      0.495       0.51      0.274      0.506      0.449      0.443      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G      2.267      4.602      3.782       1.92         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.568      0.492      0.512      0.276      0.514      0.449      0.443      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.86G      2.019      4.507      4.362      1.674         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.546      0.495      0.505      0.274      0.529      0.458       0.44      0.187\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.569      0.495      0.513      0.276      0.511      0.449      0.443      0.186\n",
      "            Helicopter         27        107      0.569      0.495      0.513      0.276      0.511      0.449      0.443      0.186\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263      0.742      0.551      0.645      0.332      0.753      0.506      0.581      0.224\n",
      "            Helicopter         28        263      0.742      0.551      0.645      0.332      0.753      0.506      0.581      0.224\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 148.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.28G      1.943      3.567      4.612      1.349         65        640: 100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.226     0.0841     0.0812     0.0425     0.0568      0.271     0.0625     0.0213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G      2.131      3.832      4.967      1.494         38        640: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.116      0.673      0.217      0.114      0.105      0.607       0.19     0.0732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      2.007      3.594       4.57      1.438         52        640: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.477      0.514      0.502      0.253      0.634      0.341      0.419       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G      1.999      3.315      3.554      1.399         55        640: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.586      0.436      0.462      0.229      0.496      0.387      0.343      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.36G      1.992      3.082      3.163      1.411         55        640: 100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.461      0.514      0.455      0.214      0.418      0.439      0.336      0.119\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.469       0.52      0.502      0.254      0.637      0.336      0.419       0.16\n",
      "            Helicopter         27        107      0.469       0.52      0.502      0.254      0.637      0.336      0.419       0.16\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                   all         28        263      0.595      0.627      0.591      0.285      0.557      0.593      0.541      0.199\n",
      "            Helicopter         28        263      0.595      0.627      0.591      0.285      0.557      0.593      0.541      0.199\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 137.82it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      1.583      2.412      2.564      1.017         82        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         27        107      0.378      0.458      0.368      0.168      0.331      0.411      0.264      0.088\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       4.1G      1.718       2.62      1.804      1.142         36        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.379      0.505      0.362      0.165       0.33      0.439      0.267     0.0904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.04G      1.942      2.816      10.52       1.15          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.388      0.514      0.369       0.17      0.347      0.421      0.278     0.0924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.04G      1.082      3.323      7.269     0.8674          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.408       0.49      0.374       0.17      0.368      0.449      0.282      0.093\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.07G      1.749      2.655      3.337      1.274         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.399      0.486      0.373       0.17       0.36      0.439      0.282     0.0927\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107      0.406      0.495      0.373       0.17      0.367      0.449      0.283     0.0929\n",
      "            Helicopter         27        107      0.406      0.495      0.373       0.17      0.367      0.449      0.283     0.0929\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         28        263      0.584      0.665      0.556      0.258      0.527      0.593      0.454      0.134\n",
      "            Helicopter         28        263      0.584      0.665      0.556      0.258      0.527      0.593      0.454      0.134\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 8.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 146.96it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.23G        1.7      3.329      6.599       1.32          0        640: 100%|██████████| 6/6 [00:04<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                   all         27        107      0.317     0.0748     0.0743     0.0394      0.238     0.0561     0.0533     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G       1.81      3.389      4.732      1.428          1        640: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.219      0.215      0.164      0.091      0.188      0.234      0.149      0.056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      1.765      3.233      6.432      1.171          1        640: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         27        107       0.52      0.533      0.541      0.319      0.524      0.495      0.514      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G      1.368      2.658      4.916      1.043          0        640: 100%|██████████| 6/6 [00:04<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all         27        107      0.766      0.486      0.617      0.342      0.727      0.458       0.56       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G      1.854      3.003      2.728      1.228         13        640: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.65      0.626       0.64       0.35      0.607      0.578      0.566      0.233\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107      0.654      0.618       0.64      0.349      0.605       0.57      0.566      0.233\n",
      "            Helicopter         27        107      0.654      0.618       0.64      0.349      0.605       0.57      0.566      0.233\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         28        263      0.826      0.775      0.861      0.466      0.797      0.745      0.815      0.298\n",
      "            Helicopter         28        263      0.826      0.775      0.861      0.466      0.797      0.745      0.815      0.298\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 8.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 149.14it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.59G      1.884      2.413      2.109      1.005        103        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.605      0.505      0.587      0.299      0.645      0.439      0.517        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.01G      2.107      2.972      3.227      1.396         47        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.636      0.495      0.588      0.302      0.629      0.449      0.514        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5         4G      1.783      2.881      1.908      1.315         67        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.639      0.477      0.589      0.304      0.649      0.449      0.514        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.11G      1.824      3.196      1.903      1.382         73        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.556      0.579      0.593      0.306      0.646      0.458      0.516      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.05G      1.735      2.258      1.804      1.198         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.553      0.579      0.595      0.307      0.655      0.443      0.518      0.202\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.558      0.579      0.593      0.308      0.624      0.458      0.517      0.202\n",
      "            Helicopter         27        107      0.558      0.579      0.593      0.308      0.624      0.458      0.517      0.202\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         28        263      0.751      0.741      0.812      0.439      0.739      0.722       0.77      0.266\n",
      "            Helicopter         28        263      0.751      0.741      0.812      0.439      0.739      0.722       0.77      0.266\n",
      "Speed: 0.7ms preprocess, 16.0ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 147.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      2.022      4.109      5.026      1.451         26        640: 100%|██████████| 6/6 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.113      0.103     0.0839     0.0441      0.103     0.0935     0.0668     0.0236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G       2.06      3.882      4.756      1.558          9        640: 100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.246      0.252      0.187     0.0999      0.227      0.234      0.159     0.0594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      1.962      3.423      3.514      1.353         18        640: 100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.486      0.561      0.566      0.307      0.755      0.374      0.515      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.39G      1.815       2.93      2.777      1.282         28        640: 100%|██████████| 6/6 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.657       0.52      0.621      0.329       0.58      0.505      0.561      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.41G      1.722       3.05      2.428      1.257         21        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.542      0.665      0.655       0.35      0.489      0.599      0.554      0.232\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107      0.561      0.673      0.664      0.353      0.491      0.605      0.554      0.232\n",
      "            Helicopter         27        107      0.561      0.673      0.664      0.353      0.491      0.605      0.554      0.232\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         28        263      0.763      0.677      0.742      0.397      0.739      0.636      0.686      0.257\n",
      "            Helicopter         28        263      0.763      0.677      0.742      0.397      0.739      0.636      0.686      0.257\n",
      "Speed: 0.4ms preprocess, 15.2ms inference, 0.0ms loss, 7.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 181.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.26G      1.549      2.067      2.389      1.235         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         27        107      0.727      0.486      0.616      0.319      0.654       0.43       0.48      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.99G      1.121      2.287      3.064      1.419          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.761      0.486       0.62       0.32      0.673       0.43      0.484      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.05G      1.854      2.573      4.356      1.716          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.646      0.551      0.622      0.322      0.658      0.421      0.481      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         4G      1.803      2.866      5.244      1.789          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.646      0.561      0.624      0.323      0.648      0.421      0.481      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.93G      1.843      2.801      2.722      1.485         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.685      0.551      0.625      0.321      0.581      0.467      0.487      0.191\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.686      0.551      0.625      0.322      0.581      0.467      0.487      0.191\n",
      "            Helicopter         27        107      0.686      0.551      0.625      0.322      0.581      0.467      0.487      0.191\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                   all         28        263      0.712      0.666      0.704      0.361       0.68       0.62      0.622      0.221\n",
      "            Helicopter         28        263      0.712      0.666      0.704      0.361       0.68       0.62      0.622      0.221\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 154.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      1.968      4.122      5.128       1.48         30        640: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.143      0.103     0.0792     0.0403       0.05      0.243     0.0578     0.0197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.52G      2.047      3.814      4.942      1.487         30        640: 100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107       0.63      0.355      0.439      0.257      0.697      0.308      0.405      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      1.817      3.206      2.894      1.235        124        640: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.585        0.5      0.549        0.3      0.554      0.475      0.498      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G      1.834      3.068       2.89      1.275         41        640: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.511      0.567      0.472      0.243      0.451      0.514      0.373       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      1.668      2.746      2.281       1.19         61        640: 100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.795      0.542      0.652      0.366      0.759      0.523      0.584      0.248\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.796      0.542      0.653      0.367      0.762      0.523      0.585      0.249\n",
      "            Helicopter         27        107      0.796      0.542      0.653      0.367      0.762      0.523      0.585      0.249\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                   all         28        263      0.854       0.76      0.857       0.48      0.796      0.741      0.809      0.313\n",
      "            Helicopter         28        263      0.854       0.76      0.857       0.48      0.796      0.741      0.809      0.313\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 138.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.85G      1.621      3.175      2.062       1.31         64        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                   all         27        107      0.703      0.486      0.574      0.316      0.656      0.481      0.508      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         4G       1.51      4.302       2.54      1.546         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107       0.72      0.505      0.597       0.33       0.68      0.477      0.528      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      1.849      3.406      3.855      1.408         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.711      0.505      0.608      0.338      0.728      0.467      0.537      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.05G      1.693      3.888      4.802      1.322          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.703      0.523      0.617      0.341       0.75      0.477      0.547      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.44G      1.918      2.381      1.957      1.241        159        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.718      0.523      0.621       0.34      0.691      0.505      0.553      0.241\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.718      0.523       0.62       0.34       0.69      0.505      0.553      0.241\n",
      "            Helicopter         27        107      0.718      0.523       0.62       0.34       0.69      0.505      0.553      0.241\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         28        263      0.812      0.757       0.83      0.452       0.81      0.713      0.781      0.305\n",
      "            Helicopter         28        263      0.812      0.757       0.83      0.452       0.81      0.713      0.781      0.305\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 150.52it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      2.088      4.006      4.808      1.428         68        640: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.223     0.0935     0.0797     0.0412     0.0525      0.252     0.0593     0.0203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.52G       2.05      3.651       4.63      1.464         81        640: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.588      0.346      0.416      0.234      0.575      0.346      0.383      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      1.834      3.335      3.061       1.32         84        640: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.761       0.43      0.602      0.338      0.734      0.439       0.56      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.39G      1.701      2.869      2.514      1.188         77        640: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.678      0.533      0.583      0.327      0.586      0.486       0.46      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.4G      1.596      2.817      2.263      1.184         79        640: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.706      0.589      0.684        0.4      0.701      0.542      0.594      0.242\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.706      0.589      0.684      0.401        0.7      0.542      0.594      0.241\n",
      "            Helicopter         27        107      0.706      0.589      0.684      0.401        0.7      0.542      0.594      0.241\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263      0.807      0.783      0.847      0.473      0.756      0.734      0.762      0.293\n",
      "            Helicopter         28        263      0.807      0.783      0.847      0.473      0.756      0.734      0.762      0.293\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 176.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.24G      1.608      2.361      1.487      1.048         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         27        107      0.787      0.561      0.677      0.372      0.721      0.495      0.539      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.25G       1.36      2.679       1.09     0.9286         50        640: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.786      0.589       0.68      0.375      0.685      0.508       0.55      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G      2.035      4.964      6.859       1.63          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.752      0.617      0.697      0.386      0.703      0.531      0.578      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      2.336      4.434      6.859      1.541         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.754      0.602      0.705      0.393      0.768      0.495      0.584       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       4.8G      1.422      2.228      1.343     0.9603        189        640: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         27        107      0.811       0.57      0.711      0.397      0.779      0.505      0.591      0.243\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.811       0.57      0.712      0.395      0.779      0.505      0.591      0.243\n",
      "            Helicopter         27        107      0.811       0.57      0.712      0.395      0.779      0.505      0.591      0.243\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                   all         28        263      0.837      0.753      0.842      0.459      0.799      0.719      0.776      0.293\n",
      "            Helicopter         28        263      0.837      0.753      0.842      0.459      0.799      0.719      0.776      0.293\n",
      "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 9.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 155.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.6G      1.971      3.868      5.149      1.429         24        640: 100%|██████████| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.307     0.0748     0.0783     0.0412     0.0526      0.234     0.0588     0.0197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G      1.991      3.931      4.545      1.468         14        640: 100%|██████████| 7/7 [00:05<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.641      0.393      0.482      0.264      0.611      0.374       0.43      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G      1.827      3.003      2.854      1.247         14        640: 100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.908      0.495       0.67      0.372      0.924      0.456        0.6      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G       1.67      2.918      2.363       1.23         18        640: 100%|██████████| 7/7 [00:05<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                   all         27        107      0.822      0.654      0.761      0.441       0.79       0.57      0.662      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G      1.552      2.495       1.65      1.089         89        640: 100%|██████████| 7/7 [00:05<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107       0.87      0.636      0.764      0.458      0.778      0.555      0.643      0.298\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.863      0.636      0.763      0.459       0.79      0.551      0.639      0.298\n",
      "            Helicopter         27        107      0.863      0.636      0.763      0.459       0.79      0.551      0.639      0.298\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         28        263      0.907      0.806       0.89      0.501      0.901      0.792      0.868      0.348\n",
      "            Helicopter         28        263      0.907      0.806       0.89      0.501      0.901      0.792      0.868      0.348\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 181.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.07G      2.038      3.976      4.544      1.367         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.748      0.626      0.724      0.422      0.673      0.561      0.636       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      2.131      4.054      4.133      1.466         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.738      0.631      0.724      0.423      0.657      0.573      0.636      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      2.396      3.898       4.57      1.708         40        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.725      0.645      0.724      0.423       0.65      0.579      0.634      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G       1.78      3.601      4.172      1.364         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.736      0.653      0.724      0.424      0.661      0.589      0.633      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.598      3.369      3.053      1.256         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.734      0.654      0.725      0.424      0.616      0.579      0.622       0.28\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27        107      0.737      0.653      0.725      0.422      0.656      0.589      0.634      0.284\n",
      "            Helicopter         27        107      0.737      0.653      0.725      0.422      0.656      0.589      0.634      0.284\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263      0.903      0.814      0.889      0.504       0.88      0.787      0.846      0.341\n",
      "            Helicopter         28        263      0.903      0.814      0.889      0.504       0.88      0.787      0.846      0.341\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 7.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 153.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.2G      2.124      4.139      5.221      1.493         48        640: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.159      0.103     0.0782     0.0407     0.0509      0.243     0.0585     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G          2      3.672      4.231      1.407         51        640: 100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.654       0.43      0.522      0.313      0.574      0.449      0.487       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      1.735      3.023       2.51      1.267        108        640: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.742      0.467      0.607      0.352      0.689      0.421       0.53      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      1.562      2.768      2.157      1.175        166        640: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.581      0.579      0.505      0.287      0.525      0.561      0.454      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.36G      1.547      2.812      2.168      1.195         91        640: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.746      0.617      0.686      0.382      0.688       0.57      0.591      0.265\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27        107      0.747      0.617      0.688      0.382      0.689       0.57      0.593      0.265\n",
      "            Helicopter         27        107      0.747      0.617      0.688      0.382      0.689       0.57      0.593      0.265\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         28        263      0.859      0.798      0.871      0.469      0.815      0.757       0.82      0.315\n",
      "            Helicopter         28        263      0.859      0.798      0.871      0.469      0.815      0.757       0.82      0.315\n",
      "Speed: 0.2ms preprocess, 15.8ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 153.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.97G      1.224      2.747      2.298      1.088         53        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.591      0.661       0.63      0.331      0.541      0.605       0.53      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.01G      1.795      3.092      2.588      1.213         57        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.608      0.668      0.633      0.334       0.56       0.63      0.535      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      1.715      3.574      2.553      1.137         56        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.627      0.664      0.635      0.335      0.572      0.607      0.532      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      1.742      3.648      2.352       1.42         41        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.642       0.67      0.639       0.34      0.591       0.62      0.541      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      1.253      2.602      2.516      1.083         49        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.646      0.666      0.642      0.344      0.593      0.626      0.544      0.229\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.647      0.669      0.643      0.344      0.592      0.625      0.543      0.229\n",
      "            Helicopter         27        107      0.647      0.669      0.643      0.344      0.592      0.625      0.543      0.229\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         28        263      0.873      0.795       0.87      0.469      0.841      0.745      0.805      0.308\n",
      "            Helicopter         28        263      0.873      0.795       0.87      0.469      0.841      0.745      0.805      0.308\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 149.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.18G      1.926      3.728      4.831      1.409         46        640: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.112      0.626      0.199      0.109      0.102       0.57      0.176     0.0635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.32G      1.924      3.536      3.795      1.362         47        640: 100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107      0.635      0.495      0.604      0.318      0.635      0.495      0.578      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      1.723      3.187      2.853       1.26         53        640: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                   all         27        107       0.67      0.606      0.646      0.334      0.633      0.533      0.533      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.36G      1.681      2.864      2.242      1.209         83        640: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.877      0.542      0.736      0.428      0.816      0.514       0.66      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G      1.596       2.72       2.07      1.206         55        640: 100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.715      0.673      0.767      0.456      0.676      0.663      0.695      0.299\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27        107       0.71      0.685      0.771      0.455      0.676      0.663      0.695        0.3\n",
      "            Helicopter         27        107       0.71      0.685      0.771      0.455      0.676      0.663      0.695        0.3\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         28        263      0.859      0.863      0.905      0.522      0.786      0.798      0.808      0.311\n",
      "            Helicopter         28        263      0.859      0.863      0.905      0.522      0.786      0.798      0.808      0.311\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 186.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.93G      1.848       3.58      3.106      1.663         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         27        107      0.718      0.654      0.729      0.414      0.675      0.607      0.633      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.296      3.411        2.4      1.311         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.745      0.664      0.754      0.419      0.681      0.607      0.623      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      1.864      3.171      4.688      1.896         16        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.754      0.658      0.758      0.421      0.701      0.615      0.651      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      1.997      3.309      3.625      1.964         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.759      0.645       0.76      0.424      0.704      0.599      0.654      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G       1.76      3.554      1.876      1.622         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.697      0.729      0.764      0.426      0.663      0.662      0.662      0.282\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27        107      0.708      0.726      0.765      0.426      0.656      0.654       0.66      0.282\n",
      "            Helicopter         27        107      0.708      0.726      0.765      0.426      0.656      0.654       0.66      0.282\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         28        263      0.892      0.821      0.879      0.511      0.832      0.773      0.803      0.294\n",
      "            Helicopter         28        263      0.892      0.821      0.879      0.511      0.832      0.773      0.803      0.294\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:00<00:00, 153.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      2.065      3.868       5.01      1.399         26        640: 100%|██████████| 9/9 [00:07<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         27        107      0.106      0.617      0.169     0.0921     0.0984       0.57       0.15     0.0526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.61G      2.255      3.426      10.01      1.393          2        640: 100%|██████████| 9/9 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.618      0.505       0.55      0.281      0.573      0.467      0.478      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      1.673      2.949      2.394      1.187         43        640: 100%|██████████| 9/9 [00:07<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107       0.75      0.626      0.699        0.4      0.654      0.561      0.605      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G      1.525      2.676      1.915      1.174         20        640: 100%|██████████| 9/9 [00:07<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         27        107      0.799      0.668      0.792      0.451      0.709      0.592      0.653      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      1.448      2.564      1.891      1.114         11        640: 100%|██████████| 9/9 [00:07<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.824      0.655      0.781      0.453      0.736      0.636      0.699      0.315\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27        107      0.824      0.655      0.781      0.452      0.736      0.636        0.7       0.31\n",
      "            Helicopter         27        107      0.824      0.655      0.781      0.452      0.736      0.636        0.7       0.31\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                   all         28        263      0.901      0.835      0.916      0.495      0.856      0.806      0.878       0.37\n",
      "            Helicopter         28        263      0.901      0.835      0.916      0.495      0.856      0.806      0.878       0.37\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 153.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.24G      1.432      1.967      1.139     0.9124        272        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.719      0.673      0.747       0.43      0.661      0.598      0.653        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      1.268      1.964     0.9984     0.9461        163        640: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.734      0.669      0.747      0.427      0.659      0.589      0.643      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.01G      1.463      2.486      3.058      1.002         50        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.735      0.648      0.745       0.43      0.702      0.589      0.658      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      1.264      1.938      1.093     0.9509         97        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.756      0.668      0.757      0.431       0.71      0.589      0.651      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.445      2.156      1.587     0.9384         95        640: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.782      0.664      0.758      0.433      0.723      0.586       0.65      0.292\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27        107      0.747      0.662      0.754      0.428      0.688      0.579      0.645      0.294\n",
      "            Helicopter         27        107      0.747      0.662      0.754      0.428      0.688      0.579      0.645      0.294\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                   all         28        263      0.949      0.787      0.907       0.48       0.92      0.749      0.867      0.374\n",
      "            Helicopter         28        263      0.949      0.787      0.907       0.48       0.92      0.749      0.867      0.374\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 122.04it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.6G       1.57      2.114      1.705      1.164        310        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27        107      0.853      0.551      0.712      0.428      0.657       0.57      0.642      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.45G      1.316      2.165       1.34      1.046        252        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.827      0.551      0.706      0.429      0.724       0.54      0.635      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       7.8G      1.419      2.119      1.489      1.072        335        640: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.792       0.57      0.712      0.429      0.721      0.523      0.628      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.15G       1.47      2.362      1.255      1.141        174        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.772      0.579      0.715       0.43      0.715      0.523      0.627      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.54G      1.452      2.258      1.153      1.053        241        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107       0.74      0.589      0.716      0.431      0.833      0.465      0.624      0.294\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.772      0.579      0.715      0.431      0.728      0.514      0.626      0.296\n",
      "            Helicopter         27        107      0.772      0.579      0.715      0.431      0.728      0.514      0.626      0.296\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         28        263      0.889      0.791      0.887      0.463      0.851       0.76      0.844      0.358\n",
      "            Helicopter         28        263      0.889      0.791      0.887      0.463      0.851       0.76      0.844      0.358\n",
      "Speed: 0.2ms preprocess, 15.6ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:01<00:00, 150.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      1.995      4.011      5.122      1.488         31        640: 100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.104      0.505      0.126     0.0679     0.0944      0.458      0.103     0.0394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G      1.857      3.453      3.492      1.394         25        640: 100%|██████████| 10/10 [00:08<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.591      0.477      0.523      0.312      0.598      0.459      0.484      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G       1.61      2.928      2.322      1.249         30        640: 100%|██████████| 10/10 [00:08<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.706       0.54      0.654      0.388       0.54      0.523      0.538      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.49G      1.539      2.595      2.128      1.175         22        640: 100%|██████████| 10/10 [00:08<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.693      0.626      0.728      0.441      0.631       0.57      0.624      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G      1.424       2.39      1.649      1.086         81        640: 100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.756      0.692      0.772      0.457      0.655       0.64      0.638      0.279\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27        107      0.757      0.692      0.771      0.457      0.654      0.636      0.636      0.278\n",
      "            Helicopter         27        107      0.757      0.692      0.771      0.457      0.654      0.636      0.636      0.278\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         28        263      0.907      0.855      0.909      0.529      0.829      0.787      0.817      0.339\n",
      "            Helicopter         28        263      0.907      0.855      0.909      0.529      0.829      0.787      0.817      0.339\n",
      "Speed: 0.2ms preprocess, 16.0ms inference, 0.0ms loss, 7.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 155.50it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.05G      2.314      2.893      4.261      1.418         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         27        107      0.695       0.71      0.759      0.441      0.645      0.617      0.622      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      1.717       2.55      2.666       1.43         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.719      0.695      0.766      0.448      0.621      0.607      0.607      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.01G      1.836      3.015      2.553      1.498         37        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.716      0.682      0.754      0.451      0.619      0.607      0.609      0.272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      1.539       3.04      3.151      1.251         25        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.729      0.682      0.755      0.451      0.631      0.598      0.609      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.402       2.56      2.261      1.211         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.737      0.682      0.757       0.45      0.638      0.598      0.611      0.274\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27        107      0.729      0.682      0.755       0.45       0.63      0.598      0.611      0.274\n",
      "            Helicopter         27        107      0.729      0.682      0.755       0.45       0.63      0.598      0.611      0.274\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                   all         28        263       0.88      0.837      0.902      0.515      0.795      0.757      0.809      0.343\n",
      "            Helicopter         28        263       0.88      0.837      0.902      0.515      0.795      0.757      0.809      0.343\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:01<00:00, 154.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.24G      1.978      3.955      4.914      1.496          5        640: 100%|██████████| 11/11 [00:08<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                   all         27        107      0.555      0.346      0.395      0.227      0.518      0.327      0.371      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G      1.757      3.012      2.665      1.284          4        640: 100%|██████████| 11/11 [00:08<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.659      0.598      0.648      0.371      0.644      0.524      0.577      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.4G      1.625      2.701      3.068      1.163          1        640: 100%|██████████| 11/11 [00:09<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all         27        107       0.82       0.68      0.767      0.462      0.737      0.617      0.635      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G      1.442      2.441      1.712      1.099          5        640: 100%|██████████| 11/11 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.858      0.678      0.785      0.416      0.739      0.582       0.62      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      1.275      2.176      1.299      1.014          3        640: 100%|██████████| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                   all         27        107      0.844       0.76      0.855      0.541      0.812      0.729      0.798      0.379\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27        107      0.844       0.76      0.856      0.542      0.803       0.72      0.784      0.381\n",
      "            Helicopter         27        107      0.844       0.76      0.856      0.542      0.803       0.72      0.784      0.381\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                   all         28        263      0.919      0.863      0.912      0.513      0.885      0.833      0.865      0.376\n",
      "            Helicopter         28        263      0.919      0.863      0.912      0.513      0.885      0.833      0.865      0.376\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 143.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.09G     0.9608      2.397      1.576     0.9963         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.816      0.748      0.824       0.51      0.752      0.673      0.743      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G     0.9178      2.034      1.167     0.9938         46        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107       0.83      0.748      0.844      0.512       0.76      0.682      0.742      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.8201      1.746       1.02     0.8992         82        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.834      0.753      0.844      0.514      0.761      0.684      0.741      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.8896      1.926      1.078     0.9346         66        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.841      0.748      0.845      0.515      0.768       0.68       0.74      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.9188      2.044      1.322      1.044         50        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.844      0.738      0.845      0.513      0.762      0.673      0.741      0.364\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27        107      0.845      0.738      0.845      0.512      0.767      0.673      0.741      0.363\n",
      "            Helicopter         27        107      0.845      0.738      0.845      0.512      0.767      0.673      0.741      0.363\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                   all         28        263      0.943      0.837      0.915      0.521      0.914      0.809      0.861      0.362\n",
      "            Helicopter         28        263      0.943      0.837      0.915      0.521      0.914      0.809      0.861      0.362\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:01<00:00, 151.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.21G      1.973      3.802      4.555      1.397         46        640: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.524      0.374      0.418       0.22      0.615      0.318      0.381      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.35G       1.71      3.085      2.696       1.24         94        640: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         27        107      0.747      0.458      0.623      0.361      0.799      0.467      0.589      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      1.552      2.558      1.935      1.155         90        640: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.708       0.68       0.74      0.456      0.676      0.626      0.638      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      1.365      2.273      1.519      1.054         91        640: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.722      0.654      0.702      0.426      0.674       0.58      0.588      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.36G      1.276       2.15      1.295      1.044        102        640: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.774       0.72       0.79      0.499      0.722      0.673      0.695      0.332\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27        107      0.775       0.72      0.791      0.501      0.723      0.673      0.696      0.333\n",
      "            Helicopter         27        107      0.775       0.72      0.791      0.501      0.723      0.673      0.696      0.333\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n",
      "                   all         28        263      0.814       0.84      0.872        0.5      0.777      0.802       0.81       0.35\n",
      "            Helicopter         28        263      0.814       0.84      0.872        0.5      0.777      0.802       0.81       0.35\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 141.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.79G      1.353      2.621      2.048      1.023         37        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all         27        107      0.793      0.679       0.74      0.479      0.781      0.666      0.682      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.01G       1.24      2.329      2.003     0.9361         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.789      0.664      0.742      0.477      0.778      0.654       0.68      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.08G       1.38      2.047      1.131     0.9244        251        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.814      0.656       0.74      0.475       0.78      0.631       0.66      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      1.232      1.949     0.9911     0.9475        152        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.795      0.645       0.74      0.479      0.772      0.626      0.662      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.624      2.159      1.338     0.9335        178        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27        107      0.797      0.645      0.744      0.476      0.759      0.619      0.649      0.323\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27        107      0.792      0.675      0.741      0.478      0.781      0.666      0.682      0.334\n",
      "            Helicopter         27        107      0.792      0.675      0.741      0.478      0.781      0.666      0.682      0.334\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                   all         28        263      0.833      0.815      0.881      0.503      0.793      0.795      0.821      0.341\n",
      "            Helicopter         28        263      0.833      0.815      0.881      0.503      0.793      0.795      0.821      0.341\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:01<00:00, 139.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      1.944      3.834      4.758      1.402         51        640: 100%|██████████| 12/12 [00:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.735      0.411      0.521      0.319       0.74      0.399      0.489      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.63G      1.718      3.056      2.443      1.277         23        640: 100%|██████████| 12/12 [00:10<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.662      0.664      0.697      0.399      0.557       0.57       0.49      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.38G       1.47      2.463      1.802      1.095         22        640: 100%|██████████| 12/12 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.856      0.721        0.8      0.491      0.774      0.645      0.696      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G      1.359      2.285      1.622      1.045         17        640: 100%|██████████| 12/12 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.79      0.701      0.798      0.508       0.79      0.599      0.689       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      1.245      2.193       1.41       1.04          9        640: 100%|██████████| 12/12 [00:10<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.777      0.794      0.852      0.534      0.901      0.598      0.739      0.337\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27        107      0.777      0.794      0.852      0.535      0.901      0.597      0.739      0.339\n",
      "            Helicopter         27        107      0.777      0.794      0.852      0.535      0.901      0.597      0.739      0.339\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n",
      "                   all         28        263      0.938      0.878      0.933      0.527      0.849      0.814      0.828       0.33\n",
      "            Helicopter         28        263      0.938      0.878      0.933      0.527      0.849      0.814      0.828       0.33\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 150.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.95G      1.213      2.018      2.443       1.09         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.799      0.748      0.834      0.524      0.816      0.622      0.735      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      1.488      2.656      2.669      1.317         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.864      0.715      0.839      0.526      0.809      0.634      0.738      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G       1.86      2.422      3.048      1.536         25        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.828      0.722      0.845      0.528      0.773      0.654      0.741      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G     0.8473       2.13      3.379      1.055         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107       0.79      0.773      0.848      0.531      0.734      0.664      0.742      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.658      2.596       2.29      1.346         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.799      0.782      0.847      0.528      0.726      0.692      0.733      0.338\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27        107       0.79      0.774      0.848       0.53      0.733      0.668      0.743      0.333\n",
      "            Helicopter         27        107       0.79      0.774      0.848       0.53      0.733      0.668      0.743      0.333\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "                   all         28        263      0.943      0.878      0.934      0.517      0.861      0.802      0.824       0.33\n",
      "            Helicopter         28        263      0.943      0.878      0.934      0.517      0.861      0.802      0.824       0.33\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:01<00:00, 148.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      2.003      3.703      4.741      1.397        100        640: 100%|██████████| 12/12 [00:11<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.655      0.364      0.455      0.263      0.644      0.336      0.423      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      1.717      3.002      2.994      1.239         99        640: 100%|██████████| 12/12 [00:10<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         27        107      0.633      0.613      0.646      0.364      0.543      0.534      0.518      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.38G      1.466      2.537      1.791      1.089        136        640: 100%|██████████| 12/12 [00:10<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.735      0.622      0.693      0.397      0.644      0.579      0.536      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G      1.501      2.513      1.946      1.142        112        640: 100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.782      0.785      0.819      0.519      0.728      0.729      0.725      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      1.338      2.178      1.265      1.051        133        640: 100%|██████████| 12/12 [00:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.798      0.814      0.873      0.561      0.819      0.721       0.79      0.367\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27        107      0.799      0.817      0.873       0.56       0.82      0.722      0.791      0.368\n",
      "            Helicopter         27        107      0.799      0.817      0.873       0.56       0.82      0.722      0.791      0.368\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         28        263      0.883      0.882      0.927      0.513      0.818      0.819      0.818       0.31\n",
      "            Helicopter         28        263      0.883      0.882      0.927      0.513      0.818      0.819      0.818       0.31\n",
      "Speed: 0.2ms preprocess, 16.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 147.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       6.9G       1.35      2.585       1.15      1.172         54        640: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107       0.82      0.766      0.824      0.522      0.688      0.702      0.665      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.423      2.409      1.281      1.049         84        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.825      0.766      0.829      0.522      0.724       0.71      0.684      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.01G       1.39      2.569        1.6      1.102         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.831      0.766      0.834      0.533      0.736      0.702      0.688      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.43G      1.368      2.518      1.262      1.035         96        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         27        107      0.823       0.78      0.842      0.535      0.739      0.715      0.692      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      1.306      2.344      1.367      1.042         75        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27        107      0.841      0.789      0.848      0.534      0.746       0.72      0.696      0.333\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27        107       0.83      0.776      0.843      0.533      0.738       0.71       0.69       0.33\n",
      "            Helicopter         27        107       0.83      0.776      0.843      0.533      0.738       0.71       0.69       0.33\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         28        263      0.917      0.848      0.933      0.521      0.842      0.752      0.794      0.313\n",
      "            Helicopter         28        263      0.917      0.848      0.933      0.521      0.842      0.752      0.794      0.313\n",
      "Speed: 0.2ms preprocess, 16.1ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:01<00:00, 135.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.68G      2.054      3.639      4.454      1.408         47        640: 100%|██████████| 13/13 [00:11<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         27        107      0.605      0.416      0.522      0.263      0.601      0.402       0.47      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G      1.655      2.755      2.111      1.215         72        640: 100%|██████████| 13/13 [00:11<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.739      0.645      0.756      0.445      0.678      0.589      0.653      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.5G      1.422      2.478      1.913      1.101         21        640: 100%|██████████| 13/13 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.777      0.692      0.764      0.448      0.666      0.701       0.67      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G      1.323      2.231      1.567      1.059         31        640: 100%|██████████| 13/13 [00:11<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.853      0.814      0.837      0.529      0.835      0.776      0.774      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G      1.289      2.107      1.183      1.037         53        640: 100%|██████████| 13/13 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27        107      0.854      0.817      0.875      0.562      0.834      0.797      0.851      0.423\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27        107      0.854      0.817      0.874      0.561      0.834      0.797      0.855      0.427\n",
      "            Helicopter         27        107      0.854      0.817      0.874      0.561      0.834      0.797      0.855      0.427\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "                   all         28        263      0.916      0.894      0.937       0.51      0.904      0.882      0.929      0.422\n",
      "            Helicopter         28        263      0.916      0.894      0.937       0.51      0.904      0.882      0.929      0.422\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/temp_9_37/train/labels... 15 images, 0 backgrounds, 0 corrupt: 100%|██████████| 15/15 [00:00<00:00, 129.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/temp_9_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.22G      1.326      1.945      1.296     0.9454        477        640: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27        107      0.879      0.738      0.867      0.539      0.862       0.72      0.816      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.41G      1.208       1.92     0.8716     0.9329        156        640: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27        107      0.881      0.738      0.868      0.538      0.875      0.729      0.825      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.89G      1.514      2.025      1.167     0.9632        471        640: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27        107      0.888       0.74       0.87      0.539      0.887      0.736      0.845      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.63G      1.759      2.005      1.064      1.092        298        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.865      0.748      0.869      0.537      0.877      0.732      0.843      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.45G      1.183      2.093     0.9409     0.9474        196        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27        107      0.865      0.748      0.874      0.544      0.876      0.738      0.841      0.406\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27        107      0.865      0.748      0.874      0.545      0.886      0.725      0.841      0.408\n",
      "            Helicopter         27        107      0.865      0.748      0.874      0.545      0.886      0.725      0.841      0.408\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n",
      "                   all         28        263      0.878       0.85       0.91      0.497      0.841      0.844      0.879      0.395\n",
      "            Helicopter         28        263      0.878       0.85       0.91      0.497      0.841      0.844      0.879      0.395\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/retrain/train/labels... 216 images, 0 backgrounds, 0 corrupt: 100%|██████████| 216/216 [00:01<00:00, 148.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/valid_9/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      2.031      3.637      4.682      1.369         15        640: 100%|██████████| 14/14 [00:12<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         27        107      0.568      0.645      0.597      0.329      0.541      0.617      0.547      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G      1.615      2.821      2.267      1.185        146        640: 100%|██████████| 14/14 [00:12<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         27        107      0.603      0.652      0.574      0.319      0.566       0.56      0.454      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G      1.445      2.299      1.573       1.08         77        640: 100%|██████████| 14/14 [00:12<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27        107      0.594       0.71       0.67      0.387      0.549      0.664      0.542      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.5G      1.313      2.154      1.367      1.017         72        640: 100%|██████████| 14/14 [00:11<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27        107       0.84      0.776      0.841      0.546      0.808      0.748      0.789      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.52G      1.267      2.129       1.29      1.016        127        640: 100%|██████████| 14/14 [00:12<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27        107      0.884      0.783       0.86      0.552      0.888       0.71       0.82      0.413\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27        107      0.884      0.783       0.86      0.551      0.889       0.71      0.821      0.413\n",
      "            Helicopter         27        107      0.884      0.783       0.86      0.551      0.889       0.71      0.821      0.413\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_9/test_9/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                   all         28        263      0.948      0.897      0.942      0.528      0.908      0.859      0.876      0.358\n",
      "            Helicopter         28        263      0.948      0.897      0.942      0.528      0.908      0.859      0.876      0.358\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 6.0ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 9: \n",
      " defaultdict(<class 'list'>, {0: [0.013633970111955957, 0.039656674587681816, 0.006850561749852119], 1: [0.013464023537533665, 0.039827700984656274, 0.006860222012946598], 2: [0.012214850444288473, 0.041066633683667766, 0.006379189803361005], 3: [0.01362395796490482, 0.04153037396620989, 0.008062268855388383], 4: [0.014689017199065393, 0.045546335684972676, 0.008077008039040314], 5: [0.01435663493030496, 0.04668187025990801, 0.007181835462275151], 6: [0.015422176853964404, 0.04590153144068014, 0.008636151637315383], 7: [0.05236486098155644, 0.14008283691755224, 0.023676150803744463], 8: [0.03578313936888805, 0.09852169574272202, 0.013076818419675562], 9: [0.027722100803124455, 0.07235230514539301, 0.010443448516749708], 10: [0.04127000660228155, 0.10912668974652906, 0.018817033389783022], 11: [0.044218656291121664, 0.11745790194951417, 0.024829147766612963], 12: [0.13212579952922063, 0.3460402334350475, 0.05562844485700993], 13: [0.08518492497848149, 0.23523670140960268, 0.03297508286981968], 14: [0.15852245099840256, 0.4028894048415049, 0.06590326666893481], 15: [0.30571802713922297, 0.7249055532472279, 0.16173098088364452], 16: [0.24007090658438762, 0.6843360928985617, 0.05933110273800961], 17: [0.21258691001928817, 0.6379581777815152, 0.06869677979907109], 18: [0.2939035069256958, 0.7681170174029752, 0.1427177790559347], 19: [0.24466289395729932, 0.6198604006817143, 0.09749073376575665], 20: [0.19857246488522262, 0.5411013448311268, 0.07054459130134567], 21: [0.2984192162575968, 0.8150460387556996, 0.11617395751869668], 22: [0.25691772345976344, 0.6860236116639525, 0.11331847799159513], 23: [0.31252346863570124, 0.8093444694713493, 0.13708234159197377], 24: [0.29273820171428, 0.7617888886257651, 0.13481535285554477], 25: [0.3479079781679464, 0.8675955562730667, 0.18483354066648416], 26: [0.31507582697320846, 0.8200909979825497, 0.14139669647032851], 27: [0.3113995796157747, 0.8077279238698354, 0.14039391855655323], 28: [0.37030532130022903, 0.8775540231336987, 0.192687335485717], 29: [0.37372791738882033, 0.8668724775555519, 0.19757789880106935], 30: [0.3391836075931586, 0.816890796802956, 0.19446405829214408], 31: [0.37627227343804226, 0.8646017369995566, 0.2152893161004866], 32: [0.3501896629765983, 0.8097607701225664, 0.23659983062641518], 33: [0.3301167527903545, 0.8275125251672516, 0.17867325202248113], 34: [0.3095004748170361, 0.8184632363644333, 0.12671307540241797], 35: [0.42227861455349053, 0.9292134080038195, 0.24348791610822018], 36: [0.35793095406490194, 0.8763701446259522, 0.19008473631795467]})\n",
      "Количество данных (train) для класса 9: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 216]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACGvElEQVR4nO3dd3yT1f7A8c+TpEm696SFsvcGGaI4Kuj1p+JAVBRF1OvAhdd7Ra/gxsl1cUUQ90K9TlRQUZQ9LVs2FEo3dM8kz++Pp0mbDrqSpg3f9+uVF82TJ+f5pk3aL+d8zzmKqqoqQgghhBBeQufpAIQQQgghXEmSGyGEEEJ4FUluhBBCCOFVJLkRQgghhFeR5EYIIYQQXkWSGyGEEEJ4FUluhBBCCOFVDJ4OoLXZbDaOHz9OYGAgiqJ4OhwhhBBCNIKqqhQUFBAXF4dOd+q+mdMuuTl+/DgJCQmeDkMIIYQQzXD06FHi4+NPec5pl9wEBgYC2jcnKCjIw9EIIYQQojHy8/NJSEhw/B0/ldMuubEPRQUFBUlyI4QQQrQzjSkpkYJiIYQQQngVSW6EEEII4VUkuRFCCCGEV5HkRgghhBBeRZIbIYQQQngVSW6EEEII4VUkuRFCCCGEV5HkRgghhBBeRZIbIYQQQngVSW6EEEIIL7B9O0ybBlFREBoKF14I338PqurpyFqfJDdCCCFEO/e//8GQIfD++5CVBbm58Msv8H//Bw88cPolOJLcCCGEEO1YWhpcey1YrWCxVB23WrV///Mf+Pprj4TmMZLcCCGEEO3YW29piUxV74wKeqvjcb0eXnnFI6F5jCQ3QgghRDu2Zg3YbFX3oyZtIP7239AHFQNa4rNunYeC8xBJboQQQoh2TK8HRdG+1vmW4ZuYjT6gjLDzdzmdczqR5EYIIYRox8aPr/ra1CHX8bVfjwzMXTIxGOCCC1o/Lk+S5EYIIYRox6ZMgZAQ0OnA1OEEALYK7c97WNJOrFh54AEPBugBktwIIYQQ7VhwMPz4IwQGgjn+JAC5K3phLTDhE1rM9U8e5KyzPBxkK5PkRgghhGjnRoyAv/ba8IvPA6BncCQjffsAsKFoP0dPFHsyvFYnyY0QQgjhBY6X5mHFRqifDxuW+/PZC7GM6hJOaYWNJ5fsargBLyLJjRBCCOEFthzRhqSGdgpFURQUReHxy/pi0Cn8tCuD3/ZkejjC1iPJjRBCCOEFNjuSmzDHsR7RgUw9MxGAx7/dSZnFWtdTvY4kN0IIIUQ7p6oqm6r13FR3b1IPogJNHM4pZuEfBz0RXquT5EYIIYRo546dLCGroAwfvcKA+GCnxwJMBh65uDcAr/+2n2Mnvb+4WJIbIYQQop3bdERb36ZvXDBmn9rLEV86MI4RncNOm+JiSW6EEEKIdm5zPUNSdoqi8OSEfuh1Cst2ZrDCy4uLJbkRQggh2rnNR3IBGFZPcgOVxcWjEwF4zMuLiyW5EUIIIdqxgtIK9qTnAzDkFMkNwL1J3U+L4mJJboQQQoh2LPloLjYV4kN9iQ4yn/LcQLPPaVFc3CaSm3nz5pGYmIjZbGbEiBFs2LChUc/79NNPURSFCRMmuDdAIYQQoo2y19ucakiquurFxU8t2e3O0DzG48nN4sWLmTFjBrNnz2bLli0MHDiQ8ePHk5l56mKnw4cP849//IOzTrfdwIQQQohqGiomrklRFJ64TCsuXroznd/3ZrkzPI/weHIzd+5cbr31VqZOnUqfPn2YP38+fn5+vP322/U+x2q1MnnyZB5//HG6dOlyyvbLysrIz893ugkhhBDewGpT+TMlF2i43qa6njGB3OTFxcUeTW7Ky8vZvHkzSUlJjmM6nY6kpCTWrl1b7/OeeOIJoqKimDZtWoPXmDNnDsHBwY5bQkKCS2IXQgghPG1PegGFZRb8jXp6xQQ16bn3JXUnMtDEoewi3lp5yE0ReoZHk5vs7GysVivR0dFOx6Ojo0lPT6/zOatWrWLRokUsXLiwUdeYOXMmeXl5jtvRo0dbHLcQQgjRFmxO0YakBncMRa9TmvTcQLMPj/xNKy5+7dd9pOaWuDw+T/H4sFRTFBQUcMMNN7Bw4UIiIiIa9RyTyURQUJDTTQghhPAGW5pYb1PTZYPiOMO+cvF33rNyscGTF4+IiECv15ORkeF0PCMjg5iYmFrnHzhwgMOHD3PJJZc4jtlsNgAMBgN79uyha9eu7g1aCCGEaCPs2y40N7lRFIUnL+vH315d6SguHtsj0pUheoRHe26MRiNDhw5l+fLljmM2m43ly5czatSoWuf36tWL7du3k5yc7LhdeumlnHvuuSQnJ0s9jRBCiNNGZn4pR0+UoCgwqGNIs9vxxuJij/bcAMyYMYMbb7yRYcOGccYZZ/Dyyy9TVFTE1KlTAZgyZQodOnRgzpw5mM1m+vXr5/T8kJAQgFrHhRBCCG+2pbLepmd0IEFmnxa1dV9Sd77detxRXHzXud1cEaLHeDy5mTRpEllZWcyaNYv09HQGDRrE0qVLHUXGKSkp6HTtqjRICCGEcLtNh1tWb1Odvbj4vsXJvPbrPiYM7kCHEN8Wt+spiqqqqqeDaE35+fkEBweTl5cnxcVCCCHarcv/u5o/U3KZe/VArhgS3+L2VFVl0oJ1bDh0gov6xfDG9UNdEKXrNOXvt3SJCCGEEO1MaYWVHal5AAzrFOaSNrWVi/ui1yn8uCOdP9rxysWS3AghhBDtzPbUPCqsKhEBJhLCXDd81CsmiBtHJQLtu7hYkhshhBCinam+WaaiNG3xvobcd0F3IgJMHMwuYtGq9rlysSQ3QgghRDvjymLimoLMPjxycS8AXlu+v12uXCzJjRBCCNGOqKrqmAbelM0ym2LCoA6ckRhGSYWVp79vfysXS3IjhBBCtCOHc4o5UVSO0aCjXwf3zPpVFIXHK4uLf9iezsp97au4WJIbIYQQHpObC2vXwpYtYLF4Opr2YdNhbcuFAR2CMRn0brtO79ggpozqBMDsb9pXcbEkN0IIIVrdiRMwbRpER8Po0TB0KCQkwMsvw+m1+lrT2Yek3FFvU9P9F/Rol8XFktwIIYQXKq4oZv+J/WQUZjR8civLz4ezzoL33oPy8qrj6elw//3wwAOei6092NzCncCbIsjsw8N/qyouPt5OiosluRFCCC+SVZTFHUvuIPz5cLq/1p2Yl2I4c9GZ/HzgZ0+H5vDqq/DXX2CtZ5TjP/+B7dtbN6b2Iq+4gr0ZhYD7iolrunxwB4YnhlJSYeWpdlJcLMmNEEJ4iayiLEa8NYKFWxZSail1HF+Xuo7xH47nk+2feDC6KvPng81Wdd8Un4MhpMhx32CARYs8EFg7sOWo1mvTOcKfiABTq1xTW7m4X7sqLpbkRgghPEhVYeNGWLwYfvrJeZimqWb9NouUvBSsqnOXiE21oaJyy3e3UFBW0MKIW8Zmg9TUqvt+vY8TM3kdsVNXYorXCmUtFjjUfso7WtXmyvVthnRsnV4bu96xQdwwsrK4+NudlFtsDTzDsyS5EUIID1m9Gvr3hzPOgGuugfHjoUMHePPNprdVXFHMu1vfxapaUVRffGyd8bUOR6cGOM4pqSjh0x2fuvAVNJ1OB4GB2tf6gFLCxmnjTzqjlairNmDqcAKDAcJcs12S12nNepuaHMXFWW2/uNjg6QCEEOJ0tGEDnHde7enP2dlw++1QUgL33Vf3cy1WG2l5pRw9UUxK5W1XeiYhhc9gUKPRE+w4t1w5RLrpAVSlHIPOwJ6cPe57UY10ww2wYIFK2N+2ojdbKEsLxlZmwDcxh6iJG8n47Ayuu671/3i3dRarjeSjuQAMS2z970+wrw8zL+rFA59v5bVf93HZoDjiQly3r5UrSXIjhBAe8OCDWkGtrZ7e/Uceq2DU34o5UVaVwNhvqSdLsNhqz5c20cPxtZVcFIwY1c6EVtzKCeM8bKqNQGOgu15Soz3wAHyefATfztnYKnRkLxmENd+XqKs2YO50grhrNxDRYwQQ4ulQ25TdaQWUVFgJNBvoFhnQ8BPc4IohHfh0YwobD5/k6e93M2/yEI/E0RBJboQQopUdOQJ//FF1X/GxEDT8ED4RBRhCijGEFKP3rWDS2/W3YdTriA/zpWOYn+P23y1PsuvkH5SThqqUYLYOIqr8CQKtF1Fq2UaxYSVX9bnK/S+wAbaAQkLO2U25FXJX9EbNC0BRIfN/w+lz+0YK/U4w5Z31fHzLSPrHBzfc4Gli8xGtJmlIx1B0OtdultlYiqLw+KX9+L/XVvL99jSu3ZfNmO4RHonlVCS5EUKIVpae7nw/6IyDhIzZV+s8X8VIr4Sq5CWh8t9O4X5EB5pr/YHrFHcd4z98DxWtV6dUn0y+4TOCLdcQXnE353TvQt+ovm57XY1RYbUx47Nkyq02zuoewZSkTiT/CUYj/O1vBuI6DufGtzew6chJrl+0no9uGUG/DpLgAGxOyQW0ncA9qU9cEFNGJfLumsPM+nYHS+89G6OhbZXwSnIjhBCtLCam2h29lcDBRwDI35RI6ZFwLLl+WPP9WPiGgZtvbny7F3S9gA+v+JBbv7uVkooSDDoDBT6LMdn6Ybb1Q82dSpnF6tYl+xvy2q/72XYsj2BfH164aiAxwQoXJFU/w8C7N5/BlEXr2ZKSy/WLtB6cPnHu2UOpPdlcue2CJ4qJa7r/gh4s2Xacg1lFvL36ELeP7erpkJy0rVRLCCFOA506wZgx2swh/97H0fuXY8k3c/LX3pTsj6EiOwijzsCVVza97ev6X0f6A+m8+X9vcs+Ie3h07CMsnnYhoX4+7DpeyJwf/nL9C2qkP1NOMu+3/QA8NaEfMcHmOs8LMGkJzsCEEHKLK5j81jr+Ss9vzVDbnOO5JRzPK0WvUxiYEOLpcAj29eGhi3oD8OryfaTlta2ViyW5EUIID3jhBdDrVYKGHwagYHMiqFW/kp98EoKbORoTaArk1qG38uK4F5l9zmzGdh3I3KsHAfDumsMs3ZHWsuCbobjcwozPtmK1qVw6MI5LBsad8vwgsw/v33wGA+KDOVlcweSF69mb4dk1ejzJvp9U79hA/E1tY9DlisEdGNYplOJyK099v9vT4TiR5EYIITxg5Eh4ffEJjFH52Mr1FG5LACA0FF5/3fX7K53bK4q/n90FgAe/2MbRE8WuvUAD5vzwF4eyi4gJMvPkZf0a9ZxgXx8+uHkEfeOCyCkq57qF69ifeXomOJsqF+8b2sqL952KTqetXKxT4Pttaazal+3pkBwkuRFCCA/ZVKAthDauRwfef8vIDz9AWhrcdRcobpgM84/xPRncMYSCUgvTP/mz1VaZXbEnkw/WaXVFL04cSLCfT6OfG+znw4fTRtA7NojswnKuXbieA1mF7gq1zXLsBJ7YtlY3tBcXA8z+dgeZ2Ta2bIG9ez27u7skN0II4QEpOcX8vFvbsfuhKxKZPBkuughMbtwuyEev47VrBxPs68PWo7m8sMz99Tcni8r55xfbALhpdGKzpg2H+hv56JYR9IoJJKugjOsWruNQdlHDT/QSxeUWdh7Xao7aQjFxTfdf0INQXyMHsoroeekhhg6Fnj2hd2/47DPPxCTJjRBCeMC7aw6jqjC2RyTdolpvYb34UD9euGoAAAtXHmJ5ZYLlDqqq8sjX28ksKKNrpD8PXdSr2W2FVSY4PaIDyMgv49oF6ziSc3okOFuP5mG1qcQEmYmrpwjbk0rzfcj5VSsuDhy5D32gVly8dy9MmqQNs7Y2SW6EEKKVFZRW8NmmowDcPKZzq19/XN8Ypp6ZCMADn2/leK57Zrp8nZzKD9vTMegU/jNpEGaflk1BDw8w8dEtI+kWFUB6finXLljX6rVDnlA1JBWK4o7xyhZ6/HFIW9OB0mOh6IxWQs/Viovtw1IzZmjbirQmSW6EEKKVfbH5GIVlFrpG+nO2h1Z3nXlRbwbEB5NbXMHdn/xJhdW19TepuSXM+mYnAPec350B8SEuaTcy0MTHt46gS6Q/x/NKuWbBOo6d9O4EZ5N9fZs2VExsV1oK774LFovCiZ/7otrAv3ca5k5V2YzVCh980LpxSXIjhBCtyGpTeXfNYQCmntnZY/8TNxp0vH7tEAJNBjYfOcncn/e6rG2bTeUfn22loNTCoIQQ7jzHtQu8RQWa+eTWkXSO8Cc1t4RrF65zW++Tp9lsKlvsKxN7YLPMhmRmapu8AlRkBlPwZycAQpN2gk5LmPV6OHCgdeOS5EYIIVrRr39lciSnmGBfH64Y0sGjsXQM9+PZK7X6mzdWHOD3vVkuafedNYdZezAHXx89/5k0CIPe9X9qooO0BKdTuB9HT2gJTltbSM4VDmYXkldSgdlHR+/YtrdKc3Cw88y+3JU9Kc8OoGBTZ1C1B1RVW+KgNUlyI4QQreid1dr072vP6Iif0fOLsV08IJbrR3YEYMbiZDLyS1vU3t6MAp5bqs3CeuTi3nSO8G9xjPWJCdYSnIQwX47kFHPdwvUs+6OUKVOgSxfo0QPuvx/273dbCG5nX99mYHwIPm5IElsqOBjGj9d6ZwDUMh/SFp1N4daOjuTGYtEKi1tT2/tOCSGEl9qdls+aAznodQpTRnXydDgO/764D31itYXy7vnkT6y25i1QUm6xcf/iZMotNs7pGcnkER1dHGltcSG+fHLrSDqE+HIou4ibP1jH4m9KOXQI9u3TZur06QPffef2UNxi8xEtuWmLQ1J2s2drvTdVPThVXTk6HUycCP0at26jy0hyI4TwqGPHtNV4w8O1//0lJMBTT0Fenqcjcz17r82F/WKIC/H1cDRVzD56Xr9uMP5GPesPneCV5bV3KG+MV5bvZefxfEL9fHj+ygGtVk8UH+rHjEEjseSb8QkvInzienR+ZYDWa2CxwFVXQWpqq4TjUvbkpi2ub2M3ciR8+y2EVa4vaDBoSY2iwHXXwfvvt35MktwIITzmr79g0CB45RU4cQJsNi3ZmT0bRoxo/emj7pRTWMbXyccBuPnM1p/+3ZAukQE8c0V/AF77dR+r9zftm7/5yAneWKFVjT5zeX+iglp3PZaPFviR/ZmW4BgjCom+Zh06Xy3BUVUtwVm4sFVDarETReUcrFyscEgbnClV3UUXwfHj2qJ9jz6q7Z124IA2S8rsgaV5JLkRQniEqmrj8Lm52lTR6mw2rU7i3ns9EppbfLw+hXKLjYEJIQzpGOLpcOp02aAOXDM8AVWFez9NJqugrFHPKyqzcP/irdhUbTPFi/rHujnS2n77Dcpy/Mn4dCSWAhPGyEKir1uHIUzbqsFmg19/bfWwWmRLZa9Nt6gAQvyMHo6mYUajNgQ1a5a2tk1nD+bwktwIITxi/XrYtq16YqM6hhJAO/7ZZ9pU0/au3GLj/cq9lW4+M7FNLsRmN/uSvvSMDiS7sIz7Fyc3qv7mqe93k3KimA4hvjx2Wd9WiLI2+7fUcrJaghNRSOyU1fh2T3c6p73YdKTtbZbZXkhyI4TwiM2bnf/YBI08QMLdvxA4/KDjmMUC27d7IDgX+377cbIKyogOMnFRv9bv1WgKX6NWf+Pro2fV/mzeWHHqqUbLd2fwyYYUAF6YOIAgc+M3xXSl887Taj0ALCcCSHtvDKUpYehMFqKu2EzoOX9x7nmts1Goq9h7boa24WLitkqSGyGERxiNzrsG+/VMAyD0nN1Oq5sa235v/Cmpqsrbqw4DMGVUIkZD2/+12z06kCcqe2Dm/ryX9Qdz6jwvp7CMf/1Pyz5vGdOZ0V09s9oywH33acmwna3ITMbiEeRv0MZGgkYcYFv4BrILGzfU5mnlFhtbj+UCbbuYuK1q+58yIYRXGjeuqudGMVowRmm7His6iLj0T/SBJYSEwPDhnovRFTYfOcn21DxMBh3XnuH+qdGuMnFYAlcM6YBNhXs+/ZOcGkmBqqo8/NV2sgvL6BEdwD/G9/RQpJoxY7TCdKjqwcGmI/+PPpz8fjAmnZ4tx3L4v1dXOfZqast2Hs+jzGIj1M+HLm5cK8hbSXIjhPCITp20gmK9HkyxuSg6sOSbKUsPQu9XTuSELdx7v9UjMy1c6e3K6d9XDOlAmH/76oZ68rJ+dI30JyO/jJvmb+WqiSrdu2sz3G58LJVlOzPw0SvMvbrlm2K6wj33wJYtMGWKtoBfnz7aIn7J38ax5N4z6RLpT3p+KZPeXMsH646gqs1bz6c1VJ8C3pZrtNoqSW6EEB6zcCGMHQumeG1jwNKjYZz8bijWEh9McbmU9d3l4Qhb5tjJYpbu0IpZbxrd9qZ/N8TfZOC1a4egU3Vsz85ieepB9u+HHYeKWZGvbYo5qU8P+nUI9nCkVQYPhkWLYM8e2LlTm5LcubM21PbNXWdyUb8YKqwqj369gwc+30pJubXhRj3A3rs0RIakmkWSGyGExwQEwM8/w6hLtOSmW3AYU6/249GkQSgKfLIxhc82HfVwlM33/toj2FQY0y2CnjGBng6nWTb9EkTWMq3+JmjMHkwdThBx8VZ0JgtlqaG89Y+ulLWPMhYCzT78d/IQHv5bL3QKfLkllcv/u5ojOUWeDs2JqqqObReGdQrzcDTtkyQ3QgiPsqk2jhTlAvDui6G88QbcdkkU9yf1AODfX+9gR2r7W664qMzCp5WziG4ek+jZYFrghRegeHsCRbviUHQqUZPWY+54Alu5nuwlA8lIV/jf/zwdZeMpisJtZ3flw1tGEBFg5K/0Av7vtVUs353h6dAcjp0sIbOgDINOYUB82+kVa08kuRFCeNTutAKKy60Emg30iKrq3Zh+bjfO7xVFucXG3z/YzMmicg9G2XRfbjlGfqmFzhH+nNMjytPhNEt+PuzYATabQs6yflSc8EPno02nPrm8D5ZcfwwGWLHCs3E2x+iuESy5+yyGdAyhoNTCtPc2MfenPc3eV8uV7PU2fTsEt4lapvZIkhshhEdtPKwNSQ3rFIpOV33DPYW5kwbRKdyP1NwS7m3kgnJtgc2m8s7qwwDcNDrR6XW1J9XrbdVyH7K+GYK1xIeiXXEUbkuo87z2JCbYzKe3jeLGyk1MX/11P1Pf3ejxRNqxWabU2zSbJDdCCI+q2vW4dm1BsK8P868fitlHxx97s3j5l72tHV6z/L43i4PZRQSaDVw1NN7T4TRbUBD07Vs1Zb8iM5hjr15A9neDse/8bLFoReHtldGg4/HL+vGfSQMd77P/e20V2495bii0PWyW2dZJciOE8BhVVZ16burSOzaIOY4NHffzy662UxtRH/v072uGJ+BvMjRwdtulKNqO7c49M1W9UHo9REZqO263d5cPjuerO8909BReOX8NizemOB7/6y9tdt9bb8G+5m2a3iiFZRb+StfWfJLkpvkkuRFCeMzRE1rhpI9eYWBCSL3nXT443jF0cP9nyRzObluzW6rbm1HAyn3Z6BRtReL27qab4M47ta/11co/dDoIDIQffvDMrs/u0Ds2iG+njyGpt1br9a//beeeD7dx/jgrvXvDbbfBrbdqa+hcdBFkZbk+huSUXGwqxIf6Et3KO6t7E0luhBAes+mI1mvTrxGFk49c3IehnUIpKLVw+4ebKS63nPJ8T7HX2ozrE0NCmJ9ng3EBRYHXX4effoJLLoHERG2oatYs2LULhg3zdISuFezrw4IbhvHg+J4owLc7jrI7bi36oGKn837+Gc49F0pKXHt9GZJyDUluhBAes7FyLY/hddTb1GQ06Pjv5CFEBJj4K72AmV9ub3MrzJ4sKufLLccAuHlM+1u0rz6KAhdcAF99BYcOaTOoZs+G2La9B2iz6XQKd53bjSsjz8Ba7IMxJo/Ym1Zh7lzVVWO1aosEfvyxa69tT/ilmLhlJLkRQnjMpsp6m8b+LzU6yMy86waj1yl8k3ycd9ccdmN0TffxhhTKLDb6dQhiuOzk3O6t+CSS9PfHUJYWjN63gqiJGwgetQ/QkmpFgXffdd31rDaV5JRcQFYmbilJboQQHpFbXM6+zEKgaf9LHdElnJkX9QLg6e93OwqSPa3CauODtUcAuPnMzrIfkBfIzARLnh/pH42iILkjigIhZ+8lcsJmFKMFVYUMF9a3780ooKDMgr9RT8/o9rmidVshyY0QwiPstQVdIv0JDzA16bnTxnTm/wbEYrGp3PnRFjLzS90RYpP8uCOd9PxSIgJMXDzAS8drTjOdOmmF01j1nFjWn5wf+6NadPj1zCDmhtWYwovo1Ml117N/JgZ3DMWglz/PLSHfPSGER2w83PyFyhRF4bkrB9AjOoCsgjLu+ngLFVabq0NskrdXadO/bxjZCZNBVpX1BrfeCrZqb6vCbR1J/3gklgITxohCoq5fxZirM112vS1HZLNMV5HkRgjhEZvthZONKCaui7/JwPzrhxJoMrDx8Eme+WG3K8Nrki0pJ0k+motRr2PyyI4ei0O41jXXwOjRzlPgy9NCSXtvDGWpoejMFt49uJF5v+13SXH7Jpkp5TKS3AghWl1phZWtR7UVYBszU6o+XSIDeOnqgYA2Bfub5FSXxNdU9unflw2KI6KJQ2yi7TIatSnw06ZpXzuOW81cHjySSUM7oqrwwrI93PnRForKmr88QWZBKSknilEUGNwxpOXBn+YkuRFCtLodqXmUW22E+xtJDG/ZWjDj+sZw5zldAXjof9sdq7u2lrS8En7YngbA1DO9Z/q30Pj7w5tvQnq6luj8/DOkpcF/X9fx3MT+zLmiPz56hR93pHP5f1c3e4HJLUdyAegZHUiQ2ceFr+D0JMmNEKLVbXLsJxXqkllFD4zryZhuEZRUWLn9g83kl1a0uM3Gen/tEaw2lZFdwugTF9Rq1xWtKzRUW+snKQlCQqqOX3tGRz69bRRRgSb2ZhRy6eurWLGn6XU49mFaGZJyDUluhBCtzr6+TUuGpKrT6xRevXYwHUJ8OZxTzIzFW7HZVMrKtOm8ZWUuuUwtJeVWPl6v7T90s/TanLaGdgrlu7vHMKRjCPmlFqa+u5H/rmhaHY6sTOxaktwIIVqVzaa6pXAyzN/IG9cPwajX8cvuDM6/+wBBQRAdDcHBcPPN2uq6rvTVn6nklVTQMcyP83tHu7Zx0a5EB5n55LaRXHtGAqoKzy/dw/SP/2xUHU5phZUdqbJZpitJciOEaJbmTg45mF1IbnEFZh8dfeOCXRrTgPgQbh/eV7tOwB50cdpy+WVl8MEHMHSotruzK6iq6tj9+6bRieh1smjf6c5k0DPnigE8fXk/fPQK329P48o31nAk59R1OPYatIgAEx29YD+ytkCSGyFEox04oO0QHRysTY/t3Bmefx6KmlBDaV/fZlBCCEaD638FffpMRwq3JaAoEHHpn44NDy0WyM/XZr60hMUCOTnw2+5s9mcWEmAyMHFYvAsiF95i8ohOfHLrSCIDtX3QLn19Nb/vrX8L8aohqRBZ2dpFJLkRQjTKxo0waBAsXKglCaoKhw/DzJlw1lnasUa1c9i+MaBr6m2q27pVizPnp76O/YAiJ2zBEFYIOhtWK6xZo2142FTHj8P06VpiFxEB1z2u9dpc0DWeQJndImoYlhjGd9PHMCghhLySCqa+s4H5vx+osw5H1rdxPYOnAxBCtH1WK1x5JZSUaF9XZ7PBtm3wyCPw2msNt7W52kwpV3MkLVY9WV8PIfbGVZhi8+hw6++oNgVLni+WXD+eXupP0kl/EiP8SAz3JyHMD59TLHd/5AiMHAlZWdrrN4QVYu6charC2zMTuaEfDBni8pcj2rmYYDOL/z6SWV/vZPGmozz741/sSM3j+asG4OtjYM0a+OUXlZUllSsTd3R9wn+6kuRGCNGgpUvh6NFqBxQVnW85tmJtwTqrFd5+G+bMgYCA+tvJzC/lSI62UJk7lpj3q1auYM33I+vLYYSevwuf8EJ0Ris+ocX4hBazJiubNUuqztXrFDqE+JIY4U/ncD86hfvTOcKfTuF+JIT5ceedOkdiAxA09DAAJfuiKcrwZ/Jk2LVL2yVaiOpMBj3PXtmffvHBPP7tTpZsS2N3aiE53wxj62o/TBHFxEwrR7XouGZ8EN98CX37ejrq9k+SGyFEg7ZsAYNBqzcBCDlnN0HDDpG9ZDDFu+MAKC6Gfftg8OD627F3v7trobLzzwdfX62HCaAsNYz098cAKvqAMgwhRQTEFnHvv4s5nl/EoewijuQUU1JhJeVEMSknivmjRpt6RaE03pfwK/ypOOmHJdcf/37HAMjfnIjVqhUpr1kDZ57p8pckvICiKNwwshM9owO548PNHMgpwDZ0FeZjQ9AHapu+lqUHk3pAz9ixWg9ktEy+axFJboTXO3AAfv1V+1/3qFEwcKCnI2p/jEbn2VH+PdJRdBB2wQ5Kj4Q7enBMDew8sKmymNhV69vUFBgIDzwATz9dczaXgrXQjLXQzMxbwnn00qpHVFUls6CsMtEp4lB2ceW/VYmPvcfHt1qL5ZmBlKWEO+7v2CHJjTi1MzqHcV3EGF7ctxlTXB5RV6/HctIfgLLUUKxWyM2FN96Axx7zaKjtniQ3wmudPAk33QTffef8h+7MM+Hjj6Gj7G/YaH/7Gzz0kPa1PqAUQ4jWNaL3rSAsaSfZ3w4hIQF69Tp1O5scm2W6r3DyscfgxAn473+1GV2Kov38rVa4+2549FHn8xVFITrITHSQmZFdwp0eU1WVb38uY9ItRfiEFmEILcYQWoTer4zcVT2AqnEoP5nBKxphyWe+ZKwaRdgFOwgYcAyfcG2qYVmq9pmwWuHDDyW5aSlJboRXqqiA8eO14ZSakxPWr4cxYyA5GcKkfq9R+veHceNg+XIwddB6XywFJvT+5fj3TqNodzoz749Bd4r5l0VlFnYe16ZUNXcn8MbQ62HePLj3Xm1tm7Q0iIuDKVOgW7emtaUoChedY8a/yMyJo+H1nmcwwIUXtjBwcVo4eRJUi56cHwdQlh5M2Pm7QFUoO1aV8OfleTBALyHJjfBKX32lTQmui8UCqamwYEFVb4Ro2KefwkUXwd4ArfeleG8MisVA4IgDdLx8B9feGA7UX0ez9WguVptKXLCZDiG+9Z7nKj16wJNPtrwdoxEefhj+8Y+6H1cU+PvfITKy5dcS3q93b62mxmJRKPwzkbKUcBSDDVuJNqar00H37h4O0gvIOjfCK73/vvY/eDu/nmkEDDriuG+zabN7ROOFhsLq1dDvHK3npm9UGNcN7E6HIH9KlTLm/LD7lM+3L9431I29Nu4yYwb8859aIqPXaz01hsr/Gk6eDHPnejY+0X7cdltVYT5ARU4g5RlVK3XbbHDHHR4IzMtIz43wShkZ1ddjUQn/21Z0RiulhyOw5GoFfFn1Lxgq6lFqsZBarA0tLZ4XSlyIno2HB3D1m2tZvOkolwyMY0z3iDqfa6+3Ge7Geht3URR47jntD9N772nT4iMj4frrYcAAT0cn2pNzzoGpU+Gdd2o/ptNpw7/XXtvqYXmdNtFzM2/ePBITEzGbzYwYMYINGzbUe+6XX37JsGHDCAkJwd/fn0GDBvHBBx+0YrSiPUhMrOq50Zkr0Bm1TMcYow1mK8rpUVCcmQmLFsErr8CyZbUX4Guq6kNLcZVDS8MTw5gyshMAD325jeLy2hsFWqw2ttgX73PDysStpWtXeOIJ7Q/T889LYiOaTlHgrbfgpZe0WjC70FBtIcxvvqnqFRTN5/HkZvHixcyYMYPZs2ezZcsWBg4cyPjx48nMzKzz/LCwMB555BHWrl3Ltm3bmDp1KlOnTmXZsmWtHLloy6ZNq/pDrvMvcxw3RlftEfD3v7d2VK2nogLuuQc6dIBbbtGGVS68UNsL6vffm9+uY5n4GkNLD17Yiw4hvhw7WcKLy/bWet5f6QUUlVsJNBnoGRPY/ACE8AI6nfaZTEmB3bu1Gpz0dC1xNho9HZ138HhyM3fuXG699VamTp1Knz59mD9/Pn5+frxdT0HEOeecw+WXX07v3r3p2rUr9957LwMGDGDVqlWtHLloy8aNg0sv1X6J6P3KHceNMXno9dpCc1OnejBAN7vzTnj99aqxfZtN+zc1VfvebN7cvHbt+0LVHFoKMBl45or+ALyz5pBjiwW7TZXPG9wpVHbPFqKSXq8tn9CnjyQ1rubR5Ka8vJzNmzeTlJTkOKbT6UhKSmLt2rUNPl9VVZYvX86ePXs4++yz6zynrKyM/Px8p5vwfjodfP65tqCbX1hVz40pOo8bpqj8+qu2kq032rdP6/auY38+bDatR6s5a2hYbSp/puQCdW/wN7ZHJFcOiUdV4V//20aZpWoMzN7jM1w2BhRCtAKPJjfZ2dlYrVaia6wzHR0dTXp6er3Py8vLIyAgAKPRyMUXX8xrr73GBRdcUOe5c+bMITg42HFLSEhw6WsQbZfRqNVFPPufqp4bnW8FT75UQnDwKZ7oQlu2aDMfzj0XrrgCFi+G8vKGn9cSn37qPFPMGJNL0Kh9oNO6b6xW+OEHbSXUptiTXkBhmYUAk4FeMUF1nvPo//UmIsDI/sxCXv91P6D9J8Te4zO0HRYTCyHaH48PSzVHYGAgycnJbNy4kaeffpoZM2awYsWKOs+dOXMmeXl5jttRp93/xOmgsKLM6f6OVPf33qmqNqY+dKjWi7JihVYoeM012u7RGRnuu3Z2Nk6L6YWev4vQs/cS0P+Y45jNpi0m1hSbK2c7De4YUu/QUoifkScu6wfAf387wNT78xl+TgkZ+WXoUOhgDmnaRYUQohk8mtxERESg1+vJqPGbPiMjg5iYmHqfp9Pp6NatG4MGDeKBBx7gqquuYs6cOXWeazKZCAoKcrqJ00tWoXNXyc7j7l/+c/58+M9/tK9r1r3s2QOXX173sJErdOrkPCvKJ1Rb3t23e1VvqNEIUVFNa9dRTNzA0NLf+sfS0y8Gq6qy7OQ2/jqhJUUlx4Pp39vA6tVNu64QQjSVR5Mbo9HI0KFDWb58ueOYzWZj+fLljBo1qtHt2Gw2ysrKGj5RnJZyCrX3Rs9obZbOjlT3Jjc2m7YmSn0sFli7tv4VlFvq+uurem4UHwt6fy258+2Ug+JjwWCA664Df/+mtWvf9LKhqdyrVsHy5/tiLTVgjMkj9Bxtcb+y1FCKirR9qpraaySEEE3h8WGpGTNmsHDhQt577z12797NHXfcQVFREVMrp7JMmTKFmTNnOs6fM2cOP//8MwcPHmT37t289NJLfPDBB1x//fWeegmijcuuTG7O6amtj7/juHuHpQ4cgCNViyGjDywh5saV+PerGhI1GGDpUvdcPyoKnnmm8jrBJY7jisGGf7csQkKaXlCclldCam4Jep3CoI4hpzx37lxQysycXN4HwJFclR4LxWaDgoK6FzATQghX8fhSQZMmTSIrK4tZs2aRnp7OoEGDWLp0qaPIOCUlBV21AoKioiLuvPNOjh07hq+vL7169eLDDz9k0qRJnnoJoo3LKdL+uJ7ZLYKFKw+SVVBGRn4p0UFmt1zPUmMNO79eaZhi8tGN2k/RDq2gXVG0tWjc5cEHtU1BH1tY7HS8y9kZfPXPWDp1alp79l6b3rGBBJhO/Wvj55+174FlRzz+fY7j2zkbgLJjWo+PqmrnzJjRtBiEEKKxPJ7cAEyfPp3p06fX+VjNQuGnnnqKp556qhWiEt4ip7LmJj7Ul25RAezNKGRHap7bkpvOnSE4uGpnX5/wQu3fsGL0gSVYC3ypqIAzznDL5R2mTQN6FPPk9xBqMnOyrBRiM0noZKOpnbabm7C6cFW9j0LO0v7EXL+GipxAbMUmxzk1E0AhhHAljw9LCeFOpRVWCsu0v6QRgSb6ddDmgLtzxpTZDLffXlX34hNWWPVYp2z0ekhI0GpP3C01VxuWumJ4LOH+RvJKKhzTspvCvi9UQ8XEAKNGVU1Ft+b7kTr/PDIXV2Vyej2MGdPkEIQQotEkuRFezV5vY9TrCDQZ6BdXmdy4ecbU7Nlw5pna8JNPeJHjuF/nHPz94csvndeicZejJ7VhqU7hfpzXS5se9dPOps1DLyyzsKuyTmlYI9apuf/+GntY2XSANnVcUbSk79ZbmxSCEEI0iSQ3wqvZh6QiAowoiuLoudnp5hlTvr5aXcnzr5Q7bf8Q1jub5GSVYcPcenmHoye05CYh1I8L+mh1bD/vykBtwjz05JRcbCp0CPElNrjhZZ3/7//APgeg+gaABoOW0H36qfOGgUII4WqS3AivZu+5CQ/Q6j36xGnrHB3PK3VMEXcXkwnGXqINSUUGmjAadJQqZVj9Cxt4pmuoqsqxk9qwVEKYL2d1j8TsoyM1t4TdaQWNbsc+JNWYXhu7Z57RdiEfPx7CwyEmRtvL688/tZWahRDCnSS5EV7N3nMTHqDtShdgMtAlQlvgZaebp4QD7M/UEpnesUEMq6xXWb0/x+3XBcgtrnDUG8WH+uFr1HNWd206/E+76t/epKaqYuKmbZ0wbhwsWaKtmJyWBgsWQL9+TWpCCCGaRZIb4dWyi7TemYiAqpk6fSuHpra7eWgK4EBlctMtMoAzu0UAsOZAttuvC1X1NpGBJsw+WoFP9aGpxrBYbWxxrEzc8EwpIYRoCyS5EV4tu8C55wagX+XQVGtsw7A/S0tuukb5M7prOABrD+Rgtblp74Vqjp6oHJIKraqTOb9XFDpF67Wyz6Q6lb/SCygqtxJoMtAzJtBtsQohhCtJciO8Wo6958a/quemNaaD2x3Iquq56d8hmECTgfxSS6skVvaem4QwP8ex8ACTY62aXxrRe2Mfkhp0is0yhRCirZHkRng1x2ypwOo9N1pyk3KimLxi9y0TXFphdRT0do0KwKDXMaKL1nvTGnU31WdKVWcfmmpM3Y19s8zhiTIkJYRoPyS5EV7NMVuqWs9NsJ8PCWHaUM3ONPf1oBzMKkJVIdjXh3B/LbmyD021Rt3N0WozpaqzJzfrD54gr+TUyd3mygX/mlpMLIQQniTJjfBq2YW1a26gqvdmpxuHpuz1Nt2iAlAUbUjHXlS88fAJyizWep/rCsfq6blJjPCnR3QAFpvKij2Z9T4/NbeE43mljdosUwgh2hJJboTXstpUTlTW3ERWmy0F1epu3Fj7Yp8p1TXS33GsR3QAEQEmSits/JmS67Zr22zV17jxq/W4Y2jqFKsVb6rstekTG4SfsU1sQyeEEI0iyY3wWrnF5dgnJYX6O/fc9K2cMeXO6eDVe27sFEWpGpra776hqcyCMsqtNnQKxATX3iD0gj4xAKzYk1lvD9JmxxRwGZISQrQvktwIr5VTpA1Jhfr54KN3fqv3rRyWOpRd5FjoztWqem4CnI6f2a2yqPiA+4qK7TOlYoN9a712gAEdgokOMlFUbmVtPXFsOly5eF8TViYWQoi2QJIb4bWyC5y3XqguMtBETJAZVYXdaa6vu7HaVA5maxtmVu+5ARjdVau72Xo0122JlWOmVFjde0HpdApJve2zpmoPTRWWWfgrvXKzTFm8TwjRzkhyI7xWdmXPTXiNISm7qvVuXD80lXqyhHKLDaNBR3yNgt6EMD8Swnyx2FQ2HHJP703VAn61623s7HU3v+zKwFZjUcE/U05iUyE+1LfOYS0hhGjLJLkRXsu+MWZEYO2eG4B+HbS6G3cs5rc/S9uYskuEf52L351Z2Xuzxk3r3dS1gF9No7qGE2AykFlQxrYaCd7Gw83bT0oIIdoCSW6E17KvcRNRX8+NfTq4G2ZMHcjUhqRq1tvYja6cEu6uupuGhqUATAY9Y3tWbqS503lBv82VO4EPlcX7hBDtkCQ3wmtV7QheX8+NltzsyyyktMK1a87YdwPvGlVPclM5Y2p3Wr6jh8mVHNPATzEsBTCujo00LdaqaerScyOEaI8kuRFey76AX0Q9yU10kImIACNWm+ryomL7nlLV17ipLiLARK/KjSjXHnRt702F1UZaXv1r3FR3Ts8oDDqFfZmFHK4sgP4rvYDiys0ye0TLZplCiPZHkhvhtRxbLwTUPSylKIpjSviO465LblRVrXONm5rss6Zcvc9UWm4pNhWMBl2txQtrCvb1YWTlflf23hv74n1DOoXKZplCiHZJkhvhtRw7gteT3EBVUfFOF86YOlFUTm5xBYoCXSJOldy4Z58pezFxfKgvukYkJzU30tx4RIqJhRDtmyQ3wmtlF5x6WAqgvxu2YTiQpQ3vdAjxxdeor/e8EV3C0OsUjuQUc6wyIXGF+nYDr09SZXKz+chJcgrL2Fw5U2qoLN4nhGinJLkRXqm43EJJZZFwfQXFULVS8Z70AsotNpdce389KxPXFGj2YUC8dv01Lpw1VTUNvP6ZUtV1CPGlX1wQNhWmv3KE9PxS9IrCoIQQl8UkhBCtSZIb4ZXsM6XMPjr8T9F7Eh/qS7CvDxVWlb0ZBS659oFG1NvYVa1347qhqcYs4FddcjL8tVzba2p1zkEASo4HccetBkpKXBaWEEK0GkluhFfKshcT+5tQlPrrThRFqaq7cdHQVGN7bgBGV9tnSlXVBs5unMYs4Gd34ACMHQupG7ShKZ1R6+0qPRbGhx/C1VeDi8ISQohWI8mN8Eo5jmng9RcT29kX83PVDuFN6bkZ0jEUk0FHVkGZIylqqab03Dz/PBQXQ2l6IJbcqmGsstRQbDZYsgTWrnVJWEII0WokuRFeybH1QgNToQH6OvaYavl08JJyK6m5WnJR3xo31Zl99I5dt1e7YGiqpNzqmALfUM2NqsIHH4DFAqBQvD/a8VjZMS0mgwE+/LDFYQkhRKuS5EZ4pYbWuKmuX5w2LLU7LR+LtWVFxQezC1FVCPXzOWUhc3X29W5cUVRsn3UVaDIQ7OtzynPLynCqqSn+KxaA8uwArEXaZpk2G2S7dqa6EEK4nSQ3witlN7D1QnWJ4f4EmAyUWWyOadzN1ZR6G7szK/eZWncwB6utZQUujjVuwvxOWWsEYDJBWLWto8pSw8j4bDhZXw51HNPpoFOnFoUkhBCtTpIb4ZVyihpe48ZOp1PoE2ffIbxldTf25Kgx9TZ2/TsEE2g2kF9qafH1q+ptGp4Grihw222grzaZrPRQFJaTVbFbLHDzzS0KSQghWp0kN8IrZRc0vDpxdf3iXLOY34Fm9NzodYpjC4TVLVytuGo38MZNA//HPyAhwTnBqe6++6B37xaFJIQQrU6SG+GVqrZeaFzdS9U2DC0rKm7KTKnqzrRvxdDCfaYc08Ab0XMDEB6uzYa68krnBCciAl54AebObVE4QgjhEQZPByCEO1TV3DSy56ZyxtTO43nYbGqj9mSqyWpTOVi5s3ZTem6gWt3NgRO8udDKkEF6hg3Tho6awjEs1cieG4CYGFi8GDIyYOdOMJth+HDwOXU9shBCtFmS3AivY7HaOFlcmdz4N67npkuEP2YfHUXlVg7lFDU5OQFtplK5xYbJoKNDI3tOACoq4LVnArBaTRBQxr1P5lJ2NJxBg+D996F//8bH0JQF/GqKjtZuQgjR3smwlPA6J4srUFWt1yPMv3E9Nwa9jt6xLSsqts+U6hzhj74JPT9Tp8LrrymUHtGGpsyJWt3N9u1w1llw8GDj2skrrqCg1AJo20oIIcTpSpIb4XXsa9yE+RmblGT0dwxNNa/uxl5v07UJ9TZ//gkffaQtqFdyRBuaMnfSkhurFYqK4NlnG9eWvdcmIsCIn1E6ZYUQpy9JboTXyWlivY1djElLbj77OY8ZM2Dz5qZd195z060JQ1offqitAgw4em5MsXkoxgpAm4pdtYrwqdlnSsU3csNMIYTwVpLcCK/T1JlSqgqzZsH9N2nDUifUPF57TWXYMLjiCigtbdx17WvcNKXnJjOzamNKa74fFSf9UHQq5o4nHOeUlmo9OA1pSb2NEEJ4E0luhNfJKrBvvdC45Gb+fHjySSjPCkS16NCZLeCvzTr65hu4/faG21BVtVk9Nx06OM+IKj2kDU35ds5yHPP3h4BGNNmUBfyEEMKbSXIjvI59deLwRhQTW63w1FOVd2w6yrMCATDGaEXFNps2Y+nYsYavmVdSgaJAl0ZsmGl3003OQ04lh6IAMFcmN3o9TJtW/yJ71UnPjRBCaCS5EV7HviN4ZGDDPTfJyXD8eNX98gxtaMoY7Txj6rvvTt2OvdcmPtQXs08jMpFKvXrB9OlV90tTwlGtCj6hxRjDi4iIgH/9q3FtOVYnlpobIcRpTpIb4XUcC/g1ouemuNj5fllqKAD+vY+Dou0QrijOu2fXxTFTqhnr47zyitZ7FBwMarnBEcOgC7NYtw7i4hpuQ1VVjp20L+Anw1JCiNObJDfC69h7bhpTUNyzp/OQT/FfcViLjBhCSvDrlQZoQ1MNLaTXnHobO50OHnkE0tLgl1/g6rMiAeh/QRaJiY1rI6ugjDKLDZ0CcSGS3AghTm+S3Aiv05StF6KinPdVUi168jcnAhA88gA6nUpiIpx//qnbac5MqZp8fbXr3HapltysOZBDucXWqOfa621ig33x0cvHWghxepPfgsKrqKrqWMSvsVPBX35Zm7VkT3AKtyRiK9NjjCogsEcWH3+s9a6cin038KZumFmXPrFBRASYKC63sunIiYafQNVMKVmZWAghJLkRXqao3EpZZW9HYxfxi42FjRvhnnsgKAhsZT4Ub+8IwJjbDjBq1KmfX1xuITVXSy6aU3NTk06ncHZ3bUr4H3uzG/WcYzJTSgghHCS5EV4lu3KNGz+jvklbEERFwdy5cOKEdtvyaRd89Ao7Mk6wuYHek4OVQ1Jh/sZG72XVkLE9taGp3/dmNXCmpmqNG0luhBBCkhvhVeyrEzd16wU7vR5CQ6FjhJkrBscD8MaKU+9cWTVTqvHr2zRkTLcIFAV2p+WTmd/wEslVa9zIsJQQQjQpubHZbDz33HOceeaZDB8+nIceeoiShubICtGK7MXEja23OZXbxnZBUeCX3Rnsyyio9zxX1tvYhQeY6Ben7XX1x76Gh6ZkAT8hhKjSpOTm6aef5uGHHyYgIIAOHTrwyiuvcNddd7krNiGazF5MHO7f8uSma2QA4/vEADD/9/p7b/a3YI2bUxnbQxua+qOBoSmL1cbxXK13RwqKhRCiicnN+++/z3//+1+WLVvG119/zXfffcdHH32Ezda46apCuFuOo+fGNbUvt5/TFYBvklMdRcM1Hchs+TTwupxdmdys3JeF1abWe15aXilWm4pRryM60OzSGIQQoj1qUnKTkpLC3/72N8f9pKQkFEXhePX164XwoKYs4NcYgxJCGN01HItN5a2VtXtvLFYbh7K15KY5C/idyuCOIQSaDJwsrmBHal6959mHpDqE+qLTKfWeJ4QQp4smJTcWiwWz2fl/hj4+PlRUVLg0KCGaqykL+DXW7WO13ptPNxzlZOWmnHbHTpZQbrVhMujo4OKVgX30OkZ3CwdOPTR1TNa4EUIIJ42fK4u2QNpNN92EyVT1v+LS0lJuv/12/P2rZop8+eWXrotQiCZo6gJ+jXFW9wj6xgWx83g+7609zH1JPRyP2bdd6BIZ4JZek7E9oli2M4Pf92Zx9/nd6zxHiomFEMJZk3pubrzxRqKioggODnbcrr/+euLi4pyOCeEpOUWu77lRFIU7Kmtv3l1zmOJyi+Mx+zRwV86Uqu7sHtpifn8ezSWvpO4eUtkNXAghnDWp5+add95xVxxCuIQ7em4ALuoXS6fwPRzJKebTDUe5eUxnoKrnxpVr3FQXH+pHl0h/DmYVsWZ/Nhf1j611zlHZDVwIIZy4bBE/VVX58ccfueqqq1zVpBBNUmG1kVus9W64OrnR6xRuO7sLAG+tPEiFVZsh6O6eG6g2JXxf3XU30nMjhBDOWpzcHDp0iEcffZSOHTty+eWXU1ra8GqqQrjDicohKZ0CIb4+Lm//yiHxRASYOJ5XyrfJx1FVtVrPjfuSm7Md691ko6rOU8JLK6xkVm45ITU3QgihaVZyU1ZWxkcffcR5551Hz549eeaZZ5gxYwaZmZksWbLE1TEK0Sj2Iakwf5NbinvNPnqmVQ5Hzf/9AHtSysgvtaAo0DnCPcNSACM7h2M06EjNLXH0FNkdqxyS8jfqCfVzfUInhBDtUZOSm82bN3PnnXcSExPDyy+/zIQJEzh69Cg6nY7x48cTFBTkrjiFaJCrF/Cry+SRHTHrDezLLGT0VG3dG1u+Hy89r6eszD3X9DXqGdE5DIDfa+wSXn2mlKLIGjdCCAFNTG5GjBiByWRi3bp1bNy4kXvuuYfo6Gh3xSZEk7irmLi6+a/6kLG6EwCBww4BUJIRwKxZcPHFUF5+qmc3n73upuYu4ccq623ipd5GCCEcmpTcnH/++SxatIgnnniCpUuX1hr/F8KTctywgF91e/fCQw9BwaZEVIsOpfLTU3HCH5sNfv0V3nrLLZd21N2sP5hDaYXVcVxmSgkhRG1NSm6WLVvGzp076dmzJ3fccQexsbHce++9ANIlLjwuu8i9PTcLF4JOB9YiM4Xb4x3HLTlVxcSvv+6WS9M9KoCYIDNlFhsbDp1wHJeZUkIIUVuTC4oTEhKYNWsWhw4d4oMPPiArKwuDwcBll13Gww8/zObNm90RpxANyi5wb8/Nrl1grew0yd/QBbVyv9iKyuRGVWHPHrdcGkVR6hyaktWJhRCithZNBb/gggv4+OOPOX78OPfccw8//vgjZ5xxhqtiE6JJctzccxMQAHq99rUl15+Ty/tSsKUjZamhjnP83JhjVE0Jr5bcnJBhKSGEqKlJKxRXV1payrZt28jMzMRms9GxY0cef/xxDhw44Mr4hGg0d8+WuuIK+OyzqvsFWxKdHjcYYOJEt1wagDHdItApsC+zkOO5JQSYDY4tGWRYSgghqjQruVm6dClTpkwhOzu71mOKonD//fe3ODAhmso+Wyrc3z09N5dfDj17woEDYLE4P6bTab06DzzglksDEOznw6CEELak5PLH3iz6x2v7uIX5G/E3Nfv/KUII4XWaNSx19913M3HiRNLS0rDZbE43q9XacANCuJiqqlU9N4HuSW6MRvjlF+jdW7vv46PdAAIDYckS6NvXLZd2GNsjCtDqbhxDUqEyJCWEENU16797GRkZzJgxQ9a4EW1GfqmF8sr9nsL93beIX3w8JCdr075/+AHKymD4cLj6avfW29id3SOC//yyl1X7sxmUEKLFJMXEQgjhpFnJzVVXXcWKFSvo2rWrq+MRollyKoekAkwGzD56t15Lp4OkJO3W2gbEhxDi50NucQXfbTsOSL2NEELU1Kzk5vXXX2fixImsXLmS/v374+PjvKfNPffc06T25s2bxwsvvEB6ejoDBw7ktddeq3fW1cKFC3n//ffZsWMHAEOHDuWZZ56RWVqnuZwi92+90BbodQrDEyL4eU8aO1LzASjO9EVVQZaaEkIITbOSm08++YSffvoJs9nMihUrnBbwUxSlScnN4sWLmTFjBvPnz2fEiBG8/PLLjB8/nj179hAVFVXr/BUrVnDttdcyevRozGYzzz33HOPGjWPnzp106NChOS9HeIHsyp2xw9249UJb8Pbb8NlrkYSOT3Mce+ExP36eD999BxERHgxOCCHaCEVtxh4KMTEx3HPPPTz00EPodC1aKocRI0YwfPhwXq9c2tVms5GQkMDdd9/NQw891ODzrVYroaGhvP7660yZMqXB8/Pz8wkODiYvL082+vQiH6w7wqNf72Bcn2gWTBnm6XDc4qefYPx40AeUEn/Xcsfx1AXnQIE/I0bAypXSgyOE8E5N+fvdrMykvLycSZMmtTixKS8vZ/PmzSRVK17Q6XQkJSWxdu3aRrVRXFxMRUUFYWFhdT5eVlZGfn6+0014H3vNjbtmSrUFTz1Vuf1DoZnyzEBAWxXZkm/GYoHVq7WbEEKc7pqVndx4440sXry4xRfPzs7GarXWmnUVHR1Nenp6o9r417/+RVxcnFOCVN2cOXMIDg523BISEloct2h7HDuCu3GmlCfl5mq9MrbKLR9KDmmrFVsLzGDVCqgNBvjqKw8FKIQQbUizam6sVivPP/88y5YtY8CAAbUKiufOneuS4Bry7LPP8umnn7JixQrMZnOd58ycOZMZM2Y47ufn50uC44XcvcaNp5WUON8v/iuWoOGHKDtW1WOpKLXPE0KI01Gzkpvt27czePBgAMesJbum7A4eERGBXq8nIyPD6XhGRgYxMTGnfO6LL77Is88+yy+//MKAAQPqPc9kMmEyeecfPFHFnty4a3ViT4uMhLAwOFG5IXh5egipb56DraSqp8pigX79PBSgEEK0Ic1Kbn777TeXXNxoNDJ06FCWL1/OhAkTAK2gePny5UyfPr3e5z3//PM8/fTTLFu2jGHDvLN4VDSNY+sFL50KbjDAHXfAs89W7Uxuza9a30ZRwNcXrr/eQwEKIUQb0rKKYBeYMWMGCxcu5L333mP37t3ccccdFBUVMXXqVACmTJnCzJkzHec/99xzPProo7z99tskJiaSnp5Oeno6hYWFnnoJog1w1Nx48VTwmTNhyBCtqLg6vV5Lbt59F2QCoBBCtIHkZtKkSbz44ovMmjWLQYMGkZyczNKlSx1FxikpKaSlVa3p8cYbb1BeXs5VV11FbGys4/biiy966iUIDyu32Mgv1Xay9OZF/Pz94bffYNYssC8BpSja9PA//nDvjuRCCNGeNGudm/ZM1rnxPml5JYya8ysGncLepy5Cp/P+hV5sNsjL04ai6qmlF0IIr9KUv9/NqrkRoi1xFBMHGE+LxAa0oanQUE9HIYQQbZPHh6WEaKksezGxl86UEkII0TSS3Ih2r3rPjRBCCCHJjWj37FsvRHrxTCkhhBCNJ8mNaPe8fY0bIYQQTSPJjWj3HFsvSM+NEEIIJLkRXiC7yF5zI8mNEEIISW6EF8gukGEpIYQQVSS5Ee1eTpEUFAshhKgiyY1o11RVlangQgghnEhyI9q1vJIKLDZtB5Ewf0luhBBCSHIj2rnsyl6bILMBk0Hv4WiEEEK0BZLciHbNvsaNTAMXQghhJ8mNaNek3kYIIURNktyIds0+U0p6boQQQthJciPaNVnjRgghRE2S3Ih2zb46sfTcCCGEsJPkRrRrOY5NMyW5EUIIoZHkRrRr9qngEbLGjRBCiEqS3Ih2zd5zExEoPTdCCCE0ktyIds0xFVx6boQQQlSS5Ea0W6UVVgrKLIDU3AghhKgiyY1odywW+N//4JKrtF4bxaZjyZcGyss9HJgQQog2QZIb0a4UF8MFF8BVV8GqzVq9TUWhkeuvVxgzBnJzPRufEEIIz5PkRrQr998Pf/yhfa2YtOTGWqzV22zZArfd5qnIhBBCtBWS3Ih248QJePddsNm0+zp/bRzKVqTV21it8MUXcPSohwIUQgjRJkhyI9qNdetwqqvR+9l7bqqKiVUVfv+9tSMTQgjRlkhyI9oNe4+NnSG0GABLgfmU5wkhhDi9SHIj2o3hw8FgqLpvjCwAoCIr0Om8M89szaiEEEK0NZLciHYjOhomTQK9HkDFJ0JLbsorkxu9Hi68ELp29VyMQgghPE+SG9GuvP46DBgAhpASdEYrqkWH9aQ/igLdumkFx0IIIU5vktyIdiUkBFavhnsezQdAzQtgQH8dL78MGzdqvTtCCCFOb4aGTxGibfH1hcSBBfAzXJUUyNyFno5ICCFEWyI9N6Jd+itDq7fpGRPYwJlCCCFON5LciHZpT7okN0IIIeomyY1od8osVg5lFwHQKybIw9EIIYRoayS5Ee3O/sxCrDaVYF8fooNMDT9BCCHEaUWSG9Hu7LXX20QHoiiKh6MRQgjR1khyI9qdv6TeRgghxClIciPaHSkmFkIIcSqS3Ih2x57c9JLkRgghRB0kuRHtSl5xBWl5pQD0kORGCCFEHSS5Ee3Knspi4g4hvgSZfTwcjRBCiLZItl8QrSItDbKyICYGoqKa386edG1PKam3EUIIUR/puRFutWEDJCVBXBwMHKglN5dcAjt2NK89mSklhBCiIZLcCLf54w846yxYsaLqmKrCjz/CiBHw559Nb9MxUypakhshhBB1k+RGuIWqws03g8UCVqvzY1YrlJXBHXc0tU3VUXMjPTdCCCHqI8mNcItVq+DAAbDZtPuKwYq5UzYoKqAlOOvXw65djW8zLa+UglILBp1C18gAN0QthBDCG0hyI9xi3z7n+0FnHCT6mvUEDT94yvNOxT4k1SXSH6NB3rpCCCHqJn8hhFsEBzvfN8WdBMC3e8YpzzuVqmJi2QlcCCFE/SS5EW4xfjz4+1fdN4QVAWCKy0UxVQDalPAxYxrfpn0auKxMLIQQ4lQkuRFuERAAM2dW3tHZMASXAKDoVMwdcwB44gkwNGGlpb9kppQQQohGkEX8hNs8/DCUlsKLbxaj6FTHcf+uWTz59xj+/vfGt1VhtXEgqxCQmVJCCCFOTXpuhNsoCjz5JHz4jTYkpVQe7zk2mwceaFpbh7KLqLCq+Bv1xIf6ujZQIYQQXkWSG+F2Jy1acjO2ZyQ+eoVjucUczi5qUhv2IakeMYEoitLA2UIIIU5nktwItztUmcj0iwtmSMdQAFbuy2pSG1JMLIQQorEkuRFuZ09uEiP8ObtHJAB/7MtuUht70ivrbaSYWAghRAMkuRFuZx+C6hzhz9ndteRm7YEcKqy2RrexJ8O+G7iscSOEEOLUJLkRblVSbuV4XimgJTd944II9fOhsMxC8tHcRrVRWGbh6AltKrkMSwkhhGiIJDfCrY6c0Hptgn19CPXzQadTGFPZe7Nyb+PqbvZWbpYZFWgi1N/onkCFEEJ4DUluhFsdrlZvY5/ldFb3CKDxdTd70mUncCGEEI0nyY1wq4OVyU2XiKq9GOzJzbZjueQWlzfYhj25kSEpIYQQjSHJjXArR89NeFVyExvsS/eoAGwqrDmQ02Abf1VOA+8hM6WEEEI0giQ3wq3s08A7R/o7HT/LXnfTwHo3qqpW67mRmVJCCCEaJsmNcKtD2cUAdA6vkdz0qKy72ZuNqqq1nmeXVVDGyeIKdAp0jw5wX6BCCCG8hiQ3wm0KSivILiwDIDHCz+mxkZ3DMep1pOaWOOpy6rKncqZUYrg/Zh+9+4IVQgjhNSS5EW5zuLLXJiLARKDZx+kxX6Oe4Z0rt2I4xZRwmSklhBCiqSS5EW5zMFvbMqFzjV4bu6q6m/qnhP8lyY0QQogmkuRGuI2956ZzhH+dj9unhK89mEO5pe6tGGQauBBCiKaS5Ea4zaHKnpvEepKb3jFBRAQYKS63siXlZK3HrTbVsTqx7CklhBCisSS5EW5zKEfruelST3Kj0ymM6ab13tQ1JfxIThFlFhtmHx0dw+oe2hJCCCFq8nhyM2/ePBITEzGbzYwYMYINGzbUe+7OnTu58sorSUxMRFEUXn755dYLVDSJqqocyjp1zw2cuu7GPiTVPSoQvU5xQ5RCCCG8kUeTm8WLFzNjxgxmz57Nli1bGDhwIOPHjyczM7PO84uLi+nSpQvPPvssMTExrRytaIqTxRXkl1oA59WJa7LX3WxPzeNEkfNWDFJMLIQQojk8mtzMnTuXW2+9lalTp9KnTx/mz5+Pn58fb7/9dp3nDx8+nBdeeIFrrrkGk8nUytGKprCvTBwXbD7l+jRRQWZ6xQSiqrB6v3PvjRQTCyGEaA6PJTfl5eVs3ryZpKSkqmB0OpKSkli7dq3LrlNWVkZ+fr7TTbjfoWq7gTfk7B7a0NQfNda7qSomluRGCCFE43ksucnOzsZqtRIdHe10PDo6mvT0dJddZ86cOQQHBztuCQkJLmtb1M++YWZ908Crsw9NrdxXtRVDaYWVwzlaG5LcCCGEaAqPFxS728yZM8nLy3Pcjh496umQTguHmpDcDE8Mw2TQkZ5fyv5MrQh5X0YhNhXC/I1EBsgQpBBCiMbzWHITERGBXq8nIyPD6XhGRoZLi4VNJhNBQUFON+F+TUluzD56zugcBsAflbOm/krXhg97RgeiKDJTSgghRON5LLkxGo0MHTqU5cuXO47ZbDaWL1/OqFGjPBWWcAFVVR1DSo2puQE42zElXKu7kT2lhBBCNJfBkxefMWMGN954I8OGDeOMM87g5ZdfpqioiKlTpwIwZcoUOnTowJw5cwCtCHnXrl2Or1NTU0lOTiYgIIBu3bp57HUIZ5kFZRSXW9HrFBJCG7f43lk9IuAHWHcwhzKL1bEbuCQ3Qgghmsqjyc2kSZPIyspi1qxZpKenM2jQIJYuXeooMk5JSUGnq+pcOn78OIMHD3bcf/HFF3nxxRcZO3YsK1asaO3wRT3sQ1Lxob4YDY3rHOwZHUhkoImsgjI2Hz4pa9wIIYRoNo8mNwDTp09n+vTpdT5WM2FJTEx0zKYRbVdT6m3sFEXhrO4RfLkllW+Sj5NVUAZAj2hJboQQQjSN18+WEq3PPg38VCsT12VwrFZ389mGVACCdL6UFXo8/xZCCNHOSHIjXO5gZXLTJbLxyc3y5XDH5dp6N6rOBkDGniA6dtQeE0IIIRpLkhvhck3tuTlyBC65BIpPmChLr5qqX54VSEmJ9lhKiltCFUII4YUkuREuZbWpHMkpBhpfc/PGG1BeDqoKpYcjHcfLs7Q9p8rLYf58t4QrhBDCC0lyI1zqeG4J5VYbRr2OuBDfRj3n22/BatW+Lj0U4ThekaUVE1ut8PXXro5UCCGEt5JqTeFS9plSHcP90Osat7JwWVnV16WpoVSc8AcVKk5W9fyUl7s0TCGEEF5MkhvhUvaViZsyDXzUKK2mxmIBrHrS3jkLVQVsWseiwaCdI4QQQjSGDEsJlzqY1fTk5q67KhObSqpFD1a9477FAvUshSSEEELUIsmNcKnm9tw89ZT2tb4qp3F8/fTTMGKEqyIUQgjh7SS5ES7V3AX8HnkEfvwRzjsPTCbtdv75sHQpPPywOyIVQgjhraTmRrhMhdXG0ZMlQNMW8LO78ELtJoQQQrSE9NwIlzl6ohirTcXPqCcq0OTpcIQQQpymJLkRLmOfBt4p3B9Fadw0cCGEEMLVJLkRLmNPbro0oZhYCCGEcDVJboTL2JObxAg/D0cihBDidCbJjXCZqmngAR6ORAghxOlMkhvhMoccC/hJz40QQgjPkeRGuERphZXjeaWA9NwIIYTwLEluhEvYh6SCzAZC/Xw8HI0QQojTmSQ3wiXsKxN3jgyQaeBCCCE8SpIb4RKHsosB6Bwu9TZCCCE8S5Ib4RKHsgsBqbcRQgjheZLcCJc4XNlzI2vcCCGE8DRJboRLHLTX3MjqxEIIITxMkhvRYgWlFWQXlgGQKMmNEEIID5PkRrSYfUgqIsBIkFmmgQshhPAsSW5Eix3KkSEpIYQQbYckN17GZoPvv4dLL4VeveDMM+G//4XCQvdd077tQmK4JDdCCCE8z+DpAITrWCxwzTXwv/+BXg9WKygKrF0LL74Iv/8OCQmuv65jw8xISW6EEEJ4nvTceJFnnoEvv9S+tlq1f1VVux09CldcoX3taofsM6Wk50YIIUQbIMmNlygvh1deqT95sVhg0yZYv97113YkN9JzI4QQog2Q5MZL7N4NJ05U3feJyCd++s8EDj3kOKbXw2+/ufa6J4vKySupAKBTmCQ3QgghPE+SGy9Rs8fGv89x9P7lhJy1B52pot7zWsq+eF9csBlfo961jQshhBDNIMmNl+jVC4KDq+4bY/MA0JmsBAw+Amh1OGed5bprWiywYZeW3HSSehshhBBthCQ3XsJshrvuAp0OQMUYk+t4LGjYIQxmKwMGwJgxLb9WeTk8+STExcHDc7TkZu3P/syf756CZSGEEKIpJLnxIrNnw/jxYAgtQm+2YKvQYcnzRe9fTszIY3z5pTY1vCUsFrj8cu1aWVnatQBOHvHnjjvg3ntd8EKEEEKIFpB1bryI0QjffguPLMhjcQoouUEEZMZRGryLTuMP0ikxgabks6qqza5atAgOHIDISIiNhR9+qDrHJ0xLbipOaMNSr70G110HI0e68pUJIYQQjSfJjZcxGMA3PhdSYOplIfzzwgTOfHYfx3KL+XFHOpcMjGtUO1Yr3HYbvP221qbFUrUwYBXV0XNTcdLfcf0335TkRgghhOfIsJQX2nYsF4BBCSH4GQ3cODoRgPm/H0BtZFHMc8/BO+9oX1ss2r/2xEYfVEzw6H3E/f03dEYrqk3BkuvnOHfnTle9EiGEEKLppOfGy1RYbew8ng/AgHht+tSNoxJ58/eD7Dyez6r92ZzVPfKUbZSVwUsv1SgO1lvx65FBQP+jmBOzHbU7tjIDeeu6gk3LkxUFQkJc/aqEEEKIxpPkxsvsSS+gzGIjyGxwbGQZ6m9k0vAE3l1zmHnLD2DIjkRRYOBA8PWt3UZysvOCgMaYXKImbkTvV+44VnI4nKLt8RTvjUW1VK1vo6ra/lZCCCGEp8iwlJfZWjkkNSA+BJ2uamrU9cM7o6gK6w7ncM7leYwaBTEx8O9/Q0WFcxv2YSgAFJWw8dvR+5VjyTeTu7o7qfPPJXPxSIp2xTslNgYDdO4syY0QQgjPkuTGy2w7qi3eNzChakW/igq49To/CndpxcRBIw8AkJ+vbbY5cSLYbFVt9O0LJpP2tX+/Y5hi8rGVGkh7dwx5q3pgyfNznOvjoyU1AH36wIoV4Ff1sBBCCNHqJLnxMtV7buw++URLOvLWdQHAr0cahhBtlpOqwjffwI8/VrUREgI33AAGs4XQs/cAkLumO7YSLePR67VE5quv4P774Z//hF9/1YazOnZ08wsUQgghGiA1N16kuNzC3owCQJspZTd/vrZycUV2EMUHIvHrmkXQGQc58VN/QEtWFiyAiy+uauvFF+GP3P2UBZRRccKPgs2JjnNDQuCLL6B3b5gwoXVemxBCCNFY0nPjRXak5mNTITrIRHSQ2XH80KGqYaf8dV0BCBh4FN8eaYA2xXv/fue28q3FqD20HcV99/TG5KMjJgYeeAC2btUSGyGEEKItkp4bL2Jf32ZgtSEpgPBwSE/Xvi47FkbhtngCBhwj8tI/yfxST/nhKCJrzA5/dulflFttjO4azkdzolu8bYMQQgjRWiS58SLJR3MBGFhtSApgyhSYOdPee6OQs7Q/itGKf680IidsJvPzMxg+PJzp06GgAIK7nuD74jR0Cjz6f31QJLMRQgjRjkhy40W2HaucKVWj5+bWW+H11yEtrXKat6oj+7tBKAYrft0yibpqI69+PAJbZiiqqhJ1/S6MMdDfvyO9Y4Na/4UIIYQQLSA1N17iZFE5KSeKAegfH+z0WGgo/PEHDBqk3dfpQIeOrK+HUHEsAp3RSvTEDejC8zD3TsUYk4etzMCSOT349ttWfiFCCCFEC0nPjZewTwHvEuFPsK9PrccTE2HjRu22apW2TUJkpJ4bpg4lauIGzAknibp6PWrlNgp5a7pBqYmnnoJLL23FFyKEEEK0kCQ3XsI+JDWgRq9NTcOHazeAhx8GvWog84vhRF+zHlOs1kbFST/yNyeCTUuGMjIgOtqd0QshhBCuI8NSXmJrPcXEp1JSovXgqOU+ZH52BuWZgag2OPlrH7Dqnc4TQggh2gvpufECqqqy1dFzE9Lo5/XvX7WvlK3USNq7Y9AHlmLNr9o/ITgYYmNdGa0QQgjhXtJz4wWO55WSXViGQafQN67xs5smTYKgIKrWsFF1TomNXq/NtLLvMyWEEEK0B5LceIFtlUNSPWMCMfvoT31yNf7+8OGHWhKjr/E0vV7r2Zk1y4WBCiGEEK1AkhsvkGxfmbgJ9TZ2l1wCq1fD//2fNkUcIDIS/v1vWLkSAgNdF6cQQgjRGqTmph3btQs+/xyWFOWBDrqHn3qmVH3OOAO+/hrKy7Xi4cDAqkRHCCGEaG/kT5iL2FQbWUVZ5JflN/o55eWQlQVFRdrO3f37g6+vNu36/vvhyBHIz4d587T6mEmTtK8zMrSv+/aFJ59UyajQionvmRzCu+82/zUYjVoBsSQ2Qggh2jNFVVXV00G0pvz8fIKDg8nLyyMoqOVbC5RaSnlpzUu8vvF10gu13Sn7l9xJwJZH2bEuBlWFs86C++6DceO05+zbB089BZ98os1W0um0fZ8UBew/Db1eK+TV6bTkx170q6raYzabdjOEF9Dhlj+wles5+vI4UHUsWQIXX9zilyaEEEK0GU35+y3DUi1QZinjoo8u4o8jf2BTbdrBDXey/Yd5oKuAykPLlsGPP2rDPaqqDf2oqn0jy6p/q6eZVisUF1fdr/6YxVL1tX3hvfKMYFB16HQwe7YkN0IIIU5fkty0wLyN85wTm4x+8MNr2te2qi0Q7MlLQUFDLaroA0u1ryr02Cr0YNUBStXj/mUYQooxhBZjCCnCr1smAOVpwY5rbd4MR49CQkLLX6MQQgjR3khy0wKvb3jdkdgoqj/mgzNQEzNRK4yoFj2qRYe10IytrPZeTwA6UwWmhBOYYnMxxuZijMlD71vhdI5qUxyJjs5oQWe01tlWaUq40/2GEykhhBDCO0ly00wV1goO5R5y3PdROxA1KAoGba51bnlmIKVHwyg7Go61yIi5Uw6+nbMwxuai1CjeVa0KqAqKoTJp0qkoJgs6kzYWpdrAmu9LRa4flpP+WHL9KM8MovRwhKMNk0l6bYQQQpy+JLlpJr1Oj4/Ohwqb1tOiUkFZtgFF9UXRW1F8bCgGK3rfCoxRBRijCmDokVrtVOT4U5YaSllaCOXpwZRnBWr7Oik2FB8rOqMVxceK4mNBrdBjyfMDW/3TmQwGuO46WZ9GCCHE6UuSm2bSKTou63kZX+/5GovNQoXuEOn718Efj4Ba9W3V+ZVhjj+BKeEE5oQT6PzKKDsWRsmhSEoPR2At8K37AqoOtVyHtbzuIS2ommVlZzBAXBw884yrXqUQQgjR/shU8BbYdHwToxaNwmqzoqJCfhy8uhesZlAbvw1CTfakJSICsrO1qd/WylIb+9fXXw8pKfDHH9pxsxmmTIEnntDWyRFCCCG8SVP+fstybS0wLG4YX0z8Al8fXxQUDCGZ6K6fAIYSUGxAw3lj9X2d+veHsWO1LRE++QRSU+Grr2DUKG2dG0WBkSPhyy/hgw/g998hMxP274ecHHjzTUlshBBCCOm5cUWbZfl8tO0jktOTMRvMnBVxBft+OYvly3UUFWnbJOTnVy3SZzBoa9WMHg09e0J8PNx4I3TtWv817MNPsnqwEEKI01FT/n5LctMKCgvh44+1faAKCrQemjvugCFDWuXyQgghRLsnyc0peCK5EUIIIUTLtLuam3nz5pGYmIjZbGbEiBFs2LDhlOd//vnn9OrVC7PZTP/+/fnhhx9aKVIhhBBCtHUeT24WL17MjBkzmD17Nlu2bGHgwIGMHz+ezMzMOs9fs2YN1157LdOmTePPP/9kwoQJTJgwgR07drRy5EIIIYRoizw+LDVixAiGDx/O66+/DoDNZiMhIYG7776bhx56qNb5kyZNoqioiCVLljiOjRw5kkGDBjF//vwGryfDUkIIIUT7026GpcrLy9m8eTNJSUmOYzqdjqSkJNauXVvnc9auXet0PsD48ePrPb+srIz8/HynmxBCCCG8l0eTm+zsbKxWK9E1FmeJjo4mPT29zuekp6c36fw5c+YQHBzsuCXIpktCCCGEV/N4zY27zZw5k7y8PMft6NGjng5JCCGEEG7k0b2lIiIi0Ov1ZGRkOB3PyMggJiamzufExMQ06XyTyYTJZHJNwEIIIYRo8zzac2M0Ghk6dCjLly93HLPZbCxfvpxRo0bV+ZxRo0Y5nQ/w888/13u+EEIIIU4vHt8VfMaMGdx4440MGzaMM844g5dffpmioiKmTp0KwJQpU+jQoQNz5swB4N5772Xs2LG89NJLXHzxxXz66ads2rSJBQsWePJlCCGEEKKN8HhyM2nSJLKyspg1axbp6ekMGjSIpUuXOoqGU1JS0FXbUGn06NF8/PHH/Pvf/+bhhx+me/fufP311/Tr189TL0EIIYQQbYjH17lpbXl5eYSEhHD06FFZ50YIIYRoJ/Lz80lISCA3N5fg4OBTnuvxnpvWVlBQACBTwoUQQoh2qKCgoMHk5rTrubHZbBw/fpzAwEAURXFp2/as0t4r1NT7dbVRX9sNHfd0Ww19b5ryfXTFudKmd7XZWO5o013tSpvSZltusy1cX1VVCgoKiIuLcypXqctp13Oj0+mIj4936zWCgoKcfqBNvV/fseYc93RbzT3PXedKm97VZmO5o013tSttSpttuU1PX7+hHhs7r1/ETwghhBCnF0luhBBCCOFVJLlxIZPJxOzZsx0rIjf1fn3HmnPc02019vmtda606V1tNpY72nRXu9KmtNmW22xP14fTsKBYCCGEEN5Nem6EEEII4VUkuRFCCCGEV5HkRgghhBBeRZIbIYQQQngVSW5aaM6cOQwfPpzAwECioqKYMGECe/bscTz+7LPPoigKt9xyC9dffz3h4eEYjUZMJhN6vR5FUYiJieHJJ59EVVX++OMPLrnkEscKykajkaSkJD7++GOn4yaTidDQUIYOHcqYMWOIi4tDURSGDx9OcHAwRqMRf39//P398fX1xWw2YzabufDCC3nggQcYPHgwRqMRg8GAXq8nNjaW0aNHM2TIEAIDAzEajSiK4nQzGo0EBgYSGRlJaGgo/v7+DBkyhNtvv51zzjmHoKAgFEWhb9++jsWbRo0axY8//uj0PVu7di3nnXce/v7+BAUFcfbZZ/Pkk0+iKAr33Xef47wFCxY4tZubm+v4flY/z95m586da8Xcq1evets71bnV4/T19cXHxwcfHx98fX3p378/mzZtcpz35ZdfMm7cOMLDw1EUhYsvvpjw8PA6zwXYvXs3fn5+dcZw1113OcWq0+lOeZ49znPPPRcfHx90Oh16vZ4uXbo43lM14wwLC0NRFDp06ICvry9du3atda49zr/97W+YTCZ0Oh06nY6hQ4eycePGel/75MmT6dSpE76+vowePZqNGzc63tM136P+/v4MHz6cI0eOMGvWLGJjY/H19SUpKYl9+/Y5xfL0008zevRo/Pz8CAkJqdXm119/7XR+zbiSk5Opqeb74fvvv6+3zYqKCv71r3/Rv39//P39iYuLY8qUKRw/frxFcT722GP06tULf39/QkNDSUpKYv369S1qs7rbb78dRVF4+eWXW9TmTTfdVOs9eOGFF7Y4zt27d3PppZc6vR9SUlKa9TMC6vysKIrCCy+80Ow4CwsLmT59OvHx8fj6+tKnTx/mz5/vdE5T48zIyOCmm24iLi4OPz8/Lrzwwlrv+Zptzpo165R/awBKS0u56667CA8PJyAggCuvvJKMjAync+655x6GDh2KyWRi0KBBtX4mdWno71xd8ebm5tbZ1vfff8+IESPw9fUlNDSUCRMmNCqGppLkpoV+//137rrrLtatW8fPP/9MRUUF48aNo6ioiI0bN/Lmm2/Sp08fPvvsM3x8fPjxxx+55JJLAPj73/8OwJQpU3j++ed57bXXKCoqoqioCJvNBsDzzz+Pv78/M2bMoG/fvtxyyy0AvPLKK6xatYqIiAg2btzo+GMfHx/PihUrGDlyJNOmTSMxMZHevXszbNgwwsPDiYuL47///S+XXHIJY8eOZe7cuZx99tnYbDaSk5PR6XSsW7eOAQMGkJCQQIcOHViwYAEffvgh69evZ8CAAfj4+FBYWMj//vc/rrjiChYsWMCAAQN4+OGHAZg9ezabN29m06ZNnHfeeVx22WXs3LkT0P4QX3jhhYwbN44NGzawceNGLrzwQhYtWsSAAQOcvrfFxcVceOGFjna3bNnCm2++Wes8e5tdu3alW7durFy5kjfffJPDhw+zatWqetvr1asXaWlpjlv1c+1tnnXWWYSFhXHJJZfw+OOP8+eff/LSSy8RGhrqOLeoqIgxY8Ywa9YsAAwGAz/++CO7du2qde6BAwcYM2YMN998Mz/99BNr167l3Xff5bPPPgNg4sSJdcb6119/kZaWxs8//+x0nj1Oo9FIQEAAb7zxBq+88gpPP/204z1VM86xY8cC8NBDD7F7926ee+65Wufa4zx48CDx8fF89NFHvPHGG5x33nkkJSWRmprq1OZzzz0HwLp16/jggw/Yvn0748aNIykpiSNHjjBw4EAeffRRp/fotm3bePTRR3nrrbd49dVXmT9/PuvXr8ff35/x48dTWlrqiKe8vJyJEydyxx13OK47cOBA5s2bR11qxlWXmt/j4uLietssLi5my5YtPProo2zZsoUvv/ySPXv2cOmllzqd19Q4e/Toweuvv8727dtZtWoViYmJjBs3jqysrGa3affVV1+xbt064uLiaj3WnDYvvPBCp8/LJ5980qI27e+xXr16Ob0fzGaz45ym/IwAp/jS0tJ4++23URSFK6+8stlxzpgxg6VLl/Lhhx+ye/du7rvvPqZPn863337brDhVVWXChAkcPHiQb775hj///JNOnTqRlJREUVFRvW2uWbOm3r81dvfffz/fffcdn3/+Ob///jvHjx/niiuuqBXDzTffzKRJk+p8vXU51d+5+uKty//+9z9uuOEGpk6dytatW1m9ejXXXXddo+NoElW4VGZmpgqoP/74o9q9e3f1559/VhMSEtS4uDjHORdffLF68803q6qqqoD61VdfqVdccYU6efJk1WazqTExMeoLL7zgeCw3N1c1mUzqJ5984vQcVVXVvLw8FVDPOeccp+Oqqqp79uxRAXXHjh2OuH777Tc1MjJSXbhwYa2YH3vsMdVoNKoVFRXq2LFj1VtvvVUF1N9//91xrr+/v/r++++roaGh6ltvvaWqqqqGhYWpCxcuVH/77TcVUE+ePOn0Pal+7ogRI9R///vfjscKCgoc36exY8eq9957b63vqb3drl271nmevc3Zs2erAwcObPBnZG+vX79+9Z5jb/Nf//qXOmbMmAbbVFVVvf3221VA/fPPP+s9Z9KkSer1119f6/i9996rdu3aVbXZbHXGav+e1jzPHmf195Sd/T1V03nnnVcrzprnTpo0Sb3mmmtUvV6vLlmyxOn5Q4YMUR955BGnY7t371YB9dVXX6333EmTJtV6j1Z/v9vVfL9X984776jBwcFOx2q2Wd2hQ4ca/JnU9b49VZt2GzZsUAH1yJEjLY7Tzv55/uWXX1rU5rFjx9QOHTqoO3bsUDt16qT+5z//qfN6jW3zxhtvVC+77LJTxt7UNuv7LNSluT+jyy67TD3vvPNaFGffvn3VJ554wulYXZ+BxsZZ/feyndVqrfV7+VRtqmrV72377+fc3FzVx8dH/fzzzx3n2D+Xa9eurdVuY39f1qXmtRsTb0VFhdqhQwfH3wJ3k54bF8vLywPgjTfe4OKLLyYpKYmcnByioqKYOHEiUVFRbNmyhW+++Ya9e/cCcOjQIVatWsVFF13EoUOHSE9PJykpydFmcHAwI0aMYO3atU7XKi8vZ8GCBQQFBTmGCh5//HGioqIYMWKEYzjIbDY74oqIiMBkMjn1UtgfA20vEINB23Lsiy++ALQsf+bMmRQXFzNq1Cj+85//UFRUxIgRI/j0008pLS3lnHPOqfW9sFqtfPrppxQVFTFq1CgyMzNZv349UVFRjB49mujoaLp27cqgQYOcXm997D0B1VVvc9GiRWzduhWTyURcXByTJ0926uKu6eDBg8TFxdGlSxenc6u3+eqrr7J582bHUNzgwYNZuHBhne398ssvADz44INERUXVOtdms/H999/To0cPxo8f7/g5ff7553z44YfcfPPNp9zMtby83Om86nFu27aNd999l+HDh7Nq1Sq2bt3qeE/VNGTIEACOHDkCUOtce5xdu3bFarUyefJkRowY4eha9/X1dXr/AFgsFgCMRqPTcfu59jbB+T365ptvNvr93tbk5eWhKAohISEuac/+eQ4ODmbgwIHNbsdms3HDDTfw4IMP0rdvX5fEBrBixQqioqLo2bMnd9xxBzk5OS2Ksa7PwqmG2JoqIyOD77//nmnTprWondGjR/Ptt9+SmpqKqqr89ttv7N27l3HjxjWrvbKyMgCnHiqdTlfr93JD7L+3w8LCANi8eTMVFRVOn6VevXrRsWNHl3+Wal67MbZs2UJqaio6nY7BgwcTGxvLRRddxI4dO1wam0OrpFCnCavVql588cVqjx491H79+qklJSWqqqqqoiiqXq9XZ86cqW7ZskV94403VL1eryqKogIqoD7zzDOqqqrq6tWrVUA9fvy4U8Y/ceJE9eqrr1ZVVfufgMlkUhVFUePi4tQffvjB0c7UqVPVP//8U50zZ44KqNHR0epVV12ljhs3Th09erT67LPPqoA6btw4p5jPOOMMtWPHjurDDz+sqqqqvvHGG+oZZ5yhDh48WP3www/VqKgoVa/Xq3q9XjUYDCqgGgwGNSgoSF22bJmqqlUZ+6pVq1R/f39Vr9erwcHB6vfff6+qqqquXbtWBdSwsDD17bffVufMmaOGh4erPj4+6t69e+vtuXn00UdVQE1LS1NVVXU6r3qb9913n/rcc8+pkydPVg0Ggzp48GC1Y8eOan5+vlN79jjfeecddevWrerSpUvVUaNGOc6t3qbBYFCNRqM6fPhw1WAwqE888YRqNpvVd999t1acRqNRBdSbb75Z3bJli/rmm286nZuWlqYCqp+fnzp37lynn5NOp1NTU1NrtVn9f0GLFy9W9Xq947zqcb711lvqTTfd5HgfKIrieE/VdODAAcc5BoOh1rnV40xMTFSHDh2qzpw5UwXUhx9+WNXpdGqPHj2c2rT3kAwdOlRNTU1VLRaL+sEHHzjOtbdZ13vU/n6vrvr7vbq20nNTUlKiDhkyRL3uuuvqfLwpcX733Xeqv7+/4/O8YcOGFrX5zDPPqBdccIGjd88VPTeffPKJ+s0336jbtm1Tv/rqK7V3797q8OHDVYvF0qw26/ssKIqirlixolabzfkZPffcc2poaKjj93BzX3tpaak6ZcoUx+88o9Govvfee3W22Zg4y8vL1Y4dO6oTJ05UT5w4oZaVldX6vdxQm/bf22eeeabj2EcffaQajcZazx8+fLj6z3/+s9bx5vbc1HXthuJVVe09BKgdO3ZUv/jiC3XTpk3qtddeq4aHh6s5OTlNjqMhp92u4O501113kZycTFlZGcuXL3fKzKOionjmmWcA2LNnD76+vsTExLB//37uvfdeXnzxReLi4ujevXujrvWf//zH0TNw2223OY5feumlDBo0iEGDBrFmzRrKysr47bffyMnJQafTERgYyEUXXeQoHr3rrrvYvn07YWFh9OnTh8ceewzQ/jefkZHBqlWriI+PJyIiggsvvJC//e1v/PnnnxQXF/P222+zfft2rr76alauXOmIoXv37iQnJ5OXl8cXX3zBjTfeyO+//+6oI/r73/9OUlISw4YN49dff+X666/n7bffrvN1Hj16lNdffx1w/p+OXfU27d9fgG3btjF27FjefvttPvvsszr/9zZhwgRCQkIYMGAAI0aMoFOnTnz22Wf07t3b0eaLL77I0KFDWbNmDQMGDKC4uJhbb72V+fPnc+ONNzq1Z/+e3n333QwaNIjBgwezY8cOx7n2WC+77DLuv/9+AAYNGsTcuXPx8fGpszaiukWLFnHRRRc5zqv+2v39/fnll1/45JNPmDVrFj179nS8p2rGae9BeeaZZ7j44otJTk7mvvvuc5xbPc4nn3ySm2++mTlz5qAoCvPnz+faa69l8+bNdcaoqiodOnRAr9czZMgQx7n2NsH5PbpkyRJWr159ytfd1lRUVHD11VejqipvvPFGi9s799xzSU5OJjs7m4ULF3L11Vc7euSaavPmzbzyyits2bLllL2ATXXNNdc4vu7fvz8DBgyga9eurFixgvPPP7/J7dX3WVizZg3z58931IW1xNtvv83kyZPr/L3RFK+99hrr1q3j22+/pVOnTvzxxx/cddddxMXFNarHuSYfHx++/PJLpk2bRlhYGHq9nqSkJKffyw2566672LFjR5N6elylude2/8wfeeQRRw3UO++8Q3x8PJ9//rmjBtVVZFjKRaZPn86SJUt49NFHyc7OZsiQIRgMBgwGA6qqkpaWhsFgwGq18uCDD3LxxRdTXFwMwDnnnMP999/PnDlziImJAahV4Z6RkeF4DCA2NpaRI0eyaNEix2yWmnr37s22bdvw9fUlOTmZ9PR0li5dSk5ODl26dGH69Ol89913hIeHEx4ezldffYWPj4/jtfz222/Ex8cDMGbMGAB++OEHfv75Z4YNG8ayZcuYPXs2w4YNcyqcMxqNdOvWjaFDhzJnzhwGDhzIK6+8QmxsLAB9+vRh8+bNZGZmMmTIEHbs2MFzzz3H77//zquvvur4PoH2y/rkyZOANqRmMBiczouOjna0WfO1Z2Zm0qNHD/bv39/gzy8kJMRxbvU4Y2NjHW337t2blJQUx781RUZG1vkzsJ9rj796rEeOHCE7O5ugoKBTxpeSksIvv/ziKCgHnOJ88MEHeeihh7jmmmsYPHgwQUFBjvdUTfZjF154If379+eGG25wOrd6nF27duX333+nsLCQO+64g169elFRUUGXLl3qjHPRokUUFhZy9OhRNmzY4DjX3mZN9mGTht7vbYU9sTly5Ag///xzgz+3xvD396dbt26Oz7PBYGDRokXNamvlypVkZmbSsWNHx++fI0eO8MADD5CYmNjiWO3sP9PGfLbqUtdnAaj3s9VUK1euZM+ePU6fl+YoKSnh4YcfZu7cuVxyySUMGDCA6dOnM2nSJF588cVmtzt06FCSk5PJzc0lLS3N6fdyQ+r6/QwQExNDeXl5rVlKrvws1Xftxqj++8rOZDLRpUsXl/zMa5LkpoVUVWX69Ol89dVX/Prrr1x33XVs376d5ORkxy0sLIzIyEiSk5PR6/UUFxeTmZlJp06dHO3o9XpsNhudO3cmJiaG5cuXOx7Lz89n/fr1jBo1qt4Yav6vX1VVPv/8c/Ly8vj1118ZOHAgkZGR7Nu3j40bN3L06FG+/PJLIiIiCAoK4ttvv8VkMjm9ls6dOzvaqz6VVqfTYbPZHGPH9tjrYz83MTGRuLg49uzZw/nnn+/4PvXo0YNp06YxbNgwJk+e7Pg+AZx//vmOXp0//viD5ORkp/O6dOniaLO6vXv3Ehsby4EDBxwfqlMpLCx0nFs9zjPPPNPR9t69e+nUqZPj35qGDRtW61j1c41GI8OHD3eK9Z133sFoNDZYY/Hxxx8TFRXFxRdf7DhWPc7i4mJHgmu/Zn0/l5KSklrHqp9bV5z+/v4cP36c2NhYli1bxmWXXVZvrP7+/sTGxnLy5EnHufY2a8rIyMBsNjfp/e4p9sRm3759/PLLL4SHh7vlOtU/W011ww03sG3bNqffP3FxcTz44IMsW7bMZTEeO3aMnJycRn226lLXewyo97PVVIsWLWLo0KEtql0C7WdeUVFR6z+PDf3Oa6zg4GDH7+VNmzad8nNV829N9d/PoCVMPj4+Tp+lPXv2kJKS0uLPUkPXbgz79PPqP/OKigoOHz7skp95TTIs1UJ33XUXH3/8Md988w2BgYEUFRURERFBcHAwvr6+AHTq1ImtW7fy7bffYjab6dWrF7/99hs33HADa9eu5dtvv+Wrr77immuuoaioiKuvvtoxPLRmzRpeeeUVIiIiiImJcQyvbN68meLiYr744guOHj3qGNr6+OOP0el0PPXUUxw6dIipU6eyfft2Tpw4we7du5k1axaJiYn88ccfxMXFUVZWxrPPPsv+/ft5/vnn+e6775g3bx4LFy7k/PPPJywsjGeeeYb169czbNgwMjIyGDduHKmpqbzzzju89NJL/PTTT7z66quO/8V98MEHdO3alaCgIL7//ntWrFjBsmXLUBSFBx98kNmzZzNw4EAGDRrEe++9x5EjRxyFf+Hh4fTr1w+A9PR00tPTHb04VqsVi8WCyWRyOs/e5tatW5k0aRLr1q1j165d+Pv7o9frufbaa53aqxmnTqfjpZdecpxbPc6ZM2fy+eefc+6557Jr1y6mTJnCv//9bxYsWOB4D5w4cYKUlBTOPfdcvv32W5599lmuu+46jh07xoIFC5zOffDBB5k0aRJnn302Y8eO5dVXX6W8vJzp06c7va9qxvruu+9y0UUXkZ+f7yjiqx7n4MGDefzxx/n999/ZtWsXt912G7NmzeLmm2+uFefQoUNZvnw5n3zyCcePHyc9PZ25c+c6nWuPMzw8nAEDBpCSksK3335Lly5d6NWrF1OnTnVq077ey+LFi0lNTaWwsJA5c+bQq1cvJk6cSHJyMldddRVr1651vEeTk5NZsmQJt956K0899RTdu3enc+fOPProo8TFxTmtf5GSkuK4ltVqZc2aNRw9epSEhARAK8q3/0eiY8eOteKy/0KNiYlx/C+25vd4/fr15ObmOh6v3mZsbCxXXXUVW7ZsYcmSJVitVtLT0wGtqNJeSN2UOMPDw3n66ae59NJLiY2NJTs7m3nz5pGamuqY6t+c114z6fLx8SEmJoaePXs2q82wsDAef/xxrrzySmJiYjhw4AD//Oc/6datG+PHj292nNU/C+eeey5Lly7lu+++Y8WKFfV+Dk71M+rYsSOgJceff/45L730EnVpapxjx47lwQcfxNfXl06dOvH777/z/vvvM3fu3GbH+fnnnxMZGUnHjh3Zvn079957LxMmTHAqUq7Z5s0338wvv/zCxx9/TGBgoOP9Z/9bExwczLRp05gxYwZhYWEEBQVx9913M2rUKEaOHOlod//+/RQWFpKenk5JSYnjP659+vSpNSHArubfuZrXrive7du3ExgYSMeOHR3x3H777cyePZuEhAQ6derkWH+o+vvdZVxexXOaobIgsubtnXfecZwzduxY9ZJLLlH79eunmkwmtUOHDnU+54YbbnAUY9W8jRkzps7jkZGR9cZQ1+2SSy5p0vmAajab1aCgINVoNKphYWFqZGSkGhISovr5+akDBgxQJ0yYUOfzAgMD1fPPP1/96aefnL5nc+bMUePj41U/Pz911KhR6sqVKx3fp+oFxbNnz66z3Z49e9YqPJ4zZ47q6+urKoqiKoqiRkZGqpMmTVL379/fYHuhoaG1zq0ep8lkUn19fVWj0aj26tVLXbBggdN577zzTp3tRkRE1DpXVVV10aJFardu3VQfHx8VUOfNm1frnPpirf6+qh5nXFyco9jRaDSqXbp0UR955BG1rKyswThDQ0NrnWuPMzo62vE9DQ0NVe+66y41Nze3wTYDAgIc59b3ng4NDVW//vpr1WazqY8++qgaHR2tmkwm9fzzz1f37NnjFMuNN97YqPfqjTfeeMq4Zs+e3eD3uK427YXJdd1+++23ZsVZUlKiXn755WpcXJxqNBrV2NhY9dJLL61VUNzU115TXQXFTWmzuLhYHTdunBoZGan6+PionTp1Um+99VY1PT29xXHaPwtms1kdOHCg+vXXXzu12ZSfkd2bb76p+vr6Or1PWxJnWlqaetNNN6lxcXGq2WxWe/bsqb700ktOyzY0Nc5XXnlFjY+PV318fNSOHTuq//73v2t9/hrbZvXfCSUlJeqdd96phoaGqn5+furll1/umIhhN3bs2DrbOXToUJ3fL1Vt3N+5xvzOKi8vVx944AE1KipKDQwMVJOSkpymxLuSUhm4EEIIIYRXkJobIYQQQngVSW6EEEII4VUkuRFCCCGEV5HkRgghhBBeRZIbIYQQQngVSW6EEEII4VUkuRFCCCGEV5HkRgghhBBeRZIbIUSboKoqt912G2FhYSiKQnJyMueccw733Xef45zExERefvllt8axfPlyevfu7dj2w9Vuuukmp60lGlJeXk5iYiKbNm1ySzxCeCNJboQ4Dd10000oisKzzz7rdPzrr79GURSPxLR06VLeffddlixZQlpaGv369ePLL7/kySefbNU4/vnPf/Lvf//bsXnrY489xqBBg1zW/iuvvMK7777b6PONRiP/+Mc/+Ne//uWyGITwdpLcCHGaMpvNPPfcc5w8edLToQA4dmUfPXo0MTExGAwGwsLCCAwMbLUYVq1axYEDB7jyyiub/NyKiopGnRccHExISEiT2p48eTKrVq1i586dTY5LiNORJDdCnKaSkpKIiYlhzpw59Z5TV6/Fyy+/TGJiouO+fZjlmWeeITo6mpCQEJ544gksFgsPPvggYWFhxMfH884779R7nZtuuom7776blJQUFEVxtF9zWKqm3NxcbrnlFiIjIwkKCuK8885j69atjse3bt3KueeeS2BgIEFBQQwdOvSUwzuffvopF1xwAWazGdB2Y3/88cfZunUriqKgKIqj10VRFN544w0uvfRS/P39efrpp7FarUybNo3OnTvj6+tLz549eeWVV2q91urDUueccw733HMP//znPwkLCyMmJobHHnvM6TmhoaGceeaZfPrpp/XGLoSoYvB0AEIIz9Dr9TzzzDNcd9113HPPPcTHxze7rV9//ZX4+Hj++OMPVq9ezbRp01izZg1nn30269evZ/Hixfz973/nggsuqPM6r7zyCl27dmXBggVs3LjRMSTUkIkTJ+Lr68uPP/5IcHAwb775Jueffz579+4lLCyMyZMnM3jwYN544w30ej3Jycn4+PjU297KlSu57rrrHPcnTZrEjh07WLp0Kb/88gug9bzYPfbYYzz77LO8/PLLGAwGbDYb8fHxfP7554SHh7NmzRpuu+02YmNjufrqq+u97nvvvceMGTNYv349a9eu5aabbuLMM8/kggsucJxzxhlnsHLlykZ9X4Q43UlyI8Rp7PLLL2fQoEHMnj2bRYsWNbudsLAwXn31VXQ6HT179uT555+nuLiYhx9+GICZM2fy7LPPsmrVKq655ppazw8ODiYwMBC9Xk9MTEyjrrlq1So2bNhAZmYmJpMJgBdffJGvv/6aL774gttuu42UlBQefPBBevXqBUD37t1P2eaRI0eIi4tz3Pf19SUgIACDwVBnXNdddx1Tp051Ovb44487vu7cuTNr167ls88+O2VyM2DAAGbPnu2I8fXXX2f58uVOyU1cXBxHjhw5ZfxCCI0MSwlxmnvuued477332L17d7Pb6Nu3Lzpd1a+T6Oho+vfv77iv1+sJDw8nMzOzRbFWt3XrVgoLCwkPDycgIMBxO3ToEAcOHABgxowZ3HLLLSQlJfHss886jtenpKTEMSTVGMOGDat1bN68eQwdOpTIyEgCAgJYsGABKSkpp2xnwIABTvdjY2Nrfa98fX0pLi5udGxCnM4kuRHiNHf22Wczfvx4Zs6cWesxnU6HqqpOx+oqnK051KMoSp3HbDabCyLWFBYWEhsbS3JystNtz549PPjgg4A2bLRz504uvvhifv31V/r06cNXX31Vb5sRERFNKrD29/d3uv/pp5/yj3/8g2nTpvHTTz+RnJzM1KlTKS8vP2U7jflenThxgsjIyEbHJsTpTIalhBA8++yzDBo0iJ49ezodj4yMJD09HVVVHVPEk5OTPRBhbUOGDCE9PR2DweBU4FxTjx496NGjB/fffz/XXnst77zzDpdffnmd5w4ePJhdu3Y5HTMajY1e82b16tWMHj2aO++803Gsod6ixtqxYweDBw92SVtCeDvpuRFC0L9/fyZPnsyrr77qdPycc84hKyuL559/ngMHDjBv3jx+/PFHD0XpLCkpiVGjRjFhwgR++uknDh8+zJo1a3jkkUfYtGkTJSUlTJ8+nRUrVnDkyBFWr17Nxo0b6d27d71tjh8/nlWrVjkdS0xM5NChQyQnJ5OdnU1ZWVm9z+/evTubNm1i2bJl7N27l0cffZSNGze65PWuXLmScePGuaQtIbydJDdCCACeeOKJWkMhvXv35r///S/z5s1j4MCBbNiwgX/84x8eitCZoij88MMPnH322UydOpUePXpwzTXXcOTIEaKjo9Hr9eTk5DBlyhR69OjB1VdfzUUXXeRU8FvT5MmT2blzJ3v27HEcu/LKK7nwwgs599xziYyM5JNPPqn3+X//+9+54oormDRpEiNGjCAnJ8epF6e51q5dS15eHldddVWL2xLidKCoNQfUhRDiNPbggw+Sn5/Pm2++6elQHCZNmsTAgQMds8+EEKcmPTdCCFHNI488QqdOnVxa/NwS5eXl9O/fn/vvv9/ToQjRbkjPjRBCCCG8ivTcCCGEEMKrSHIjhBBCCK8iyY0QQgghvIokN0IIIYTwKpLcCCGEEMKrSHIjhBBCCK8iyY0QQgghvIokN0IIIYTwKpLcCCGEEMKr/D+CgAx2NzaCaAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/dataset/isaid_class_9/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('9', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91850e0d",
   "metadata": {
    "papermill": {
     "duration": 0.927912,
     "end_time": "2024-05-14T13:41:55.870747",
     "exception": false,
     "start_time": "2024-05-14T13:41:54.942835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07284cb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.823289,
     "end_time": "2024-05-14T13:41:57.580292",
     "exception": false,
     "start_time": "2024-05-14T13:41:56.757003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b955c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.817591,
     "end_time": "2024-05-14T13:41:59.266845",
     "exception": false,
     "start_time": "2024-05-14T13:41:58.449254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29868f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.905125,
     "end_time": "2024-05-14T13:42:01.065725",
     "exception": false,
     "start_time": "2024-05-14T13:42:00.160600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adcc01",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.822617,
     "end_time": "2024-05-14T13:42:02.702320",
     "exception": false,
     "start_time": "2024-05-14T13:42:01.879703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976c434",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.821724,
     "end_time": "2024-05-14T13:42:04.405216",
     "exception": false,
     "start_time": "2024-05-14T13:42:03.583492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5005351,
     "sourceId": 8410186,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7386.501549,
   "end_time": "2024-05-14T13:42:08.943613",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-14T11:39:02.442064",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
