{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40c6a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:32:24.300498Z",
     "iopub.status.busy": "2023-12-03T08:32:24.300161Z",
     "iopub.status.idle": "2023-12-03T08:33:41.725283Z",
     "shell.execute_reply": "2023-12-03T08:33:41.724320Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 77.433374,
     "end_time": "2023-12-03T08:33:41.727461",
     "exception": false,
     "start_time": "2023-12-03T08:32:24.294087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\r\n",
      "pytoolconfig 1.2.6 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\r\n",
      "tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m--2023-12-03 08:33:16--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.121.3\r\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231203%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231203T083316Z&X-Amz-Expires=300&X-Amz-Signature=34aa5ad52f38ebbe0f2e2bf739b8a03964776164cafd31375fb27ecf6fda4cae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-12-03 08:33:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231203%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231203T083316Z&X-Amz-Expires=300&X-Amz-Signature=34aa5ad52f38ebbe0f2e2bf739b8a03964776164cafd31375fb27ecf6fda4cae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: ‘yolov8m-seg.pt’\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   339MB/s    in 0.2s    \r\n",
      "\r\n",
      "2023-12-03 08:33:17 (339 MB/s) - ‘yolov8m-seg.pt’ saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.221, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Pothole-Detection-9 to yolov8:: 100%|██████████| 457340/457340 [00:14<00:00, 30700.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Pothole-Detection-9 in yolov8:: 100%|██████████| 6402/6402 [00:01<00:00, 4469.65it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"imacs-pothole-detection-wo8mu\").project(\"pothole-detection-irkz9\")\n",
    "dataset = project.version(9).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a914ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:33:41.761888Z",
     "iopub.status.busy": "2023-12-03T08:33:41.761121Z",
     "iopub.status.idle": "2023-12-03T08:33:41.787157Z",
     "shell.execute_reply": "2023-12-03T08:33:41.786179Z"
    },
    "papermill": {
     "duration": 0.044985,
     "end_time": "2023-12-03T08:33:41.789114",
     "exception": false,
     "start_time": "2023-12-03T08:33:41.744129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Pothole-Detection-9\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Pothole-Detection-9\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6297de1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:33:41.822283Z",
     "iopub.status.busy": "2023-12-03T08:33:41.821999Z",
     "iopub.status.idle": "2023-12-03T08:33:41.916912Z",
     "shell.execute_reply": "2023-12-03T08:33:41.916187Z"
    },
    "papermill": {
     "duration": 0.114151,
     "end_time": "2023-12-03T08:33:41.918942",
     "exception": false,
     "start_time": "2023-12-03T08:33:41.804791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "\n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1db93ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:33:41.952211Z",
     "iopub.status.busy": "2023-12-03T08:33:41.951918Z",
     "iopub.status.idle": "2023-12-03T13:04:56.908537Z",
     "shell.execute_reply": "2023-12-03T13:04:56.907583Z"
    },
    "papermill": {
     "duration": 16275.56785,
     "end_time": "2023-12-03T13:04:57.502731",
     "exception": false,
     "start_time": "2023-12-03T08:33:41.934881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пустой файл: temp/labels/img_1640_jpg.rf.1778c59bf5036fc27da508f6dfaa70b6.txt\n",
      "Пустой файл: temp/labels/img_1879_jpg.rf.2238fea06fb0d033bd756e9230bc6dac.txt\n",
      "Пустой файл: temp/labels/img_0832_jpg.rf.30f1a5963e4aed5abeb054b59fda1fbf.txt\n",
      "Пустой файл: temp/labels/img_1557_jpg.rf.c77f0a674c2532c9aad2340dac155939.txt\n",
      "Пустой файл: temp/labels/img_1879_jpg.rf.4f6782ce35182b93e51f4e0ff9cd7950.txt\n",
      "Пустой файл: temp/labels/img_0832_jpg.rf.7fac992dd44b00885280ec87ee3e1da6.txt\n",
      "Пустой файл: temp/labels/img_1557_jpg.rf.63ace4635038aaa14502e0b1db6b3c7b.txt\n",
      "Пустой файл: temp/labels/img_0832_jpg.rf.298af72a8437240adc8e31cf658b1c17.txt\n",
      "Пустой файл: temp/labels/img_0048_jpg.rf.c092197014696025124d178e2bab72b8.txt\n",
      "Пустой файл: temp/labels/img_1640_jpg.rf.bb5e2ef933ba51f4ef29482ff939e5ec.txt\n",
      "Пустой файл: temp/labels/img_0056_jpg.rf.9542cc1a9628937f64d1be4b885a7b6f.txt\n",
      "Пустой файл: temp/labels/img_0905_jpg.rf.87137efed7788ee2327b85f51cbf5e78.txt\n",
      "Пустой файл: temp/labels/img_0199_jpg.rf.32b1bd220181ed008a5457e2b8e8b3f0.txt\n",
      "Пустой файл: temp/labels/img_0076_jpg.rf.6ab33d3a56bf9d20130837c46ca26536.txt\n",
      "Пустой файл: temp/labels/img_1640_jpg.rf.293b317df3f8f291b962f6c76289b458.txt\n",
      "Пустой файл: temp/labels/img_0199_jpg.rf.1c5f6b4d92811236c082ab622d30c35f.txt\n",
      "Пустой файл: temp/labels/img_0905_jpg.rf.b77095817fc500f41c6fbee096047303.txt\n",
      "Пустой файл: temp/labels/img_0905_jpg.rf.30db59ca566e2c17100a868ae33cadb3.txt\n",
      "Пустой файл: temp/labels/img_1879_jpg.rf.43ad4919ac8bcdae241a3e5c57f56b5e.txt\n",
      "Пустой файл: temp/labels/img_1557_jpg.rf.9eee23ae13df5ccac3a75c786f36c364.txt\n",
      "Пустой файл: temp/labels/img_0199_jpg.rf.241089bdac6b1f39adb98489c4b5a863.txt\n",
      "Кол-во пустых файлов - 21\n",
      "valid_0/images 317\n",
      "test_0/images 318\n",
      "train/labels 2539 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 0 содержит 2539 объекта(-ов)\n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 2539\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 2539]\n",
      "\tКол-во директорий для класса 0: 45 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 500, folder 40, cls 0\n",
      "\tnum_to_mv_train 500, folder 41, cls 0\n",
      "\tnum_to_mv_train 500, folder 42, cls 0\n",
      "\tnum_to_mv_train 500, folder 43, cls 0\n",
      "\tnum_to_mv_train 38, folder 44, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 500\n",
      "temp_0_41/train/images 500 \n",
      "\n",
      "temp_0_42/train/labels 500\n",
      "temp_0_42/train/images 500 \n",
      "\n",
      "temp_0_43/train/labels 500\n",
      "temp_0_43/train/images 500 \n",
      "\n",
      "temp_0_44/train/labels 500\n",
      "temp_0_44/train/images 500 \n",
      "\n",
      "temp_0_45/train/labels 38\n",
      "temp_0_45/train/images 38 \n",
      "\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 38.6MB/s]\n",
      "2023-12-03 08:33:48,734\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-03 08:33:50,078\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 158MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 186.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<00:00, 753.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/valid_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      1.59G      1.985      5.879      3.137      2.021          8        640: 100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.02     0.0485     0.0054    0.00188     0.0111     0.0364     0.0032    0.00118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G      2.098       4.49      4.073      2.187          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0246     0.0607    0.00603    0.00228     0.0153     0.0312    0.00394    0.00143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.61G      1.763      4.209      3.769      1.995          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0262     0.0503    0.00684    0.00274     0.0174     0.0381    0.00468    0.00182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.59G      1.516      4.598      5.309      1.716          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0308     0.0607    0.00851    0.00317     0.0246     0.0416    0.00579    0.00228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.59G      2.381      3.992      4.213      2.212          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0343     0.0711    0.00912     0.0036     0.0251      0.052    0.00661    0.00265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0342     0.0659    0.00906    0.00353     0.0261     0.0503    0.00651    0.00258\n",
      "Speed: 0.8ms preprocess, 12.5ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.38144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.21325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.21198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.99184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.83698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.17335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.96086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.74236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_083405-mykfovg4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_083405-mykfovg4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<00:00, 981.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/test_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0276     0.0775    0.00787    0.00323     0.0173     0.0568    0.00536    0.00223\n",
      "Speed: 1.1ms preprocess, 27.4ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 896.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.54G      2.297      4.104       4.26       2.23         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0265      0.052    0.00804    0.00293     0.0127     0.0277    0.00357    0.00131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.57G      1.114      5.436        6.6      1.288          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0379     0.0641    0.00905    0.00325     0.0161     0.0312    0.00416    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.49G       1.65      2.968      4.302      1.851          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0431     0.0607     0.0096    0.00368     0.0167     0.0329    0.00474    0.00178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.51G      2.202      5.043      4.865      2.092          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.041     0.0589    0.00949    0.00383     0.0209     0.0364    0.00496    0.00189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.49G      1.433      4.721       4.21       1.67          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0399     0.0711    0.00986    0.00387     0.0205     0.0555    0.00536    0.00201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0402     0.0711    0.00989    0.00389     0.0215     0.0555    0.00537    0.00201\n",
      "Speed: 1.1ms preprocess, 12.6ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▄▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▅▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▁▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.4326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.2102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.72077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.93716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.48602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.03811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.36388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_083725-7zw1ue04\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_083725-7zw1ue04/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0327     0.0585    0.00852    0.00322     0.0291     0.0413    0.00628    0.00213\n",
      "Speed: 0.9ms preprocess, 28.0ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 640.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.56G      1.808      4.897      3.795      2.087         11        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0175     0.0503      0.005    0.00181     0.0103     0.0329    0.00307    0.00113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.97G      2.261      4.895      6.106      2.215          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0209     0.0607    0.00548    0.00204     0.0139     0.0433    0.00362    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         3G      2.222      3.695      4.047      2.044         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0244     0.0676    0.00655     0.0025     0.0145     0.0451    0.00417    0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         3G      2.295       4.27      3.678      2.118         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0303     0.0537    0.00741    0.00277     0.0196     0.0381      0.005    0.00185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.89G      1.784      3.034      3.868      1.595         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0286      0.052    0.00755    0.00296     0.0231     0.0433    0.00556    0.00215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0287      0.052    0.00753    0.00298     0.0223     0.0381     0.0056    0.00214\n",
      "Speed: 1.1ms preprocess, 12.9ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▆▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▃▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▁▄▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.02873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.78358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.8681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.59458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.03355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.17445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.99316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.77721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_083942-oi6rtl3a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_083942-oi6rtl3a/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0233     0.0551    0.00648    0.00266     0.0136     0.0551    0.00476      0.002\n",
      "Speed: 1.0ms preprocess, 28.4ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 568.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.87G      2.137      4.256      4.703      2.042          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0203     0.0433     0.0067    0.00244     0.0114     0.0312    0.00306     0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.58G      1.995      6.152        5.7      2.559          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0314     0.0503    0.00787    0.00282     0.0119     0.0381     0.0036    0.00126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.46G      1.677      4.223      5.153        1.9          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0314     0.0468    0.00896    0.00308     0.0163     0.0433    0.00403    0.00142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.48G      1.752      3.513      5.737      1.826          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0355     0.0503    0.00929    0.00339     0.0221      0.026    0.00444     0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      1.506      5.155      7.312      1.951          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0415     0.0555    0.00992    0.00375     0.0212     0.0468    0.00543     0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0422     0.0537    0.00995    0.00376     0.0214     0.0485    0.00557    0.00193\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▅▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃█▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▃▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▅█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.50573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 7.3124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.95099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.15494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.00507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.5027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.09479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.60766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_084351-nsysa4lm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_084351-nsysa4lm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0278     0.0568    0.00725    0.00265     0.0249     0.0413    0.00494    0.00181\n",
      "Speed: 0.9ms preprocess, 28.2ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 714.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.52G      1.366      3.418      4.512      1.664         12        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0183     0.0503    0.00519    0.00183     0.0114     0.0347    0.00307    0.00112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.95G      1.517      4.971      3.962      1.698         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0196     0.0537    0.00555    0.00205     0.0139     0.0381    0.00363    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.84G      1.925      4.041      4.899      2.047         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.023     0.0693    0.00648    0.00245      0.015     0.0468    0.00431    0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.89G      1.906      4.374      4.558       2.05         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0337     0.0641    0.00742    0.00271     0.0183     0.0381    0.00501    0.00187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.87G       1.74      4.202      4.112      1.774         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0357     0.0589     0.0082    0.00297     0.0211     0.0416    0.00577    0.00211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0354     0.0607    0.00825    0.00298     0.0208     0.0399    0.00565    0.00211\n",
      "Speed: 0.9ms preprocess, 12.9ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃█▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▃██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅▁█▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▂██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▄▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.7403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.11212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.77421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.20214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.88052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.16143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.00614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.80856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_084607-8eyomip1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_084607-8eyomip1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0196     0.0568    0.00634    0.00263     0.0158     0.0551    0.00486    0.00197\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 528.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.68G      1.868       3.57      5.138      2.161          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0254     0.0537    0.00748    0.00259      0.011     0.0277    0.00331    0.00118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G      1.123      3.355      12.72      1.318          1        640: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0283     0.0676    0.00841    0.00298     0.0203     0.0243    0.00421    0.00143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.48G      3.176      4.384      7.437      2.656          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0347     0.0503    0.00879    0.00328     0.0233     0.0312    0.00463    0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.47G       1.49      4.633      7.766      1.934          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0353     0.0589    0.00922    0.00361     0.0194     0.0364    0.00499    0.00189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      1.553      3.653      4.686      1.597          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0415     0.0641    0.00964    0.00378     0.0228     0.0503    0.00546    0.00209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0417     0.0641    0.00955    0.00377     0.0234     0.0503    0.00546     0.0021\n",
      "Speed: 1.0ms preprocess, 12.9ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂█▁▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁█▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▁█▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▁▇█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▅█▇▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.55327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.68604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.59715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.65298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.94052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.52796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.0383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.35022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_085017-lr6jpupm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_085017-lr6jpupm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0321     0.0654    0.00795    0.00301     0.0238     0.0448     0.0055    0.00195\n",
      "Speed: 1.1ms preprocess, 27.9ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 1425.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.32G      1.747      3.789       3.78      1.777         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.017     0.0537    0.00514    0.00179     0.0122     0.0295    0.00312    0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.67G      1.637       3.65      4.591      1.797         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.021     0.0485    0.00562      0.002     0.0133     0.0381    0.00354    0.00128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.56G      1.801       4.45      4.779       1.86         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0234     0.0589    0.00608    0.00228     0.0152     0.0312    0.00417    0.00154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.55G      1.698      3.721      4.339      1.702         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0265     0.0659    0.00713    0.00263     0.0167     0.0416    0.00477    0.00182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.57G      2.549      4.459       5.14      2.323         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0336     0.0624    0.00814    0.00294     0.0207     0.0399    0.00543    0.00206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0332     0.0641     0.0081    0.00292     0.0207     0.0399    0.00541    0.00206\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▂█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▁▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▅▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▂▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▁█▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▁▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.54871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.14049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.32271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.45896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.16952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.99292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.78249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_085234-de23rkfh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_085234-de23rkfh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.021     0.0671    0.00625    0.00255     0.0135     0.0482    0.00472    0.00194\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 806.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.83G     0.9794      2.466      4.563      1.294          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.028     0.0607    0.00731    0.00267     0.0139     0.0295    0.00372     0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.58G       1.84      5.362       4.32      1.785          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0317     0.0589    0.00839    0.00303     0.0165     0.0277    0.00369    0.00138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.47G      1.388      3.094        4.8       1.61          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0391     0.0589    0.00901    0.00313     0.0175     0.0277    0.00414    0.00147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.49G      1.401      2.843      4.634      1.499          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0369     0.0485     0.0093    0.00345     0.0192     0.0243    0.00455    0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G     0.9995      3.366      5.586      1.242          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0362     0.0537    0.00922    0.00365     0.0184     0.0329    0.00491    0.00178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0365     0.0537    0.00923    0.00362     0.0202     0.0364    0.00491    0.00177\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▇▇▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▄▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▃▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▆▄▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.0202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.0364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.99947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.58568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.24173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.36574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.98909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.55321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.05936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.46011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_085643-g191hr9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_085643-g191hr9d/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0248     0.0585    0.00693    0.00267      0.039     0.0207    0.00496    0.00177\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1738.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.25G      1.388      3.386      4.454       1.48         26        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0166     0.0537    0.00496    0.00175     0.0091      0.026    0.00304    0.00109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.39G      2.151      4.687      5.575      2.153         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0205     0.0572    0.00566    0.00203     0.0143     0.0399    0.00365    0.00133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.32G      1.638       4.15        4.6      1.806         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0209     0.0659    0.00633    0.00236     0.0149     0.0451    0.00422    0.00157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.29G      1.908      3.764      5.074      1.881         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.026     0.0572     0.0069     0.0026     0.0172     0.0399    0.00475    0.00181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.27G      1.777      3.651      4.819      1.868         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0366     0.0607    0.00807    0.00297     0.0167     0.0381    0.00543    0.00215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0366     0.0607    0.00805    0.00296     0.0177     0.0381    0.00538    0.00216\n",
      "Speed: 0.9ms preprocess, 12.9ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃█▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▃▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▄▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▅▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▁▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.77723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.81909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.86844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.65082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.19073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.77221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_085901-kdvlxxlo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_085901-kdvlxxlo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0205     0.0688    0.00619     0.0026     0.0143     0.0534    0.00473    0.00198\n",
      "Speed: 1.0ms preprocess, 28.4ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1039.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.62G      1.585      3.615      3.619      1.713         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0271     0.0555    0.00819    0.00282     0.0131     0.0468    0.00329    0.00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      2.044      4.094      4.306       2.15          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0321     0.0624    0.00898    0.00308     0.0124     0.0312    0.00347    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.09G      1.473       4.14      3.547      1.614         12        640: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0429     0.0572    0.00955    0.00338     0.0214     0.0295    0.00429    0.00159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      2.057      3.717       4.17      2.581          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0392     0.0555     0.0102    0.00365      0.021     0.0381    0.00519    0.00183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.07G       1.83      4.873        3.4      1.992         11        640: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0411      0.052    0.00978    0.00384     0.0202     0.0468    0.00545    0.00201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0417      0.052    0.00973    0.00382     0.0215     0.0485    0.00558    0.00202\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃█▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▇▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂█▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃█▂▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▅▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.83025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.39972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.99212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.87312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.52586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.04543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.38484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_090312-iximbt6p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_090312-iximbt6p/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0235     0.0602    0.00745    0.00303     0.0258     0.0396    0.00539    0.00194\n",
      "Speed: 0.9ms preprocess, 28.2ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 947.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.48G      1.545      3.784      4.396      1.581         38        640: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0167     0.0555     0.0049    0.00172    0.00943     0.0277    0.00301    0.00107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       7.1G      1.495      3.479      4.659      1.685         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.022     0.0485    0.00552    0.00194     0.0117     0.0312    0.00347    0.00124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.02G       1.64      3.057      4.272      1.653         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0203     0.0537    0.00602    0.00222     0.0117      0.026    0.00381    0.00143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.01G      2.101       4.73      5.011      2.121         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0241     0.0589     0.0067    0.00253      0.015     0.0416     0.0046    0.00174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      6.99G      1.492      4.052      4.034      1.677         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0283     0.0589    0.00738    0.00284     0.0183     0.0381    0.00499    0.00198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0293     0.0607    0.00736    0.00283     0.0179     0.0381    0.00498    0.00197\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▅▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▃▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▁▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▅▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▂▂█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▃▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▁▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.02931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.4922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.03362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.05195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.16538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.00727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_090530-y0pt657w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_090530-y0pt657w/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0198     0.0585    0.00611     0.0025     0.0152     0.0482    0.00471    0.00192\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1024.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.62G      1.659      4.441      4.414      1.712         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0292     0.0589    0.00765    0.00253     0.0118      0.052    0.00308    0.00116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.206      3.045      4.781      1.518          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0294     0.0676    0.00854    0.00285      0.012     0.0364    0.00341    0.00125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.06G      1.611      3.666        4.2      1.807          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0332     0.0633    0.00874    0.00302     0.0131     0.0329     0.0037    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G        2.3      5.418      5.761      2.331          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0382     0.0589      0.009    0.00313      0.014     0.0347    0.00446    0.00151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G      1.687      5.195      5.129      1.953          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0378     0.0537    0.00932    0.00345     0.0256     0.0364    0.00485    0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0373     0.0537    0.00928    0.00345     0.0216     0.0399    0.00489    0.00169\n",
      "Speed: 0.8ms preprocess, 12.9ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▂▁▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▄▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▁▃█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▁▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▆▇▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.03726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.12905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.95332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.19461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.50375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.06533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.4379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_090949-s2jajl00\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_090949-s2jajl00/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0298     0.0516    0.00725    0.00284     0.0292     0.0293    0.00541    0.00182\n",
      "Speed: 0.9ms preprocess, 28.2ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 947.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G      1.607       4.16      4.291      1.734         45        640: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0164     0.0468    0.00512    0.00179    0.00971     0.0277    0.00301     0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G       1.97      4.206       4.54      1.767         55        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.021     0.0468    0.00567      0.002     0.0115     0.0312    0.00363    0.00128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.42G       1.59      4.431      3.983      1.725         41        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0213     0.0659    0.00617     0.0023     0.0152     0.0485    0.00418    0.00157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.42G      1.768      4.029      4.576      1.655         40        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.027     0.0555    0.00697    0.00262     0.0163     0.0295     0.0048    0.00182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.5G      1.822      4.657      4.163      1.792         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0306     0.0589    0.00792     0.0029     0.0179     0.0399     0.0053    0.00205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0299     0.0572    0.00788    0.00291     0.0185     0.0399    0.00528    0.00205\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁█▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂█▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▁▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅█▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▇▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▃▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▁▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.02988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.82162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.16272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.79215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.65678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.15947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.99621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.79154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_091207-qsvoxpt0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_091207-qsvoxpt0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0216     0.0654    0.00613    0.00257     0.0147     0.0551    0.00481    0.00197\n",
      "Speed: 1.1ms preprocess, 28.5ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 861.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       4.8G      1.122      3.632      2.671      1.608         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0221     0.0572    0.00704    0.00257     0.0121     0.0347    0.00333    0.00117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G       2.06      5.711      3.645      2.236          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0321     0.0624    0.00837    0.00289     0.0148     0.0329    0.00385    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.07G      1.555      5.387      2.989      1.785         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0339     0.0624    0.00926    0.00316     0.0184     0.0347    0.00464    0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.06G      1.671      5.077      3.781       1.98          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0399     0.0589    0.00927    0.00344     0.0246     0.0295    0.00504    0.00191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.11G      1.999      5.338      3.183      2.114         14        640: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.042     0.0537    0.00955     0.0038     0.0288     0.0468    0.00617    0.00224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0421     0.0537    0.00949    0.00382     0.0262     0.0451    0.00624    0.00223\n",
      "Speed: 0.9ms preprocess, 12.8ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄██▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▃▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.99912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.18304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.11356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.3384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.94472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.41944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.03557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.29259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_091627-n51g8npe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_091627-n51g8npe/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0317     0.0602     0.0078    0.00306     0.0342      0.043    0.00601     0.0021\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 875.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.44G      2.396      4.403      6.474      2.441          3        640: 100%|██████████| 2/2 [00:01<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0198     0.0537    0.00585    0.00212      0.015     0.0364    0.00381    0.00137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.6G      1.759      3.751      4.525      1.801          9        640: 100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0294     0.0607    0.00781    0.00276     0.0178     0.0381    0.00514    0.00193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.65G      1.922      4.232      3.719      1.929         11        640: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0314     0.0589    0.00911    0.00348     0.0257     0.0659    0.00686    0.00272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.63G      1.793      4.662      4.011       1.86          6        640: 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0371     0.0763     0.0104    0.00414     0.0303     0.0641    0.00841    0.00335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.71G      1.623      3.327      4.033      1.665         12        640: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0441     0.0745     0.0125    0.00488     0.0392     0.0711     0.0105    0.00404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0432     0.0763     0.0126    0.00488     0.0381     0.0711     0.0105    0.00404\n",
      "Speed: 0.9ms preprocess, 12.9ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▃▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.49\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.62258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.03264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.66461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.32659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.0648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.95975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.74624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_091845-8t820fs4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_091845-8t820fs4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0423     0.0706     0.0104    0.00447     0.0364      0.062    0.00752    0.00306\n",
      "Speed: 1.1ms preprocess, 28.1ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 6594.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.45G      1.432      3.855      4.185      1.552          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0343     0.0624     0.0101    0.00376     0.0219     0.0399    0.00514    0.00195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G        1.5      3.364      5.186      1.515          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0379     0.0659     0.0106    0.00406     0.0218     0.0364    0.00554    0.00206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.06G      1.524      3.648      4.434      1.677          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0508     0.0659     0.0121     0.0047     0.0297     0.0503    0.00677    0.00236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G       1.57      3.436      4.832       1.92          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0615     0.0745     0.0134    0.00526     0.0422     0.0503    0.00783    0.00286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.09G      1.295       3.75      4.712      1.581         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0602     0.0884     0.0143    0.00583     0.0496     0.0693    0.00962    0.00335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0608     0.0919     0.0145    0.00585     0.0511     0.0693    0.00976    0.00336\n",
      "Speed: 0.9ms preprocess, 12.8ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▆▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▃▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▁▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▅▂▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.29541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.71173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.58148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.75031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.92628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.31666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.00424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.37346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_092305-esrb6s0t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_092305-esrb6s0t/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0469     0.0757     0.0112    0.00453      0.048     0.0602    0.00907    0.00328\n",
      "Speed: 1.2ms preprocess, 28.2ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1568.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.62G      1.749      6.489      3.103      1.996          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0554     0.0659      0.013    0.00467     0.0352     0.0329    0.00535     0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.758      3.678      3.626      1.907          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0434     0.0897     0.0146    0.00531     0.0287     0.0364     0.0063    0.00216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G      1.499      5.187      3.533      1.996          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0441     0.0988     0.0149    0.00542     0.0279     0.0381    0.00692    0.00233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.772      4.568      4.255      1.997          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0455     0.0936     0.0158    0.00589     0.0383     0.0555    0.00753     0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       2.1G      2.109      5.152      3.478      2.058         19        640: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0519     0.0925     0.0162    0.00648     0.0484     0.0572    0.00834    0.00285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0525     0.0936     0.0162    0.00649     0.0473     0.0555    0.00838    0.00287\n",
      "Speed: 1.2ms preprocess, 12.9ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▁▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▄█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▅▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.10938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.47763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.05837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.15164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.05197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.87737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.07123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 5.00892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_092619-iw0wmtv7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_092619-iw0wmtv7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0479     0.0688     0.0118    0.00474     0.0348     0.0602    0.00775    0.00277\n",
      "Speed: 1.1ms preprocess, 28.4ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 1050.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.42G      1.804      4.638      3.897      1.843         21        640: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0228     0.0468    0.00541    0.00195     0.0109     0.0347    0.00338    0.00124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.62G      1.752      4.582       4.16      1.822         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.026     0.0624    0.00689     0.0026     0.0168     0.0485    0.00467    0.00178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.39G      1.475      4.922      3.972      1.736         25        640: 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0315     0.0503    0.00842    0.00313     0.0239     0.0416     0.0061    0.00235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.53G       1.79      4.333      4.083      1.781         34        640: 100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0333     0.0728    0.00967    0.00376     0.0251     0.0503    0.00731      0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.54G      1.659      4.309      3.783      1.739         37        640: 100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0449     0.0815     0.0115    0.00457     0.0392     0.0711    0.00943    0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0445     0.0832     0.0116    0.00459     0.0382     0.0693    0.00946    0.00377\n",
      "Speed: 1.0ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃█▄▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▁▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▄█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.65852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.78336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.73909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.30937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.00249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.75464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_092836-ldbgw36n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_092836-ldbgw36n/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0406     0.0706     0.0102    0.00439     0.0334     0.0602    0.00752    0.00308\n",
      "Speed: 1.2ms preprocess, 28.7ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 773.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.12G      1.138      3.076      3.121      1.401         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0413     0.0659     0.0101    0.00359     0.0194     0.0381    0.00514    0.00182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.22G      2.014      4.784      3.242      2.026         15        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0406     0.0669     0.0105    0.00386     0.0239     0.0451    0.00562      0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.07G      1.793      4.724      3.366      1.822         12        640: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0463     0.0728     0.0112    0.00432     0.0331      0.052    0.00663     0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.07G      2.243      6.946      3.935       2.13         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0626     0.0849     0.0136    0.00558     0.0515     0.0607    0.00863    0.00312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.13G      1.515      3.647      3.582      1.676         18        640: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0729      0.078     0.0154    0.00669     0.0621     0.0589     0.0108    0.00396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0731     0.0763     0.0154    0.00664      0.064     0.0572     0.0105    0.00391\n",
      "Speed: 0.8ms preprocess, 12.9ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▄█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▇▅█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▂▃█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▇▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.51493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.58203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.64666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.90621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.29588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.26097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_093301-2jbvon7l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_093301-2jbvon7l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.056     0.0723     0.0133    0.00557     0.0651     0.0637      0.011    0.00434\n",
      "Speed: 1.1ms preprocess, 28.1ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 4122.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.42G     0.8422       2.88      3.736      1.421          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0429     0.0745     0.0117     0.0041     0.0269     0.0329    0.00509    0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.15G      0.728       2.61      3.336      1.288          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0451     0.0832     0.0128    0.00444     0.0314     0.0399    0.00587    0.00199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.06G       1.05      2.008      3.072      1.388          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0458     0.0763     0.0137    0.00489     0.0311     0.0607    0.00643    0.00223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.527      2.475      4.756       2.15          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0599     0.0572     0.0145     0.0051      0.033     0.0433    0.00708    0.00252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.07G      1.144      3.472      3.423      1.679         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0721     0.0555     0.0156    0.00582     0.0659     0.0347    0.00818    0.00295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0726     0.0555     0.0159    0.00587     0.0673     0.0347    0.00789    0.00293\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▂▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆█▆▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▁▄█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▂▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▁▂█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▄▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00587\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.14379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.42322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.47247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.07833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.8046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.08747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 5.17919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_093615-jygufooy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_093615-jygufooy/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0414     0.0826     0.0112    0.00442     0.0393     0.0563    0.00746    0.00251\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 1161.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.11G      1.545      4.377      4.208      1.698         29        640: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0194     0.0485    0.00563    0.00205     0.0137     0.0399    0.00354    0.00126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.57G      1.446      3.758      3.898      1.655         44        640: 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0263     0.0711    0.00694    0.00263     0.0167     0.0503    0.00463    0.00171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.47G      1.685      4.176      3.828      1.842         43        640: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.032     0.0503    0.00826    0.00323     0.0243     0.0416    0.00617     0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.47G      1.624      4.355      3.714      1.676         57        640: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0335     0.0676    0.00939    0.00389     0.0273     0.0589     0.0077     0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.62G      1.554      3.898      3.846      1.643         65        640: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0448     0.0763     0.0126    0.00501     0.0325     0.0624    0.00957    0.00405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0448     0.0763     0.0126    0.00505     0.0325     0.0624    0.00966     0.0041\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁█▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▃▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▁█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.54\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.55364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.84627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.64256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.8975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.84132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.00891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.96612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.64983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_093834-8j4g3bew\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_093834-8j4g3bew/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0467     0.0809     0.0105    0.00459     0.0334     0.0637    0.00736    0.00317\n",
      "Speed: 1.1ms preprocess, 28.8ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 2918.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.14G      2.008      4.299      3.751      1.721         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0408     0.0659     0.0102    0.00363     0.0209     0.0364    0.00515    0.00191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.16G      1.852      4.779      4.011      1.884         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0368     0.0641     0.0102    0.00387     0.0239     0.0416    0.00563    0.00219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.727       4.04      4.338      1.553         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0506     0.0641     0.0107    0.00439     0.0389     0.0468    0.00677    0.00253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.04G      1.823      4.995      3.784      1.875         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.049     0.0693     0.0119    0.00501     0.0408     0.0451    0.00766    0.00295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       3.1G       2.01      3.904      3.998      1.898         29        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0554     0.0849     0.0146    0.00577     0.0495     0.0555    0.00936    0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0559     0.0849      0.015    0.00585     0.0492     0.0555     0.0094    0.00359\n",
      "Speed: 0.9ms preprocess, 12.8ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄█▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▇▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.01018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.99818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.89767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.90386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.91553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.26561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.00818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.17921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_094259-g8zmzxm5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_094259-g8zmzxm5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0462     0.0723     0.0119    0.00502      0.058     0.0551     0.0101    0.00394\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 1103.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.43G      1.495      3.939      3.524      1.676          9        640: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0229     0.0659    0.00612    0.00225     0.0144     0.0433     0.0041    0.00149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G      1.635      4.505      3.956      1.787         11        640: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0319     0.0572    0.00845    0.00323     0.0239     0.0312    0.00603    0.00239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.51G      1.664      4.329      4.308      1.773         12        640: 100%|██████████| 3/3 [00:01<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0471     0.0919     0.0118     0.0045     0.0338     0.0659    0.00852    0.00356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.75G      1.846      4.085      3.916       1.86         18        640: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0804     0.0919     0.0204    0.00904     0.0697     0.0728      0.017    0.00706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.64G      1.754       3.68      3.836      1.755         12        640: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0935     0.0988     0.0265      0.012     0.0879      0.102      0.024     0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0934     0.0988     0.0267     0.0121     0.0913      0.102      0.025     0.0102\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▅█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▅▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.09335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.09128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.75449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.83594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.75508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.67991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.55275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.94857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.66157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_094518-w8b5mtbz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_094518-w8b5mtbz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0892     0.0929     0.0225     0.0103     0.0698     0.0775     0.0172    0.00713\n",
      "Speed: 1.1ms preprocess, 28.9ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 2066.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.12G      1.823      3.773      3.937      1.741         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0766     0.0815     0.0186    0.00784     0.0577     0.0728     0.0128    0.00495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      2.145       4.42      4.856      2.519          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0787     0.0936     0.0218     0.0091      0.073     0.0728     0.0161    0.00583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.11G      1.496      2.732      3.452      1.527         24        640: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0894      0.104     0.0241     0.0105     0.0763     0.0763     0.0183    0.00718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.06G      1.654      3.379      3.909      1.658         17        640: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0875     0.0936     0.0252     0.0114     0.0786     0.0763     0.0197    0.00776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       3.1G      1.517      3.261      4.022      1.526         23        640: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0908     0.0884     0.0272     0.0125     0.0865     0.0711     0.0213    0.00846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0901     0.0891     0.0273     0.0125      0.088     0.0745      0.021     0.0085\n",
      "Speed: 0.9ms preprocess, 12.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁██▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅█▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃█▁▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃█▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▁▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.09008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.08805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.51683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.02217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.52594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.26093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.82304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.79888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.92477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.06311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_094948-5tmmaoe7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_094948-5tmmaoe7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.109     0.0671     0.0217     0.0102      0.106     0.0654     0.0185    0.00779\n",
      "Speed: 1.1ms preprocess, 28.2ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1412.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.65G      1.784      4.064      4.629      1.708         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0552     0.0797     0.0198    0.00837     0.0416     0.0485     0.0098    0.00389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G      1.567      4.771      3.858      1.736          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0546     0.0901     0.0187    0.00786     0.0642     0.0381    0.00964    0.00359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.363      4.298      3.564      1.524         13        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0552      0.101     0.0198    0.00839     0.0355     0.0641     0.0102    0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.04G      2.144      5.072      4.152      2.054         15        640: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0532      0.102     0.0205     0.0086     0.0564     0.0381     0.0107    0.00393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.633      3.963      3.901      1.806         15        640: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0649     0.0797     0.0207    0.00881     0.0537     0.0416     0.0114    0.00409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0664     0.0797     0.0209    0.00882     0.0538     0.0468     0.0115    0.00404\n",
      "Speed: 1.2ms preprocess, 13.0ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▄▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▆▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▂▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂█▁▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▄▁█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▃▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▁▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▄▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▆▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.6331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.9015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.80635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.96341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.99984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.23133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.02801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.73365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_095308-mryiv8x1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_095308-mryiv8x1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0458     0.0792     0.0142     0.0057     0.0317      0.062    0.00918     0.0033\n",
      "Speed: 1.1ms preprocess, 28.4ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 1010.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.45G      1.726      4.446      3.901      1.789         58        640: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0237     0.0728    0.00651     0.0024     0.0152     0.0468     0.0042    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.38G      1.753      4.321      3.913      1.816         51        640: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0318      0.052    0.00854    0.00322     0.0229     0.0399    0.00605    0.00239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.29G      1.569      4.231      3.766      1.677         41        640: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0403     0.0607     0.0112    0.00467     0.0307     0.0607    0.00872    0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.73G      1.555      4.282      3.667       1.61         46        640: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0531     0.0763     0.0166    0.00701     0.0436     0.0607     0.0126    0.00541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.529      3.848      3.824       1.68         49        640: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0788     0.0901     0.0203     0.0094     0.0683     0.0763     0.0173     0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0774     0.0867     0.0203    0.00947     0.0689     0.0763     0.0172    0.00787\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▅▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▃▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.52857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.82376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.6805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.84828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.54578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.66148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_095524-guniarqa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_095524-guniarqa/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.069     0.0947     0.0166    0.00693     0.0516     0.0688     0.0114    0.00473\n",
      "Speed: 1.1ms preprocess, 28.9ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 711.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       4.9G      1.078      3.055      3.994      1.399         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0797     0.0884      0.019     0.0078      0.052     0.0607      0.012    0.00487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.929      2.446      5.213      1.744          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0913     0.0867     0.0207    0.00876     0.0722     0.0624     0.0139    0.00578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.914       4.99      4.302      2.116         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0999     0.0849      0.023    0.00971     0.0825     0.0669      0.016    0.00636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      2.076      4.198      5.033      2.327          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0912     0.0884     0.0248      0.011      0.074     0.0711     0.0185    0.00732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.909      4.513      5.375      1.736         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0933     0.0919     0.0253     0.0114     0.0803      0.078     0.0198    0.00797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0925     0.0936     0.0255     0.0115     0.0804      0.078     0.0198    0.00797\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▁█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.08039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.90864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.3747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.73553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.51257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.84085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.83335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.9442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.00109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_095958-32w5n13f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_095958-32w5n13f/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581     0.0714     0.0861     0.0187    0.00764     0.0607     0.0688     0.0139     0.0057\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 921.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.42G      1.605      4.389      3.946      1.755          8        640: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0254     0.0624    0.00687    0.00257     0.0176     0.0485    0.00452     0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.65G      1.698      4.296      4.361      1.776          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0353     0.0728     0.0101    0.00397     0.0272     0.0659    0.00771    0.00316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.6G      1.498      3.839      3.934      1.597          6        640: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0655     0.0953     0.0182    0.00737     0.0536     0.0659     0.0141    0.00578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.6G      1.561       3.66      3.898      1.647         12        640: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.11     0.0988     0.0311     0.0156      0.103     0.0919     0.0284     0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.65G      1.353      2.988      3.701      1.519          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.151      0.118     0.0427     0.0218      0.135      0.106     0.0387     0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.154      0.118     0.0429     0.0219      0.136      0.106     0.0387     0.0193\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▄▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.04295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.03875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.15369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.13641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.35346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.70101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.51901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.98767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.7649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.10696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.91501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.47884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_100217-b5dsmkav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_100217-b5dsmkav/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.125     0.0878     0.0349     0.0163       0.12     0.0749     0.0311     0.0135\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 2294.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.15G      1.629      3.114      4.552       1.96         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.123     0.0971     0.0365     0.0185      0.129     0.0901     0.0297     0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      2.084      4.479      4.379      2.028         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.136      0.104     0.0386     0.0198      0.139      0.101     0.0329     0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      2.257      4.904      4.343      2.336         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.134      0.115     0.0406     0.0201      0.131      0.102     0.0329     0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.451      3.268      3.773      1.755         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.148      0.111     0.0417     0.0206      0.146     0.0971     0.0369     0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      2.019      3.021      4.288      1.969         17        640: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.155      0.104     0.0426     0.0211      0.149     0.0971     0.0375     0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.153      0.102     0.0428     0.0213      0.152     0.0936     0.0377     0.0176\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄█▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▇█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▆▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▄█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▆█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇█▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.04277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.03772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.15337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.15214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.09359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.0186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.28761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.9686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.0214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.77848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.32563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.92001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.73278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_100651-pvuyjgbz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_100651-pvuyjgbz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.149     0.0912     0.0359     0.0182      0.133     0.0861     0.0316     0.0153\n",
      "Speed: 1.1ms preprocess, 28.3ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 976.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.42G      1.382      4.483       3.14      1.593         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0796      0.109     0.0225    0.00979     0.0589     0.0763     0.0137    0.00545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      1.476      5.083      4.276      1.899          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0792      0.114      0.025     0.0112     0.0617     0.0815     0.0163    0.00661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.13G      1.235      2.977      3.458      1.626          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0874      0.113     0.0271     0.0127     0.0719     0.0797     0.0177     0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.12G      1.421      2.986      2.701      1.854         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0996      0.107     0.0293     0.0137     0.0808     0.0745     0.0199    0.00885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.13G      1.202      2.692       4.37      1.644          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.108      0.116     0.0313      0.015     0.0943     0.0867     0.0231     0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.107      0.114     0.0317      0.015      0.095     0.0849     0.0229     0.0101\n",
      "Speed: 1.0ms preprocess, 12.9ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃█▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▆▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▂▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃█▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▂▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.10739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.09501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.2016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.36956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.64384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.69237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.92316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.69822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.01745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.27174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_101008-syrldcul\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_101008-syrldcul/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.07      0.074     0.0235     0.0097     0.0695     0.0585     0.0173    0.00731\n",
      "Speed: 1.2ms preprocess, 28.3ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<00:00, 1078.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.15G      1.592      4.057      3.939      1.739         23        640: 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0249     0.0624    0.00681     0.0026     0.0173     0.0433    0.00456    0.00173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.51G      1.565      4.564      4.195      1.701         31        640: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0342     0.0711     0.0102    0.00411     0.0268     0.0572    0.00789    0.00324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.57G      1.599      3.918      4.026      1.716         46        640: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0757     0.0884     0.0182    0.00797     0.0652     0.0745     0.0151    0.00643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.59G      1.478      3.932      3.766      1.647         25        640: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.135      0.111     0.0389     0.0209      0.127      0.104     0.0359     0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.65G      1.416      3.335      3.402      1.598         31        640: 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.197      0.116      0.057     0.0311      0.183      0.106     0.0538     0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.195      0.114     0.0571     0.0311      0.183      0.107     0.0537     0.0263\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.05706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.19483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.18302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.41586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.40172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.59842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.33542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.70623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.91245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.91778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.41506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_101226-9zvsljrg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_101226-9zvsljrg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.145      0.107     0.0419     0.0237      0.149      0.102     0.0385     0.0205\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1592.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.55G      1.928      3.795      3.678       1.94         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577        0.1     0.0988      0.034     0.0171      0.083     0.0832     0.0258     0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G       1.72      2.684       5.32      1.854          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.105      0.101     0.0362     0.0187     0.0868     0.0832     0.0272     0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      2.101      3.924      4.351      2.225          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.122      0.114     0.0396     0.0204     0.0995     0.0936     0.0304     0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.995      4.618      3.972      2.475         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.133      0.125     0.0423     0.0222      0.118      0.113      0.037     0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.04G      1.882      3.611      3.294      1.874         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.143      0.128     0.0481     0.0248      0.132      0.116     0.0424     0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.142       0.13     0.0483     0.0248      0.131      0.116     0.0427     0.0195\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▁█▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▁▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▁▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.04832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.14213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.1312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.11612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.88211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.29417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.87429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.61124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.69735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.10599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.89991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_101704-ns76la51\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_101704-ns76la51/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.149      0.114     0.0493     0.0285      0.153      0.102      0.043     0.0233\n",
      "Speed: 1.0ms preprocess, 27.8ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1406.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.62G      1.836      4.133      3.157      2.071         33        640: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0865      0.121     0.0281     0.0123     0.0744     0.0988     0.0195    0.00721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       3.2G      1.799      4.755      3.463      1.776         22        640: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0829      0.113     0.0275     0.0124     0.0735      0.102     0.0195    0.00748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.859      4.833       3.41      1.974         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0953      0.128     0.0284     0.0127      0.083      0.114     0.0206    0.00814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.08G      2.368      4.557      3.534       2.13         25        640: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0947      0.123     0.0295     0.0137      0.088      0.114     0.0219    0.00862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.09G      1.689      3.592      3.078      1.676         31        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577        0.1      0.113     0.0299     0.0141     0.0875      0.101     0.0212    0.00882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.103      0.113       0.03      0.014     0.0894      0.104     0.0212    0.00882\n",
      "Speed: 0.9ms preprocess, 12.8ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▅▁█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▂▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▇▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇▃▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄██▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.10336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.08935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.07827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.59249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.83643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.99975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.08906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_102024-qya8z54z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_102024-qya8z54z/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.103      0.112     0.0335      0.018     0.0952     0.0947     0.0274     0.0135\n",
      "Speed: 0.9ms preprocess, 27.8ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 924.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G       1.62      4.337      3.936       1.74         14        640: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0323     0.0572    0.00778    0.00289     0.0205     0.0364     0.0054    0.00201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.28G      1.746      4.607       4.06      1.795         22        640: 100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0448     0.0641     0.0137    0.00574     0.0433     0.0537     0.0115    0.00477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.69G      1.627      4.193      3.784      1.808         18        640: 100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0975     0.0763      0.024     0.0115     0.0912     0.0693     0.0208    0.00958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.27G      1.545      3.914      3.554      1.662         15        640: 100%|██████████| 5/5 [00:02<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.137     0.0971     0.0378     0.0177      0.107     0.0849     0.0297     0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.66G      1.418      3.329       3.34      1.582         22        640: 100%|██████████| 5/5 [00:02<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.18      0.113     0.0545     0.0283      0.161      0.106     0.0458      0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.179      0.113     0.0544     0.0285      0.164      0.106     0.0459     0.0239\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅█▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇█▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆██▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▂▁▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.05441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.16364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.1058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.4177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.33984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.58164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.32924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.91832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.70601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.06031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.9142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_102244-kcx27ztx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_102244-kcx27ztx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.128      0.112     0.0385     0.0171      0.121     0.0912     0.0281     0.0122\n",
      "Speed: 1.1ms preprocess, 28.5ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 609.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.11G       1.93       3.88       3.49       2.01         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.17      0.139     0.0564     0.0276      0.169      0.127     0.0453     0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      1.658      4.084      3.674      1.742         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.172      0.146     0.0569     0.0268      0.156      0.132     0.0453     0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         3G      1.541      4.331      4.408       1.82          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.17      0.154     0.0575     0.0278      0.154      0.137     0.0463     0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G      1.904      3.435      4.445      2.011          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.168      0.147     0.0588      0.028      0.163      0.132     0.0486      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.968        4.9      4.376      2.212          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.183      0.146      0.061     0.0295      0.171      0.133     0.0502     0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.189      0.142     0.0608     0.0291      0.171      0.135     0.0496      0.022\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▂▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅█▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇▃▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▂██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▄▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.06084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.18916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.17066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.14211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.13481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.96765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.37614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.21237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.90019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.76847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.95724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.14442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_102722-7f5b3j5o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_102722-7f5b3j5o/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.134      0.141     0.0548     0.0243      0.134      0.114     0.0447     0.0183\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 1084.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.13G      1.709      4.405      4.019      1.863         37        640: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.027     0.0468    0.00721    0.00275      0.019     0.0329    0.00494    0.00193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G      1.631      4.043      4.124      1.708         32        640: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0422     0.0728     0.0119    0.00489     0.0382     0.0659    0.00987    0.00406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.59G      1.632      4.124      3.814      1.801         29        640: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0718     0.0693     0.0157    0.00689     0.0552     0.0572     0.0119    0.00548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.64G      1.502       3.55      3.419      1.638         39        640: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.114     0.0745     0.0303     0.0155      0.111     0.0728     0.0253     0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.34G      1.569      3.259      3.201      1.655         54        640: 100%|██████████| 5/5 [00:02<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.181      0.127     0.0511     0.0247      0.159      0.111     0.0424     0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.179      0.125     0.0516     0.0249      0.154      0.109     0.0425     0.0207\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▅▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▆▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃▁█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁█▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.1539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.56946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.20113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.65463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.25866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.00035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.69439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.13702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.89648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_102937-xm0njc6i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_102937-xm0njc6i/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.135     0.0981     0.0438     0.0207      0.131     0.0878     0.0329     0.0157\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 803.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         6G      1.529      3.587      3.336      1.807         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.141      0.142     0.0514     0.0235       0.13      0.118     0.0349     0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      1.536      3.455      3.947      1.721          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.142       0.14      0.051     0.0248      0.133       0.12     0.0368     0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.701       3.82      4.345      1.998          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.144      0.146     0.0503     0.0251      0.139      0.132      0.038     0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      2.193       4.26      4.367      2.479          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.148      0.156     0.0508     0.0262      0.141      0.123     0.0401      0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.873      3.249      3.763      1.713         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.158      0.154     0.0544      0.028      0.154      0.137     0.0418     0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.151      0.165     0.0541     0.0278      0.152      0.135     0.0414     0.0204\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▂▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▁▃█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▅██▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▁▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▂▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.05408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.15147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.15178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.16464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.13518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.87309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.76347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.71254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.24878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.89191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.76167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.39897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_103417-wqddi4jr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_103417-wqddi4jr/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.14       0.15     0.0569     0.0265       0.13       0.12     0.0415     0.0182\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 1055.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.52G      1.772      4.487      3.996      1.833          4        640: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0336     0.0589    0.00833    0.00312     0.0238     0.0485    0.00594    0.00233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.73G      1.421      4.576      3.785      1.648          4        640: 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0612      0.078     0.0167    0.00692     0.0498     0.0676     0.0134    0.00565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.69G      1.672      4.054      4.167      1.874          1        640: 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.162      0.107     0.0455     0.0244      0.152     0.0901     0.0406     0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.33G      1.446      3.623      3.168       1.73          2        640: 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.257      0.163     0.0913     0.0478      0.252      0.142     0.0862     0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.34G      1.782      3.364      3.075       1.82          3        640: 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.28      0.185      0.113     0.0613      0.293      0.184      0.113     0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.281      0.185      0.113     0.0613      0.292      0.184      0.113     0.0563\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▆█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇▁█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▁▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.11282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.11261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.06128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.05634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.29154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.18508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.18371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.78222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.07464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.82044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.36355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.75816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.28536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.99663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_103634-4dmkb940\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_103634-4dmkb940/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.262      0.189       0.11     0.0592       0.26      0.176     0.0987     0.0507\n",
      "Speed: 1.2ms preprocess, 28.5ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 578.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.01G      1.611      3.568       3.21      1.793         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.211      0.194        0.1     0.0536      0.226      0.192     0.0908     0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.17G      2.201      4.316      3.492      2.198         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.227      0.201      0.104     0.0555      0.231      0.197     0.0955     0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      2.217      5.099      4.048      2.418         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.236      0.205      0.105     0.0564      0.241      0.192     0.0963     0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.848      3.996      3.442      1.916          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.234      0.208      0.107     0.0573      0.238      0.196     0.0964     0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G      1.624       2.96      3.538       1.72         15        640: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.231      0.213       0.11     0.0588      0.228      0.194     0.0991     0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.231      0.213      0.111      0.059      0.227      0.194     0.0998     0.0494\n",
      "Speed: 1.1ms preprocess, 12.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▁▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁██▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃█▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▆█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▅█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▄▁▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅▁▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.11074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.09981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.04938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.23129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.22744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.21317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.19411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.62422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.53786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.72002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.96035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.71361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.49209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.9034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.53088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_104114-g385euvd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_104114-g385euvd/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.249        0.2      0.108     0.0583      0.272      0.206       0.11     0.0512\n",
      "Speed: 1.0ms preprocess, 28.4ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 659.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.61G      1.336      3.246      2.479      1.594         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.143      0.203     0.0662     0.0301      0.139      0.154     0.0553     0.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.274      3.901      3.497      1.759         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.145      0.227     0.0672     0.0309      0.143      0.153      0.057     0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.724      2.692      3.352      1.928         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.152      0.224       0.07     0.0318       0.15      0.166     0.0579     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.285      3.546      2.923      1.524          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.167      0.205     0.0723     0.0329      0.169      0.161     0.0606     0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.379      2.044      2.999      1.651         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.176      0.198     0.0766     0.0347      0.181      0.168      0.064     0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.174      0.196      0.077     0.0345      0.178       0.17      0.064     0.0269\n",
      "Speed: 1.1ms preprocess, 13.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃█▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁▇▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▁█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▇▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▅█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆█▃▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.06405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.17836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.19584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.16984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.37903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.99893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.65079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.04379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.80877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.27447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.97043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.85352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_104432-j8qybckx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_104432-j8qybckx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.155      0.205     0.0857      0.044      0.186      0.165     0.0849     0.0364\n",
      "Speed: 1.1ms preprocess, 28.1ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 1073.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.47G      1.734      4.286      4.199      1.808         34        640: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0308     0.0468    0.00801    0.00303     0.0244     0.0364    0.00586    0.00225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.59G      1.637      4.209      3.945       1.77         38        640: 100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0786     0.0867     0.0222     0.0102     0.0655     0.0797     0.0175    0.00772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.59G       1.58      3.971      3.581       1.73         31        640: 100%|██████████| 6/6 [00:04<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.16      0.107     0.0526     0.0265      0.136     0.0953     0.0429     0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.27G      1.462      3.063      3.214      1.631         27        640: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.166      0.121     0.0663     0.0325       0.16      0.106     0.0498     0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.29G      1.502      3.113       3.01      1.637         28        640: 100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.253      0.179     0.0973     0.0474      0.222      0.146     0.0688     0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.253      0.179     0.0972     0.0474      0.227      0.147     0.0693     0.0329\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▆▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅▁▃█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▄▁▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.09724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.03288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.2533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.22734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.17851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.14731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.50239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.01039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.1125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.88688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.23288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.05442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.32717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_104650-dsfdt6zx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_104650-dsfdt6zx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.206      0.174      0.085     0.0412       0.18      0.138      0.062     0.0279\n",
      "Speed: 1.1ms preprocess, 28.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 654.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.56G      1.489      2.964       3.48      1.677         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.196      0.187     0.0838     0.0398      0.142      0.142     0.0493     0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.412      3.886      2.791      1.845         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.215      0.191     0.0875     0.0407      0.158      0.147     0.0513     0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G        1.4      3.669      2.493      1.684         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.206      0.182     0.0909     0.0419      0.168      0.146     0.0559      0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.565      3.499      2.624      2.127          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.219      0.177     0.0927      0.043       0.18      0.146     0.0594     0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.455      4.211      3.737      1.872         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.224      0.179     0.0963     0.0448      0.188      0.151     0.0632     0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.223       0.18     0.0961     0.0449      0.191      0.147     0.0631     0.0275\n",
      "Speed: 1.3ms preprocess, 13.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆█▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▂▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▃▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▆▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.09612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.06305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.2233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.19072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.18024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.14731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.49\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.73668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.87232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.21103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.40422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.62971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_105131-r5tjjxr7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_105131-r5tjjxr7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.22      0.185      0.103     0.0512       0.17      0.145     0.0727     0.0326\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 996.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G      1.702      4.293       4.18      1.745         43        640: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.035      0.052    0.00808      0.003     0.0226     0.0312    0.00575    0.00222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.72G      1.518      4.021      3.985      1.659         34        640: 100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.111      0.104     0.0298     0.0141      0.096     0.0884     0.0255     0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.68G      1.636      3.491      3.505      1.735         50        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.212      0.132     0.0848     0.0458      0.199       0.12     0.0774     0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.33G      1.474      3.201      3.079      1.622         58        640: 100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.276      0.185       0.13     0.0712      0.275      0.184       0.12     0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G       1.46      3.013      2.878      1.624         35        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.312      0.265      0.176     0.0939      0.303      0.255      0.161     0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.314      0.265      0.176     0.0939      0.301      0.255      0.161     0.0832\n",
      "Speed: 0.9ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▆▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▇▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.17627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.16121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.09393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.31379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.30149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.26516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.25477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.87843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.62447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.01331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.64698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.95617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.84196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.53062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_105347-08ndsu5a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_105347-08ndsu5a/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.296      0.258       0.17      0.095       0.31      0.222      0.158     0.0805\n",
      "Speed: 1.0ms preprocess, 28.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 641.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.36G      1.353      2.986      3.219      1.489         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.237      0.243      0.137     0.0715      0.236      0.228      0.131     0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.362      1.998      2.608      1.497          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.233       0.26      0.138     0.0717      0.229      0.239      0.132     0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      2.321      4.374      4.809       2.24         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.241      0.258      0.139     0.0726      0.226      0.244      0.133     0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.05G      1.598      3.034      3.521      1.579         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.243      0.263      0.139     0.0725      0.243      0.248      0.135     0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.875      3.311      4.277      2.034          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.257      0.262       0.14     0.0728      0.265      0.236      0.134     0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.258      0.262      0.139     0.0726      0.264      0.237      0.134     0.0641\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▁█▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▁█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▁█▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▁█▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.13931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.13428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.07264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.06413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.26379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.2617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.23744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.87524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.27674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.03394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.31123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.64436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.24938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.85061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.54184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_105828-xecgpowv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_105828-xecgpowv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.263      0.253      0.138     0.0731      0.261      0.243       0.14     0.0642\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 971.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         8G      1.696       4.21      4.168      1.828         17        640: 100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0307     0.0503    0.00961     0.0038     0.0251     0.0468    0.00737    0.00293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.38G      1.647      4.112      4.146      1.726          9        640: 100%|██████████| 7/7 [00:04<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.145       0.12     0.0438     0.0215      0.141      0.114     0.0423     0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.38G       1.49       3.79      3.194      1.653         13        640: 100%|██████████| 7/7 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.288      0.196      0.141      0.072      0.263      0.179       0.12     0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.32G      1.518      3.373       3.12      1.651         13        640: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.354      0.253      0.195      0.107      0.327      0.237      0.171     0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.515      3.219      2.973      1.677          8        640: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.39      0.308      0.242      0.139      0.386      0.282      0.217      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.389      0.307      0.242      0.139      0.382      0.282      0.218      0.121\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▄▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.24207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.21764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.38941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.38202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.2825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.51478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.97309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.21919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.61999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.67911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.49096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_110046-mbw5d0kl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_110046-mbw5d0kl/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.376        0.3       0.21      0.117      0.352      0.284       0.19     0.0961\n",
      "Speed: 1.1ms preprocess, 28.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 494.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.1G      1.261      2.892      2.367      1.468         33        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.337        0.3      0.222      0.128      0.343      0.291      0.208      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.14G      1.657      3.173      2.622      1.686         49        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.33       0.31      0.226      0.129      0.336      0.296       0.21      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.01G      1.546      3.204      2.425      1.601         47        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.345      0.314      0.225       0.13      0.332      0.307      0.208      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.96G      1.305      2.659      2.376      1.501         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.338      0.306      0.226      0.131      0.329       0.31      0.213      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.96G      1.592      3.609      3.102       1.77         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.34        0.3      0.227      0.131      0.336      0.299      0.215      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.341      0.304      0.227      0.131      0.334      0.303      0.216      0.117\n",
      "Speed: 1.0ms preprocess, 12.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄▁█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▄▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆█▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▆▂▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁█▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.22687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.21552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.34069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.33399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.30329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.59219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.10197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.76979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.60852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.57905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.8072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.79693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.33969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_110530-t2pkh756\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_110530-t2pkh756/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.34      0.305       0.21      0.116      0.328      0.277      0.186     0.0949\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 1105.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G      1.706       4.45      3.934      1.802         75        640: 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0305     0.0537    0.00884    0.00344     0.0229     0.0416    0.00656    0.00266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.57G      1.566       4.19      3.962      1.693         36        640: 100%|██████████| 7/7 [00:04<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.097      0.102     0.0251     0.0122     0.0981     0.0919     0.0245     0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.57G      1.548      3.662      3.403      1.728         49        640: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.178      0.118     0.0499     0.0236       0.18      0.113     0.0447     0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.3G      1.472       3.14      3.042      1.624         34        640: 100%|██████████| 7/7 [00:04<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.209      0.171     0.0813     0.0393      0.196      0.158     0.0689     0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G      1.374      2.978      2.637      1.548         46        640: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.269      0.235      0.134     0.0726      0.271      0.219      0.121     0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.269      0.237      0.134     0.0727      0.269      0.218      0.121     0.0638\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▁▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.13391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.12105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.07267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.06378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.26942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.23659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.21794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.37353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.63674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.54807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.97834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.00866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.95698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_110750-l6ohp3ct\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_110750-l6ohp3ct/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.28      0.246       0.13     0.0643      0.267      0.212      0.114     0.0548\n",
      "Speed: 1.1ms preprocess, 28.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 553.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.97G      1.358      3.863      2.398      1.577         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.202       0.22      0.106     0.0514      0.218      0.189     0.0848      0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G      1.161      3.565      2.727      1.311         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.225      0.222      0.107     0.0525      0.222      0.205     0.0876     0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.96G      1.427      3.572      2.695      1.523         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.233       0.21      0.108     0.0536      0.222      0.196     0.0878     0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.89G      1.234      2.553      3.406      1.614         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.221      0.218      0.109     0.0538      0.223      0.198     0.0899     0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G      1.469      3.331      3.033       1.73         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.209      0.225      0.112     0.0553      0.249      0.184     0.0955     0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.209      0.225      0.112     0.0552      0.247      0.182     0.0948     0.0463\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▂▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆▆▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃█▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▁▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃▃█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.11179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.09481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.05519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.04628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.20891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.24703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.2253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.18198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.46872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.03314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.72978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.33118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.86699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.1672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.92572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.23559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_111235-acukiz0j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_111235-acukiz0j/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.203       0.22      0.114     0.0608      0.244       0.21      0.109     0.0506\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 986.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.35G      1.627      4.361      4.168      1.739         28        640: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0379     0.0797     0.0101    0.00375     0.0265     0.0624     0.0071    0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.76G      1.601      3.775      3.773      1.687         35        640: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.135     0.0988     0.0422     0.0211      0.125     0.0953     0.0355     0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.52G      1.471      3.313      3.093      1.646         29        640: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.283      0.203      0.126     0.0696      0.268      0.185      0.111     0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.26G      1.464      3.267      2.861      1.643         21        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.385      0.276      0.208      0.122      0.376      0.263      0.183      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G      1.356      3.024       2.38      1.558         28        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.371      0.293      0.233      0.136      0.366      0.273      0.216      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.37      0.296      0.232      0.136      0.364      0.272      0.216      0.117\n",
      "Speed: 1.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▃▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.23241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.21551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.37004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.36359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.29636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.2721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.35586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.37997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.55841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.0241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.64365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.61624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.83419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.46439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_111453-b0awj3wr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_111453-b0awj3wr/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.374      0.253        0.2      0.112       0.37      0.248      0.197     0.0998\n",
      "Speed: 1.0ms preprocess, 28.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 588.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.72G       1.28      3.128      3.237      1.411         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.345      0.287      0.199      0.109      0.387      0.252      0.179     0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.99G       1.84      2.288      3.572      1.968         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.359      0.296      0.199      0.108      0.376       0.26      0.181     0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.95G      1.366      2.764      2.515      1.623         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.369      0.284      0.202      0.108      0.382      0.267      0.179     0.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G      1.241      1.948      2.934      1.569         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.406      0.277      0.204      0.109      0.398      0.256      0.184     0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G      1.385      2.274      2.389       1.42         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.401      0.277      0.205       0.11      0.395      0.255      0.184     0.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.403      0.277      0.205       0.11      0.393      0.253      0.183      0.093\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂▃▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▇▆▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁▃█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▅█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅█▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▂▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.20499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.18276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.10953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.39284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.2773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.25303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.38458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.38851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.41965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.27404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.67861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.7968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.81644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.62364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_111939-mdkhc8s4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_111939-mdkhc8s4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.33      0.301      0.207      0.112      0.348      0.279      0.201     0.0986\n",
      "Speed: 1.3ms preprocess, 28.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:00<00:00, 1026.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.6G      1.592      4.206      4.146      1.725          9        640: 100%|██████████| 9/9 [00:06<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0333     0.0468     0.0103    0.00431     0.0269     0.0555    0.00836     0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.69G      1.622      3.914      3.903      1.806          8        640: 100%|██████████| 9/9 [00:05<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.128     0.0901       0.03     0.0153      0.118     0.0884      0.027     0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.25G      1.457      3.243      3.034      1.615          8        640: 100%|██████████| 9/9 [00:05<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.319      0.256      0.153     0.0801       0.32      0.243      0.143     0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.25G      1.291      2.865      2.461      1.506          8        640: 100%|██████████| 9/9 [00:05<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.388      0.336      0.233       0.13      0.404      0.308      0.223       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.301      2.794      2.263      1.517          8        640: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.393      0.369      0.296      0.176      0.396       0.35      0.283      0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.394       0.37      0.296      0.177      0.394      0.357      0.283      0.159\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅█▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▅█▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.29569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.28316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.17653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.15899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.39408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.39365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.36972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.35702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.30065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.26285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.51694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.79443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.51894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.31098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.70259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.19632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_112155-otv976pq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_112155-otv976pq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.412      0.352      0.288      0.166      0.423      0.312      0.266      0.146\n",
      "Speed: 1.2ms preprocess, 28.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 460.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.59G      1.486      3.312      2.324       1.57         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.341      0.355      0.256      0.151      0.348      0.357      0.252      0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G      1.299      2.857      2.545      1.535         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.34      0.359      0.258      0.153      0.357      0.363      0.255      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.95G      1.362       2.87      2.365      1.481         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.351      0.364       0.26      0.155      0.359      0.348      0.256      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.95G      1.787      3.626      3.032      1.774         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.35      0.362      0.261      0.156      0.354      0.361      0.256      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.89G      1.419      2.608      2.572      1.649         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.359      0.354      0.263      0.156      0.361      0.354      0.257      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.356      0.354      0.263      0.156      0.363      0.355      0.258      0.138\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▄█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅█▁▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▂▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆▃▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▄▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.26309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.2583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.13793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.35615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.36258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.35355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.35529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.4187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.57206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.64889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.60843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.52451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.4724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.67771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.30879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_112648-h4gzeupt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_112648-h4gzeupt/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.397      0.317      0.252      0.139      0.387      0.317      0.241      0.123\n",
      "Speed: 0.9ms preprocess, 28.3ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:00<00:00, 908.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.32G      1.678      4.306      4.163      1.813         43        640: 100%|██████████| 9/9 [00:06<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.042     0.0763     0.0118    0.00484      0.029     0.0537    0.00913    0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.73G      1.583      3.671      3.651       1.71         36        640: 100%|██████████| 9/9 [00:05<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.198      0.106     0.0543     0.0243      0.173     0.0988      0.043     0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G       1.56      3.326      3.018      1.692         31        640: 100%|██████████| 9/9 [00:05<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.306      0.213      0.133     0.0672      0.301      0.205      0.123     0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.6G      1.427      3.205      2.724      1.573         39        640: 100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.354      0.255      0.198      0.109      0.361       0.26      0.188     0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.66G      1.386      2.958      2.327      1.566         40        640: 100%|██████████| 9/9 [00:05<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.404      0.322      0.289      0.168      0.382      0.304      0.259      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.404      0.322      0.288      0.168      0.376      0.305      0.259      0.145\n",
      "Speed: 0.6ms preprocess, 13.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅█▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▅█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.28834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.25888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.16793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.14545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.37632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.30503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.38576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.56623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.95844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.55841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.34233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.71764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.29594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_112907-3s1z6fym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_112907-3s1z6fym/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.478      0.257      0.271      0.153      0.369      0.293      0.253      0.131\n",
      "Speed: 1.1ms preprocess, 29.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 555.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.94G      1.719      2.941      2.698      1.547         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.344      0.315      0.238      0.136      0.356      0.315      0.227      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.16G      1.576        2.8      2.231      1.492         49        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.345      0.322      0.242      0.141      0.361      0.314      0.234      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         5G      1.482      2.361      2.368      1.601         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.355       0.31      0.248      0.144      0.356      0.308      0.239      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.03G       1.57      3.001      2.198      1.701         44        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.36      0.322      0.251      0.148      0.356      0.319      0.243      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G      1.349      3.022      2.714      1.629         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.374      0.324      0.256      0.152      0.413        0.3      0.248      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.37      0.322      0.258      0.152      0.433      0.286       0.25      0.132\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄█▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▇▇▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▄▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▁▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▁▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▆▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.25779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.24956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.15158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.13186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.36957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.43285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.28596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.34868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.71366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.62877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.02184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.5533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.48006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.67908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.26984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_113400-895754wr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_113400-895754wr/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.337      0.312      0.236      0.132      0.344      0.298      0.225       0.11\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:00<00:00, 982.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.34G      1.583      4.208      4.016      1.755         17        640: 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0478     0.0763     0.0132    0.00552     0.0365     0.0676    0.00989    0.00422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.65G      1.656      3.834      3.663      1.758         21        640: 100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.277      0.179     0.0995     0.0496      0.269      0.165     0.0912     0.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.34G      1.476      3.373      2.889      1.652         23        640: 100%|██████████| 10/10 [00:05<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.366      0.247       0.18     0.0988      0.331      0.236       0.16      0.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.63G      1.446      3.168      2.498      1.622         19        640: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.375      0.263      0.198      0.111      0.345      0.236      0.175     0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.59G      1.301      2.828      2.115       1.52         24        640: 100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.401      0.336      0.274      0.155      0.395      0.319      0.245       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.401      0.336      0.274      0.155      0.391      0.317      0.244       0.13\n",
      "Speed: 1.1ms preprocess, 13.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▇▅▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▁▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.27445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.2443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.15539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.39127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.31716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.30057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.11482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.51969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.82765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.56704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.29587\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.7664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.62987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_113620-iyzv0i38\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_113620-iyzv0i38/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.388      0.317      0.251      0.141      0.377      0.303      0.231      0.117\n",
      "Speed: 1.0ms preprocess, 28.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 492.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       5.4G      1.324      4.023       2.29      1.649         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577        0.3      0.288      0.201      0.113      0.332      0.218       0.17     0.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.9593      1.745      1.508      1.336         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.304      0.302      0.206      0.115       0.32      0.236      0.176     0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.97G      1.144      2.585      1.926      1.458         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.322      0.289      0.211      0.119      0.346      0.248      0.192      0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.87G      1.049      2.175      2.118      1.395         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.336      0.281      0.214       0.12      0.331      0.263      0.195      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.88G      1.018      2.319      2.278       1.34         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.312      0.302      0.218      0.122      0.357      0.251      0.199      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.31      0.302      0.218      0.123      0.358      0.251      0.198      0.105\n",
      "Speed: 1.5ms preprocess, 13.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁▆▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃█▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▅▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▄▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.21764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.19814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.12272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.1055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.30989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.35769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.2513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.01763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.27799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.34001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.31935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.6241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.50034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.79598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.70889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_114112-lxxsbpba\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_114112-lxxsbpba/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.333      0.289      0.222      0.126      0.321      0.279      0.203        0.1\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:00<00:00, 925.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.01G      1.658      3.979      4.065       1.75          7        640: 100%|██████████| 11/11 [00:08<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0413     0.0659     0.0109    0.00419     0.0346     0.0659    0.00912     0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.84G      1.595      3.666      3.381       1.73          3        640: 100%|██████████| 11/11 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.149      0.132     0.0582      0.028      0.136       0.12      0.044     0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.62G      1.466      3.194      2.821      1.627          2        640: 100%|██████████| 11/11 [00:06<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.41      0.286      0.251      0.144        0.4      0.279      0.227      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.33G      1.412      2.951      2.224      1.578          3        640: 100%|██████████| 11/11 [00:06<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.449      0.341      0.328      0.195      0.432      0.331      0.297      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.58G      1.313       2.77      2.076       1.46          6        640: 100%|██████████| 11/11 [00:06<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.417      0.406      0.351      0.205      0.403      0.392      0.316      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.418      0.406       0.35      0.205      0.406      0.393      0.317      0.177\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▆█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▄█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.34978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.31657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.20528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.17678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.41828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.40577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.31304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.07644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.46021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.77022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.47476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.10339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.62235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.31379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_114330-y9eknok3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_114330-y9eknok3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.381      0.378      0.322      0.173      0.412      0.339      0.305      0.147\n",
      "Speed: 1.0ms preprocess, 28.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 530.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.05G      1.377      2.913      2.326      1.389         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.388      0.383       0.32      0.194      0.381      0.374      0.299      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.13G      1.923      3.706      2.369      1.848         41        640: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.417      0.366      0.325      0.196        0.4      0.357      0.304      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.04G      1.376      3.477      2.293      1.524         44        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.409      0.366      0.325      0.197      0.397      0.354      0.303      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.01G      1.866      4.557      2.778      1.979         40        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.353      0.416      0.325      0.197      0.363      0.392      0.308       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.95G      1.461      3.693      2.173      1.616         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.375      0.399      0.326      0.198      0.365      0.397       0.31      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.376      0.397      0.327      0.198      0.371      0.392       0.31      0.171\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▇▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄█▇▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▂▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▁▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▃▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▆▆██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃█▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.32671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.31009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.19763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.17112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.37603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.37109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.39688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.46078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.17254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.61636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.69295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.45284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.20955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.60987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.07834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_114825-axzrr6wn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_114825-axzrr6wn/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.378      0.339      0.286      0.163      0.384      0.344      0.283      0.141\n",
      "Speed: 0.9ms preprocess, 28.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<00:00, 1031.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.03G      1.787      4.305      4.293      1.869         30        640: 100%|██████████| 11/11 [00:08<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0441     0.0624     0.0121    0.00504     0.0347     0.0537     0.0097    0.00409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.7G      1.614      3.746      3.563       1.74         36        640: 100%|██████████| 11/11 [00:06<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.281      0.196      0.115     0.0599       0.26      0.185      0.103     0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.26G      1.446      3.079      2.689      1.649         33        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.459        0.3      0.281      0.177       0.41      0.295       0.26       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.57G      1.401          3      2.299      1.587         27        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.471      0.371      0.356      0.224      0.463      0.354      0.334      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G       1.36      2.721      2.119      1.512         46        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.506      0.402      0.396      0.251      0.517      0.378      0.381      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.506      0.406      0.396      0.251      0.518       0.38      0.381      0.226\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.3955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.38112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.25095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.50582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.51821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.37955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.35995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.11921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.51217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.72086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.58005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.07344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_115046-2edzhepo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_115046-2edzhepo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.513      0.384      0.376      0.225      0.506      0.379      0.363        0.2\n",
      "Speed: 1.1ms preprocess, 29.0ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 525.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.88G      1.625      2.468      2.507      1.839         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.439      0.409      0.368       0.23      0.443      0.412      0.363       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G      1.692      3.548      2.373      1.778         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.449      0.402      0.374      0.237      0.449      0.409      0.368      0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.01G       1.54      3.014       2.11       1.69         35        640: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.467      0.406      0.379      0.239      0.467      0.402      0.373      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.97G      1.334      3.622      2.043      1.758         37        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.468      0.407      0.384      0.241      0.478      0.393      0.379       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.01G      1.459      3.156      1.994      1.661         40        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.468      0.404      0.388      0.245      0.492       0.39      0.384      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.471      0.404      0.388      0.245       0.49      0.393      0.384      0.221\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▅▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▅▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▄█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.38848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.38411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.24515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.47074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.49037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.99394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.66093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.15559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.42727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.09704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.60925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.10121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_115544-2nai4tcn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_115544-2nai4tcn/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.503      0.392      0.372       0.22      0.515      0.384      0.365      0.196\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:00<00:00, 925.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.14G      1.666      4.144      4.056      1.784         25        640: 100%|██████████| 12/12 [00:08<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0753     0.0728     0.0198    0.00827     0.0739     0.0659     0.0168    0.00731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.66G      1.585      3.571      3.339      1.721         13        640: 100%|██████████| 12/12 [00:06<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.278      0.201      0.134     0.0718      0.283      0.198      0.126     0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.59G      1.466      3.085      2.637       1.61         11        640: 100%|██████████| 12/12 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.402      0.393      0.327      0.195      0.395      0.386      0.301      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.63G      1.299      2.652      2.048      1.475         16        640: 100%|██████████| 12/12 [00:06<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.458      0.445      0.384      0.219      0.465      0.418      0.351      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.63G      1.315      2.666      1.933      1.453         21        640: 100%|██████████| 12/12 [00:06<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.532      0.416      0.409      0.246      0.547      0.392      0.384      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.523      0.416      0.409      0.245      0.533      0.399      0.384      0.215\n",
      "Speed: 0.7ms preprocess, 13.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.4088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.38381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.24548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.21541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.52288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.53328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.41594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.31517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.9326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.45252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.66639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.46127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.93262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.59975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.19987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_115804-i7ibgmtd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_115804-i7ibgmtd/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.468      0.389      0.368      0.212      0.464      0.375      0.354      0.181\n",
      "Speed: 0.8ms preprocess, 29.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 491.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.06G      1.222      2.136      1.731      1.385         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.542      0.347      0.385      0.225      0.443      0.388      0.365      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.13G      1.401      2.151      2.123      1.369         46        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.436      0.421       0.39      0.226      0.445      0.409      0.367        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.01G      1.427      2.665      1.926       1.45         38        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.462      0.395      0.393       0.23      0.457      0.388      0.371      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.94G      1.373      3.191      2.609       1.51         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.442      0.428      0.397      0.232       0.47      0.376      0.374      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.99G      1.261      2.091      1.644      1.267         45        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.426      0.447        0.4      0.235      0.492      0.378      0.375      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.423       0.45        0.4      0.235      0.499      0.378      0.375      0.209\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▂▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▇█▆▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▄▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▄▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▁▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.39989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.23498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.20929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.42333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.49879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.45039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.37782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.26078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.64353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.26661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.09076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.43615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.00404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.57596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.05779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_120303-sxv2xrdc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_120303-sxv2xrdc/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.494      0.372      0.357      0.203      0.544      0.334      0.346      0.178\n",
      "Speed: 1.2ms preprocess, 28.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:00<00:00, 854.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G      1.611      4.193       4.04      1.731         46        640: 100%|██████████| 12/12 [00:09<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0547     0.0555     0.0133     0.0052     0.0433     0.0515     0.0083     0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.43G      1.626      3.627      3.265      1.738         38        640: 100%|██████████| 12/12 [00:07<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.21       0.17     0.0851      0.042       0.19      0.147     0.0688      0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.45G      1.426      2.954      2.502      1.576         42        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.381      0.303      0.244      0.134      0.363      0.289       0.22      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.52G      1.358      2.785      2.196      1.532         51        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.409      0.383      0.315      0.179      0.404      0.355      0.291      0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.63G      1.251      2.515      1.791      1.428         44        640: 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.505      0.466      0.432      0.266      0.495      0.448      0.417      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.504      0.466      0.432      0.266      0.493      0.449      0.416      0.243\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.43158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.41638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.26613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.2428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.50445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.49309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.4662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.25061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.79144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.42804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.42036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.89307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.59153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.81132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_120524-98t9r24q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_120524-98t9r24q/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.439       0.42      0.389      0.222      0.448      0.398      0.373      0.199\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 416.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.62G      1.187      2.391      1.531      1.438         44        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.465      0.421      0.389      0.243      0.453      0.414      0.371      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.08G     0.8991      1.853      1.436      1.245         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.471      0.407      0.392      0.245      0.456      0.411      0.375      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.96G     0.9787      2.248      1.319      1.343         30        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.461      0.412      0.393      0.245      0.455      0.409      0.377      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G     0.8085      2.486      2.146       1.31         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.484      0.406      0.394      0.244      0.469        0.4      0.379      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.8478      2.422      1.635       1.28         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.468        0.4      0.394      0.245      0.465      0.395       0.38      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.469      0.402      0.394      0.244      0.467      0.397      0.381      0.225\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▄▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▂█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▃▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▂▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▅▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▆█▅▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅▇▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.39403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.38105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.24413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.46927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.4673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.84778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.63508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.28031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.42163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.4488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.02302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.62824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.84124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_121028-ourapwez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_121028-ourapwez/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.517      0.391      0.383      0.222      0.512      0.383      0.371      0.198\n",
      "Speed: 1.2ms preprocess, 28.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<00:00, 917.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.51G      1.684      4.308       3.93      1.762         39        640: 100%|██████████| 13/13 [00:09<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577     0.0984      0.101     0.0268     0.0124     0.0899     0.0919     0.0245     0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.44G      1.552      3.498      3.163      1.691         28        640: 100%|██████████| 13/13 [00:07<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.387       0.33      0.234      0.129      0.376      0.303      0.217      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.29G      1.426      2.969      2.479      1.605         31        640: 100%|██████████| 13/13 [00:07<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.432      0.314      0.269      0.159      0.459      0.295      0.252      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G      1.296      2.616      2.047      1.475         25        640: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.519      0.373      0.394      0.246      0.529      0.369      0.377      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.36G      1.172      2.405      1.701       1.35         36        640: 100%|██████████| 13/13 [00:08<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.503      0.463       0.45      0.271       0.54      0.433      0.434      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.504      0.461       0.45      0.271      0.521      0.444      0.434      0.241\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.03733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.44975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.27056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.50442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.52126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.46101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.17189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.70134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.35006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.40519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.42282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.88407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.59704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.01489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_121248-w9eeyvk0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_121248-w9eeyvk0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.523      0.442      0.436      0.248      0.498      0.434       0.41      0.216\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 503.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.91G      1.448          3      1.963      1.493         15        640: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.476      0.421      0.415      0.251      0.509      0.402      0.409      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.26G       1.44      2.831       1.94      1.535          8        640: 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.538      0.395      0.426      0.259      0.541      0.397      0.416      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.22G      1.395      2.752       1.98      1.572          6        640: 100%|██████████| 4/4 [00:01<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.514      0.444      0.443      0.272      0.512      0.455      0.432       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.3G      1.628      2.622      2.634      1.711          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.554      0.421      0.442      0.274       0.55      0.416      0.431      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.318      2.592      1.947      1.468          6        640: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.505      0.454      0.441      0.274      0.508      0.449      0.432      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.505      0.456      0.442      0.274      0.505      0.454      0.432      0.253\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▇▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▁▇▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁█▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▄▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▁▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▃▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.44155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.27398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.25326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.50461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.50481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.45581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.31788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.94693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.46799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.59195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.84171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.55812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.86361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_121755-gs87bh6v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_121755-gs87bh6v/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.501      0.454      0.419      0.244      0.515      0.449      0.416      0.222\n",
      "Speed: 0.9ms preprocess, 28.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 464.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.07G       1.12      2.414       1.61       1.37          5        640: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.465      0.407      0.382      0.239      0.482      0.418      0.386      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.3G      1.026      2.196       1.55      1.302          4        640: 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.466      0.456       0.41      0.253      0.481      0.452      0.409      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.27G      1.289      2.461      1.836      1.467          2        640: 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.526       0.43      0.422      0.262      0.517      0.442      0.414      0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.2G      1.156      2.115      1.529       1.35          3        640: 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.494      0.457      0.426      0.265       0.49      0.454      0.414      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.16G      1.196      2.642      1.597      1.442          5        640: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.487      0.459      0.425      0.265       0.48      0.438      0.413      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.483      0.461      0.425      0.266       0.48      0.442      0.413      0.247\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁█▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▁█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▁█▃▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▂▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▇▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.42464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.41296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.26565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.48324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.47999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.46101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.19639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.59746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.44186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.64164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.42583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.86373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.59516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.82841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_122128-bowh3gsa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_122128-bowh3gsa/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.461      0.446       0.38      0.217       0.48      0.413      0.381        0.2\n",
      "Speed: 0.9ms preprocess, 28.9ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|██████████| 301/301 [00:00<00:00, 923.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.6G      1.599      4.005      3.751      1.725         33        640: 100%|██████████| 19/19 [00:13<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.316      0.229      0.171     0.0954      0.299      0.205      0.144     0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.91G      1.385      2.945      2.446      1.556         50        640: 100%|██████████| 19/19 [00:11<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.466      0.303      0.283      0.176      0.452      0.288      0.265      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.86G      1.263      2.633      1.879      1.409         55        640: 100%|██████████| 19/19 [00:11<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.545      0.407      0.433      0.267      0.543      0.404       0.41      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.93G      1.154      2.335      1.528      1.331         47        640: 100%|██████████| 19/19 [00:11<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577        0.5       0.51       0.48      0.302      0.623      0.428      0.473      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.54G      1.117      2.164      1.358      1.316         54        640: 100%|██████████| 19/19 [00:11<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.518      0.562      0.515      0.333      0.508      0.551      0.507      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.515       0.56      0.515      0.333      0.514      0.548      0.507      0.305\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.51478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.50677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.33276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.30474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.51549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.51374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.55979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.54766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.11664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.35815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.3159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.16433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.34597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.55058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.48596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.61879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_122401-cb4p4dh9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_122401-cb4p4dh9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.578      0.506      0.529      0.317      0.576      0.505      0.521      0.298\n",
      "Speed: 1.1ms preprocess, 29.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 472.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       7.8G      1.258      2.372      1.514      1.412         15        640: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.534      0.518      0.495      0.319      0.532      0.522      0.492      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.07G      1.255      2.258       1.36      1.433          9        640: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.546      0.501      0.506      0.321      0.535       0.49       0.49      0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.25G      1.223      2.301      1.414      1.381         11        640: 100%|██████████| 7/7 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.589      0.506      0.523      0.336      0.601      0.516      0.529      0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.31G      1.169      2.276      1.346      1.317         17        640: 100%|██████████| 7/7 [00:03<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.616       0.52      0.551      0.353      0.599      0.529      0.546      0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.92G      1.003      2.021      1.203      1.263         19        640: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.594      0.577      0.576      0.366      0.602      0.558      0.566      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.594      0.581      0.576      0.366      0.603      0.558      0.566      0.346\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▄▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.57599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.56582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.36622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.34642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.59409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.60285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.58059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.55771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.00298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.20285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.26298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.02087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.28599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.45919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.4433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.43436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_122925-avpum5od\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_122925-avpum5od/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.589      0.555      0.563      0.339      0.592      0.559      0.559      0.319\n",
      "Speed: 1.1ms preprocess, 28.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 437.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.98G      1.337      2.694      1.501      1.506         12        640: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.571      0.534      0.538      0.344      0.571      0.534      0.536      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.33G      1.269      2.296      1.446      1.419         15        640: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.54      0.516      0.513      0.325      0.547       0.52      0.515      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.22G       1.33      2.434      1.458        1.5         13        640: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.657      0.484      0.547      0.358      0.655      0.482      0.541      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.18G      1.222      2.394      1.464      1.371         24        640: 100%|██████████| 7/7 [00:03<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.614      0.496      0.537      0.351       0.62      0.485      0.525      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G      1.289      2.382      1.372      1.444         11        640: 100%|██████████| 7/7 [00:03<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.604      0.494       0.54      0.354      0.612      0.499      0.536      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.655      0.484      0.547      0.358      0.652      0.482      0.541      0.328\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▁█▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅▁█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▇▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▁█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▆▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▆▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄█▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▆▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃█▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▄█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▇▁▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.54738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.54112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.3578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.32846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.65545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.65153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.48354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.4818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.28906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.37231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.44401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.38188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.29338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.4916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.45193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.51199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_123309-v7mt7sjv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_123309-v7mt7sjv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.575      0.553      0.557      0.333      0.587      0.535      0.547      0.305\n",
      "Speed: 0.8ms preprocess, 28.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/retrain/train/labels... 501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 501/501 [00:00<00:00, 937.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.76G      1.522      3.453      3.294      1.647         12        640: 100%|██████████| 32/32 [00:21<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.434      0.352      0.315      0.192      0.426      0.334      0.284      0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.56G      1.266      2.547       1.82      1.418         14        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.479      0.379      0.359      0.206      0.463      0.343      0.321      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.42G      1.198      2.311      1.513      1.343         21        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.579      0.407      0.439      0.243      0.569      0.399      0.425      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.39G       1.18       2.21      1.335       1.34         14        640: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.593       0.52      0.537      0.332      0.597      0.501      0.526      0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.68G      1.162      2.069       1.25      1.352         14        640: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.671      0.555      0.607      0.385      0.681      0.549      0.599       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.042 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.669      0.555      0.606      0.385      0.677       0.55      0.598      0.359\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇██▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.60619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.5982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.38521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.35899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.66885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.6774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.55459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.54953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.16176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.24977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.35166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.06937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.31293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.36409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.4889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.44433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_123547-4df4r096\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_123547-4df4r096/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.642      0.557      0.595      0.355      0.686      0.549        0.6      0.336\n",
      "Speed: 1.1ms preprocess, 29.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_41/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 445.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.08G      1.235      2.157       1.29      1.377          9        640: 100%|██████████| 32/32 [00:20<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.781      0.504       0.65      0.429       0.78      0.497      0.634      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.03G      1.197      2.145      1.275      1.324         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.638      0.577       0.62      0.384      0.652      0.563       0.61      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.91G      1.176      2.077      1.147      1.321         15        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.699      0.615      0.675      0.426      0.698      0.614      0.668      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.22G      1.156      2.061      1.166      1.284         12        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.685      0.643      0.664      0.421      0.686      0.634      0.666      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.19G      1.146      2.015      1.111      1.281         19        640: 100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.718      0.546      0.631      0.393      0.723      0.551      0.626      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.782      0.504       0.65      0.429      0.784      0.497      0.634      0.399\n",
      "Speed: 1.1ms preprocess, 13.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▅▁█▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▁██▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▇▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄█▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁█▄▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃█▄▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.64991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.63393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.42897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.39874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.78189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.78418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.50433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.4974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.14568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.11077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.28078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.01482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.34377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.33531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.47927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.3551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_124148-k28lv6io\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_124148-k28lv6io/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581       0.67      0.578      0.646      0.399       0.68      0.578       0.64      0.377\n",
      "Speed: 1.3ms preprocess, 29.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_42/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 478.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_42/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.83G      1.183       2.09       1.17      1.302         15        640: 100%|██████████| 32/32 [00:21<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.706      0.635      0.693       0.46       0.72      0.622      0.684       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.01G       1.13      1.895      1.068      1.275         10        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.667      0.542      0.613      0.383      0.637      0.562      0.602      0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.94G      1.087      1.878      1.059      1.274         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.685      0.567      0.631      0.393      0.705      0.565      0.624      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.23G      1.109      1.859      1.066      1.255         13        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.661      0.608      0.648      0.412      0.657      0.607      0.643      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.24G      1.097      1.837     0.9972      1.226         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.711      0.586      0.646      0.405      0.721      0.577      0.638      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.707      0.633      0.692       0.46      0.717      0.623      0.684       0.42\n",
      "Speed: 1.1ms preprocess, 13.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▂▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▇█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁█▇▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▆█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.69231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.68404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.45977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.4198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.70655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.71679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.63258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.62286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.09674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.99719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.22634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.83655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.33585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.29323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.45999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.41547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_124643-z1s0o4dp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_124643-z1s0o4dp/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.702      0.577      0.666      0.418      0.785      0.544      0.659      0.405\n",
      "Speed: 1.3ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_43/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 466.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_43/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.04G      1.275      2.205      1.284      1.375         11        640: 100%|██████████| 32/32 [00:20<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.699      0.639      0.696      0.437      0.696      0.643      0.687      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.31G      1.232      2.132      1.218      1.351         24        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.688      0.503      0.572      0.355      0.675      0.504      0.568      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.95G      1.158      2.057      1.133      1.302         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.706      0.561      0.641      0.409      0.712      0.566      0.639      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.22G      1.173      1.997      1.184       1.31         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.696      0.564      0.622      0.389       0.72      0.552      0.627      0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G      1.173      2.009      1.108      1.303         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.725      0.544      0.625      0.386       0.72      0.558      0.626      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.699       0.64      0.695      0.437      0.695      0.641      0.687      0.413\n",
      "Speed: 0.8ms preprocess, 13.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▁▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅▁█▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁▇█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▂▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁█▄▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁█▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.69526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.68652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.4369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.41301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.69855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.69549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.63951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.64124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.17308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.10752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.30272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.00882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.3964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.37716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.53142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_125138-iy3v7684\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_125138-iy3v7684/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.794      0.598      0.709       0.44      0.804      0.594      0.707      0.428\n",
      "Speed: 1.1ms preprocess, 29.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_44/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 452.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_44/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.12G      1.241      2.136      1.211      1.366         16        640: 100%|██████████| 32/32 [00:21<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577       0.77      0.627      0.725      0.476      0.761      0.617      0.712      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.07G      1.158      2.083      1.107       1.29         17        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.675      0.639      0.675      0.422       0.68       0.64      0.675      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.95G      1.129      1.971      1.091      1.285         10        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.722       0.57      0.648      0.431      0.714      0.567      0.639      0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.23G      1.143      2.003      1.097      1.288         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.713      0.602      0.656      0.422      0.713      0.595      0.648      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.24G      1.116      1.957     0.9997      1.272          7        640: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.744      0.633       0.71      0.465      0.754      0.655      0.718      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.768      0.625      0.724      0.476      0.761      0.617      0.712      0.443\n",
      "Speed: 1.3ms preprocess, 13.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▃▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▄▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁▂▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇█▁▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆█▁▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▂█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄▇█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▃█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.72368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.71202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.47645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.44287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.7679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.76104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.62501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.11602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.99972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.27168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.95681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.28446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.1155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.43365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.28012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_125633-eeeznkta\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_125633-eeeznkta/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.693      0.673      0.721      0.453      0.738      0.654      0.722      0.435\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Pothole-Detection-9/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/temp_0_45/train/labels... 38 images, 0 backgrounds, 0 corrupt: 100%|██████████| 38/38 [00:00<00:00, 519.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Pothole-Detection-9/temp_0_45/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/valid_0/labels.cache... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.96G      1.375      2.141      1.143       1.49         16        640: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.725       0.64      0.701      0.455      0.731      0.646      0.709      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.26G      1.296      2.303      1.167      1.434         18        640: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.745      0.634      0.703      0.457      0.756      0.635      0.711      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.18G       1.22      2.097      1.217      1.379         15        640: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.734      0.638      0.706      0.459      0.765      0.633      0.716       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.19G      1.288      2.471      1.278      1.379         14        640: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.729      0.645      0.709      0.463      0.749      0.651      0.716      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.2G      1.238      2.067      1.155      1.409         17        640: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.747       0.65      0.711      0.466      0.753      0.652      0.716      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        317        577      0.738      0.652      0.711      0.465      0.753      0.651      0.715      0.444\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▄▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▂▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▁▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▂▅█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▁▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▅▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.71118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.71536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.46515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.44355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.73786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.7534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.65165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.65128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.23796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.15502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.40944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.06731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.26182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.09181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.41614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.22004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/Pothole-Detection-9/wandb/offline-run-20231203_130129-kocrwca0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231203_130129-kocrwca0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Pothole-Detection-9/test_0/labels.cache... 318 images, 0 backgrounds, 0 corrupt: 100%|██████████| 318/318 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        318        581      0.781      0.639      0.718      0.453      0.768      0.656      0.725      0.441\n",
      "Speed: 0.9ms preprocess, 28.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Итоговый результат (инкрементальное обучение) для класса 0: \n",
      " defaultdict(<class 'list'>, {0: [0.002227729296095378, 0.005361294462911356, 0.0016583516892033033], 1: [0.0020014771585026244, 0.00476338185661084, 0.0015311830425362358], 2: [0.001967599707510882, 0.004856354878482477, 0.0015134203416287163], 3: [0.0019421694612822365, 0.004723971285407612, 0.0013889010167556627], 4: [0.001975963563109217, 0.004730573587828044, 0.0014062960519465552], 5: [0.0019157972319545549, 0.004709378710265009, 0.0014212904221374873], 6: [0.0019684879565298454, 0.004808777623938056, 0.001495732190915728], 7: [0.0030588170883455667, 0.007515713718411281, 0.0021930790807309962], 8: [0.0032765413706996654, 0.009068760589693754, 0.001917154475403018], 9: [0.003079465753965948, 0.0075241830039075065, 0.0022692453528093044], 10: [0.0043350797047050785, 0.011003258358115086, 0.002668033137338868], 11: [0.0031672849553424248, 0.007356895685805917, 0.0023408099718852118], 12: [0.007128271373174044, 0.017201060233249132, 0.00498232660236406], 13: [0.007790046753117908, 0.01851708463997798, 0.005041454883732158], 14: [0.004725464549593528, 0.01143151483902624, 0.0031075262582494377], 15: [0.01349320137342829, 0.03109463613619366, 0.009991894304762902], 16: [0.015257318918167498, 0.03159573181748425, 0.012694375869804793], 17: [0.02052815103350921, 0.03848703251313703, 0.01837314156534123], 18: [0.023344886584500277, 0.04302103374027026, 0.021433270330668178], 19: [0.012227550633930507, 0.02812790611344726, 0.009872345528865992], 20: [0.015651178685806535, 0.03294446466364414, 0.011913198439722453], 21: [0.050709120761069856, 0.09873665392259827, 0.046123918307871076], 22: [0.051207459065769026, 0.1099545027027429, 0.04014911393547564], 23: [0.027899023866829287, 0.06203873929603383, 0.01908477888697498], 24: [0.08045641091145372, 0.15817058030884049, 0.07304918029621732], 25: [0.09608619126545184, 0.19008332727023614, 0.08575204546187971], 26: [0.05479184733542849, 0.11424231345516186, 0.0488296510195083], 27: [0.09983040661461007, 0.19653908627103794, 0.09571532225584009], 28: [0.14598650691183387, 0.26645946988750147, 0.1476433695844609], 29: [0.1308154724294382, 0.25304287419217153, 0.12638933444482295], 30: [0.11708164231473259, 0.23147486096733258, 0.10953253136531413], 31: [0.14658574577241643, 0.3052290191352698, 0.12046071758919907], 32: [0.19978627139201938, 0.3627928858052931, 0.19047113227269455], 33: [0.1814150893588087, 0.3539794706145762, 0.17023855681760822], 34: [0.19874411644235018, 0.37279235723161885, 0.17051165001003046], 35: [0.2164169167130357, 0.41043297706204507, 0.19921909451954709], 36: [0.22210371739512066, 0.4164279345337347, 0.21010995464808305], 37: [0.298136605625031, 0.5212440577864943, 0.30314495496501387], 38: [0.3188457491130962, 0.5589896640015874, 0.3175589807633921], 39: [0.3364338083199438, 0.600008658843726, 0.34651602520679836], 40: [0.3771785408881777, 0.6398932954230241, 0.3898188029695836], 41: [0.40532443141521135, 0.6594265701607992, 0.4440881748351378], 42: [0.42798482078634204, 0.7067575466336802, 0.4355665519386819], 43: [0.43510282382816756, 0.7219423792187031, 0.46976493311370116], 44: [0.44068777822264665, 0.7249151979898123, 0.47729648470741737]})\n",
      "Количество данных (train) для класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 2539]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/Pothole-Detection-9/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737119a2",
   "metadata": {
    "papermill": {
     "duration": 1.607241,
     "end_time": "2023-12-03T13:05:00.749290",
     "exception": false,
     "start_time": "2023-12-03T13:04:59.142049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa48317",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 1.631294,
     "end_time": "2023-12-03T13:05:04.125994",
     "exception": false,
     "start_time": "2023-12-03T13:05:02.494700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af72b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 1.62191,
     "end_time": "2023-12-03T13:05:07.468154",
     "exception": false,
     "start_time": "2023-12-03T13:05:05.846244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77cfcf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 1.615629,
     "end_time": "2023-12-03T13:05:10.794405",
     "exception": false,
     "start_time": "2023-12-03T13:05:09.178776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae2ccf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 1.609144,
     "end_time": "2023-12-03T13:05:14.081136",
     "exception": false,
     "start_time": "2023-12-03T13:05:12.471992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974b075",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 1.627861,
     "end_time": "2023-12-03T13:05:17.422524",
     "exception": false,
     "start_time": "2023-12-03T13:05:15.794663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16384.905674,
   "end_time": "2023-12-03T13:05:25.717455",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T08:32:20.811781",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
