{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2374d772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T07:41:35.685501Z",
     "iopub.status.busy": "2024-01-16T07:41:35.684845Z",
     "iopub.status.idle": "2024-01-16T07:42:52.999032Z",
     "shell.execute_reply": "2024-01-16T07:42:52.998226Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 77.323025,
     "end_time": "2024-01-16T07:42:53.001276",
     "exception": false,
     "start_time": "2024-01-16T07:41:35.678251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-16 07:42:40--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.113.3\r\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240116T074240Z&X-Amz-Expires=300&X-Amz-Signature=6e4bc3f0f6e5ca843161408152f9ff2a2c599f16d1c51cbaf7ad17f1f195b79d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-16 07:42:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240116T074240Z&X-Amz-Expires=300&X-Amz-Signature=6e4bc3f0f6e5ca843161408152f9ff2a2c599f16d1c51cbaf7ad17f1f195b79d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   247MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-01-16 07:42:41 (247 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Coffee-Fruit-Maturity-â˜•ðŸ’-5 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147374/147374 [00:03<00:00, 41558.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Coffee-Fruit-Maturity-â˜•ðŸ’-5 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4732/4732 [00:00<00:00, 6778.32it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"ciencia-cafeto\").project(\"coffee-fruit-maturity-befkg\")\n",
    "dataset = project.version(5).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78314f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T07:42:53.024752Z",
     "iopub.status.busy": "2024-01-16T07:42:53.024297Z",
     "iopub.status.idle": "2024-01-16T07:43:16.144044Z",
     "shell.execute_reply": "2024-01-16T07:43:16.142809Z"
    },
    "papermill": {
     "duration": 23.134111,
     "end_time": "2024-01-16T07:43:16.146472",
     "exception": false,
     "start_time": "2024-01-16T07:42:53.012361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379055e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T07:43:16.171097Z",
     "iopub.status.busy": "2024-01-16T07:43:16.170413Z",
     "iopub.status.idle": "2024-01-16T07:43:16.196527Z",
     "shell.execute_reply": "2024-01-16T07:43:16.195723Z"
    },
    "papermill": {
     "duration": 0.040997,
     "end_time": "2024-01-16T07:43:16.198677",
     "exception": false,
     "start_time": "2024-01-16T07:43:16.157680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af148b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T07:43:16.223672Z",
     "iopub.status.busy": "2024-01-16T07:43:16.223343Z",
     "iopub.status.idle": "2024-01-16T07:43:16.333342Z",
     "shell.execute_reply": "2024-01-16T07:43:16.332533Z"
    },
    "papermill": {
     "duration": 0.125447,
     "end_time": "2024-01-16T07:43:16.335691",
     "exception": false,
     "start_time": "2024-01-16T07:43:16.210244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ…\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): Ð¿ÑƒÑ‚ÑŒ Ð´Ð¾ Ð²ÐµÑÐ¾Ð² yolov8.pt\n",
    "            path_to_yaml (str): Ð¿ÑƒÑ‚ÑŒ Ð´Ð¾ data.yaml Ñ„Ð°Ð¹Ð»Ð° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°\n",
    "            train_perc (float): Ð´Ð¾Ð»Ñ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… \n",
    "            test_perc (float): Ð´Ð¾Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            val_perc (float): Ð´Ð¾Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ train Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ Ñ‡Ð°ÑÑ‚ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            iters (int): ÐºÐ¾Ð»-Ð²Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹\n",
    "\n",
    "        Returns:\n",
    "            YOLO: ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "        \"\"\"        \n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð²ÑÐµÑ… Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… Ñ‡Ð°ÑÑ‚ÑÑ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ Ð¿Ñ€Ð¾ÑÐ°Ð´ÐºÐ¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ Ñ‡Ð°ÑÑ‚ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "            iters (int): ÐºÐ¾Ð»-Ð²Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹\n",
    "\n",
    "        Returns:\n",
    "            YOLO: ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÐºÑƒÑÐºÐ¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ Ð½Ð°ÑˆÐµÐ³Ð¾ folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ ÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ðµ ÐºÑƒÑÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð¿Ð°Ð¿ÐºÑƒ retrain\n",
    "        for path in source_pathes:\n",
    "            # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ð° Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð»Ð¸ train/test/val. Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ 1-keep_perc Ð´Ð¾Ð»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð½ÑƒÐ¶Ð½Ð¾ Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ\n",
    "        \"\"\"        \n",
    "        # ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ð²ÑÐµÑ… Ñ„Ð°Ð¹Ð»Ð¾Ð²\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "            allfiles = os.listdir(path)\n",
    "            # Ð¸Ñ‚ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»Ð°Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÑÑ‚Ð¸Ñ‚ÑŒ Ð¸Ñ… Ð² Ð¿Ð°Ð¿ÐºÑƒ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ, Ð³Ð´Ðµ ÐºÐ»ÑŽÑ‡ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¿ÑƒÑ‚ÐµÐ¹ Ðº label Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # ÐšÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð´Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ°, Ð³Ð´Ðµ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°,\n",
    "                # Ð° Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ - ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ„Ð°Ð¹Ð»: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - {empty_count}\")\n",
    "        # ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ (ÑÐºÐ¾Ñ€ÐµÐµ Ð²ÑÐµÐ³Ð¾ Ð¸Ð¼ÐµÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð¸ Ð±Ñ‹Ð» ÑƒÐ¶Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ data.yaml Ñ„Ð°Ð¹Ð»\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼ train, test, val Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¹\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸ Ñ€Ð°Ð²Ð½Ñ‹Ðµ Ð´Ð¾Ð»Ðµ piece_perc Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼ temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): Ð´Ð¾Ð»Ñ Ñ‡Ð°ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ð¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ, Ð³Ð´Ðµ ÐºÐ»ÑŽÑ‡ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¿ÑƒÑ‚ÐµÐ¹ Ðº label Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # ÐšÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð´Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ°, Ð³Ð´Ðµ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ - Ð¼ÐµÑ‚ÐºÐ° ÐºÐ»Ð°ÑÑÐ°,\n",
    "                # Ð° Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ - ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ„Ð°Ð¹Ð»: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"ÐšÐ»Ð°ÑÑ {key} ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ {value} Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼, Ð° Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐºÐ»Ð°ÑÑÐ° Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð¿Ð¾ __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"ÐšÐ»Ð°ÑÑ {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÐ¼  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¾Ñ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "            color_dict (dict): ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ RAM Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        # Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "            color_dict = defaultdict(str)\n",
    "            # Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ map Ð² Ñ†ÐµÐ»ÑÑ… Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾ÑÐ°Ð´Ð¾Ðº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                model = self.train(folder_name, iters)\n",
    "                # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ÑÑ\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: \\n {result_dict}\")\n",
    "            print(f\"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        # Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "        color_dict = defaultdict(str)\n",
    "        # Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ map Ð² Ñ†ÐµÐ»ÑÑ… Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾ÑÐ°Ð´Ð¾Ðº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            model = self.train(folder_name, iters)\n",
    "            # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ÑÑ\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: \\n {result_dict}\")\n",
    "        print(f\"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # Ð´ÐµÐ»Ð¸Ð¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ/Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ/Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð²ÐµÑÐ°Ð¼ yolov8 Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð½Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ {Ð´Ð¾Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…: Ð¼Ð°ÑÑÐ¸Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ðº}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "            metrics = self.test(model)\n",
    "            # Ð·Ð°Ð½Ð¾ÑÐ¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð±Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65cc613",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-16T07:43:16.359592Z",
     "iopub.status.busy": "2024-01-16T07:43:16.359249Z",
     "iopub.status.idle": "2024-01-16T09:35:39.755257Z",
     "shell.execute_reply": "2024-01-16T09:35:39.754248Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6743.410215,
     "end_time": "2024-01-16T09:35:39.757286",
     "exception": false,
     "start_time": "2024-01-16T07:43:16.347071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - 0\n",
      "valid_2/images 66\n",
      "test_2/images 68\n",
      "valid_4/images 205\n",
      "test_4/images 207\n",
      "valid_1/images 27\n",
      "test_1/images 29\n",
      "valid_0/images 36\n",
      "test_0/images 37\n",
      "valid_3/images 55\n",
      "test_3/images 56\n",
      "train/labels 2013 \n",
      "\n",
      "ÐšÐ¾Ð»-Ð²Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² - 0\n",
      "ÐšÐ»Ð°ÑÑ 2 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 607 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 4 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 1767 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 1 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 256 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 0 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 333 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      " ÐšÐ»Ð°ÑÑ 3 ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 513 Ð¾Ð±ÑŠÐµÐºÑ‚Ð°(-Ð¾Ð²)\n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 2\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 2: 607\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 2: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 607]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 2: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 2\n",
      "\tnum_to_mv_train 2, folder 1, cls 2\n",
      "\tnum_to_mv_train 2, folder 2, cls 2\n",
      "\tnum_to_mv_train 2, folder 3, cls 2\n",
      "\tnum_to_mv_train 2, folder 4, cls 2\n",
      "\tnum_to_mv_train 3, folder 5, cls 2\n",
      "\tnum_to_mv_train 3, folder 6, cls 2\n",
      "\tnum_to_mv_train 3, folder 7, cls 2\n",
      "\tnum_to_mv_train 3, folder 8, cls 2\n",
      "\tnum_to_mv_train 3, folder 9, cls 2\n",
      "\tnum_to_mv_train 3, folder 10, cls 2\n",
      "\tnum_to_mv_train 3, folder 11, cls 2\n",
      "\tnum_to_mv_train 5, folder 12, cls 2\n",
      "\tnum_to_mv_train 5, folder 13, cls 2\n",
      "\tnum_to_mv_train 5, folder 14, cls 2\n",
      "\tnum_to_mv_train 5, folder 15, cls 2\n",
      "\tnum_to_mv_train 5, folder 16, cls 2\n",
      "\tnum_to_mv_train 5, folder 17, cls 2\n",
      "\tnum_to_mv_train 5, folder 18, cls 2\n",
      "\tnum_to_mv_train 5, folder 19, cls 2\n",
      "\tnum_to_mv_train 5, folder 20, cls 2\n",
      "\tnum_to_mv_train 5, folder 21, cls 2\n",
      "\tnum_to_mv_train 5, folder 22, cls 2\n",
      "\tnum_to_mv_train 5, folder 23, cls 2\n",
      "\tnum_to_mv_train 5, folder 24, cls 2\n",
      "\tnum_to_mv_train 5, folder 25, cls 2\n",
      "\tnum_to_mv_train 10, folder 26, cls 2\n",
      "\tnum_to_mv_train 10, folder 27, cls 2\n",
      "\tnum_to_mv_train 10, folder 28, cls 2\n",
      "\tnum_to_mv_train 10, folder 29, cls 2\n",
      "\tnum_to_mv_train 10, folder 30, cls 2\n",
      "\tnum_to_mv_train 10, folder 31, cls 2\n",
      "\tnum_to_mv_train 10, folder 32, cls 2\n",
      "\tnum_to_mv_train 10, folder 33, cls 2\n",
      "\tnum_to_mv_train 10, folder 34, cls 2\n",
      "\tnum_to_mv_train 10, folder 35, cls 2\n",
      "\tnum_to_mv_train 50, folder 36, cls 2\n",
      "\tnum_to_mv_train 50, folder 37, cls 2\n",
      "\tnum_to_mv_train 100, folder 38, cls 2\n",
      "\tnum_to_mv_train 100, folder 39, cls 2\n",
      "\tnum_to_mv_train 106, folder 40, cls 2\n",
      "temp_2_1/train/labels 2\n",
      "temp_2_1/train/images 2 \n",
      "\n",
      "temp_2_2/train/labels 2\n",
      "temp_2_2/train/images 2 \n",
      "\n",
      "temp_2_3/train/labels 2\n",
      "temp_2_3/train/images 2 \n",
      "\n",
      "temp_2_4/train/labels 2\n",
      "temp_2_4/train/images 2 \n",
      "\n",
      "temp_2_5/train/labels 2\n",
      "temp_2_5/train/images 2 \n",
      "\n",
      "temp_2_6/train/labels 3\n",
      "temp_2_6/train/images 3 \n",
      "\n",
      "temp_2_7/train/labels 3\n",
      "temp_2_7/train/images 3 \n",
      "\n",
      "temp_2_8/train/labels 3\n",
      "temp_2_8/train/images 3 \n",
      "\n",
      "temp_2_9/train/labels 3\n",
      "temp_2_9/train/images 3 \n",
      "\n",
      "temp_2_10/train/labels 3\n",
      "temp_2_10/train/images 3 \n",
      "\n",
      "temp_2_11/train/labels 3\n",
      "temp_2_11/train/images 3 \n",
      "\n",
      "temp_2_12/train/labels 3\n",
      "temp_2_12/train/images 3 \n",
      "\n",
      "temp_2_13/train/labels 5\n",
      "temp_2_13/train/images 5 \n",
      "\n",
      "temp_2_14/train/labels 5\n",
      "temp_2_14/train/images 5 \n",
      "\n",
      "temp_2_15/train/labels 5\n",
      "temp_2_15/train/images 5 \n",
      "\n",
      "temp_2_16/train/labels 5\n",
      "temp_2_16/train/images 5 \n",
      "\n",
      "temp_2_17/train/labels 5\n",
      "temp_2_17/train/images 5 \n",
      "\n",
      "temp_2_18/train/labels 5\n",
      "temp_2_18/train/images 5 \n",
      "\n",
      "temp_2_19/train/labels 5\n",
      "temp_2_19/train/images 5 \n",
      "\n",
      "temp_2_20/train/labels 5\n",
      "temp_2_20/train/images 5 \n",
      "\n",
      "temp_2_21/train/labels 5\n",
      "temp_2_21/train/images 5 \n",
      "\n",
      "temp_2_22/train/labels 5\n",
      "temp_2_22/train/images 5 \n",
      "\n",
      "temp_2_23/train/labels 5\n",
      "temp_2_23/train/images 5 \n",
      "\n",
      "temp_2_24/train/labels 5\n",
      "temp_2_24/train/images 5 \n",
      "\n",
      "temp_2_25/train/labels 5\n",
      "temp_2_25/train/images 5 \n",
      "\n",
      "temp_2_26/train/labels 5\n",
      "temp_2_26/train/images 5 \n",
      "\n",
      "temp_2_27/train/labels 10\n",
      "temp_2_27/train/images 10 \n",
      "\n",
      "temp_2_28/train/labels 10\n",
      "temp_2_28/train/images 10 \n",
      "\n",
      "temp_2_29/train/labels 10\n",
      "temp_2_29/train/images 10 \n",
      "\n",
      "temp_2_30/train/labels 10\n",
      "temp_2_30/train/images 10 \n",
      "\n",
      "temp_2_31/train/labels 10\n",
      "temp_2_31/train/images 10 \n",
      "\n",
      "temp_2_32/train/labels 10\n",
      "temp_2_32/train/images 10 \n",
      "\n",
      "temp_2_33/train/labels 10\n",
      "temp_2_33/train/images 10 \n",
      "\n",
      "temp_2_34/train/labels 10\n",
      "temp_2_34/train/images 10 \n",
      "\n",
      "temp_2_35/train/labels 10\n",
      "temp_2_35/train/images 10 \n",
      "\n",
      "temp_2_36/train/labels 10\n",
      "temp_2_36/train/images 10 \n",
      "\n",
      "temp_2_37/train/labels 50\n",
      "temp_2_37/train/images 50 \n",
      "\n",
      "temp_2_38/train/labels 50\n",
      "temp_2_38/train/images 50 \n",
      "\n",
      "temp_2_39/train/labels 100\n",
      "temp_2_39/train/images 100 \n",
      "\n",
      "temp_2_40/train/labels 100\n",
      "temp_2_40/train/images 100 \n",
      "\n",
      "temp_2_41/train/labels 106\n",
      "temp_2_41/train/images 106 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 4\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 4: 1767\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 4: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1767]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 4: 43 \n",
      "\tnum_to_mv_train 2, folder 0, cls 4\n",
      "\tnum_to_mv_train 2, folder 1, cls 4\n",
      "\tnum_to_mv_train 2, folder 2, cls 4\n",
      "\tnum_to_mv_train 2, folder 3, cls 4\n",
      "\tnum_to_mv_train 2, folder 4, cls 4\n",
      "\tnum_to_mv_train 3, folder 5, cls 4\n",
      "\tnum_to_mv_train 3, folder 6, cls 4\n",
      "\tnum_to_mv_train 3, folder 7, cls 4\n",
      "\tnum_to_mv_train 3, folder 8, cls 4\n",
      "\tnum_to_mv_train 3, folder 9, cls 4\n",
      "\tnum_to_mv_train 3, folder 10, cls 4\n",
      "\tnum_to_mv_train 3, folder 11, cls 4\n",
      "\tnum_to_mv_train 5, folder 12, cls 4\n",
      "\tnum_to_mv_train 5, folder 13, cls 4\n",
      "\tnum_to_mv_train 5, folder 14, cls 4\n",
      "\tnum_to_mv_train 5, folder 15, cls 4\n",
      "\tnum_to_mv_train 5, folder 16, cls 4\n",
      "\tnum_to_mv_train 5, folder 17, cls 4\n",
      "\tnum_to_mv_train 5, folder 18, cls 4\n",
      "\tnum_to_mv_train 5, folder 19, cls 4\n",
      "\tnum_to_mv_train 5, folder 20, cls 4\n",
      "\tnum_to_mv_train 5, folder 21, cls 4\n",
      "\tnum_to_mv_train 5, folder 22, cls 4\n",
      "\tnum_to_mv_train 5, folder 23, cls 4\n",
      "\tnum_to_mv_train 5, folder 24, cls 4\n",
      "\tnum_to_mv_train 5, folder 25, cls 4\n",
      "\tnum_to_mv_train 10, folder 26, cls 4\n",
      "\tnum_to_mv_train 10, folder 27, cls 4\n",
      "\tnum_to_mv_train 10, folder 28, cls 4\n",
      "\tnum_to_mv_train 10, folder 29, cls 4\n",
      "\tnum_to_mv_train 10, folder 30, cls 4\n",
      "\tnum_to_mv_train 10, folder 31, cls 4\n",
      "\tnum_to_mv_train 10, folder 32, cls 4\n",
      "\tnum_to_mv_train 10, folder 33, cls 4\n",
      "\tnum_to_mv_train 10, folder 34, cls 4\n",
      "\tnum_to_mv_train 10, folder 35, cls 4\n",
      "\tnum_to_mv_train 50, folder 36, cls 4\n",
      "\tnum_to_mv_train 50, folder 37, cls 4\n",
      "\tnum_to_mv_train 100, folder 38, cls 4\n",
      "\tnum_to_mv_train 100, folder 39, cls 4\n",
      "\tnum_to_mv_train 500, folder 40, cls 4\n",
      "\tnum_to_mv_train 500, folder 41, cls 4\n",
      "\tnum_to_mv_train 266, folder 42, cls 4\n",
      "temp_4_1/train/labels 2\n",
      "temp_4_1/train/images 2 \n",
      "\n",
      "temp_4_2/train/labels 2\n",
      "temp_4_2/train/images 2 \n",
      "\n",
      "temp_4_3/train/labels 2\n",
      "temp_4_3/train/images 2 \n",
      "\n",
      "temp_4_4/train/labels 2\n",
      "temp_4_4/train/images 2 \n",
      "\n",
      "temp_4_5/train/labels 2\n",
      "temp_4_5/train/images 2 \n",
      "\n",
      "temp_4_6/train/labels 3\n",
      "temp_4_6/train/images 3 \n",
      "\n",
      "temp_4_7/train/labels 3\n",
      "temp_4_7/train/images 3 \n",
      "\n",
      "temp_4_8/train/labels 3\n",
      "temp_4_8/train/images 3 \n",
      "\n",
      "temp_4_9/train/labels 3\n",
      "temp_4_9/train/images 3 \n",
      "\n",
      "temp_4_10/train/labels 3\n",
      "temp_4_10/train/images 3 \n",
      "\n",
      "temp_4_11/train/labels 3\n",
      "temp_4_11/train/images 3 \n",
      "\n",
      "temp_4_12/train/labels 3\n",
      "temp_4_12/train/images 3 \n",
      "\n",
      "temp_4_13/train/labels 5\n",
      "temp_4_13/train/images 5 \n",
      "\n",
      "temp_4_14/train/labels 5\n",
      "temp_4_14/train/images 5 \n",
      "\n",
      "temp_4_15/train/labels 5\n",
      "temp_4_15/train/images 5 \n",
      "\n",
      "temp_4_16/train/labels 5\n",
      "temp_4_16/train/images 5 \n",
      "\n",
      "temp_4_17/train/labels 5\n",
      "temp_4_17/train/images 5 \n",
      "\n",
      "temp_4_18/train/labels 5\n",
      "temp_4_18/train/images 5 \n",
      "\n",
      "temp_4_19/train/labels 5\n",
      "temp_4_19/train/images 5 \n",
      "\n",
      "temp_4_20/train/labels 5\n",
      "temp_4_20/train/images 5 \n",
      "\n",
      "temp_4_21/train/labels 5\n",
      "temp_4_21/train/images 5 \n",
      "\n",
      "temp_4_22/train/labels 5\n",
      "temp_4_22/train/images 5 \n",
      "\n",
      "temp_4_23/train/labels 5\n",
      "temp_4_23/train/images 5 \n",
      "\n",
      "temp_4_24/train/labels 5\n",
      "temp_4_24/train/images 5 \n",
      "\n",
      "temp_4_25/train/labels 5\n",
      "temp_4_25/train/images 5 \n",
      "\n",
      "temp_4_26/train/labels 5\n",
      "temp_4_26/train/images 5 \n",
      "\n",
      "temp_4_27/train/labels 10\n",
      "temp_4_27/train/images 10 \n",
      "\n",
      "temp_4_28/train/labels 10\n",
      "temp_4_28/train/images 10 \n",
      "\n",
      "temp_4_29/train/labels 10\n",
      "temp_4_29/train/images 10 \n",
      "\n",
      "temp_4_30/train/labels 10\n",
      "temp_4_30/train/images 10 \n",
      "\n",
      "temp_4_31/train/labels 10\n",
      "temp_4_31/train/images 10 \n",
      "\n",
      "temp_4_32/train/labels 10\n",
      "temp_4_32/train/images 10 \n",
      "\n",
      "temp_4_33/train/labels 10\n",
      "temp_4_33/train/images 10 \n",
      "\n",
      "temp_4_34/train/labels 10\n",
      "temp_4_34/train/images 10 \n",
      "\n",
      "temp_4_35/train/labels 10\n",
      "temp_4_35/train/images 10 \n",
      "\n",
      "temp_4_36/train/labels 10\n",
      "temp_4_36/train/images 10 \n",
      "\n",
      "temp_4_37/train/labels 50\n",
      "temp_4_37/train/images 50 \n",
      "\n",
      "temp_4_38/train/labels 50\n",
      "temp_4_38/train/images 50 \n",
      "\n",
      "temp_4_39/train/labels 100\n",
      "temp_4_39/train/images 100 \n",
      "\n",
      "temp_4_40/train/labels 100\n",
      "temp_4_40/train/images 100 \n",
      "\n",
      "temp_4_41/train/labels 500\n",
      "temp_4_41/train/images 500 \n",
      "\n",
      "temp_4_42/train/labels 500\n",
      "temp_4_42/train/images 500 \n",
      "\n",
      "temp_4_43/train/labels 266\n",
      "temp_4_43/train/images 266 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 1\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 1: 256\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 256]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 1: 38 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 50, folder 36, cls 1\n",
      "\tnum_to_mv_train 5, folder 37, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 50\n",
      "temp_1_37/train/images 50 \n",
      "\n",
      "temp_1_38/train/labels 5\n",
      "temp_1_38/train/images 5 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 0\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 0: 333\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 333]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 0: 39 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 32, folder 38, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 32\n",
      "temp_0_39/train/images 32 \n",
      "\n",
      "ÐšÐ»Ð°ÑÑ 3\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ train ÐºÐ»Ð°ÑÑÐ° 3: 513\n",
      "\tÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ° 3: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 513]\n",
      "\tÐšÐ¾Ð»-Ð²Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 3: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 3\n",
      "\tnum_to_mv_train 2, folder 1, cls 3\n",
      "\tnum_to_mv_train 2, folder 2, cls 3\n",
      "\tnum_to_mv_train 2, folder 3, cls 3\n",
      "\tnum_to_mv_train 2, folder 4, cls 3\n",
      "\tnum_to_mv_train 3, folder 5, cls 3\n",
      "\tnum_to_mv_train 3, folder 6, cls 3\n",
      "\tnum_to_mv_train 3, folder 7, cls 3\n",
      "\tnum_to_mv_train 3, folder 8, cls 3\n",
      "\tnum_to_mv_train 3, folder 9, cls 3\n",
      "\tnum_to_mv_train 3, folder 10, cls 3\n",
      "\tnum_to_mv_train 3, folder 11, cls 3\n",
      "\tnum_to_mv_train 5, folder 12, cls 3\n",
      "\tnum_to_mv_train 5, folder 13, cls 3\n",
      "\tnum_to_mv_train 5, folder 14, cls 3\n",
      "\tnum_to_mv_train 5, folder 15, cls 3\n",
      "\tnum_to_mv_train 5, folder 16, cls 3\n",
      "\tnum_to_mv_train 5, folder 17, cls 3\n",
      "\tnum_to_mv_train 5, folder 18, cls 3\n",
      "\tnum_to_mv_train 5, folder 19, cls 3\n",
      "\tnum_to_mv_train 5, folder 20, cls 3\n",
      "\tnum_to_mv_train 5, folder 21, cls 3\n",
      "\tnum_to_mv_train 5, folder 22, cls 3\n",
      "\tnum_to_mv_train 5, folder 23, cls 3\n",
      "\tnum_to_mv_train 5, folder 24, cls 3\n",
      "\tnum_to_mv_train 5, folder 25, cls 3\n",
      "\tnum_to_mv_train 10, folder 26, cls 3\n",
      "\tnum_to_mv_train 10, folder 27, cls 3\n",
      "\tnum_to_mv_train 10, folder 28, cls 3\n",
      "\tnum_to_mv_train 10, folder 29, cls 3\n",
      "\tnum_to_mv_train 10, folder 30, cls 3\n",
      "\tnum_to_mv_train 10, folder 31, cls 3\n",
      "\tnum_to_mv_train 10, folder 32, cls 3\n",
      "\tnum_to_mv_train 10, folder 33, cls 3\n",
      "\tnum_to_mv_train 10, folder 34, cls 3\n",
      "\tnum_to_mv_train 10, folder 35, cls 3\n",
      "\tnum_to_mv_train 50, folder 36, cls 3\n",
      "\tnum_to_mv_train 50, folder 37, cls 3\n",
      "\tnum_to_mv_train 100, folder 38, cls 3\n",
      "\tnum_to_mv_train 100, folder 39, cls 3\n",
      "\tnum_to_mv_train 12, folder 40, cls 3\n",
      "temp_3_1/train/labels 2\n",
      "temp_3_1/train/images 2 \n",
      "\n",
      "temp_3_2/train/labels 2\n",
      "temp_3_2/train/images 2 \n",
      "\n",
      "temp_3_3/train/labels 2\n",
      "temp_3_3/train/images 2 \n",
      "\n",
      "temp_3_4/train/labels 2\n",
      "temp_3_4/train/images 2 \n",
      "\n",
      "temp_3_5/train/labels 2\n",
      "temp_3_5/train/images 2 \n",
      "\n",
      "temp_3_6/train/labels 3\n",
      "temp_3_6/train/images 3 \n",
      "\n",
      "temp_3_7/train/labels 3\n",
      "temp_3_7/train/images 3 \n",
      "\n",
      "temp_3_8/train/labels 3\n",
      "temp_3_8/train/images 3 \n",
      "\n",
      "temp_3_9/train/labels 3\n",
      "temp_3_9/train/images 3 \n",
      "\n",
      "temp_3_10/train/labels 3\n",
      "temp_3_10/train/images 3 \n",
      "\n",
      "temp_3_11/train/labels 3\n",
      "temp_3_11/train/images 3 \n",
      "\n",
      "temp_3_12/train/labels 3\n",
      "temp_3_12/train/images 3 \n",
      "\n",
      "temp_3_13/train/labels 5\n",
      "temp_3_13/train/images 5 \n",
      "\n",
      "temp_3_14/train/labels 5\n",
      "temp_3_14/train/images 5 \n",
      "\n",
      "temp_3_15/train/labels 5\n",
      "temp_3_15/train/images 5 \n",
      "\n",
      "temp_3_16/train/labels 5\n",
      "temp_3_16/train/images 5 \n",
      "\n",
      "temp_3_17/train/labels 5\n",
      "temp_3_17/train/images 5 \n",
      "\n",
      "temp_3_18/train/labels 5\n",
      "temp_3_18/train/images 5 \n",
      "\n",
      "temp_3_19/train/labels 5\n",
      "temp_3_19/train/images 5 \n",
      "\n",
      "temp_3_20/train/labels 5\n",
      "temp_3_20/train/images 5 \n",
      "\n",
      "temp_3_21/train/labels 5\n",
      "temp_3_21/train/images 5 \n",
      "\n",
      "temp_3_22/train/labels 5\n",
      "temp_3_22/train/images 5 \n",
      "\n",
      "temp_3_23/train/labels 5\n",
      "temp_3_23/train/images 5 \n",
      "\n",
      "temp_3_24/train/labels 5\n",
      "temp_3_24/train/images 5 \n",
      "\n",
      "temp_3_25/train/labels 5\n",
      "temp_3_25/train/images 5 \n",
      "\n",
      "temp_3_26/train/labels 5\n",
      "temp_3_26/train/images 5 \n",
      "\n",
      "temp_3_27/train/labels 10\n",
      "temp_3_27/train/images 10 \n",
      "\n",
      "temp_3_28/train/labels 10\n",
      "temp_3_28/train/images 10 \n",
      "\n",
      "temp_3_29/train/labels 10\n",
      "temp_3_29/train/images 10 \n",
      "\n",
      "temp_3_30/train/labels 10\n",
      "temp_3_30/train/images 10 \n",
      "\n",
      "temp_3_31/train/labels 10\n",
      "temp_3_31/train/images 10 \n",
      "\n",
      "temp_3_32/train/labels 10\n",
      "temp_3_32/train/images 10 \n",
      "\n",
      "temp_3_33/train/labels 10\n",
      "temp_3_33/train/images 10 \n",
      "\n",
      "temp_3_34/train/labels 10\n",
      "temp_3_34/train/images 10 \n",
      "\n",
      "temp_3_35/train/labels 10\n",
      "temp_3_35/train/images 10 \n",
      "\n",
      "temp_3_36/train/labels 10\n",
      "temp_3_36/train/images 10 \n",
      "\n",
      "temp_3_37/train/labels 50\n",
      "temp_3_37/train/images 50 \n",
      "\n",
      "temp_3_38/train/labels 50\n",
      "temp_3_38/train/images 50 \n",
      "\n",
      "temp_3_39/train/labels 100\n",
      "temp_3_39/train/images 100 \n",
      "\n",
      "temp_3_40/train/labels 100\n",
      "temp_3_40/train/images 100 \n",
      "\n",
      "temp_3_41/train/labels 12\n",
      "temp_3_41/train/images 12 \n",
      "\n",
      "/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml\n",
      "defaultdict(<class 'int'>, {'2': 41, '4': 43, '1': 38, '0': 39, '3': 41}) defaultdict(<class 'list'>, {'2': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 607], '4': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1767], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 256], '0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 333], '3': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 513]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 14.2MB/s]\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 75.7MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 193.33it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 885.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.23G      1.345      2.171       4.96      1.381         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         27         94     0.0164     0.0106     0.0118    0.00118     0.0656     0.0426     0.0383    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.35G     0.9645      1.894      4.383      1.345          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0147     0.0106      0.011     0.0011     0.0735     0.0532     0.0434    0.00666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G      1.303      2.618      4.805      1.636          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0429     0.0319     0.0256    0.00479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.35G      1.308       2.43      5.087      1.523         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0448     0.0319     0.0265    0.00574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.31G     0.8078      2.794       4.73      1.349          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0143     0.0106      0.012     0.0012     0.0714     0.0532     0.0422    0.00762\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                   all         27         94     0.0141     0.0106     0.0119    0.00119     0.0704     0.0532     0.0417    0.00754\n",
      "              overripe         27         94     0.0141     0.0106     0.0119    0.00119     0.0704     0.0532     0.0417    0.00754\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<00:00, 964.12it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.79it/s]\n",
      "                   all         29         92     0.0179     0.0217     0.0105    0.00105     0.0536     0.0652     0.0329    0.00813\n",
      "              overripe         29         92     0.0179     0.0217     0.0105    0.00105     0.0536     0.0652     0.0329    0.00813\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 872.90it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.02G     0.8864      1.784      4.065      1.359         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94     0.0541     0.0213     0.0323    0.00323     0.0811     0.0319      0.046     0.0105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.34G     0.7956      1.598      4.139      1.204         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0238     0.0106     0.0154    0.00154     0.0714     0.0319     0.0399    0.00916\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G      1.134      1.766      4.203      1.492          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0435     0.0213     0.0246    0.00246     0.0652     0.0319     0.0358    0.00824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.32G     0.8393      1.471       4.01      1.301         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0217     0.0106     0.0137    0.00137     0.0435     0.0213     0.0246    0.00713\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.21G     0.8379      1.646       4.43       1.44          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0444     0.0213     0.0253    0.00253     0.0667     0.0319     0.0367    0.00844\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0526     0.0213     0.0316    0.00316     0.0789     0.0319      0.045     0.0103\n",
      "              overripe         27         94     0.0526     0.0213     0.0316    0.00316     0.0789     0.0319      0.045     0.0103\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                   all         29         92      0.019     0.0217     0.0108    0.00169     0.0476     0.0543     0.0263    0.00735\n",
      "              overripe         29         92      0.019     0.0217     0.0108    0.00169     0.0476     0.0543     0.0263    0.00735\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 808.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.19G      1.097      2.347      4.644      1.349         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0169     0.0106     0.0121    0.00121     0.0678     0.0426     0.0395    0.00661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.93G     0.8135      1.568      4.215      1.219         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0606     0.0426     0.0355    0.00592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.81G     0.8719      1.842      4.038      1.389         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0147     0.0106      0.011     0.0011     0.0441     0.0319     0.0263    0.00493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       3.8G      1.019      2.545      4.266      1.424         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0448     0.0319     0.0265    0.00574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.66G     0.9759      1.832      4.453      1.284         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0462     0.0319      0.027    0.00587\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94     0.0169     0.0106     0.0121    0.00121     0.0678     0.0426     0.0395    0.00661\n",
      "              overripe         27         94     0.0169     0.0106     0.0121    0.00121     0.0678     0.0426     0.0395    0.00661\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.71it/s]\n",
      "                   all         29         92          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 657.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.44G      1.109       2.19      4.633      1.376          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94     0.0286     0.0106     0.0178    0.00178     0.0857     0.0319     0.0475     0.0109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.36G     0.5476       1.32      4.359      1.125          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0488     0.0213     0.0274    0.00274     0.0732     0.0319     0.0402    0.00926\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.32G      0.804      1.904      4.093      1.335          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0227     0.0106     0.0136    0.00136     0.0682     0.0319      0.037    0.00853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.3G     0.8163       1.46      4.705      1.254          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0213     0.0106     0.0129    0.00129     0.0638     0.0319     0.0348    0.00802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.3G     0.8493      1.622      4.292      1.351          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0179     0.0106     0.0113    0.00113     0.0536     0.0319     0.0295    0.00679\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0286     0.0106     0.0178    0.00178     0.0857     0.0319     0.0475     0.0109\n",
      "              overripe         27         94     0.0286     0.0106     0.0178    0.00178     0.0857     0.0319     0.0475     0.0109\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.87it/s]\n",
      "                   all         29         92     0.0101     0.0109    0.00595   0.000595     0.0404     0.0435     0.0232    0.00404\n",
      "              overripe         29         92     0.0101     0.0109    0.00595   0.000595     0.0404     0.0435     0.0232    0.00404\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 885.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.18G     0.7928      2.019      4.211      1.296         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0366    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.31G      0.721      1.608       4.11      1.237         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0746     0.0532     0.0438    0.00672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.04G     0.7444       1.78      4.274      1.227         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0462     0.0319     0.0273    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.97G      1.059      2.405      4.615      1.358         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0145     0.0106     0.0109    0.00109     0.0435     0.0319     0.0258    0.00558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5         5G      0.871      1.992      4.588      1.286         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0139     0.0106     0.0118    0.00118     0.0417     0.0319      0.026    0.00547\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0746     0.0532     0.0436    0.00669\n",
      "              overripe         27         94     0.0149     0.0106     0.0111    0.00111     0.0746     0.0532     0.0436    0.00669\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.81it/s]\n",
      "                   all         29         92    0.00893     0.0109    0.00563   0.000563     0.0625     0.0761     0.0375     0.0102\n",
      "              overripe         29         92    0.00893     0.0109    0.00563   0.000563     0.0625     0.0761     0.0375     0.0102\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 735.78it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.44G     0.9579      2.332      4.615      1.279         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27         94      0.027     0.0106      0.017     0.0017     0.0811     0.0319     0.0452     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.31G      1.386      2.576      5.261      1.683          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0208     0.0106      0.014     0.0014     0.0625     0.0319     0.0359     0.0082\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G     0.8514      2.647      4.736      1.476          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0364     0.0213     0.0219    0.00219     0.0545     0.0319     0.0314     0.0072\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.32G     0.9143      2.481      4.797       1.14         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0185     0.0106     0.0128    0.00128      0.037     0.0213     0.0223    0.00635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.29G      1.143      2.904      4.681      1.582          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0192     0.0106     0.0124    0.00124     0.0577     0.0319      0.032    0.00837\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94     0.0256     0.0106     0.0163    0.00163     0.0769     0.0319     0.0431    0.00989\n",
      "              overripe         27         94     0.0256     0.0106     0.0163    0.00163     0.0769     0.0319     0.0431    0.00989\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92       0.01     0.0109     0.0059    0.00059       0.04     0.0435      0.022    0.00438\n",
      "              overripe         29         92       0.01     0.0109     0.0059    0.00059       0.04     0.0435      0.022    0.00438\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 924.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.01G      0.847      1.888      4.463      1.237         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94     0.0164     0.0106     0.0118    0.00118     0.0656     0.0426     0.0381    0.00637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.49G      1.132      2.619      4.542      1.405         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0156     0.0106     0.0114    0.00114     0.0781     0.0532     0.0452    0.00696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.17G      1.048      1.928      4.482      1.285         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0141     0.0106     0.0107    0.00107     0.0563     0.0426     0.0332    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      6.14G     0.7985      1.722      4.379       1.33         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0145     0.0106     0.0109    0.00109     0.0435     0.0319     0.0258    0.00559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      6.17G     0.9776       2.18       4.49      1.319         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0139     0.0106     0.0106    0.00106     0.0556     0.0426     0.0323     0.0061\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0758     0.0532     0.0439    0.00675\n",
      "              overripe         27         94     0.0152     0.0106     0.0112    0.00112     0.0758     0.0532     0.0439    0.00675\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.88it/s]\n",
      "                   all         29         92    0.00901     0.0109    0.00567   0.000567     0.0631     0.0761     0.0373    0.00833\n",
      "              overripe         29         92    0.00901     0.0109    0.00567   0.000567     0.0631     0.0761     0.0373    0.00833\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 7.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 814.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.33G     0.3997        1.1      4.241     0.8802          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0263     0.0106     0.0167    0.00167     0.0789     0.0319     0.0441     0.0101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.23G     0.5386      1.476      4.397      1.166          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0217     0.0106     0.0137    0.00137     0.0652     0.0319     0.0364     0.0084\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.26G     0.6362      1.433      4.382      1.361          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94     0.0192     0.0106     0.0124    0.00124     0.0385     0.0213     0.0223    0.00645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.32G     0.6573      1.665      4.532      1.215          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0192     0.0106     0.0124    0.00124     0.0385     0.0213     0.0223    0.00644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.28G     0.5308     0.9354      4.299      1.023          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0175     0.0106     0.0116    0.00116     0.0351     0.0213     0.0205     0.0059\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0256     0.0106     0.0163    0.00163     0.0769     0.0319     0.0431    0.00989\n",
      "              overripe         27         94     0.0256     0.0106     0.0163    0.00163     0.0769     0.0319     0.0431    0.00989\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         29         92    0.00893     0.0109    0.00553   0.000553     0.0536     0.0652     0.0299    0.00638\n",
      "              overripe         29         92    0.00893     0.0109    0.00553   0.000553     0.0536     0.0652     0.0299    0.00638\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 829.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.72G     0.7061      1.824      4.535      1.135         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94     0.0167     0.0106     0.0119    0.00119     0.0667     0.0426     0.0387    0.00649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.74G     0.9257      2.335      4.516      1.331         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0769     0.0532     0.0446    0.00685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.52G     0.9411      2.151      4.354      1.295         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0147     0.0106      0.011     0.0011     0.0441     0.0319     0.0263    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.49G      0.877      1.828      4.444      1.279         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0141     0.0106     0.0107    0.00107     0.0423     0.0319     0.0252    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.49G      1.061      2.255      4.474      1.425         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0571     0.0426      0.033    0.00625\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0364    0.00608\n",
      "              overripe         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0364    0.00608\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                   all         29         92    0.00943     0.0109    0.00588   0.000588     0.0566     0.0652     0.0339    0.00768\n",
      "              overripe         29         92    0.00943     0.0109    0.00588   0.000588     0.0566     0.0652     0.0339    0.00768\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1700.16it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G     0.9896      2.258       4.68      1.236          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94     0.0256     0.0106     0.0156    0.00156     0.0769     0.0319     0.0419    0.00969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.86G      1.178      2.918       6.03       1.45          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0213     0.0106     0.0134    0.00134     0.0426     0.0213     0.0243    0.00705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.74G     0.9258      2.532       4.31      1.249          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94     0.0222     0.0106     0.0139    0.00139     0.0444     0.0213     0.0252    0.00731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.84G      1.809      3.297      6.184      1.654          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0222     0.0106     0.0134    0.00134     0.0444     0.0213     0.0246    0.00718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.75G      1.632      3.027      5.153      1.814          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0222     0.0106     0.0134    0.00134     0.0444     0.0213     0.0246    0.00718\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94     0.0256     0.0106     0.0156    0.00156     0.0769     0.0319     0.0419    0.00969\n",
      "              overripe         27         94     0.0256     0.0106     0.0156    0.00156     0.0769     0.0319     0.0419    0.00969\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92     0.0105     0.0109    0.00604   0.000604     0.0526     0.0543     0.0292    0.00521\n",
      "              overripe         29         92     0.0105     0.0109    0.00604   0.000604     0.0526     0.0543     0.0292    0.00521\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 887.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.89G     0.9582      1.869      4.431       1.41         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0161     0.0106     0.0117    0.00117     0.0645     0.0426     0.0376    0.00628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.24G     0.8568      1.888      4.597      1.316         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0606     0.0426     0.0353    0.00589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5         9G     0.8959      2.076      4.456      1.303         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0145     0.0106     0.0109    0.00109     0.0435     0.0319     0.0258    0.00482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.69G     0.7768      1.876      4.184      1.271         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0448     0.0319     0.0264    0.00572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.99G      1.104      2.224      4.696      1.342         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0448     0.0319     0.0264    0.00417\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0161     0.0106     0.0117    0.00117     0.0645     0.0426     0.0376    0.00629\n",
      "              overripe         27         94     0.0161     0.0106     0.0117    0.00117     0.0645     0.0426     0.0376    0.00629\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                   all         29         92    0.00952     0.0109    0.00495   0.000495     0.0762      0.087     0.0443     0.0113\n",
      "              overripe         29         92    0.00952     0.0109    0.00495   0.000495     0.0762      0.087     0.0443     0.0113\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 771.06it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.73G     0.8244      1.907      4.273      1.171          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94     0.0278     0.0106     0.0166    0.00166     0.0833     0.0319     0.0452     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.85G      1.231      2.189       6.02      1.389          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0244     0.0106      0.015     0.0015     0.0732     0.0319     0.0399    0.00919\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.73G     0.8704      2.591      4.663      1.267          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0217     0.0106     0.0132    0.00132     0.0435     0.0213     0.0241    0.00703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.85G     0.9714      2.477      5.644      1.611          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0213     0.0106     0.0129    0.00129     0.0426     0.0213     0.0237    0.00689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      1.101      2.856      5.533      1.313          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0213     0.0106     0.0129    0.00129     0.0426     0.0213     0.0237    0.00689\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.027     0.0106     0.0163    0.00163     0.0811     0.0319     0.0441     0.0102\n",
      "              overripe         27         94      0.027     0.0106     0.0163    0.00163     0.0811     0.0319     0.0441     0.0102\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                   all         29         92    0.00952     0.0109    0.00567   0.000567     0.0476     0.0543     0.0269     0.0048\n",
      "              overripe         29         92    0.00952     0.0109    0.00567   0.000567     0.0476     0.0543     0.0269     0.0048\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 927.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.27G     0.9829       2.11       4.58      1.344         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         27         94     0.0164     0.0106     0.0118    0.00118     0.0656     0.0426     0.0381    0.00638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.3G     0.9317      2.222      4.747      1.376         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0615     0.0426     0.0358    0.00598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.3G      0.779      1.817      4.281       1.22         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0429     0.0319     0.0255    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.2G     0.9684      2.729       4.69      1.417         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0145     0.0106     0.0109    0.00109     0.0435     0.0319     0.0258    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.19G     0.8699      2.087      4.598      1.285         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0149     0.0106     0.0111    0.00111     0.0299     0.0213     0.0187    0.00339\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0164     0.0106     0.0118    0.00118     0.0656     0.0426     0.0381    0.00638\n",
      "              overripe         27         94     0.0164     0.0106     0.0118    0.00118     0.0656     0.0426     0.0381    0.00638\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         29         92    0.00971     0.0109    0.00503   0.000503     0.0777      0.087     0.0449     0.0109\n",
      "              overripe         29         92    0.00971     0.0109    0.00503   0.000503     0.0777      0.087     0.0449     0.0109\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 629.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.33G      1.208      2.724      4.611      1.512         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94     0.0556     0.0213     0.0306    0.00306     0.0833     0.0319     0.0451     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.93G      1.298      2.819      4.344      1.494         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0227     0.0106     0.0141    0.00141     0.0682     0.0319     0.0374    0.00865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.78G      1.264      2.579      4.373      1.604         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0204     0.0106      0.013     0.0013     0.0612     0.0319     0.0338    0.00783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.9G      1.236      2.867      4.463      1.629         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0204     0.0106      0.013     0.0013     0.0612     0.0319     0.0338    0.00783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.86G      1.221      2.876      4.275      1.403         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0204     0.0106      0.013     0.0013     0.0612     0.0319     0.0338    0.00783\n",
      "\n",
      "5 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0556     0.0213     0.0306    0.00306     0.0833     0.0319     0.0451     0.0104\n",
      "              overripe         27         94     0.0556     0.0213     0.0306    0.00306     0.0833     0.0319     0.0451     0.0104\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  2.00it/s]\n",
      "                   all         29         92    0.00971     0.0109     0.0057    0.00057     0.0583     0.0652     0.0323    0.00735\n",
      "              overripe         29         92    0.00971     0.0109     0.0057    0.00057     0.0583     0.0652     0.0323    0.00735\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 902.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.4G      1.401      2.625      5.374      1.555          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0615     0.0426     0.0357    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.42G      1.185      2.344      5.166       1.36          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0135     0.0106     0.0104    0.00104     0.0405     0.0319     0.0242    0.00521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.43G     0.9889      2.397      4.435      1.392         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.013     0.0106    0.00937   0.000937      0.039     0.0319     0.0227    0.00361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.43G      1.131      2.999      5.736      1.312          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0116     0.0106     0.0087    0.00087     0.0233     0.0213     0.0147    0.00413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.43G       1.11      2.053      4.652      1.315         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0116     0.0106     0.0087    0.00087     0.0233     0.0213     0.0147    0.00413\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0362    0.00605\n",
      "              overripe         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0362    0.00605\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         29         92    0.00917     0.0109    0.00586   0.000586      0.055     0.0652     0.0323    0.00788\n",
      "              overripe         29         92    0.00917     0.0109    0.00586   0.000586      0.055     0.0652     0.0323    0.00788\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 720.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.53G      1.615      3.106      4.726      1.537         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0196     0.0106     0.0107    0.00107     0.0196     0.0106     0.0107    0.00107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.93G      1.191       2.57      4.236      1.457         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0179     0.0106    0.00983   0.000983     0.0357     0.0213     0.0188    0.00459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.84G      1.346      2.442      4.658      1.516         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0159     0.0106    0.00885   0.000885     0.0159     0.0106    0.00885   0.000885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.88G      1.378      3.439      4.447      1.562         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0156     0.0106    0.00882   0.000882     0.0156     0.0106    0.00882   0.000882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      1.452      2.869      4.275      1.526         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94     0.0139     0.0106    0.00817   0.000817     0.0139     0.0106    0.00817   0.000817\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0179     0.0106    0.00983   0.000983     0.0357     0.0213     0.0188    0.00459\n",
      "              overripe         27         94     0.0179     0.0106    0.00983   0.000983     0.0357     0.0213     0.0188    0.00459\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         29         92     0.0082     0.0109     0.0046    0.00046     0.0492     0.0652     0.0275    0.00674\n",
      "              overripe         29         92     0.0082     0.0109     0.0046    0.00046     0.0492     0.0652     0.0275    0.00674\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 929.60it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G     0.9963      2.259      4.393       1.33         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0758     0.0532      0.044    0.00676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G      1.134      2.618      4.829      1.347         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0133     0.0106     0.0103    0.00103       0.04     0.0319      0.024    0.00517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G     0.9681      2.374      4.584      1.316         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94     0.0104     0.0106    0.00811   0.000811     0.0417     0.0426     0.0243    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.44G      1.007      2.412      4.551      1.313         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94       0.01     0.0106     0.0079    0.00079       0.02     0.0213      0.013    0.00363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G      1.079      2.267      4.482      1.325         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94       0.01     0.0106     0.0079    0.00079       0.02     0.0213      0.013    0.00363\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0615     0.0426     0.0358    0.00599\n",
      "              overripe         27         94     0.0154     0.0106     0.0113    0.00113     0.0615     0.0426     0.0358    0.00599\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         29         92     0.0175     0.0217     0.0101    0.00101     0.0789     0.0978     0.0457     0.0118\n",
      "              overripe         29         92     0.0175     0.0217     0.0101    0.00101     0.0789     0.0978     0.0457     0.0118\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 862.85it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.59G      1.065      2.241      4.355      1.193         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.85G     0.7034      1.939      5.078      1.287          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.76G     0.5784      1.645       4.47      1.122          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0175     0.0106     0.0096    0.00096     0.0351     0.0213     0.0186    0.00456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.82G     0.7308      1.287      4.906      1.199          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0164     0.0106    0.00911   0.000911     0.0328     0.0213     0.0176    0.00431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.76G     0.7071      2.267       4.54      1.244          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0154     0.0106    0.00861   0.000861     0.0308     0.0213     0.0167    0.00408\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94     0.0175     0.0106     0.0096    0.00096     0.0351     0.0213     0.0186    0.00455\n",
      "              overripe         27         94     0.0175     0.0106     0.0096    0.00096     0.0351     0.0213     0.0186    0.00455\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.75it/s]\n",
      "                   all         29         92     0.0231     0.0326     0.0121     0.0024     0.0615      0.087     0.0335    0.00904\n",
      "              overripe         29         92     0.0231     0.0326     0.0121     0.0024     0.0615      0.087     0.0335    0.00904\n",
      "Speed: 1.5ms preprocess, 14.8ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 924.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      1.235      2.506      4.607      1.444         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0571     0.0426     0.0336    0.00634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G     0.8344      1.793      4.843       1.26         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0132     0.0106     0.0115    0.00115     0.0395     0.0319      0.025    0.00524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.21G     0.9728      2.584      4.346      1.326         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0123     0.0106     0.0111    0.00111      0.037     0.0319     0.0237    0.00428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      1.124      2.421      4.504      1.319         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0114     0.0106     0.0106    0.00106     0.0227     0.0213     0.0164    0.00444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G     0.9302      2.178      4.396      1.246         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0114     0.0106     0.0106    0.00106     0.0227     0.0213     0.0164    0.00444\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0571     0.0426     0.0336    0.00635\n",
      "              overripe         27         94     0.0143     0.0106     0.0108    0.00108     0.0571     0.0426     0.0336    0.00635\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         29         92      0.018     0.0217     0.0102    0.00102     0.0631     0.0761     0.0374     0.0102\n",
      "              overripe         29         92      0.018     0.0217     0.0102    0.00102     0.0631     0.0761     0.0374     0.0102\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 717.14it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.77G     0.9482      2.052      4.303      1.327         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.87G     0.8953      2.577      5.793      1.283          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0169     0.0106    0.00925   0.000925     0.0339     0.0213      0.018    0.00442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.92G     0.8654      2.449      4.012      1.287         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0167     0.0106    0.00911   0.000911     0.0333     0.0213     0.0177    0.00436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G      1.094      2.376      4.446      1.385         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0141     0.0106    0.00774   0.000774     0.0282     0.0213     0.0151     0.0037\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.95G     0.9687      2.071      4.196      1.319         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.012     0.0106    0.00656   0.000656     0.0241     0.0213     0.0128    0.00316\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0169     0.0106    0.00925   0.000925     0.0339     0.0213      0.018    0.00442\n",
      "              overripe         27         94     0.0169     0.0106    0.00925   0.000925     0.0339     0.0213      0.018    0.00442\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         29         92      0.016     0.0217    0.00819    0.00164      0.072     0.0978     0.0396    0.00943\n",
      "              overripe         29         92      0.016     0.0217    0.00819    0.00164      0.072     0.0978     0.0396    0.00943\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 837.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G     0.9776      2.178      4.561      1.352         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0154     0.0106     0.0113    0.00113     0.0615     0.0426     0.0357    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.49G      1.117      2.393      4.472      1.382         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0145     0.0106     0.0109    0.00109     0.0435     0.0319     0.0257    0.00556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.23G       1.02      2.364      4.474      1.278         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.013     0.0106     0.0114    0.00114      0.026     0.0213      0.018    0.00381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      1.072       2.67      4.513      1.375         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0122     0.0106      0.011     0.0011     0.0366     0.0319     0.0237    0.00534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G      1.059      2.491      4.386       1.35         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0122     0.0106      0.011     0.0011     0.0366     0.0319     0.0237    0.00534\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0606     0.0426     0.0353    0.00589\n",
      "              overripe         27         94     0.0152     0.0106     0.0112    0.00112     0.0606     0.0426     0.0353    0.00589\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]\n",
      "                   all         29         92    0.00885     0.0109    0.00584   0.000584     0.0619     0.0761      0.036      0.009\n",
      "              overripe         29         92    0.00885     0.0109    0.00584   0.000584     0.0619     0.0761      0.036      0.009\n",
      "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 892.60it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.66G      1.081      2.426       4.32      1.356         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94     0.0179     0.0106     0.0101    0.00101     0.0357     0.0213     0.0194    0.00474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.88G       1.86      3.856      5.541      1.971          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0159     0.0106    0.00885   0.000885     0.0317     0.0213     0.0175    0.00427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.91G     0.8705      2.615      4.571      1.245         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0145     0.0106    0.00826   0.000826      0.029     0.0213      0.016     0.0039\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.88G      1.317      3.344      5.468      1.462          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0122     0.0106    0.00705   0.000705     0.0244     0.0213     0.0138    0.00334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.87G      1.029      2.279      4.053       1.31         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.011     0.0106     0.0061    0.00061      0.033     0.0319     0.0179    0.00356\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0189     0.0106     0.0106    0.00106     0.0377     0.0213     0.0205    0.00499\n",
      "              overripe         27         94     0.0189     0.0106     0.0106    0.00106     0.0377     0.0213     0.0205    0.00499\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]\n",
      "                   all         29         92    0.00826     0.0109    0.00433   0.000866     0.0413     0.0543     0.0223    0.00524\n",
      "              overripe         29         92    0.00826     0.0109    0.00433   0.000866     0.0413     0.0543     0.0223    0.00524\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:00<00:00, 898.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.39G      1.039      2.356      4.542      1.351         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0152     0.0106     0.0112    0.00112     0.0606     0.0426     0.0352    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G      1.005      2.388      4.449      1.285         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0147     0.0106      0.011     0.0011     0.0441     0.0319     0.0261    0.00564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.9795      2.435      4.539      1.308         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0135     0.0106     0.0116    0.00116     0.0405     0.0319     0.0255    0.00463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      1.048       2.31      4.533      1.307         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0127     0.0106     0.0112    0.00112     0.0253     0.0213     0.0177    0.00177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.44G      1.015       2.34      4.553      1.288         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0127     0.0106     0.0112    0.00112     0.0253     0.0213     0.0177    0.00177\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0363    0.00607\n",
      "              overripe         27         94     0.0156     0.0106     0.0114    0.00114     0.0625     0.0426     0.0363    0.00607\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.81it/s]\n",
      "                   all         29         92    0.00909     0.0109    0.00571   0.000571     0.0636     0.0761      0.037     0.0083\n",
      "              overripe         29         92    0.00909     0.0109    0.00571   0.000571     0.0636     0.0761      0.037     0.0083\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 706.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.85G      1.225      3.023      4.793      1.327         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.13G      1.329      2.937      4.667      1.477         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.85G      1.224      2.951      4.802      1.433         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0147     0.0106    0.00821   0.000821     0.0294     0.0213     0.0159    0.00391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G      1.021      2.307      4.457       1.37         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0156     0.0106    0.00882   0.000882     0.0312     0.0213      0.017    0.00415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G      1.261      2.913      4.943      1.362         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0141     0.0106    0.00827   0.000827     0.0282     0.0213     0.0157    0.00379\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94     0.0156     0.0106    0.00882   0.000882     0.0312     0.0213      0.017    0.00415\n",
      "              overripe         27         94     0.0156     0.0106    0.00882   0.000882     0.0312     0.0213      0.017    0.00415\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         29         92     0.0254     0.0326     0.0134    0.00178     0.0678      0.087      0.037       0.01\n",
      "              overripe         29         92     0.0254     0.0326     0.0134    0.00178     0.0678      0.087      0.037       0.01\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:00<00:00, 834.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.6G      1.202      2.643      4.828      1.421         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0135     0.0106     0.0104    0.00104     0.0541     0.0426     0.0317    0.00668\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      1.169      2.856      4.758      1.396         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0127     0.0106     0.0112    0.00112      0.038     0.0319     0.0241    0.00437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      1.103      2.461      4.568      1.364         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0101     0.0106    0.00602   0.000602     0.0303     0.0319     0.0166    0.00383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G      1.069      2.297      4.212      1.329         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0102     0.0106     0.0055    0.00055     0.0306     0.0319     0.0162    0.00323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G      0.978      2.127       4.08       1.25         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0213     0.0319     0.0122    0.00517     0.0496     0.0745     0.0274    0.00755\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                   all         27         94     0.0211     0.0319     0.0121    0.00514     0.0493     0.0745     0.0272    0.00751\n",
      "              overripe         27         94     0.0211     0.0319     0.0121    0.00514     0.0493     0.0745     0.0272    0.00751\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                   all         29         92     0.0514     0.0978     0.0401     0.0241     0.0743      0.141      0.056     0.0327\n",
      "              overripe         29         92     0.0514     0.0978     0.0401     0.0241     0.0743      0.141      0.056     0.0327\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 6.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 703.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.56G     0.9088      1.608      3.678      1.288         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         27         94     0.0391     0.0532     0.0225     0.0131     0.0547     0.0745      0.031     0.0144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G      1.051      1.757      3.674      1.254         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0462     0.0638     0.0267     0.0166     0.0538     0.0745     0.0311     0.0163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G     0.7095      1.532      4.016      1.034          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94     0.0507     0.0745     0.0297     0.0193      0.058     0.0851     0.0341     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      1.456      2.632       3.92      1.419         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94       0.06     0.0957      0.035     0.0272     0.0667      0.106     0.0387     0.0263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G      1.147      2.004      3.833      1.273         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0621      0.106     0.0378     0.0289     0.0745      0.128     0.0441      0.029\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94     0.0625      0.106     0.0379      0.029      0.075      0.128     0.0443     0.0292\n",
      "              overripe         27         94     0.0625      0.106     0.0379      0.029      0.075      0.128     0.0443     0.0292\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.75it/s]\n",
      "                   all         29         92     0.0616      0.141     0.0408     0.0255     0.0806      0.185     0.0524     0.0308\n",
      "              overripe         29         92     0.0616      0.141     0.0408     0.0255     0.0806      0.185     0.0524     0.0308\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 787.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G      1.095      2.764      4.729      1.363         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27         94     0.0137     0.0106     0.0105    0.00105     0.0411     0.0319     0.0246    0.00601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.34G      1.149      2.694      4.451      1.426         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0115     0.0106     0.0106    0.00106     0.0345     0.0319     0.0224    0.00402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.42G      1.163      2.587      4.701      1.339         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0106     0.0106    0.00545   0.000545     0.0426     0.0426     0.0257    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.44G      1.069      2.296      4.313        1.3         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94    0.00847     0.0106    0.00478   0.000478     0.0254     0.0319     0.0139    0.00367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.43G      1.027       2.14      3.876      1.242         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.026     0.0426     0.0159     0.0084     0.0584     0.0957     0.0338     0.0126\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94      0.026     0.0426     0.0159     0.0084     0.0584     0.0957     0.0338     0.0126\n",
      "              overripe         27         94      0.026     0.0426     0.0159     0.0084     0.0584     0.0957     0.0338     0.0126\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         29         92     0.0808      0.174      0.071     0.0458      0.096      0.207     0.0826     0.0528\n",
      "              overripe         29         92     0.0808      0.174      0.071     0.0458      0.096      0.207     0.0826     0.0528\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 726.29it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.52G      1.064      1.841      3.304      1.337         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.107       0.17     0.0695     0.0457      0.114      0.181     0.0742     0.0442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G     0.9667      2.029      3.483       1.29         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94       0.11      0.181     0.0723     0.0479      0.116      0.191      0.077     0.0467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G     0.7438      1.601      3.556      1.173         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.112      0.202      0.079     0.0498      0.118      0.213     0.0836     0.0475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G     0.6836      1.467      3.339       1.04         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.106      0.202      0.076      0.049      0.112      0.213     0.0812     0.0466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G      1.043      2.078      3.601      1.246         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.103      0.202     0.0738     0.0485      0.109      0.213     0.0778     0.0455\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.112      0.202     0.0786     0.0494      0.118      0.213     0.0832     0.0471\n",
      "              overripe         27         94      0.112      0.202     0.0786     0.0494      0.118      0.213     0.0832     0.0471\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         29         92     0.0809      0.207     0.0608     0.0432     0.0979       0.25     0.0732     0.0484\n",
      "              overripe         29         92     0.0809      0.207     0.0608     0.0432     0.0979       0.25     0.0732     0.0484\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 906.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      1.172      2.733      4.614      1.391         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0133     0.0106     0.0103    0.00103     0.0533     0.0426     0.0314    0.00661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G      1.023      2.346       4.49      1.319         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0122     0.0106      0.011     0.0011     0.0366     0.0319     0.0235    0.00423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G      1.114      2.574      4.586      1.342         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94     0.0127     0.0106    0.00646   0.000646      0.038     0.0319     0.0208    0.00469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      1.002      1.969      4.197       1.25         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0206     0.0213     0.0111    0.00483     0.0309     0.0319     0.0164    0.00808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G      1.031       2.01      3.725       1.22        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94     0.0651      0.117     0.0397     0.0261      0.071      0.128     0.0431     0.0261\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94     0.0651      0.117     0.0394     0.0259      0.071      0.128      0.043      0.026\n",
      "              overripe         27         94     0.0651      0.117     0.0394     0.0259      0.071      0.128      0.043      0.026\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]\n",
      "                   all         29         92      0.108      0.228     0.0969     0.0732      0.129      0.272      0.112     0.0789\n",
      "              overripe         29         92      0.108      0.228     0.0969     0.0732      0.129      0.272      0.112     0.0789\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1134.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.77G     0.8894      1.401      3.066      1.174         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94      0.125      0.277      0.107     0.0668       0.13      0.287       0.11     0.0626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.96G      0.968      2.037      3.326      1.246         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.126      0.298      0.111     0.0716      0.131      0.309      0.114     0.0665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G     0.9522      1.879      3.203      1.363         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.131       0.33      0.115     0.0754      0.131       0.33      0.115       0.07\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      1.077      2.104      3.751      1.423         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94       0.13       0.34      0.119     0.0781      0.126       0.33      0.115      0.073\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.95G     0.9014      1.802      3.175      1.199         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.124       0.34       0.12      0.079       0.12       0.33      0.116      0.074\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94      0.122       0.34       0.12     0.0788      0.118       0.33      0.116     0.0738\n",
      "              overripe         27         94      0.122       0.34       0.12     0.0788      0.118       0.33      0.116     0.0738\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92      0.101      0.326       0.11     0.0917      0.108      0.348      0.116     0.0928\n",
      "              overripe         29         92      0.101      0.326       0.11     0.0917      0.108      0.348      0.116     0.0928\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 817.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5         4G     0.8991      2.543      3.813      1.248         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27         94        0.1      0.468      0.136     0.0898        0.1      0.468      0.135     0.0819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.96G     0.8475      2.189      4.508      1.344          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0993      0.468      0.138     0.0905     0.0971      0.457      0.136     0.0822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G     0.9457      3.032      4.842      1.529          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0964      0.457      0.137       0.09     0.0964      0.457      0.136     0.0828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G     0.8558      2.122      4.979      1.197          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.102      0.489      0.144     0.0946     0.0998      0.479      0.142     0.0878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.9012      2.599      4.172      1.129         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.101        0.5      0.142     0.0923     0.0991      0.489       0.14     0.0857\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.102      0.489      0.144     0.0941     0.0996      0.479      0.142     0.0873\n",
      "              overripe         27         94      0.102      0.489      0.144     0.0941     0.0996      0.479      0.142     0.0873\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.85it/s]\n",
      "                   all         29         92      0.101      0.565      0.179      0.146      0.101      0.565      0.179      0.142\n",
      "              overripe         29         92      0.101      0.565      0.179      0.146      0.101      0.565      0.179      0.142\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 15557.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.1G      1.925      3.032      3.544      1.598         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27         94     0.0864      0.617      0.126     0.0749      0.082      0.585      0.121     0.0676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G      1.057      2.044       3.28      1.187         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94     0.0919      0.649      0.127     0.0752     0.0873      0.617      0.122     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.04G      0.939       2.23      3.219      1.254         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0956       0.67      0.128     0.0766      0.091      0.638      0.123     0.0706\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      1.053      2.758       3.05      1.419         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94     0.0969       0.67      0.129     0.0781     0.0938      0.649      0.127     0.0728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.06G      1.119      2.212      3.354      1.244         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0942       0.66      0.127     0.0783     0.0912      0.638      0.123     0.0736\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94     0.0935       0.66      0.127     0.0783      0.092      0.649      0.126     0.0737\n",
      "              overripe         27         94     0.0935       0.66      0.127     0.0783      0.092      0.649      0.126     0.0737\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                   all         29         92      0.267      0.196      0.167      0.131      0.267      0.196      0.167      0.129\n",
      "              overripe         29         92      0.267      0.196      0.167      0.131      0.267      0.196      0.167      0.129\n",
      "Speed: 0.2ms preprocess, 15.0ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:00<00:00, 837.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G      1.102       2.47      4.764      1.381         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94     0.0143     0.0106     0.0108    0.00108     0.0429     0.0319     0.0254     0.0055\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      1.083      2.589      4.605      1.308         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94     0.0108     0.0106    0.00551   0.000551     0.0323     0.0319     0.0195    0.00419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.44G      1.096      2.285      4.363      1.281         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94     0.0101     0.0106    0.00551   0.000551     0.0303     0.0319     0.0161    0.00372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.43G      1.039      1.987      3.493      1.277         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.139      0.606       0.18      0.115      0.137      0.596      0.178      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.44G      0.955      1.905      2.891      1.201         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.293      0.404      0.222      0.137      0.293      0.404      0.214      0.128\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.293      0.404       0.22      0.136      0.293      0.404      0.213      0.127\n",
      "              overripe         27         94      0.293      0.404       0.22      0.136      0.293      0.404      0.213      0.127\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]\n",
      "                   all         29         92      0.308      0.435      0.277      0.221      0.308      0.435      0.277      0.211\n",
      "              overripe         29         92      0.308      0.435      0.277      0.221      0.308      0.435      0.277      0.211\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 898.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       5.8G      0.883       2.12      2.874      1.147         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         27         94      0.315       0.41      0.237      0.151      0.323      0.421      0.242      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.91G     0.9257      1.456      3.088      1.184         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.322      0.404      0.245      0.151      0.322      0.404      0.242      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G      1.104      1.843       3.37      1.221         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.332      0.444      0.247      0.153      0.332      0.444      0.243       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.88G      1.116      2.392      3.245      1.494         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.327      0.444      0.247      0.153      0.327      0.444      0.242       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.95G     0.8383      2.116      3.024      1.235         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.314      0.447      0.245      0.153      0.299      0.436      0.232      0.138\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.326      0.447      0.247      0.153      0.326      0.447      0.242       0.14\n",
      "              overripe         27         94      0.326      0.447      0.247      0.153      0.326      0.447      0.242       0.14\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.80it/s]\n",
      "                   all         29         92      0.288      0.522       0.29      0.231      0.288      0.522      0.289      0.222\n",
      "              overripe         29         92      0.288      0.522       0.29      0.231      0.288      0.522      0.289      0.222\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 917.07it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.99G     0.8262      1.496      2.138        1.2         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27         94      0.221      0.468      0.212      0.125      0.216      0.457        0.2      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.86G      1.074      1.949      2.844       1.29         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.231      0.489      0.212      0.125      0.226      0.479      0.202      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.93G      1.242      2.145      2.811      1.473         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94       0.23      0.496      0.215      0.127      0.234      0.479      0.202      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.93G      1.053      1.843       3.02      1.466         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94      0.234      0.521      0.214      0.126      0.234      0.489      0.203      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.7567      1.558       2.42      1.116         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27         94      0.229      0.521      0.216      0.126       0.22        0.5      0.205      0.118\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.231      0.498      0.214      0.127      0.232      0.479      0.201      0.119\n",
      "              overripe         27         94      0.231      0.498      0.214      0.127      0.232      0.479      0.201      0.119\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                   all         29         92      0.324      0.511      0.293      0.236      0.324      0.511      0.292      0.228\n",
      "              overripe         29         92      0.324      0.511      0.293      0.236      0.324      0.511      0.292      0.228\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1166.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.1G      1.097      2.052      2.598      1.263         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         27         94      0.206      0.607      0.197      0.113      0.225      0.447      0.187      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.92G     0.9002      1.646      2.239      1.236         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94       0.21      0.628      0.196      0.112      0.223      0.447      0.186      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.06G     0.7668      1.637      2.518      1.298         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94       0.21      0.606      0.199      0.114      0.204      0.584      0.189      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.01G     0.9583      1.874      2.486      1.325         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27         94      0.209      0.628      0.198      0.113      0.196      0.564      0.188      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.04G     0.9018      1.834      2.085      1.175         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.213      0.606      0.201      0.115      0.205      0.585      0.192      0.107\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.211      0.606      0.201      0.115      0.204      0.585      0.191      0.107\n",
      "              overripe         27         94      0.211      0.606      0.201      0.115      0.204      0.585      0.191      0.107\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.75it/s]\n",
      "                   all         29         92      0.264      0.457      0.238      0.186      0.264      0.457      0.238       0.18\n",
      "              overripe         29         92      0.264      0.457      0.238      0.186      0.264      0.457      0.238       0.18\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 886.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      1.061      2.539      4.634      1.346         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94     0.0137     0.0106     0.0117    0.00117     0.0411     0.0319     0.0258    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G      1.122      2.504      4.461      1.374         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0123     0.0106    0.00674   0.000674     0.0247     0.0213      0.013    0.00385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.7G      1.023       1.96      3.566      1.253         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.255      0.291      0.199      0.136      0.255      0.291      0.199      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.8637      1.719      2.423      1.163         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94       0.27      0.553       0.26      0.158       0.28      0.564      0.265       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G      1.021      1.857      2.372      1.225         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94       0.29      0.543      0.259      0.146       0.29      0.543      0.256       0.14\n",
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94      0.269      0.553       0.26      0.158      0.281      0.564      0.265       0.15\n",
      "              overripe         27         94      0.269      0.553       0.26      0.158      0.281      0.564      0.265       0.15\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]\n",
      "                   all         29         92      0.262      0.576      0.325      0.268      0.262      0.576      0.325      0.254\n",
      "              overripe         29         92      0.262      0.576      0.325      0.268      0.262      0.576      0.325      0.254\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1264.79it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G      1.314      1.802        2.7      1.137         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27         94      0.275      0.479      0.262      0.147      0.284      0.489      0.269      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G     0.6829       1.43      2.512      1.081         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.282      0.457      0.265      0.148      0.289      0.468       0.27      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G     0.7056      1.265      1.875      1.101         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.259      0.564      0.267      0.148      0.281      0.457      0.272      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         4G     0.8071      1.365       1.96      1.165         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.265      0.574      0.267      0.149      0.262      0.543      0.255       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.04G      1.276      1.866      2.169      1.303         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.262      0.582      0.276      0.155       0.25      0.553      0.263      0.146\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.263      0.583      0.277      0.156      0.252      0.558      0.263      0.146\n",
      "              overripe         27         94      0.263      0.583      0.277      0.156      0.252      0.558      0.263      0.146\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]\n",
      "                   all         29         92      0.313      0.478      0.319      0.254      0.313      0.478      0.318       0.24\n",
      "              overripe         29         92      0.313      0.478      0.319      0.254      0.313      0.478      0.318       0.24\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 812.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.61G      1.168      2.607      4.766      1.445          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94     0.0141     0.0106    0.00991   0.000991     0.0141     0.0106    0.00991   0.000991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.76G      1.224      3.053      4.711      1.415          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0227     0.0213      0.012    0.00526     0.0341     0.0319      0.018    0.00823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.5G     0.9954      2.002      3.142      1.223          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94      0.283      0.404      0.227      0.141      0.283      0.404      0.219      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.49G     0.9234      1.678      2.195      1.221          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.257      0.457      0.223      0.126       0.23      0.447      0.209      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.9449      1.642      2.063      1.204          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.256        0.5       0.23      0.133      0.245        0.5      0.218      0.122\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.282      0.404      0.226      0.141      0.282      0.404      0.218      0.134\n",
      "              overripe         27         94      0.282      0.404      0.226      0.141      0.282      0.404      0.218      0.134\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92      0.261       0.62      0.293      0.245      0.261       0.62      0.292      0.233\n",
      "              overripe         29         92      0.261       0.62      0.293      0.245      0.261       0.62      0.292      0.233\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 861.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.68G      1.318      2.187      3.534      1.312         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94      0.231      0.489      0.251      0.148      0.233      0.457      0.245      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G     0.9006      1.459      4.005      1.209          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.233        0.5      0.256      0.148      0.229      0.489      0.245       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G      1.049      1.975       3.66      1.397          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.235      0.511      0.258       0.15      0.227        0.5      0.249      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G     0.9131      1.828      3.547      1.235          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.234      0.521      0.257       0.15      0.226      0.511      0.247       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G     0.9165      1.425      4.228     0.9384          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.238      0.511      0.258      0.149      0.218        0.5      0.247      0.137\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.234      0.511      0.258       0.15      0.227        0.5      0.249      0.141\n",
      "              overripe         27         94      0.234      0.511      0.258       0.15      0.227        0.5      0.249      0.141\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.88it/s]\n",
      "                   all         29         92      0.294      0.478      0.338      0.277      0.294      0.478      0.336      0.262\n",
      "              overripe         29         92      0.294      0.478      0.338      0.277      0.294      0.478      0.336      0.262\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 983.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.85G     0.5095     0.9982      1.463      1.057         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         27         94       0.22      0.606      0.247      0.136      0.223      0.489      0.236      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.86G     0.6258      1.991      1.877      1.158         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94      0.226      0.564       0.25      0.138      0.224      0.543      0.238      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G     0.7969      1.808      1.887      1.188         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.216      0.574      0.255      0.141      0.209      0.553      0.242      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      1.022      1.665      2.689      1.411         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94      0.218      0.585      0.256       0.14       0.21      0.564      0.243      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G     0.9861      1.556      1.813      1.242         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.223      0.574      0.255      0.141      0.213      0.532      0.243      0.132\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.217      0.574      0.258      0.141      0.211      0.553      0.246      0.134\n",
      "              overripe         27         94      0.217      0.574      0.258      0.141      0.211      0.553      0.246      0.134\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                   all         29         92      0.295      0.467      0.302      0.239      0.295      0.467        0.3      0.229\n",
      "              overripe         29         92      0.295      0.467      0.302      0.239      0.295      0.467        0.3      0.229\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:00<00:00, 913.22it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.41G      1.137      2.458      4.671      1.368         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94     0.0123     0.0106     0.0098    0.00098      0.037     0.0319     0.0225    0.00416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G       1.05      2.154      4.268      1.272         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.127      0.287       0.13     0.0934      0.132      0.298      0.132     0.0863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.54G     0.9091      1.812      2.695      1.178         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.297      0.468      0.287      0.178      0.324      0.457      0.292      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.8115      1.602      2.157      1.164         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.256      0.457      0.263      0.155      0.263      0.447       0.25      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.8313      1.646      1.993      1.151         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.275      0.511      0.264      0.155       0.27      0.489       0.25      0.145\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.298      0.468      0.284      0.177      0.312      0.457      0.291      0.167\n",
      "              overripe         27         94      0.298      0.468      0.284      0.177      0.312      0.457      0.291      0.167\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.00it/s]\n",
      "                   all         29         92      0.257      0.663      0.322      0.254      0.327      0.402      0.317      0.242\n",
      "              overripe         29         92      0.257      0.663      0.322      0.254      0.327      0.402      0.317      0.242\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1055.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.37G      1.098      2.905      2.365       1.37         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94      0.267      0.543      0.269      0.162      0.276      0.553      0.264      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.03G     0.8469      3.151      2.075      1.224         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.263      0.553      0.275      0.165      0.274      0.553      0.271      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G      1.144      2.091       3.37      1.691          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.268      0.585      0.277      0.167      0.272      0.543      0.272      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      1.198      2.101      2.608      1.267          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.266      0.585      0.278      0.169      0.274      0.564      0.272      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G     0.6639       1.69      2.068      1.095         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.273      0.617      0.283      0.171      0.276      0.543      0.276      0.158\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.273      0.617      0.283      0.171      0.273      0.543      0.277      0.159\n",
      "              overripe         27         94      0.273      0.617      0.283      0.171      0.273      0.543      0.277      0.159\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                   all         29         92       0.43      0.424      0.417      0.335       0.43      0.424      0.415      0.318\n",
      "              overripe         29         92       0.43      0.424      0.417      0.335       0.43      0.424      0.415      0.318\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 734.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.01G      1.006      1.251      1.919      1.071         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         27         94      0.276      0.532      0.281       0.17      0.276      0.532      0.269      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.88G     0.8927      1.517      2.036      1.238         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.265      0.525      0.285      0.174      0.264      0.521      0.273      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G      1.075      1.932      1.832      1.289         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94      0.259      0.543      0.284      0.174      0.254      0.532      0.272      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G       0.92      1.551      1.668      1.238         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.259      0.564      0.291      0.179      0.261      0.553      0.279       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      1.175      2.151      1.894      1.234         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.264      0.585      0.298      0.183      0.265      0.511      0.285      0.174\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.263      0.585      0.298      0.183      0.266      0.511      0.285      0.174\n",
      "              overripe         27         94      0.263      0.585      0.298      0.183      0.266      0.511      0.285      0.174\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92      0.411      0.485      0.398      0.327      0.411      0.485      0.397      0.311\n",
      "              overripe         29         92      0.411      0.485      0.398      0.327      0.411      0.485      0.397      0.311\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 890.31it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.59G      1.106      2.522      4.578      1.393         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.013     0.0106     0.0101    0.00101      0.026     0.0213     0.0168    0.00469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G     0.9363      1.941      3.765      1.222         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.291      0.318      0.219       0.14      0.287      0.309      0.217      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G     0.8512       1.68      2.448       1.16         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.216      0.421      0.198      0.106      0.213      0.415      0.191     0.0984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8482       1.67      2.102      1.121         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.249      0.532      0.253      0.152      0.253      0.504      0.242       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G     0.8235      1.604      1.763      1.129         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.278      0.556      0.274      0.159      0.266      0.511      0.252      0.145\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.275      0.548      0.272      0.158      0.267      0.511       0.25      0.144\n",
      "              overripe         27         94      0.275      0.548      0.272      0.158      0.267      0.511       0.25      0.144\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                   all         29         92      0.341      0.554      0.389      0.316      0.343      0.543      0.385      0.299\n",
      "              overripe         29         92      0.341      0.554      0.389      0.316      0.343      0.543      0.385      0.299\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 861.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.08G     0.7439       1.18      2.607      1.092         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         27         94      0.274      0.479      0.261       0.15      0.273      0.476       0.25      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.8371      1.765      2.771      1.173         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94       0.25      0.553       0.26       0.15      0.277      0.472      0.248      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.04G     0.7551      1.185      3.412      1.153         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.241      0.532      0.261      0.152      0.237      0.521      0.249       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G     0.7686      1.384      2.979      1.104         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.244      0.532       0.26      0.151       0.24      0.521      0.248       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.03G     0.7033       1.04      2.763     0.9646         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.245      0.543      0.261      0.152      0.243      0.521      0.245      0.141\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.245      0.532      0.261      0.152      0.242      0.521      0.245      0.141\n",
      "              overripe         27         94      0.245      0.532      0.261      0.152      0.242      0.521      0.245      0.141\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                   all         29         92        0.3        0.5      0.337      0.272      0.315        0.5      0.334      0.256\n",
      "              overripe         29         92        0.3        0.5      0.337      0.272      0.315        0.5      0.334      0.256\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 874.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.18G      1.096      2.591      4.607      1.373         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94     0.0125     0.0106    0.00988   0.000988      0.025     0.0213     0.0163    0.00456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.34G      1.071      2.142      3.957      1.301         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.227      0.415      0.206       0.13       0.23      0.415        0.2      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G     0.9855      1.841      2.478      1.228         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.272      0.383      0.239      0.151      0.278      0.389      0.232      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G     0.8788      1.635      1.956      1.147         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.256      0.425      0.244      0.159      0.256      0.425      0.237      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G     0.8301      1.622      1.948      1.141         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94       0.27      0.415      0.258      0.161      0.271      0.415      0.247      0.149\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94       0.27      0.415      0.258      0.162       0.27      0.412      0.247      0.149\n",
      "              overripe         27         94       0.27      0.415      0.258      0.162       0.27      0.412      0.247      0.149\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                   all         29         92      0.413      0.478      0.407      0.338      0.413      0.478      0.403      0.317\n",
      "              overripe         29         92      0.413      0.478      0.407      0.338      0.413      0.478      0.403      0.317\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 955.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.96G     0.5772      1.443      2.096      1.091         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.267      0.404       0.26      0.163      0.267      0.404      0.251      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.8986      1.496      2.157      1.144         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.267      0.414      0.269      0.168      0.267      0.414      0.259       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.04G     0.7897      1.601      1.923      1.149         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.271      0.415      0.267      0.167      0.271      0.415      0.257      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.04G     0.9577      1.733      2.726      1.282         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.267      0.426      0.272      0.169      0.267      0.426       0.26      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.7027      1.681      1.841      1.099         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.277      0.436      0.277      0.173      0.277      0.436      0.265      0.162\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.278      0.436      0.276      0.172      0.278      0.436      0.264      0.161\n",
      "              overripe         27         94      0.278      0.436      0.276      0.172      0.278      0.436      0.264      0.161\n",
      "Speed: 0.2ms preprocess, 14.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         29         92      0.426      0.475      0.383      0.316      0.426      0.475       0.38      0.299\n",
      "              overripe         29         92      0.426      0.475      0.383      0.316      0.426      0.475       0.38      0.299\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:00<00:00, 840.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.3G      1.052      2.384      4.737      1.328         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G      1.106      2.181      3.551      1.335         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.344      0.362       0.26      0.162      0.354      0.372      0.272      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.8837      1.744      2.338      1.158         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.303      0.394      0.241      0.148      0.319      0.404      0.243       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.48G     0.8648      1.648      2.022      1.134         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.354      0.467      0.298      0.196      0.344      0.452      0.286       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G     0.8138      1.533       1.91      1.073         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.361      0.543      0.313      0.189      0.361      0.543      0.298      0.175\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.351      0.468      0.298      0.196      0.342      0.449      0.286      0.181\n",
      "              overripe         27         94      0.351      0.468      0.298      0.196      0.342      0.449      0.286      0.181\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         29         92      0.415      0.511      0.409      0.329      0.415      0.511      0.407      0.311\n",
      "              overripe         29         92      0.415      0.511      0.409      0.329      0.415      0.511      0.407      0.311\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 836.50it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.61G     0.7281      1.643      1.953      1.119         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         27         94      0.322      0.468      0.316      0.188       0.32      0.457        0.3      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.8378      1.717      2.465      1.093         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.315        0.5      0.321      0.189      0.324      0.454      0.301      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G     0.6844       1.79      2.145      1.086         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.316      0.511       0.32      0.188      0.322      0.479        0.3      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.7065      1.893      2.825      1.156         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.325      0.521      0.327       0.19      0.313        0.5      0.305      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.7011       1.45      1.946      1.145         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.317      0.521      0.327      0.187      0.307        0.5      0.305      0.177\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94      0.326      0.521      0.328      0.191      0.314        0.5      0.306       0.18\n",
      "              overripe         27         94      0.326      0.521      0.328      0.191      0.314        0.5      0.306       0.18\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92      0.387      0.609      0.412      0.334      0.387      0.609       0.41      0.315\n",
      "              overripe         29         92      0.387      0.609      0.412      0.334      0.387      0.609       0.41      0.315\n",
      "Speed: 0.2ms preprocess, 14.9ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:00<00:00, 932.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.32G      1.123      2.593      4.602      1.368         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G      0.938      1.944      3.294      1.218          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.251      0.553      0.233      0.134      0.259      0.543       0.23      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G     0.9327      1.779      2.189      1.187         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.322      0.532      0.328      0.207       0.31      0.511      0.306      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.7709      1.456      1.864      1.081         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.327      0.649      0.335      0.185      0.311      0.617        0.3      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G     0.8006      1.431      1.663      1.077         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.355      0.723       0.39      0.218      0.357       0.66      0.362      0.197\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         27         94      0.355      0.723      0.391      0.218      0.353       0.66      0.362      0.197\n",
      "              overripe         27         94      0.355      0.723      0.391      0.218      0.353       0.66      0.362      0.197\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.85it/s]\n",
      "                   all         29         92      0.448      0.554      0.466      0.383      0.448      0.554      0.463      0.366\n",
      "              overripe         29         92      0.448      0.554      0.466      0.383      0.448      0.554      0.463      0.366\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 922.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.94G      1.029      1.708      1.501      1.162         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.347       0.69      0.408      0.235      0.353      0.606      0.389      0.219\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.04G     0.8527      1.334      1.541      1.116         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.353       0.67      0.412      0.237      0.354      0.607      0.392      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.8752      1.609      1.507        1.1         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.373       0.66      0.416      0.238      0.359      0.617      0.395      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      0.956      1.629      1.813      1.196         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.368      0.668      0.411      0.239      0.368      0.585       0.39      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.8973      1.496      1.397      1.102         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.365      0.681      0.417      0.241      0.377      0.585      0.395      0.222\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94      0.365      0.681      0.417      0.241      0.375      0.585      0.396      0.222\n",
      "              overripe         27         94      0.365      0.681      0.417      0.241      0.375      0.585      0.396      0.222\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         29         92      0.513      0.543      0.456      0.374      0.513      0.543      0.455      0.351\n",
      "              overripe         29         92      0.513      0.543      0.456      0.374      0.513      0.543      0.455      0.351\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [00:00<00:00, 914.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G     0.9992      2.229      4.522      1.325         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.72G      1.026      2.001      3.163      1.242         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.257      0.585      0.278      0.175      0.258      0.553      0.283      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G     0.8823       1.66       2.18       1.16         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.265      0.556      0.317      0.205       0.29      0.468      0.305      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G     0.8113      1.519      1.807      1.078         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94       0.31       0.55      0.321      0.185        0.3      0.511      0.304      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.7819      1.375      1.568      1.045         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94       0.37      0.702      0.388      0.229      0.369      0.628      0.368      0.207\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.369      0.702      0.388       0.23      0.372      0.637      0.368      0.207\n",
      "              overripe         27         94      0.369      0.702      0.388       0.23      0.372      0.637      0.368      0.207\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         29         92      0.418       0.75      0.492      0.405      0.418       0.75      0.489       0.38\n",
      "              overripe         29         92      0.418       0.75      0.492      0.405      0.418       0.75      0.489       0.38\n",
      "Speed: 0.3ms preprocess, 14.7ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 830.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.08G     0.9639       2.13      1.766      1.135         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.312      0.702      0.367      0.214      0.331      0.585      0.349      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.163      1.923      1.887       1.17         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.317      0.734      0.373      0.221      0.349      0.596      0.354      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      1.077      1.843        1.5      1.227         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.325      0.734      0.379      0.224      0.348      0.596       0.36      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G       1.13      1.652      3.155      1.468         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.329      0.726      0.388      0.229      0.352      0.585      0.368      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.9356      1.444      1.731       1.13         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.332      0.723      0.396      0.235      0.359      0.585      0.376      0.216\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.332      0.725      0.395      0.235      0.381      0.584      0.375      0.217\n",
      "              overripe         27         94      0.332      0.725      0.395      0.235      0.381      0.584      0.375      0.217\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         29         92      0.451      0.587      0.469      0.387      0.451      0.587      0.467      0.362\n",
      "              overripe         29         92      0.451      0.587      0.469      0.387      0.451      0.587      0.467      0.362\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:00<00:00, 907.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      1.028      2.271      4.572      1.288         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94      0.012     0.0106    0.00651   0.000651     0.0241     0.0213     0.0132    0.00384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G      1.025      2.025      3.078      1.255         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         27         94      0.193      0.468      0.177      0.104      0.213      0.426      0.178      0.099\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.39G     0.8978      1.743      2.099      1.174         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         27         94       0.31       0.33      0.257      0.152       0.31       0.33      0.245      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G     0.8038      1.537      1.778      1.087         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.313      0.681      0.365      0.212      0.293      0.649      0.336      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G     0.8488      1.513      1.596      1.076         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.437      0.569      0.415       0.23      0.412      0.537      0.367      0.208\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94      0.425      0.574      0.419       0.23      0.401      0.543      0.367      0.208\n",
      "              overripe         27         94      0.425      0.574      0.419       0.23      0.401      0.543      0.367      0.208\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  2.00it/s]\n",
      "                   all         29         92      0.487      0.681      0.541       0.43      0.487      0.681      0.537      0.414\n",
      "              overripe         29         92      0.487      0.681      0.541       0.43      0.487      0.681      0.537      0.414\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 832.04it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.42G      1.244      1.621      2.067      1.235         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.413      0.585      0.425      0.231      0.391      0.553      0.376       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.8998      1.624      1.883      1.114         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.416      0.585      0.427      0.233      0.396      0.553      0.378       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G     0.7051      1.147      1.665      1.009         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.417      0.585       0.43      0.235      0.397      0.546       0.38      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.5928      1.119      1.701     0.9978         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.422      0.564      0.433      0.237      0.411      0.521      0.383      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.7338      1.273      1.845     0.9951         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.412      0.617      0.437      0.242      0.414      0.532      0.387      0.219\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                   all         27         94      0.412      0.617      0.438      0.243      0.414      0.532      0.388       0.22\n",
      "              overripe         27         94      0.412      0.617      0.438      0.243      0.414      0.532      0.388       0.22\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                   all         29         92      0.431      0.587      0.488      0.386      0.431      0.587      0.485      0.368\n",
      "              overripe         29         92      0.431      0.587      0.488      0.386      0.431      0.587      0.485      0.368\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 161/161 [00:00<00:00, 784.22it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.62G      1.029      2.408      4.483      1.305         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         27         94     0.0177     0.0213     0.0105    0.00449     0.0265     0.0319     0.0152    0.00734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.75G     0.8994      1.747      2.777       1.18          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94       0.24      0.521      0.228      0.127      0.238      0.513      0.222      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G     0.8671      1.626       1.95      1.155          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.311      0.564      0.308      0.163      0.293      0.543      0.285      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.7811      1.384      1.518      1.065          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         27         94      0.341      0.691      0.405      0.248      0.327       0.66      0.384      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G     0.7542      1.353      1.486      1.053          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.417      0.702      0.466      0.249      0.385      0.649       0.42      0.224\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94      0.417      0.702      0.466       0.25      0.385      0.649       0.42      0.224\n",
      "              overripe         27         94      0.417      0.702      0.466       0.25      0.385      0.649       0.42      0.224\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         29         92      0.627      0.622      0.594      0.478      0.627      0.622      0.591      0.449\n",
      "              overripe         29         92      0.627      0.622      0.594      0.478      0.627      0.622      0.591      0.449\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 876.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.86G      1.435       2.77      1.744      1.415         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.415      0.723      0.454      0.246      0.391      0.681      0.417      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      1.411      2.522      1.871      1.237         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.422      0.715       0.46      0.249      0.403      0.653      0.422      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      1.161      1.969      1.792      1.281         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.435      0.672      0.468      0.254      0.407      0.629      0.431      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G     0.8239       1.83      2.045       1.14         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.455       0.66      0.471      0.255      0.434      0.617      0.433      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G     0.7967      1.541      2.345      1.114         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.483       0.66      0.478      0.258      0.441      0.585       0.44      0.234\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                   all         27         94      0.482      0.652      0.478      0.258      0.441      0.587       0.44      0.234\n",
      "              overripe         27         94      0.482      0.652      0.478      0.258      0.441      0.587       0.44      0.234\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         29         92      0.497      0.652      0.562      0.455      0.497      0.652       0.56      0.428\n",
      "              overripe         29         92      0.497      0.652      0.562      0.455      0.497      0.652       0.56      0.428\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:00<00:00, 945.14it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.25G      1.114      2.445      4.461      1.321         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94     0.0164     0.0213     0.0109    0.00565     0.0328     0.0426     0.0204     0.0083\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G     0.9786      1.864        2.7      1.227         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.322       0.33      0.248      0.168      0.325       0.33      0.245      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G     0.8074      1.537      1.928      1.096         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.359       0.66      0.347      0.199      0.343      0.638      0.317      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G     0.8069      1.471      1.658       1.07         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:08<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.435      0.649      0.393      0.219      0.412      0.617      0.359      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G     0.7882       1.41      1.437      1.038         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.406      0.681      0.428       0.23      0.387      0.649      0.384      0.214\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         27         94      0.406      0.681      0.429       0.23      0.387      0.649      0.385      0.214\n",
      "              overripe         27         94      0.406      0.681      0.429       0.23      0.387      0.649      0.385      0.214\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         29         92      0.521      0.598      0.491      0.387      0.521      0.598      0.489       0.36\n",
      "              overripe         29         92      0.521      0.598      0.491      0.387      0.521      0.598      0.489       0.36\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 891.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.24G     0.8194       1.53      1.806      1.165         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.404      0.553      0.399      0.216      0.382      0.521      0.361      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.9259       1.51      1.582      1.012         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.418      0.543      0.389      0.215      0.401      0.521      0.361      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.04G     0.7487      1.368      1.802     0.9968         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.414      0.521      0.391      0.214      0.383      0.521      0.362      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G      1.033      1.649      1.869      1.328         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.392      0.543      0.393      0.216      0.377      0.521      0.364      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.03G     0.5842      1.118       1.46     0.9472         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.404      0.543      0.396      0.219      0.387      0.521      0.367      0.208\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         27         94      0.401      0.543      0.397       0.22      0.383      0.521      0.368      0.208\n",
      "              overripe         27         94      0.401      0.543      0.397       0.22      0.383      0.521      0.368      0.208\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.18it/s]\n",
      "                   all         29         92      0.456      0.641      0.452      0.361      0.456      0.641       0.45      0.335\n",
      "              overripe         29         92      0.456      0.641      0.452      0.361      0.456      0.641       0.45      0.335\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181/181 [00:00<00:00, 855.85it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      1.113      2.447      4.537       1.35         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         27         94     0.0256     0.0319     0.0141    0.00786     0.0342     0.0426     0.0186     0.0102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.43G     0.9386      1.752       2.63      1.202         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         27         94      0.325      0.479      0.288      0.173      0.332      0.489       0.29      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.9373      1.719      1.986       1.13         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.346      0.592      0.344      0.185      0.327      0.557      0.316      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.48G     0.8098      1.446       1.74      1.058         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.401      0.681      0.408      0.227      0.389       0.66      0.383      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.7831      1.357      1.453      1.051         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.448      0.718      0.488      0.278       0.43       0.69      0.439      0.246\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94      0.447      0.713      0.489      0.278      0.425      0.681       0.44      0.246\n",
      "              overripe         27         94      0.447      0.713      0.489      0.278      0.425      0.681       0.44      0.246\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]\n",
      "                   all         29         92      0.618       0.63      0.653      0.529      0.618       0.63       0.65      0.506\n",
      "              overripe         29         92      0.618       0.63      0.653      0.529      0.618       0.63       0.65      0.506\n",
      "Speed: 0.2ms preprocess, 14.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 944.22it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.09G     0.7722      1.695       1.84       1.08         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         27         94      0.461      0.655      0.477      0.289      0.454      0.645      0.453      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.7646      1.508      1.916      1.073         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.448      0.666      0.477      0.287      0.441      0.655      0.452      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G     0.6787      1.368      1.444      1.033         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.443      0.649      0.479      0.288       0.43      0.649      0.453      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G     0.7387       1.39       1.87      1.097         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.436       0.67       0.48      0.288      0.427       0.66      0.457      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.6963      1.379      1.489     0.9973         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94       0.41      0.718      0.484      0.287      0.425       0.67      0.441      0.262\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94      0.461      0.654      0.476      0.289      0.453      0.643      0.452      0.265\n",
      "              overripe         27         94      0.461      0.654      0.476      0.289      0.453      0.643      0.452      0.265\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         29         92       0.59      0.593      0.622      0.509       0.59      0.593       0.62      0.486\n",
      "              overripe         29         92       0.59      0.593      0.622      0.509       0.59      0.593       0.62      0.486\n",
      "Speed: 0.2ms preprocess, 15.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [00:00<00:00, 966.48it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.58G      1.126      2.514      4.545      1.345         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94     0.0719      0.117     0.0462      0.025      0.085      0.138     0.0536     0.0246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G     0.9895      1.879      2.562      1.207         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.247      0.451      0.235      0.144      0.246      0.436      0.218      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.8813      1.645          2      1.122         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.274      0.489      0.297      0.155      0.296      0.457      0.266      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.6G     0.8115      1.474       1.72      1.061         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.446      0.553      0.413      0.202      0.394      0.489      0.349      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.42G     0.8071       1.47      1.438      1.059         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:10<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.488      0.766      0.518      0.262      0.454      0.713      0.435       0.24\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         27         94      0.489      0.766      0.518      0.262      0.455      0.713      0.435       0.24\n",
      "              overripe         27         94      0.489      0.766      0.518      0.262      0.455      0.713      0.435       0.24\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.01it/s]\n",
      "                   all         29         92      0.463      0.707       0.51      0.405      0.463      0.707      0.509      0.379\n",
      "              overripe         29         92      0.463      0.707       0.51      0.405      0.463      0.707      0.509      0.379\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 938.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.07G     0.5857      1.167      2.111      1.051         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.438      0.713      0.489      0.258        0.4       0.67      0.416      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G     0.5001      1.159      1.724     0.9875         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.436      0.734      0.492      0.262      0.403      0.681      0.422      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.04G     0.5507      1.061      1.595       0.99         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.432      0.734      0.495      0.263        0.4      0.681      0.422      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G     0.7461      1.016      2.135      1.205         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.435      0.752      0.496      0.263      0.404      0.699      0.424      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.03G     0.6709      1.101      1.745       1.16         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.433      0.745      0.495      0.268      0.386      0.702      0.429      0.248\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         27         94      0.433      0.745      0.499      0.268       0.39      0.702       0.43      0.248\n",
      "              overripe         27         94      0.433      0.745      0.499      0.268       0.39      0.702       0.43      0.248\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         29         92        0.4      0.728      0.516      0.416        0.4      0.728      0.514      0.389\n",
      "              overripe         29         92        0.4      0.728      0.516      0.416        0.4      0.728      0.514      0.389\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 915.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.28G      1.025      2.231      4.277      1.291         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.301       0.33      0.248      0.154      0.302       0.33      0.243      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G     0.9419      1.805      2.278      1.166         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.299      0.436      0.287      0.162      0.292      0.426       0.27      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.8317      1.537      1.785      1.078         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.427      0.723      0.418       0.23      0.411      0.625      0.378      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G     0.8593      1.511      1.535      1.072         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         27         94      0.426      0.583      0.448      0.253      0.393       0.53      0.408      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G     0.8409      1.369      1.384      1.039         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:10<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         27         94      0.494      0.723      0.564      0.314      0.455       0.67      0.495      0.282\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         27         94        0.5      0.723      0.562      0.313      0.456       0.67      0.494      0.281\n",
      "              overripe         27         94        0.5      0.723      0.562      0.313      0.456       0.67      0.494      0.281\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.05it/s]\n",
      "                   all         29         92      0.629      0.663      0.653      0.522      0.629      0.663      0.649      0.488\n",
      "              overripe         29         92      0.629      0.663      0.653      0.522      0.629      0.663      0.649      0.488\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 933.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.89G      1.241      1.991      1.709      1.206         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.462      0.685      0.528      0.301       0.46      0.638      0.481      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.99G      1.133      1.753      1.633      1.152          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94       0.47      0.736      0.547      0.313       0.45      0.706      0.506      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5         9G      1.099      1.768      1.809      1.207          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.493      0.734      0.566      0.331      0.489      0.692      0.527      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.98G      1.313      2.169      1.427      1.293         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.534       0.67       0.59      0.351      0.542      0.606      0.561      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.99G      1.104      1.729      1.313      1.093         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94      0.517      0.691      0.586      0.346      0.508      0.681      0.567      0.318\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                   all         27         94      0.534       0.67      0.591      0.351      0.544      0.606      0.561      0.323\n",
      "              overripe         27         94      0.534       0.67      0.591      0.351      0.544      0.606      0.561      0.323\n",
      "Speed: 0.2ms preprocess, 14.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         29         92      0.629      0.652       0.63      0.501      0.629      0.652      0.627      0.472\n",
      "              overripe         29         92      0.629      0.652       0.63      0.501      0.629      0.652      0.627      0.472\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 251 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:00<00:00, 923.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G      1.125      2.347      4.114      1.323         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         27         94      0.294      0.436      0.247      0.156      0.301      0.447      0.249      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.69G     0.8815      1.673      2.131      1.141         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         27         94       0.34       0.67      0.367      0.193      0.339      0.574      0.317      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.6G     0.8674      1.536      1.722      1.088         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         27         94      0.437      0.659      0.442      0.261      0.417      0.638      0.413      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.6G     0.8854      1.494      1.536      1.071         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         27         94      0.514      0.681      0.563      0.355      0.497      0.617      0.522       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.6G     0.8717      1.485      1.317      1.044         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.631      0.672      0.662      0.414      0.604      0.648      0.622      0.375\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         27         94      0.631      0.672      0.662      0.413      0.604      0.648      0.622      0.374\n",
      "              overripe         27         94      0.631      0.672      0.662      0.413      0.604      0.648      0.622      0.374\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.08it/s]\n",
      "                   all         29         92      0.686      0.696      0.713      0.578      0.686      0.696      0.709      0.546\n",
      "              overripe         29         92      0.686      0.696      0.713      0.578      0.686      0.696      0.709      0.546\n",
      "Speed: 0.2ms preprocess, 14.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_38/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 988.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/temp_1_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.48G     0.8908      1.192      1.979      1.097         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.543      0.702      0.597      0.338      0.512       0.66      0.552      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G     0.9935      1.469      3.309      1.152          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94       0.59      0.628      0.607      0.343      0.507      0.649       0.56      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.95G      1.732      2.679      2.841      1.552          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.598      0.628      0.613      0.346      0.545      0.585      0.565      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.05G      1.595      2.233      2.641      1.293          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         27         94      0.613      0.628      0.618       0.35      0.555      0.617       0.57      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      1.128      1.624      1.918      1.135         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         27         94      0.601      0.638      0.627      0.355      0.567      0.617       0.58      0.327\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         27         94      0.601      0.638      0.627      0.355      0.565      0.617       0.58      0.327\n",
      "              overripe         27         94      0.601      0.638      0.627      0.355      0.565      0.617       0.58      0.327\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         29         92      0.576      0.783      0.662       0.54      0.576      0.783      0.657      0.508\n",
      "              overripe         29         92      0.576      0.783      0.662       0.54      0.576      0.783      0.657      0.508\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5161919  ultralytics.nn.modules.head.Segment          [5, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27242543 parameters, 27242527 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels... 256 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 973.82it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/valid_1/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.42G      1.063      2.221      4.095      1.276         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         27         94       0.19      0.511      0.236      0.138      0.187        0.5      0.229      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.58G     0.8881      1.653      2.218      1.143         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         27         94      0.311      0.468      0.331      0.184      0.303      0.457      0.313      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.6G     0.8408      1.522      1.767      1.082        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94      0.414      0.532      0.411      0.248      0.408      0.479      0.384      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G     0.7711      1.355      1.473       1.02         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         27         94      0.518      0.617      0.547      0.295       0.49      0.593      0.483      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G     0.8028      1.398      1.339       1.05         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         27         94      0.607       0.69      0.624      0.377      0.588      0.669      0.585      0.346\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         27         94      0.607      0.689      0.624      0.377      0.588      0.668      0.585      0.346\n",
      "              overripe         27         94      0.607      0.689      0.624      0.377      0.588      0.668      0.585      0.346\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27225279 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64it/s]\n",
      "                   all         29         92      0.598      0.792      0.692      0.554      0.629      0.739      0.684      0.505\n",
      "              overripe         29         92      0.598      0.792      0.692      0.554      0.629      0.739      0.684      0.505\n",
      "Speed: 0.2ms preprocess, 15.0ms inference, 0.0ms loss, 4.1ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 1: \n",
      " defaultdict(<class 'list'>, {0: [0.008131848309780119, 0.03292688574384428, 0.0], 1: [0.0, 0.0, 0.0], 2: [0.010214312568998081, 0.0375353718071387, 0.0], 3: [0.008326599975373643, 0.03729891562962557, 0.0], 4: [0.00768356305936051, 0.0338626766185417, 0.0], 5: [0.011337375794324957, 0.0443309463808433, 0.0], 6: [0.010948416690180332, 0.04494239482200647, 0.0], 7: [0.007879666376228098, 0.032293680693462, 0.0], 8: [0.011803700674015472, 0.045695001545207115, 0.004543959775368945], 9: [0.010212325276917962, 0.03735273264506661, 0.004660230702166186], 10: [0.008999816664609448, 0.035951673255764885, 0.0], 11: [0.008304324244798619, 0.03701718839228771, 0.0], 12: [0.03273335998318437, 0.056047670523502555, 0.028858180051150893], 13: [0.0528482085001233, 0.08258160964398048, 0.04835785239373473], 14: [0.07890622832470533, 0.11221988039555694, 0.07961921850584606], 15: [0.09281934106980905, 0.11552664884341482, 0.09217240789261197], 16: [0.1415694487050729, 0.1794310416613459, 0.16113117062640048], 17: [0.211404129086277, 0.27692954094556427, 0.22845563190429657], 18: [0.2221233215354624, 0.28850138227165856, 0.2393984679919387], 19: [0.2282419878062596, 0.2922757783275347, 0.2620855468812524], 20: [0.2535293099499869, 0.32457833167629413, 0.2911839399041192], 21: [0.23268427650996615, 0.2918484380524293, 0.2627523849658205], 22: [0.26155899486247147, 0.3363794576128357, 0.2928056831884488], 23: [0.24187183709099275, 0.316535078568892, 0.27150057035440356], 24: [0.31768953054241866, 0.415387659136413, 0.3601502394156383], 25: [0.29920797281269407, 0.38470625198315656, 0.33146330288615083], 26: [0.31736262421027683, 0.40328017057916943, 0.36916949748085903], 27: [0.31081107643035927, 0.4065735373731117, 0.36106398338199885], 28: [0.36609462461682984, 0.46323000313915697, 0.4181239955607953], 29: [0.3803791538787282, 0.488721568319899, 0.43403344752822093], 30: [0.4135600001489828, 0.5374679902946647, 0.4835578423716676], 31: [0.4485441942702659, 0.5911802756282553, 0.5255049350613507], 32: [0.3597647122319919, 0.4888140034244172, 0.41688212126938895], 33: [0.5058852903413678, 0.6501893135778659, 0.5911603743682743], 34: [0.3789313021245919, 0.5087920610514247, 0.45503998168417], 35: [0.48815122347984374, 0.6490043481984935, 0.5776667931477938], 36: [0.5464709091399467, 0.7089341889024068, 0.6282781434070452], 37: [0.5048625433247822, 0.6836816528718817, 0.5951482289796615]})\n",
      "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… (train) Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ° 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 256]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+w0lEQVR4nO3dd3yT5drA8d+TpOnee0FZhZY9y1BALcODAxVFRUFcx4UeUVRcOF4FxYEDj6IgjuPeE2QqyBIQkL1pgQ5K90yb3O8fIWlDW2jpSMf19ZOPzZP7uXMlPE2u3lNTSimEEEIIIVoInbMDEEIIIYSoT5LcCCGEEKJFkeRGCCGEEC2KJDdCCCGEaFEkuRFCCCFEiyLJjRBCCCFaFEluhBBCCNGiGJwdQGOzWCwcP34cb29vNE1zdjhCCCGEqAGlFHl5eURERKDTnbltptUlN8ePHyc6OtrZYQghhBDiHCQnJxMVFXXGMq0uufH29gasb46Pj4+ToxFCCCFETeTm5hIdHW3/Hj+TVpfc2LqifHx8JLkRQgghmpmaDCmRAcVCCCGEaFEkuRFCCCFEiyLJjRBCCCFaFEluhBBCCNGiSHIjhBBCiBZFkhshhBBCtCiS3AghhBCiRZHkRgghhBAtiiQ3QgghhGhRJLkRQgghRLWUgh9/hBEjwN8fQkLg1lth+3ZnR1Y9SW6EEEIIUSWl4L774LLLYMUKyM6GEyfggw+gd2/4/ntnR1g1SW6EEEIIUaWvvoI33rD+bDaXHy8rs94fPx7S050T25lIciOEEEKIKr36Kuj15fc1gxk0C2Bt1SkthQULnBTcGbS6XcGFEEIIcXZKwYYNoPkU4NMpFfeO6bhGZlJyNIC0TwcCGhYLrF3r7Egrk+RGCCGEEHZmi+LvpCyW7EwjdHIaLoEFDo+7tcnEvWMaRfvD0DQwNMFMogmGJIQQQojGVFBSxqp9GSzdlcby3elkFpgAcAkEZdYoTg6kaF8ILoH5ePdJwu+8fRTtDwU0EhOdG3tVJLkRQgghWqG03GKW7kpj6c40/jxwElOZxf6Yj5uBC7qEEG4J5dHJwSiTCwA6NxOeXY9hDM3Fs3Mabhlh3HCDs15B9SS5EUIIIVoBpRS7UvKsCc2uNLYdzXF4PDrAnRFxYSTGh9A/JgAXvXXOkU823HOPdWBxWbGRvE0x+A4+gP95+/jm36F4e2tOeDVnJsmNEEII0UKZyixsOJTJ0l1pLNmZxrHsIvtjmga9ov1IjAtlRHwonUK80LTKicpdd8GFF8Lbb8P69WAwtidVOwJBuWR6pAFhjfiKakaSGyGEEKIFySksZeXedJbsTOP3PSfIKymzP+bmouO8jsGMiA/hgi4hhHi71ajOLl1gzhzbPSMvLY7hzRX7eW3pPkbGh1aZFDmTJDdCCCFEM5d0spAlp8bPbDicidmi7I8FebmSGBdCYlwoQzoG4W7Un6GmmrnlvHYsXHOYnSm5LN6RxuhuTav1RpIbIYQQopmxWBRbjmazdKd1/MzetHyHx2NDvUiMCyUxPpReUX7odPXbsuLvaeSmwadab5ZZW2/q+znqQpIbIYQQohkoMplZvT+DpTvTWLY7nYz8Evtjep3GgJgAEuNDSYwLoW2gZ4PHc+v51tabXSm5/LazabXeSHIjhBBCNFHpecUs35XO0l1prNqXQUmF6drergaGdQ5mRHwow2ND8PVwadTY/DyMTB4SwxvLm17rjSQ3QgghRBOhlGJfej5LTnU3bUnORpUPnyHSz50R8aEkxoUyoF0ARoNzt4i85bx2vP9n02u9cfrGmXPnziUmJgY3NzcSEhLYsGHDGctnZ2dz9913Ex4ejqurK7Gxsfzyyy+NFK0QQghRv0rNFtYcyOCZH3cybPZKRr76B7MX7+HvJGti0zPKlwdGxPLrfeez+uELeOqyrpzXKcjpiQ2Ut94AzFm6F0uFgczO5NSWm88//5ypU6fy9ttvk5CQwJw5cxg1ahR79uwhJCSkUnmTycSIESMICQnhq6++IjIykiNHjuDn59f4wQshhBDnKLe4lN/3nGDprjRW7E4nt7h8urbRoGNIh0AS40O5qEsoYb41m67tLLbWm92peXy9IZV2hnC8vKBzZ+taOs6gKaWclmYlJCTQv39/3nzzTQAsFgvR0dFMmTKFRx55pFL5t99+m9mzZ7N7925cXM6tbzE3NxdfX19ycnLw8fGpU/xCCCFETSVnFrJsVxpLd6Wz7uBJyiq0cgR4Grmwi3W69vmdgvB0bV6jRp76eg8L/9pPabo3x98/H9CIjYWnn4Zrr62f56jN97fT3j2TycSmTZuYPn26/ZhOpyMxMZG11eyf/sMPPzBo0CDuvvtuvv/+e4KDg7n++ut5+OGH0eurnrdfUlJCSUn5iPLc3Nz6fSFCCNFKlZVBTg54eYGrq7OjaXosFsX24zks2WldHXh3ap7D4x2CPUmMD2VEXCi92/ijbyKDcWsrNRXmP9QO7bLDuITk4R6bStHecPbtg+uug/R0uPfexo3JaclNRkYGZrOZ0NBQh+OhoaHs3r27ynMOHjzI8uXLmTBhAr/88gv79+/nrrvuorS0lBkzZlR5zsyZM3n66afrPX4hhGit0tLg+edh/nwoKAAXFxg3Dh5/HOLjnR2dcxWXmll74CRLdqWxbFcaabnlf1zrNOgXE8CIuFAuiguhfbCXEyOtP888AylHjHhtjMFvyH78huyjaG8YSlmTtQcftCY5wcGNF1OzaveyWCyEhIQwb9489Ho9ffv25dixY8yePbva5Gb69OlMnTrVfj83N5fo6OjGClkIIVqUo0dh4EDrX+tms/VYaSl8+SV8/z0sXw4JCc6NsbGdzC9h+W7rdO0/9mZQVGq2P+Zp1DOsczCJcaFc0DkEf0+jEyOtf8XFsHCh9VrI29gOn36HMYbk4RGbSuHecMD62Mcfw/33N15cTktugoKC0Ov1pKWlORxPS0sjLKzqqWTh4eG4uLg4dEHFxcWRmpqKyWTCaKx80bi6uuIq7aVCCFEvpkxxTGxsyspAKbj+eti3D3TOn8jTYJRSHDhRYN1de2cam5KyHKZrh/u62VcHHtg+AFdD3bc7aKrS06Ho1F6clmIjuadab3yH7KNwbxigodfDgQONG5fTkhuj0Ujfvn1ZtmwZY8eOBawtM8uWLeOee+6p8pwhQ4bwySefYLFY0J36zdm7dy/h4eFVJjZCCCHqT0oK/PADWOzryCkMAQWUZXuARYfZDAcPwsqV1l2kW5Iys4VNR7KsCc2udA5lFDg83jXCx767dtcInya3kWRD8fW1zoiyJXd5G9vh0TmVvC1tQFOgNJQCf//Gjcup3VJTp05l0qRJ9OvXjwEDBjBnzhwKCgqYPHkyABMnTiQyMpKZM2cCcOedd/Lmm29y3333MWXKFPbt28fzzz/PvY09UkkIIVqh3bsrJjbg0TmV4LGbyVnTkexVnQFri8327S0juckvKWPV3hMsOTVdO6uw1P6Yi15jUIcgRsSFcFFcKBF+7k6M1Hl8fWH0aPjtN2trnqXYSMr8oUB5cldWVn8zpmrKqcnN+PHjOXHiBE8++SSpqan06tWLRYsW2QcZJyUl2VtoAKKjo1m8eDH3338/PXr0IDIykvvuu4+HH37YWS9BCCFaDQ8Px/vu7dOt/49NtSc3Fkvlcs1JSk4RS3els3RnGmsPnMRkLs/m/DxcuLBzCInx1una3m6Nu91BUzVjBixZUrEFpzyx0eng6quha9fGjcmp69w4g6xzI4QQ56asDKKirLOlAMImrcI1zLq8RvIbiVgKXdHrISkJIiKcGGgtKKXYcTz3VHdTGtuPOS4XEhPoYd/uoG9bfwz6FjyYqA4WL4Ybb4QTJ8BgsCa5SlmPvfMOuNXDOoTNYp0bIYQQzYvBYJ3uPWUKoLNgDMq3P+YWlUnx/nBuvrnxE5v9+2HuXPj5Z+vMrfPOg3vuqX7WVkmZmXUHM1l6av+mlJxi+2OaBn3b+J/aXTuUDsGerWb8TF2MGgXHjlnHZO3aZV37aOxYiIlxTjyS3AghhKixu++2zpB54Z18NEN5l41rdCaX9g7njTcaN56ffoIrr7S2FNhmcB09ap16PHu2dY0VgKwCEyv2WKdr/77nBAWm8ule7i56zu8URGJ8KBd2CSHIS2bYngsXF7jqKmdHYSXJjRBCiBrTNOuibeGDc3hhJWhKQ2mKHomZfFZ515wGdfy4dfFA2zR0m7JT2zRNf76AjMA0DprS2Hg4k4p7OoZ4u3JRXCgj4kMY3CEIN5eWO127NZLkRgghRK2lmaxjUy7tFc4PW49zJCeXnMJSfD0ab5Dtu++elthoCteILNw7puPeMQ1jUD6f7Skv3yXM2z5+pnukL7pmut2BODtJboQQQtTazhRrcjMsNpjtx3M4eKKAvw5nkhgfepYz68/KlY6LCYaOX49b25P2+8qsUXY8kOfusk7Xjg5oxtO4RK1IciOEEKJWLBbFruPW5CY+woeEdgEcPFHAhkZObiqO8zX4FuLW9iTKAoW7IyjcF0rRwWB83F246X+NFpJoImROmxBCiFpJziokr6QMo0FHxxAvEtoFArD+4MmznFm/LrigfJsHt5gMAEqO+ZPxY28Kd0egt7i0iMUERe1JciOEEKJWdpxqtekc6o2LXseAdgEAbD+eS35JWaPFcdttYDRaW3DcYk4AUHy4fOvpsjL4z38aLRzRhEhyI4QQolZ2nkpuukZYF1KL8HMnyt8ds0Wx6UhWo8URFgbffgtGV4X7qbE2RYeDMJwacDFnDgwd2mjhiCZEkhshhBC1suN4DlCe3AD2rqkNhxq3a2r0aPju9xx07qVQaiDGx5eJE2HTJrjvvkYNRTQhktwIIYSolR0VBhPbJJzqmlp/MLPR49mfb+2SGtUrkD27dMyfD336NHoYogmR5EYIIUSNncgrIT2vBE2DLmEVkpv21uRm69FsikvN1Z3eIFbtsw4mPq9T8FlKitZCkhshhBA1ZuuSahfkiadr+WoibQI8CPVxpdSs+Dspu9HiKSgpY3OSdZzP+R2DGu15RdMmyY0QQogasy3e1zXC1+G4pmnlU8IbcdzN+kMnKTUrogPcaRsoi/QJK0luhBBC1Jh9vE24T6XHbFPCNxxqvHE39i6pjsGye7ewk+RGCCFEjZ0+Dbwi26DizUlZmMoslR5vCKtPJTfnd5IuKVFOkhshhBA1kl9SxqGMAqDq5KZjiBcBnkaKSy38cyy7weNJySliX3o+Og0Gdwhs8OcTzYckN0IIIWpk96nxNmE+bgR6uVZ6XNM0BsRYW2/WNcKUcFurTfcoP/w8jA3+fKL5kORGCCFEjVS1vs3pbFPCG2Pczer9p7qkZJaUOI0kN0IIIWqkqpWJT2cbVLzxcCZl5oYbd2OxKP7cb1vfRpIb4UiSGyGEEDWy4wyDiW26hPng42agwGS2TxtvCLtSc8nIN+Fh1NOnjX+DPY9oniS5EUIIcVamMgv70vKBymvcVKTXafSPafiuKdt4m4HtAzEa5KtMOJIrQgghxFntT8/HZLbg7WYgyt/9jGVt424aclCxbbzNeTLeRlRBkhshhBBnZRtvEx/uc9bF8gacWqn4r8OZWCyq3mMpLjWz/lSr0NBYSW5EZZLcCCGEOKvy8TbVd0nZdI3wwcOoJ6eolD1pefUey1+HMzGVWQjzcaNDsFe91y+aP0luhBBCnFX5nlLVDya2cdHr6NvWOsi3IcbdrN5XPktKtlwQVZHkRgghxBlZLIpdNVjjpiLbVgwNsYnmH7LlgjgLSW6EEEKcUXJWIXklZRgNOjqG1KwbKKG9ddzNhkOZKFV/425O5JWw61Qr0hAZTCyqIcmNEEI0A2vWwNVXg7c3uLvDBRfA999DPeYN1bKNt+kc6o2LvmZfGz2ifHE16MjIN3Hw1H5U9WHNAWurTXy4D0FVbAEhBEhyI4QQTd78+XDeefDdd5CfD8XFsGoVjB0LDz7Y8AlOTVYmPp2rQU/vNn4ArK/HKeF/7JUuKXF2ktwIIUQTtn8/3H67NYEpKys/bjZb///KK/DLLw0bw84arExcFduU8A31NO5GKcXq/ScAOL9TcL3UKVomSW6EEKIJe+cdcJgQpDejuZRnOXo9vP56w8ZQkw0zq1I+qLh+xt3sT88nLbcEV4OOfjGy5YKoniQ3QgjRhK1bV95Ko3MzETF5FZH/XoHOtRSwPrZ+fcM9/4m8EtLzStA0675RtdGnjT8GnUZKTjFHs4rqHMuqU7OkBrQLwM1FX+f6RMslyY0QQjRhLi6nftAUQZf9jUtgAXpPE+4d0iqXaQC28TbtgjzxdDXU6lx3o54eUdZF/9YdrHvX1Kp9ti4pGW8jzkySGyGEaML+9S/Q6cDv/D24t8uwH3fvZE1uDAa45JKGe/7yxfvOvjJxVSpOCa8LU5nFvuXCeR1lvI04M0luhBCiCZs8GQJ6pOA76AAAORvaAeDe7gSawYxScN99Dff89vE24bXrkrIZcGrczYbDdUtuNidlUWgyE+RlpEuYd53qEi2fJDdCCNGEZZnzCByzFYDcv9qRvSKOsjxXdK5mPGMy+eQT6NWr4Z7/XGdK2fRr649OgyMnC0nNKT7nOGxdUkM6BqHTyZYL4swkuRFCiCYqr7iU2z/aRHGZmX5tAnji0i5cfLFGYHEoALc9lcY11zTc8+eXlHHo1AJ855rceLu52Lu06rIVw2r7lgvSJSXOTpIbIYRogiwWxdQvtnLwRAHhvm68PbEP9/9Hxy+/wKvTQgBYm5RWr1sbnG73qfE2YT5uBNZhNeCKU8LPRXahiW3HrAObz5MtF0QNSHIjhBBN0Fsr97NkZxpGvY63b+jrsNXA4A5BuLvoSckpto+JaQjnur7N6ezjbs4xuflz/0mUgk4hXoT5utUpFtE6SHIjhBBNzMo96by8ZC8Az47tSs9oP4fH3Vz0DI21tmAs2Zl2+un15ly2XahK/xhrcrM/PZ+M/JJany+rEovakuRGCCGakKSThdz32RaUgusT2jC+f5sqyyXGWcfdLN3VkMlN3QYT2/h7ls9w+quWrTdKKfvifbK+jagpSW6EEKKJKDSVcftHG8kpKqV3Gz9mXBpfbdkLu4SgadYE5Hh23Vf/PZ2pzMK+tHzg3Ne4qWjAOY67OXKykKNZRbjoNRLaB9Q5DtE6NInkZu7cucTExODm5kZCQgIbNmyotuzChQvRNM3h5uYmfbBCiOZNKcX0b/5hd2oeQV5G/juhL66G6rcYCPRypW8b6/5KDdF6sz89H5PZgrebgSh/9zrXl3BqE83aJje2KeB92/rjYazdCsmi9XJ6cvP5558zdepUZsyYwebNm+nZsyejRo0iPT292nN8fHxISUmx344cOdKIEQshRP1b8Odhvt9yHINOY+71fWo0cHZEvLVrqiHG3djG28SH+6BpdV9Xpn87ayK2OzWXnMLSGp+3SqaAi3Pg9OTmlVde4bbbbmPy5MnEx8fz9ttv4+HhwYIFC6o9R9M0wsLC7LfQ0NBGjFgIIerXuoMnef6XXQA8NibOvmXB2SSeSm7WHTxJXnHNE4aaKB9vU/cuKYAQbzfaB3uiFPxVw9WKy8wW1h6wro0jU8BFbTg1uTGZTGzatInExET7MZ1OR2JiImvXrq32vPz8fNq2bUt0dDSXX345O3bsqLZsSUkJubm5DjchhGgqUnKKuOeTzZgtirG9IrhpcEyNz+0Q7EX7IE9KzYo/9mac/YRaKN9Tqm6DiStKqOVWDFuPZpNXUoavuwvdIusnyRKtg1OTm4yMDMxmc6WWl9DQUFJTU6s8p3PnzixYsIDvv/+ejz/+GIvFwuDBgzl69GiV5WfOnImvr6/9Fh0dXe+vQwghzkVJmZk7Pt5MRr6J+HAfZl7Zo9ZdQIn2rqmqPzPPhcWi2GVruYmsv+TGPqi4hjuE27qkzusYhF62XBC14PRuqdoaNGgQEydOpFevXgwbNoxvvvmG4OBg3nnnnSrLT58+nZycHPstOTm5kSMWQoiqPfXDDrYmZ+Pr7sI7N/bF3Vj9AOLq2KaEL9+dTqnZUi9xJWcVkldShtGgo0OwV73UCeWDircfzyW/pOys5W1bLpwnU8BFLTk1uQkKCkKv15OW5jgYLi0tjbCwsBrV4eLiQu/evdm/f3+Vj7u6uuLj4+NwE0IIZ/t0QxKfbkhG0+D163oTHeBxTvX0beuPv4cLucVlbDycVS+x2cbbdA71xkVff18TEX7uRPm7Y7YoNh85c6y5xaX8nZwNyHgbUXtOTW6MRiN9+/Zl2bJl9mMWi4Vly5YxaNCgGtVhNpv5559/CA8Pb6gwhRCiTg4cgFmz4JFHYP58WLMnixnfW8cKPjiyM8Niz30mkF6ncWGX+l3Qr75WJq5K+ZTwM3dNrTtwErNF0S7I85wTP9F6OX3RgKlTpzJp0iT69evHgAEDmDNnDgUFBUyePBmAiRMnEhkZycyZMwF45plnGDhwIB07diQ7O5vZs2dz5MgRbr31Vme+DCGEqKSkBG6/HT78EPR60OnAYiwh/KbN6L0sjOoayl3DO9T5eUbEh/D15qMs2ZnG42Pi6jx1e2c9rUxclYR2AXy9+ehZ95lavb98vI0QteX05Gb8+PGcOHGCJ598ktTUVHr16sWiRYvsg4yTkpLQ6cobmLKysrjttttITU3F39+fvn37smbNGuLjq1/JUwghnOGOO+Djj60/m81gVhZCL9uM3quY0pOejPTtWS9ryJzfKRijQUdSZiH70vOJDfWuU331tWFmVWyrDG9NzqG41IybS9XjjGS8jagLpyc3APfccw/33HNPlY+tXLnS4f6rr77Kq6++2ghRCSHEuTt4ED74AJQqP+Y/fDdubTKxlBjI+K4fM/924arL6v5cnq4GhnQIZMWeEyzZmVan5OZEXgnpeSVoGnQJq//kpk2AB6E+rqTllvB3UjaDOlRe0+doViEHMwrQ67QqHxfibJrdbCkhhGgOvv7a2g1l4xF3DJ/+hwDI+LknpgwvNm2C+lpg3TYlvK7jbmzjbdoFeeLpWv9//2qadtZxN7ZWm17Rfvi4udR7DKLlk+RGCCEaQE5OeXKj9y4icOR26/E1HSjaVz4btL7WFb3o1KDiLcnZpOcVn3M95Yv3Ndyiebb1bqobd7NKxtuIOpLkRgghGkBsLJSWAigCR/+Dzq2MkuN+ZK+OtZcxGKC+1hUN83WjR5QvSsHyXdXvzXc29vE24Q23bIZtpeLNSVmYyhzX5jFbFH/ut+0nJcmNODeS3AghRAMYNw68vcGrRzLu7U+gynRk/NwTlPVj12CA8ePBz6/+nnNEXN27phpyppRNxxAvAjyNFJda+OdYtsNjO47nkF1YirergZ7Rfg0Wg2jZJLkRQogG4OEBs98qwv9C64aY2atiKcu0rvZrMEBwMLzwQv0+p23czap9GRSZzLU+P7+kjEMZBUDDJjeapjEg5tRWDKd1Tdm2XBjYIbBeFxAUrYtcOUII0QCUUqwu2YbOtQyXHD9y/2oPgNEIEybAX39BZGT9PmeXMG8i/dwpKbPY14mpjd2nxtuE+bgR6OVav8GdxjYlfP3B05ObE4B0SYm6keRGCCEawGd/JbNqXwauBh2LnunJsaMaO3fCiROwcGH9JzZgbREZUYeNNBtyfZvT2QYVbzqSRdmpPbEKTWVsOrUtw/mdzn3VZiEkuRFCiHp2NKuQ//tpJwDTRnWmQ7AXEREQFwcNvb2dLblZtisds0WdpbSjhtx24XRdwnzwcTOQX1Jmn6G1/lAmpWZFpJ87MYGy5YI4d5LcCCFEPVJK8fDX2ygwmenX1p/JQ9o16vMPaBeAt5uBkwUmtpzaeLKmdjTCYGIbvU6jf4zjlHDb+jbndwqql5WbReslyY0QQtSj/61P4s/9J3Fz0TH76p7odY37Je2i1zG8cwhQu1lTpjIL+9LygYZd46YiW9eUbVBx+Xgb6ZISdSPJjRBC1JPkzEKe/8U6O+qhUV1oF+TplDgS46zJzZKdNU9u9qfnYzJb8HYzEOXv3lChOUhob12p+K/DmaTmFLM3LR9Ng8Gy5YKoI0luhBCiHlgsioe+2kahycyAmABuGhzjtFiGdw7BoNPYn55vn9p9NrbxNvHhPo3WJdQ1wgcPo57swlKe+Ni6NUX3SF/8PY2N8vyi5ZLkRggh6sHH64+w9uBJ3F30zL66B7pG7o6qyNfdxT7VelkNu6bKx9s0TpcUwGef6Cg44g/A4oOHATi8Lojt2xstBNFCSXIjhBB1lHSykJm/7AbgkYu70DbQOd1RFSXG2aaE1yy5aYyViSt66y2YOBGy91mTMJ2LdTr4gT+DGTQIdu5slDBECyXJjRBC1IHFonjwq60UlZoZ2D6AGwe2dXZIQHlys/FIFlkFpjOWtVhU+YaZkQ2f3OTkwIMPWn8uSSofX2Mx6SlM9qOoCB55pMHDEC2YJDdCCFEHH6w9zIZDmXgY9cwe19Op3VEVRQd40CXMG7NFsWLPmTfSTM4qJL+kDKNBR4dgrwaP7csvofjUxuUlqb5YSq1fRSXJAWDWYzbDTz9B+rnv/ylaOUluhBDiHB3OKOCFRdbuqOn/iiM6oGktPGdb0O9sU8Jt4206h3o3yn5OycnW/bUAMOspOWYdd1N0qHwKuFJw7FiDhyJaKEluhBDiHFgsimlfbaW41MKQjoFMGNDG2SFVYuua+n3PCUrKqt9IszFXJgbrpqHmCuFkLe1K9h+x5G1pU6mcEOdCkhshhDgH7685zF+Hs/A06nnhKufOjqpO90hfQrxdKTCZWXfaBpUVNfZg4quvBl2Fb5/Sk97krO0EZj1gfWzoUIiKapRwRAskyY0QQtTSwRP5vHiqO+qxMfFE+Tet7igbnU7jorizb6TZmBtmAoSGwrRpVT+madbk5rnnGiUU0UJJciOEELVgtiimfbWNkjIL53cK4roB0c4O6YxG2sbd7ExHqcobaZ7IKyE9rwRNs25m2Vj+7/9gxgxwc7Pet60bGBkJP/8M553XaKGIFshw9iJCCCFsFqw+xKYjWXi5Gph1VY8mv8HjoA6BuLvoSc0tZsfxXLpFOi7SZxtv0y7IE0/XxvtK0Ongqafg/vutyUx2NnToAImJoNc3WhiihZLkRgghzkApKCwEd3c4mJHP7N/2APDEJXFE+jXOHkx14eaiZ2hsEIt3pLFkZ1ql5Ma+vk0jrkxcka8vXH+9U55atGDSLSWEEFU4ccI6LiQgALy8wNNLceULWzGVWRgWG8w1/Zp2d1RFZ1qt2D7eJrzxuqSEaGjSciOEEKc5fhwGDbKus2KbsmzsfpBcl2wsJQZu6Ny9yXdHVXRhlxB0mrWV5lh2kUOLU2PPlBKiMUjLjRBCnGbKFMfExiUwD7/z9wKQvTyee291p4qxuU1WoJcrfdtaF8qruJFmfkmZfddwSW5ESyLJjRBCVJCSAt99V2GROc1C4L+2ohksFO4PIW9bFLt3w+rVzoyy9qrqmtp9arxNmI8bgV6uTolLiIYgyY0QQlSwcydYLIBmwTP+GOGTV+EakYO52EDm4u6AhqbB1q3OjrR2Ek9NCV938CR5xaVA469vI0RjkTE3QghRgcFoxqvnMXwSDuDiXwiApcTAyZ97Ys63LsqilHX2VHPSIdiL9kGeHMwo4Pe9J7ikR0Sjb7sgRGORlhshhAAKTWW8t+og0/5YQeDof3DxL8RcaCTr984cfetCivaH2cvq9XDxxU4M9hzZN9I81TW1QwYTixZKWm6EEK1aTlEpH645zII/D5FVaO2u8dS5kfxbe/K3tkGVOa4op9PBpEkQEeGMaOsmMT6Ud/44yPLd6RSZzOxLywect8aNEA1FkhshRItjMsG338KWLeDqCpdcAv36OZbJyC9hwepDfLT2CHklZQC0CfDgzuEduKJ3JI+V6HllExgM1m4oTYOyMrj0Upg7t/FfU33o08Yffw8XsgpL+XRDEiazBW83A1H+zayPTYiz0FRVm420YLm5ufj6+pKTk4OPjzTFCtHSrFxp3XU6IwNcXKyJSVkZDB8OX30FJfoi5v1xkM/+SqK41AJAbKgXd1/QkTHdwzHoy3vr9+yB99+HI0cgOBhuuAH69y/fB6k5mvD6Vv48fhRV6IrmUUKwCuDLOwcRE+PsyIQ4s9p8f0tyI4RoMbZvtyYfJtOpGU8VGAMLaPevA5ijj1Jqtn7s9Yzy5e4LOpIYF4pO14wzlhpQCh55BN74NpWQKzfZj+dtbEfRmnh++gkuvNCJAQpxFrX5/pZuKSFEi/Hii9ZWmoqJjUtQLr6DDuDR5TjFOsAMA9sHcM8FnRjSMbBZrTRcF998Y31/NJcgVJkOzWB9k0pSfSgpgcsvh+Rk8PNzbpxC1AdJboQQLYJS8MUX1uQGAL2ZoDFb8YxLsZcpPhjMEL+OfDYrwDlBOtErr1gHQ1tKDRQdCcSjwwkATGk+WCxQUAAffgj33uvkQIWoBzIVXAjRIpSVQUlJ+X3fhIN4xqWgFBTsDuf4++eR/tUAtMzWl9hYLLBuXXmLVtE+65RwVaajNNMLsI4jWrXKWREKUb+k5UYI0SK4uEBUFBw9CnrvInwG7gcg48deFO6KBKzr08TGOjPKpqFwTzjefY9QkuwPlvK/cVtJD51oBaTlRgjRYtx1l7XrxX/4bnQuFoqTAyjcVb4gjcUCt9zixACdRKeD88+3JncAlmIjKQuGkrmku72MUnDBBU4KUIh6JsmNEKLFuPde6HZhJp7xx1EKMpfGY9sLCuD//g86dHBqiE7z4IMVNgM9jU4Hvr7Wqe5CtASS3AghWgw3d0X4v3YAULKzDaXp1pV3O3eGjz+GRx91ZnTOdckl8Oyz1p8NFQYk6HTg6Qm//ALe3s6JTYj6JmNuhBAtxud/JbM7LRdvNwNrFsaSlwFubtCmjYwnAXj8cRg1Ct56C9avt743Y8fC7bdDWNhZTxei2WgSLTdz584lJiYGNzc3EhIS2LBhQ43O++yzz9A0jbFjxzZsgEKIJi+nsJSXftsDwP2JsUQEutK5M7RtK4lNRf37W1dd3rkTNm+GJ5+UxEa0PE5Pbj7//HOmTp3KjBkz2Lx5Mz179mTUqFGkp6ef8bzDhw/z4IMPcv755zdSpEKIpmzOsr1kFpjoFOLFjYPaOjscIYQTOT25eeWVV7jtttuYPHky8fHxvP3223h4eLBgwYJqzzGbzUyYMIGnn36a9u3bN2K0QoimaF9aHh+uPQLAk5fG46J3+kebEMKJnPoJYDKZ2LRpE4mJifZjOp2OxMRE1q5dW+15zzzzDCEhIdxSgzmdJSUl5ObmOtyEEC2HUopnftqJ2aIYER/K+Z2CnR2SEMLJnJrcZGRkYDabCQ0NdTgeGhpKampqleesXr2a+fPn8+6779boOWbOnImvr6/9Fh0dXee4hRBNx5Kdaazal4FRr+PxMXHODkcI0QQ0q7bbvLw8brzxRt59912CgoJqdM706dPJycmx35KTkxs4SiFEYykpM/N/P+8C4Nbz29E20NPJEQkhmgKnTgUPCgpCr9eTlpbmcDwtLY2wKobvHzhwgMOHD3PppZfaj1lObZZiMBjYs2cPHU5bocvV1RVXV9cGiF4I4WzzVx8iKbOQUB9X7r6go7PDEUI0EU5tuTEajfTt25dly5bZj1ksFpYtW8agQYMqle/SpQv//PMPW7Zssd8uu+wyLrjgArZs2SJdTkK0Imm5xby53Lp/1CMXd8HTVZbtEkJYOf3TYOrUqUyaNIl+/foxYMAA5syZQ0FBAZMnTwZg4sSJREZGMnPmTNzc3OjWrZvD+X5+fgCVjgshWrYXft1NoclMnzZ+jO0V6exwhBBNiNOTm/Hjx3PixAmefPJJUlNT6dWrF4sWLbIPMk5KSkKna1ZDg4QQDWxzUhbf/H0MgBmXdkWTVfqEEBVoSinl7CAaU25uLr6+vuTk5ODj4+PscIQQtWSxKK5460+2Hs3h6r5RzL66p7NDEkI0gtp8f0uTiBCiWflq81G2Hs3By9XAtNGdnR2OEKIJkuRGCNFs5BWX8uIi6/5R917UkRBvNydHJIRoiiS5EUI0G28s309Gfgntgzy5aXA7Z4cjhGiiJLkRQjQLB0/k8/6fhwB44pJ4jAb5+BJCVM3ps6WEEC1DUREsWwY5OdCpE/TvD/U5ienZn3ZSalZc0DmYC7qE1F/FQogWR5IbIUSdKAUvvwzPPgsV96Xt2hXmz4eEhLo/x4rd6azYcwIXvcYTl8TXvUIhRIsm7bpCiDp59lmYNs0xsQHYtQsuuAC2bKlb/aYyC8/+tBOAyUPa0T7Yq24VCiFaPEluhBDnLD3dmtxUxWIBkwkefbRuz7FwzSEOZhQQ5OXKlAtl/yghxNlJciOEOGeffWZNYmxcgnLxHbwP9w5paK6lmM2waJE1CaoNiwXMZkjPK+b1Zdb9ox4a3RlvN5d6jF4I0VLJmBshWrACUwFf7PiCvSf34u3qzbj4ccQGxtZb/ampoNdbkxFDQD6h169D714KWMfimNJ8KDkawHcbAxg3LJAAT+MZ61u0CGbPhpUrrXV2umEPpsgyekT6Mq5PVL3FLYRo2SS5EaKF+nz759z6463km/Jx0blgURYeW/4Y13W7jgWXL8DNUPcF8MLDrS0sOo8SQq7egN69lNJMTwBcAgpwDcvFNSyX5/84zPN/QKcQLxLaBzCgXSAD2wUQ4lMewyuvwAMPlCdLxrBsTJFHAXDfLftHCSFqTvaWEqIFWnJgCaM+HgWAwvFXXKfpuCb+Gj4d92mdn+fECYhsU0bgNetwDc+hNMuD1I8GYylyRe9ZjHvbTDoNziQo/iR70/IrnR8T6EFCu0AijQFMvTEAc67HqUcUYTeswTUym/ztkZz8uRfffgtjx9Y5ZCFEM1Wb729JboRogQbPH8z6Y+uxKEu1ZXbdvYsuQV3q9DxlZgsXPLmJZHM65kIjqR8Npizb2nKj14PRCOvWQY8ekFlgYsOhTDYcymT9oZPsTMnl9E+fshx3ipMDsBS74NPvMBaTnuPvDociN4YPh6VL6xSuEKIZq833t3RLCdHCpOSlsPboWvt9TbnhX3obhfpVFOu3AKDX9Hy18yseH/r4OT+PUoonf9hBsjkdAzryF/ezJzYA3brBe+9ZExuAAE8jo7uFMbpbGAA5RaVsOpLJ+oOZLPgpE5NXDgbfIrx8j9nryFnbEXO+tetq8+ZzDlUI0cpIciNEC5Nb4rjgjKd5GN7mUXiYh3Dc7XYsWi46TVepXG29tfIAn6xPQtNg7g29Gf60PytWWNe76dQJevc+8/m+7i5c2CWUC7uEsvhF+GNNGa6RWbhFZ+IanYml0IXcv8r3j3J1rVO4QohWRJIbIVqYSJ9IXPWulJhLADBa2gOgxwu/0uvJNL5NmaWMTgGdzvk5vv37KLMXW3fnfvqyrozqam2NGT363OobOxb++MNA8eFgig8HV3rcYIArrjjXaIUQrY2scyNEC+Nl9GJCjwnoNT0ALqp9+WPmi3GxtMXdxZ1ru117TvX/uT+Dh77aBsC/h7Zn4qCYOsd8000QEGAdp3M6TQOdDu69t85PI4RoJSS5EaIFeu7C54jwjsCAEaMlBoASbR8aegJKb+edMfPwdvWudb27U3O546NNlJoVl/aM4OHRdRuQbOPnZx0sHBhova/XWxMaTQN3d/juO+hSP08lhGgFpFtKiBYozCuMDbdt4P6fZ7L2b3csFJNhnEWk6W3cLD0J0vetdZ0pOUXctOAv8krKSGgXwEtX90Cnq7+1Z3r1gsOHraseL1kCZWUwaJC1Vcffv96eRgjRCtRpKvjx48d555132L9/P+Hh4dx66610aeJ/XslUcNGa/LTtOPd88jedw1xZcHMcn6/L5/Xl+4kOcGfJ/cNwc6miH6gKucWlXPP2Wnan5tEpxIuv7hiMr4dshSCEaDy1+f6uVbeUh4cHJ06cAGDnzp3Ex8fzySefUFpays8//0zfvn3Ztm3buUcuhKhXO49bZ0T1aRNKpE8kdwzvQJiPG8mZRcxffahGdZjKLNz58SZ2p+YR4u3K+5P7S2IjhGjSapXcFBcXY2voefTRRxk6dCi7du3iiy++YMeOHVx22WU89thjDRKoEKL2dqZYk5v4COtfOR5GA9P/ZW1dnbtiP6k5xWc8XynFw19v48/9J/E06nl/cn+i/D3OeI4QQjjbOQ8o3rx5M9OmTcNgsA7b0el0PPTQQ2zatKneghNC1I2t5SY+vLwJ97KeEfRt60+hycyLi3af8fyXftvDt38fQ6/TeOuGvnSN8G3QeIUQoj7UKrnRNM2+eZ1Op8PX1/GDzs/Pj6ysrPqLTghxzk7klZCeV4KmQZew8plRmqYx49J4AL75+xibk6r+nf1kfRJzVxwAYOaV3RkWW3n9GSGEaIpqldwopYiNjSUgIIDjx49XGl+zf/9+wsLC6jVAIcS52XWqS6pdoCeero4TI3tE+XF13ygAnv5xJympir//huRk6+PLdqXx+Hf/APCfxE5c0y+68QIXQog6qtVU8Pfff9/hfseOHR3ur1u3jitkGVEhmgTbeJu4iKpnFUwb3ZmftqawNTmb2BHHyN9uTXb6j84mu8/fWBRc0y+K+y4695WMhRDCGWqV3EyaNOmMjz/xxBN1CkYIUX+qGm9TUdphNzL+6ITn4N34Dt1Nwd4w9O4mUjr+hd5spmtAMM9d0d3eFS2EEM2FrFAsRAt1+kyp091zD2Stj6E0ywODdwn+w3cRcvUG9J4mTGk+bH2rDzr5iBBCNEO1+uTy9vbmlltuYc2aNQ0VjxCiHhSZzBw8kQ9A1ypabvbvhz/+ALNJT9Zy6+Bi795JuAQWUJbjTvqX/Tl2xMDSpY0athBC1ItaJTcFBQWsX7+e8847j7i4OF5++WX7on5CiKZjT1oeFgVBXkaCvV0rPX7gQPnPRftDKDoUBIC52EDal/0xF7ihaY7lhBCiuah1m/Py5cv5+++/SUxM5PnnnycqKoqrrrqKX3/9lTrs5CCEqEe28TZx4T5Vjpnx86t4T+Pkou7k/xNF+hcJlJ20ThtX6vRyQgjRPJxTh3rPnj154403OH78OAsXLiQnJ4dLLrmENm3a8OSTT9Z3jEKIWtqZkgNUP96mf3+IrjC725zrwclfemJK8bMfc3ODMWMaMkohhGgYtV7EryJXV1euu+46li5dyoEDB7jppptYuHBhfcYnhDgHu1LygOpnSul08NxzZ67j4YfBVxYkFkI0Q7VexK86MTExPPvssxw5cqTOQQkhzp3FouwL+FWX3ADceCO89Ra4u4OmgYuLNekxGGD6dJBGWCFEc1WrdW5mzJiBl5fXGcvImhhCONeRzEIKTWZcDTraBXmeseydd8KECfDll5CUBMHBcPXVEBraSMEKIUQDqHVyI4Ro2myDibuEeWPQn71x1scHbrmloaMSQojGU6tuKYvFwgsvvMCQIUPo378/jzzyCEVFRQ0VmxDiHJxtMLEQQrR0tUpunnvuOR599FG8vLyIjIzktdde4+67726o2IQQ5+Bs2y4IIURLV6vk5sMPP+Stt95i8eLFfPfdd/z444/873//w2KxNFR8QohaOtu2C0II0dLVKrlJSkriX//6l/1+YmIimqZx/Pjxeg9MCFF7GfklpOWWoGnQOUySGyFE61Sr5KasrAw3NzeHYy4uLpSWltZrUEKIc2ObAh4T6ImXa63mCwghRItRq08/pRQ33XQTrq7le9UUFxdzxx134OlZPuX0m2++qb8IhRA1JuNthBCilsnNpEmTKh274YYb6i0YIUTdyHgbIYSoZXLz/vvvN0gQc+fOZfbs2aSmptr3rRowYECVZb/55huef/559u/fT2lpKZ06deKBBx7gxhtvbJDYhGhOpOVGCCHOcePMqiil+PXXXxk3blytzvv888+ZOnUqM2bMYPPmzfTs2ZNRo0aRnp5eZfmAgAAee+wx1q5dy7Zt25g8eTKTJ09m8eLF9fEyhGi2ikvNHDiRD0jLjRCiddPUmTaMqoFDhw6xYMECFi5cyIkTJ0hMTOSnn36q8fkJCQn079+fN998E7AuFBgdHc2UKVN45JFHalRHnz59GDNmDM8++2ylx0pKSigpKbHfz83NJTo6mpycHHx85AtANE0WZWHJgSWsSV6DXqfnonYXMTh68Bm3N9manM3lc/8k0NPIxscTZSsUIUSLkpubi6+vb42+v89pOkVJSQlfffUV8+fPZ/Xq1ZjNZl566SVuueWWWiUMJpOJTZs2MX36dPsxnU5HYmIia9euPev5SimWL1/Onj17eOGFF6osM3PmTJ5++ukaxyREXZSVwc8/w48/QnEx9OwJN91k3bOppnak7+Dyzy7nQNYBDDrrr+iMlTPoE96H78Z/R7RvdJXn2cbbxIX7SGIjhGjVatUttWnTJu666y7CwsKYM2cOY8eOJTk5GZ1Ox6hRo2rdEpKRkYHZbCb0tF36QkNDSU1Nrfa8nJwcvLy8MBqNjBkzhjfeeIMRI0ZUWXb69Onk5OTYb8nJybWKUYiaSk6G7t1h7Fj44AP47DN45BGIioJPPqlZHan5qQxbOIzD2YcBKLOUUWYpA2Bb2jYu+OACCksLqzzXPt5GuqSEEK1crVpuEhISmDJlCuvWraNz584NFdNZeXt7s2XLFvLz81m2bBlTp06lffv2DB8+vFJZV1dXh6nrQjSEsjIYORL27y+/b2MywQ03QJs2cN55Z67nrb/eIrs4G7MyV34OSxkHsg7w6T+fckufyjtd2mdKyWBiIUQrV6uWm4suuoj58+fzzDPPsGjRIuo4XIegoCD0ej1paWkOx9PS0ggLC6v2PJ1OR8eOHenVqxcPPPAA48aNY+bMmXWKRYi6+Okn2L3bMampSKeDanpOHXy87ePyxEaBb+kEfEqvgFO/ahoan27/tNJ5FouyL+AnLTdCiNauVsnN4sWL2bFjB507d+bOO+8kPDyc++67D+Cc+viNRiN9+/Zl2bJl9mMWi4Vly5YxaNCgGtdjsVgcBg0L0dh++AEMFdpBfQYcIPiqv9C5WlfvNpvhl1+qT35sckpy7D97mIfiV3Yd/mW34GUeBYBCkVmUWem8pMxCCk1mjAYd7YM8Kz0uhBCtSa2ngkdHR/Pkk09y6NAhPvroI06cOIHBYODyyy/n0UcfZdOmTbWqb+rUqbz77rt88MEH7Nq1izvvvJOCggImT54MwMSJEx0GHM+cOZMlS5Zw8OBBdu3axcsvv8xHH30kiwkKpyoqAtv+scbQHPyG78ajYzq+5++xl7FYzp7cdA7sjE7TgTLgXzbRfjyg9A6Mlk4YdAa6BHWpdJ6tS6pLmDcGfb2t8CCEEM1SnTafGTFiBCNGjCArK4v//e9/zJ8/nxdeeAGzufJ4geqMHz+eEydO8OSTT5KamkqvXr1YtGiRfZBxUlISOl35h3VBQQF33XUXR48exd3dnS5duvDxxx8zfvz4urwUIeqkZ0/44gsAhf+FO7E1ZHr3TiJ/S1vKTnoTEwOnbc1WyR397mDt0bV4l12OQYVRxklMugN4WAYQbJpOivYfbu97e6XzZPE+IYQod87r3BQXF7Nt2zbS09Ox2P5kBQ4cOMD9999fbwHWt9rMkxeiptLSIDoaXNqlEHzFZiylOkzH/XFre5Kiw4Gc+CKBV17R+M9/zlxPmaWM0R9eyd7dE9DhRYbLaxTq1xBe8iouKoIAvzQ2TLupUuvMzQv/YvnudJ65vCsTB8U02OsUQghnafB1bhYtWsTEiRPJyMio9JimaU06uRGiIYSGwtvvmnly7S4Acjd0oOCfKCJu/R33mJMMHJfK3XeHn7Ueg87A+YHPsZ8kzPokCvTLQLOA/7sYcp4gMzuU15ftY+pIx9mK0nIjhBDlzqlzfsqUKVx99dWkpKRgsVgcbrXpkhKiJSlpexiDXxGGUlfyNrSnLMcDbU97ALQ+uzBz9t+NpJOFfLzOuhbT+zdczo67/2HX3btIenAts8f1BuD15ftZtqt8huHJ/BJSc4sB6CLJjRBCnFtyk5aWxtSpUystvidEa5WeV8zcFdZFbl6c0IXifAMFBbDjqw6E+7pxLLuId34/eNZ6Xly8m1Kz4vxOQSTGRRAfHE+XoC7odXqu6B3FxEFtAbj/8y0cOVlAaSn8sS0PgJhAD7xc6zSMTgghWoRzSm7GjRvHypUr6zkUIZqvV37bS35JGT2jfBnbKxIXF/DwAE9XA4/+Kw6A//6+n2PZRdXW8XdSFj9tS0HTsJ9zusfHxNO7jR+5xWWMnb2ZsEgzN91vnT5+fKcP335b/69NCCGam3P6M+/NN9/k6quvZtWqVXTv3h0XFxeHx++99956CU6I5mDH8Rw+32jtSnry0nh0Osc1ny7pEc5H646w4VAmz/+yi7nX96lUh1KK53+xjte5qk8UcdV0LxkNOl65qg8XvbCaLGMuWv/tGHXWAf3pe3248kp49VXOOnBZCCFasnNKbj799FN+++033NzcWLlypcMCfpqmSXIjWg2lFM/8uBOl4NKeEfRtG1CpjKZpzLg0nkvfWM3P21K4ceBJBrYPdCjz2840/jqchZuLjgdGxp7xOb9Y6E7qt70Jvno9Xt2PosqsDbCmVGtC9MADcOWV1u0ehBCiNTqnbqnHHnuMp59+mpycHA4fPsyhQ4fst4MHzz6uQIiWYvGONNYfysTVoOPh0dXvt9Y1wpfrBlizjad+2EGZuXz5hFKzhVm/7gbg1vPaE+7rfsbnnDsXig4Hkf27dTE/zWCty5Tua72vwfz55/6ahBCiuTunlhuTycT48eMdFtcTorUoLC0k35SPp4ufvSvp9qHtifL3OON5D4zszE/bUtidmserPyTjfqwtZjPkhiZxKKOAIC8jdwzvcMY6TCbr7uMAuRva4xqRhUfnNMyFLpjzrRvEKgW7dtX9dQohRHN1TtnJpEmT+Pzzz+s7FiGatPVH13PJJ5fgPdOb0JdCaf/8ZJIyCwnycuGOYWdOSgACPI3cPsja5fT6yj385yETDzxSyrw1+wCY0Cv2rLOdDAYoH+KmkfFLT/K3RZG1Ih6wdg/rdODlda6vUgghmr9zarkxm828+OKLLF68mB49elQaUPzKK6/US3BCNBU/7f2JKz6/AqUUFmVBp/xwLR4LQI7Lh5RY+uFJ5fE2FZlMMO/hNpT2ScIlOA+fIXtRJgN6DxOlJz156Y5obtwCQUHV16HTWcfTfP21dZ8qZXLh5K89HcqUlcG4cXV8wUII0YydU3Lzzz//0Lu3dUGx7du3Ozx2LruDC9GUFZUWceO3N2K2mFFYdyvxK52ADg9KtH0cLf6cJ1f48ea/3jxjPV99Bdu26HDNjCfsuvV49z4CFmvjadbKOEpSdLzzDjz22Jnjefhh+OYb69ia0zdPMRige3cYPfqcX64QQjR755TcrFixor7jEKLJ+nrX12QXZ9vvu1ja4WUeCUCWy7uYKeP9Le/z4ogX8XCpftzNRx9ZW15KkoIo2B2GZ5dU0FkoTgqgaH8IAAsXnj256d0bvv8err0WcnOt3VRKWVts+veH776zPo8QQrRWspypEGexPX07LjoXSi2loPQEmu5GQ0+B/g9K9DsB6yDjpJwkugR1qbaeEyfAtsds1oo43DukoxksZK2IwzZe5uTJmsV08cWQkmLdifzvv627jV92GQweDNJ4KoRo7SS5EeIsPF08sShrVuJXNgFX1QUL+WQZ3q9U7kzat4etW60tLOZcD9L+NxjNWIYp1Q+wJiUxMTWPy8MDbrrJehNCCFFOGq+FOIsr4q7ArMy4mXviU2YdqXvS+AZm3QkAdJqOnqE9ifaNPmM9t95qTWxsTGm+lCQ7LuZ3++31G7sQQrRGktwIcRbdQroxut04gkwPoKEjT7+IQv2f9sctysKMYTPOWs+IEXDVVVV3G+n1MGCAtMIIIUR9kORGiLOwWBQBpvvRE4BJO0Ke6wJcdC7oNB0uOhfm/msuV8RdcdZ6NA0+/dQ6YNinwtZRbm7WFpulS60/CyGEqBtNqdMnk7Zsubm5+Pr6kpOTg49P1ZsTClHRu38c5LlfduFq0PHcNb6sTfma3JJcYgNjmdRrEiGeIbWus6jIOhDYbIYePcDXtwECF0KIFqQ2398yoFiIM9ianM2Li637Pj1xSTzjerRlXI/Bda7X3d06s0kIIUT9k24pIaqRV1zKlE//ptSsuLhbGBMSZJttIYRoDqTlRgggvSCdN9a/wcItC8koyiDCK5L2uqdJyvQj0s+dWVf2kNW3hRCimZDkRrR6B7MOct6C80gvSMeszACkZcRgLvUDzDx7RXt8PVzOWIcQQoimQ7qlRKs34esJnCg8YU9sDJYoAkrvBCDH5RPmbz/LfghCCCGaFEluRKv2d8rfrDu2jjLLqdX1lAvBpofQ4UaRbivZ+i/5YucXpBekOzdQIYQQNSbJjWjV/jr+l/1ngyWUUNNTGFV7zORw0vgyaBbKLGVsSd3ivCCFEELUioy5Ea1GcTFkZlrXlPE8tQ2UQWcApeFtHoNf6SR0uGOhmAzjS5i1TPu5LjoZcyOEEM2FtNyIFi8pybqvk58fREZak5trroEdO6Cz3/mEmmYSUHoHOtwp1v1DiusUivV/28/3MnoxIHKA816AEEKIWpGWG9GiHTgAAwdCVpZ1NWCw/v+bbxXLjx0iYPh+3CzdsFBElstC8vW/gFa+aLeGxpQBU/A0nnnHbyGEEE2HJDeiRbvrLsfEBsAQmEfQxdtwjczGZIaB7f1I4r8kp/yMXtNjVmYMOgNlljKu6XoNz1zwjPNegBBCiFqT5Ea0WIcPw2+/VTyi8Ek4iN95e9EMFiwlBrJWxHHna9Gcd/73LNq/iI+2fURKfgoxfjHc0vsWzm9zvizeJ4QQzYwkN6LF2r3b8b5Xz2T8h1sPFh0M5uSi7pjz3Nm1C4YN0zMmdgxjYsc4IVIhhBD1SZIb0WJ5njZMxr1jGgA5G9qRvSIO0KosJ4QQonmT2VKixRo4EIKCTt3RFG5R1qndhbsisCU2RiP861/OiU8IIUTDkORGtFguLvDEE9afjSG56NzKsJQYMKX5AKBpcPfdEBjoxCCFEELUO+mWEi3alCmQkQGvLToJgOm4Pwa9jrIyuPlmePFFJwcohBCi3klyI1o0TYNnnoGDkZmsPgQ9wgIZOB0mTIDOnZ0dnRBCiIYgyY1o8SwWxfY063ibWQ8E0KeNkwMSQgjRoGTMjWjx9qTlkV1YiodRT/dIX2eHI4QQooFJciNavPUHreNt+rb1x0Uvl7wQQrR08kkvWrz1h6xdUgPby7QoIYRoDSS5ES2aUsqe3CS0C3ByNEIIIRqDJDeiRduXnk9mgQk3Fx09ovycHY4QQohG0CSSm7lz5xITE4ObmxsJCQls2LCh2rLvvvsu559/Pv7+/vj7+5OYmHjG8qJ1s4236dPGH6OhSVzuQgghGpjTP+0///xzpk6dyowZM9i8eTM9e/Zk1KhRpKenV1l+5cqVXHfddaxYsYK1a9cSHR3NyJEjOXbsWCNHLpqDdfYuKRlvI4QQrYWmlFLODCAhIYH+/fvz5ptvAmCxWIiOjmbKlCk88sgjZz3fbDbj7+/Pm2++ycSJE89aPjc3F19fX3JycvDx8alz/KLpUkrR/7llZOSX8NntA2VAsRBCNGO1+f52asuNyWRi06ZNJCYm2o/pdDoSExNZu3ZtjeooLCyktLSUgICqB4uWlJSQm5vrcBOtw8GMAjLySzAadPSK9nN2OEIIIRqJU5ObjIwMzGYzoaGhDsdDQ0NJTU2tUR0PP/wwERERDglSRTNnzsTX19d+i46OrnPconlYf9DaJdU72g83F72ToxFCCNFYnD7mpi5mzZrFZ599xrfffoubm1uVZaZPn05OTo79lpyc3MhRCmdZf8g6mDhBuqOEEKJVcereUkFBQej1etLS0hyOp6WlERYWdsZzX3rpJWbNmsXSpUvp0aNHteVcXV1xdXWtl3hF86GUsrfcDJT1bYQQolVxasuN0Wikb9++LFu2zH7MYrGwbNkyBg0aVO15L774Is8++yyLFi2iX79+jRGqaGaOnCwkNbcYF71G7zb+zg5HCCFEI3L6ruBTp05l0qRJ9OvXjwEDBjBnzhwKCgqYPHkyABMnTiQyMpKZM2cC8MILL/Dkk0/yySefEBMTYx+b4+XlhZeXl9Neh2habF1SPaP8cDfKeBshhGhNnJ7cjB8/nhMnTvDkk0+SmppKr169WLRokX2QcVJSEjpdeQPTf//7X0wmE+PGjXOoZ8aMGTz11FONGbpowmxdUgntpUtKCCFaG6evc9PYZJ2b1mHIrOUcyy7iw5sHMDQ22NnhCCGEqKNms86NEA0hObOQY9lF6HUafdvKeBshhGhtJLkRLY5tF/Dukb54ujq951UIIUQjk+RGtDi2zTJluwUhhGidJLkRLY6t5UYGEwshROskyY1oUY5nF5GUWYhOg34y3kYIIVolSW5Ei2Jb36ZbpC/ebi5OjkYIIYQzSHIjWhT7+jay5YIQQrRaktyIFsU+3qadDCYWQojWSubJihah1FzK7rQUDmUUoGnQX1puhBCi1ZKWG9GsZRZl8sDiBwiaHcTA/94IgNH1BDsy/nJyZEIIIZxFkhvRbJ0sPMnA9wby2vrXyC3Jxc3SDYCMsrUMWziMH/f86OQIhRBCOIMkN6LZemLFExzMOohZmQFwPZXcFOm2YbaYufHbGykqLXJmiEIIIZxAkhvRLBWYCnh/y/v2xEan/DCqNgCU6HagUOSU5PDVzq+cGaYQQggnkORGNEvJuckUlxXb77tZugJg0g5h0fIAcNG5sOPEDqfEJ4QQwnkkuRHNkqeLp8N9V7M1uSnWlSczFmXBy+jVqHEJIYRwPkluRLMU5RNFz9Ce6DTrJWwbTFyi224vY1ZmruhyhVPiE0II4TyS3IhmSdM0nhr+FBZlQVOeuKgYAEr01pYbvabnss6X0TWkqxOjFEII4QyS3Ihma2yXsfx3zH/xVN3R0FGmHUfTW8fbjOowiv9d+T8nRyiEEMIZZIVi0azd0e8Ojh8bwIdrU2gbUsb13e7n6vir6R/Z39mhCSGEcBJJbkSzt/2YdS2b/5x/CVf3i3ZyNEIIIZxNuqVEs1ZkMrPtaA4gm2UKIYSwkuRGNGt/J2dRZlGE+bgRHeDu7HCEEEI0AZLciGZtw6FMwLoLuKZpTo5GCCFEUyDJjWjWbMnNgHYBTo5ECCFEUyHJjWi2TGUWNidlATAgRpIbIYQQVpLciGZr+/Ecikst+Hm40ClEtlkQQghhJcmNaLb+so23iQlAp5PxNkIIIawkuRHNln28jXRJCSGEqECSG9EsWSyKvw7LYGIhhBCVSXIjmqU9aXnkFpfhYdTTNcLH2eEIIYRoQiS5Ec2SrUuqb1t/DHq5jIUQQpSTbwXRLG04LONthBBCVE2SG9HsKKUcViYWQgghKpLkRjQ7h08WciKvBKNeR69oP2eHI4QQoomR5EY0O7b1bXpG++LmondyNEIIIZoaSW5Es7O+wuJ9QgghxOkkuRHNzobDJwFZ30YIIUTVJLkRzUpKThHJmUXoNOs0cCGEEOJ0ktyIZsU2Syo+wgdvNxcnRyOEEKIpkuRGNCv2LRdiAp0ciRBCiKZKkhvRrNg3y2wnXVJCCCGqJsmNaDayCkzsTcsHZKaUEEKI6klyI5oNW5dUxxAvAr1cnRyNEEKIpsrpyc3cuXOJiYnBzc2NhIQENmzYUG3ZHTt2cNVVVxETE4OmacyZM6fxAhVOt0HWtxFCCFEDTk1uPv/8c6ZOncqMGTPYvHkzPXv2ZNSoUaSnp1dZvrCwkPbt2zNr1izCwsIaOVrhbLaWmwRZ30YIIcQZODW5eeWVV7jtttuYPHky8fHxvP3223h4eLBgwYIqy/fv35/Zs2dz7bXX4upas26JkpIScnNzHW6ieckuzub3Q+v451gOIJtlCiGEODOnJTcmk4lNmzaRmJhYHoxOR2JiImvXrq2355k5cya+vr72W3R0dL3VLRpWRmEGk7+fTOhLoYx+/y4sCpTuJD/u/wCllLPDE0II0UQ5LbnJyMjAbDYTGhrqcDw0NJTU1NR6e57p06eTk5NjvyUnJ9db3aLhZBdnM2TBED7a+hEmswlXS1cACrSt3PnznTy54kknRyiEEKKpcvqA4obm6uqKj4+Pw000fS+teYkDmQcwKzMAbqeSmxLdDgD+b9X/sT9zv9PiE0II0XQ5LbkJCgpCr9eTlpbmcDwtLU0GC7dySine3vi2PbFBGXC1dAagWLcdAL2mZ8HfVY/NEkII0bo5LbkxGo307duXZcuW2Y9ZLBaWLVvGoEGDnBWWaAKKyoo4WWTd+VunPAk2PYyGETNZlGnHAFAoDmYddGaYQgghmiiDM5986tSpTJo0iX79+jFgwADmzJlDQUEBkydPBmDixIlERkYyc+ZMwDoIeefOnfafjx07xpYtW/Dy8qJjx45Oex2ifrkZ3DDqjVDahmDTIxhUGIpSMl3eBc1aRqfpCHCXWVNCCCEqc2pyM378eE6cOMGTTz5JamoqvXr1YtGiRfZBxklJSeh05Y1Lx48fp3fv3vb7L730Ei+99BLDhg1j5cqVjR2+qCOLBZYtg7VrQa+HxEQYMAA0NIYGPcHew93QcKFUSyXDOBOT7oD93DJLGdd1u86J0QshhGiqNNXK5tTm5ubi6+tLTk6ODC52op07YexY2LcPDAZQCsxm6D+4lG6T/2H5/hQACvVryXCZg9IK7OfqNT0XtruQxTcsRtM0J70CIYQQjak2398tfraUaHpSU2HoUDh4ashMWZk1sXEJyeF4t9Us35+CQacx8TwP3AI/RGkFGHQGdJr1ch3bZSzfjP9GEhshhBBVcmq3lGid5s6F7GxrQmOl8OqZTEDiDjSDhbIcd27p0ZsnLvFnhuUQvx34ja1pW3EzuHFJ7CV0DJDxVUIIIaon3VKi0bVrB4cP2+4pAi/ehlePowAU7g8h69eeXHiekcWLnRWhEEKIpqY239/SciMaXU5O+c8enVPx6nEUZdHI/r0zuRvaAxonTzotPCGEEM2cjLkRja5jR9DpAJ0Fv6F7AMhZ05HcDR0ADYMBOnd2aohCCCGaMUluRKO7807rNHCv7kdxCSjAXGgk96/29sfLyuD2250YoBBCiGZNkhvR6G64AYZfZMZ3yF7A2mqjTOU9pDffbJ1NJYQQQpwLSW5Eo3NxgXHTD2PwLsGS507eljYAhIfDSy/Bu++CzPIWQghxrmRAsWh0OUWlzFttXW141g2d6PZvPQYDxMZaF/QTQggh6kK+SkSje/ePg+QUldIpxIvxCVHopf1QCCFEPZKvFdGo0vOKmb/6EAAPjuqMXif9T0IIIeqXJDeiUb25fD9FpWZ6RfsxMj7U2eEIIYRogSS5EY0m6WQhn6xPAuDh0V1kbyghhBANQpIb0WheWbKHMotiaGwwgzoEOjscIYQQLZQkN6JR7Dyey/dbjwPw0ChZflgIIUTDkdlSokEcPw7z5sGiRdbViHXD96B0cEmPcLpF+jo7PCGEEC2YJDei3v32G4wdCyYTmM3gGpVJmC4dZdHoWCStNkIIIRqWdEuJenXsmDWxKS62Jjag8Bu2G4D8rdE8cLsnW7Y4MUAhhBAtniQ3ol7Nm2dtsVHKet+9fTpuUVlYSnXkrOmETgevvebcGIUQQrRs0i0l6tXixbYWG9BcyvC7wNpqk7epHeZ8N8A6DkcIIYRoKNJyI+qVLbEBRdCYLRiD8jEXGsld376KMkIIIUT9k+RG1KuhQ0GvB79hu/HonIYq03Him75Yio2AdWPMYcOcHKQQQogWTZIbUa/uuAM8uiXhO/AgABm/9KDkWID98bIyuPdeZ0UnhBCiNZDkRtSrdC2DoNHbAchd04nCXZGAtcUGYNYsOP98Z0UnhBCiNZABxaLe7E/P446PN2FBMbRNBLq0Tizaa13Eb9gwmDLF2m0lhBBCNCRJbsQ5ycqC5cuhpAR69oSwtiXcvHAjecVl9Gvrz7xbe+B2l2yMKYQQovFJciNqpbQUHn4Y3nrLmtgAoDfT6bZNmHwLaRPgwTs39sXNRe/UOIUQQrRektyIWpk0CT77rHyRPlAEXbwNk28WqsTArIv7E+jl6swQhRBCtHIyoFjU2MaN8OmnFRMb8B2yD8+ux1FmjZM/9OXLBV7OC1AIIYRAkhtRCx9+WD7rCcAj7hh+5+0DIPO3bhQcDGLBAsfkRwghhGhsktyIGktJKV9dWOdRQuAo65TvnHXtyd/WBoDcXOveUkIIIYSzSHIjaiwiwrr6MIDf0D3oXMsoSfEl+/cu9jK+vmA0OilAIYQQAkluRC1MmmRdYdglJAevHskAZC2LB6xTvvV6uOUW0GQGuBBCCCeS2VKixvr0gRsnKn4r24mmQcHOCPvWCno9BAfDgw86OUghhBCtnrTciFoZd38qbtGZqFIdWSvLu6OGDoU1ayA83InBCSGEEEjLjaiF4lIzLyzaBcBdF3ag6wXuFBdbVyju1MnJwQkhhBCnSHIjauy9VQc5ll1EuK8b947ogLsMHBZCCNEESbeUqJHUnGLmrjgAwCMXd8HdKNsrCCGEaJqk5aYFKiqCZcsgJ8faXdS/v3Vn7qVLYf9+8PODSy6xTtuuqRcX7aao1Ezftv5c1jOiwWIXQggh6kqSmxZEKXjlFXj2WWtiY9O2LRQWwokT1mnaSoGbm3UDzCefBN1Z2u/+Tsrim7+PAfDkJfFoMtdbCCFEEybJTQvyf/9nTVZOd+RI+c+2rRGKi+Hpp627fD/3XPV1KqV45qedAFzVJ4qe0X71F7AQQgjRACS5qSOlFN/t/o43NrzB36l/YyiMpO2eF0hZM4L8HCPBweDuDkePWltNYmIgI8PashIQYO0iOnLE+tiwYXDjjdYNKj/+GLKzoUMHuO026zoy8+bBvn3g4wMTJsDAgfDJJ9YuKIvFsbWmpp5/Ht56y9p6M2IEXHutdUr3J59Afj60Of84uV2z8TTqeXh053p+94QQQoj6pynl/G0O586dy+zZs0lNTaVnz5688cYbDBgwoNryX375JU888QSHDx+mU6dOvPDCC/zrX/+q0XPl5ubi6+tLTk4OPj4+dYpbKcW/f/o3725+F72mx3yiAyxYBUUBoGqfN+r11r2bbF1H4PizTmdNYioet51zWmS4tcvALeYEmk6h6RRoCnQKFBQfCqZwXxgox+4lW12259Fcyoi47XcM3sWEpHRm9bsdZWsFIYQQTlGb72+nt9x8/vnnTJ06lbfffpuEhATmzJnDqFGj2LNnDyEhIZXKr1mzhuuuu46ZM2dyySWX8MknnzB27Fg2b95Mt27dGjX2j7Z9xLub3wXAbDHD519Dkf85JTZQnqRUTDcr/mxLbCoed0hsdBY8447jM+AgxpC8ap/Hu1cypSc9yd3QnvwdkWDWO9Rlex6fhAMYvIspzXZn06ftmNWh6m4vIYQQoilxestNQkIC/fv358033wTAYrEQHR3NlClTeOSRRyqVHz9+PAUFBfz000/2YwMHDqRXr168/fbbZ32++my56f1Ob7albcOiLHB4OPpvfq5TfedK0yk8YlPx7ncYg3cxABaTnoKdEVgKjSilWVtpLBo6t1I8ux9F714KQFmeK3kb21G4J9whkdK7lxI6YQ06Fwsnvu1D4d5wgoLg+HFwcXHGqxRCCNGaNZuWG5PJxKZNm5g+fbr9mE6nIzExkbVr11Z5ztq1a5k6darDsVGjRvHdd99VWb6kpISSkhL7/dzc3LoHDpRZytiSusV+35h1IeF3rqiXuuuiLN+VvI0x5G9pi6Wk6iwke3UsXj2T8BlwCIN3Mf4X7Mb/gt1Vli0+EkDh3jDAOlboyBHo2LHBwhdCCCHqzKnJTUZGBmazmdDQUIfjoaGh7N5d9ZdtampqleVTU1OrLD9z5kyefvrp+gm4Au3Ufwrb4BgLllLnrYlYluVJ7sZ2FOyMsHczVUeVGsjb2J68zTF4dj2GT/9DGPwKKpWzFBvJXNoN267fAAand2QKIYQQZ9biv6qmT5/u0NKTm5tLdHR0nevV6/QMjxnOH0f+wKzMmMK+JvmVGXWutyF06gSenrBly2kPWHQU/BNNwT9nfz9sM73atGmICIUQQoj649TkJigoCL1eT1pamsPxtLQ0wsLCqjwnLCysVuVdXV1xdXWtn4BP89CQh1hx+FRXVNg/ELMcjpwPynmDUjStfNq4p6e1C6l3b+vx/fvh4EHrlPHrr7cOIK7piCul4KGHzr7gnxBCCOFsTv2qMhqN9O3bl2XLltmPWSwWli1bxqBBg6o8Z9CgQQ7lAZYsWVJt+YY0uuNoXh75MgAGnQGuHg/B1l2z0SrNzz6riomD7Wd9hR4mW5dQVeVsZV1c4JtvYPJkuOYa6NPHmtiANdEZORKuvhq++MJaX8X6dbrysrZ6bc95773w73/X+iUJIYQQjc7ps6U+//xzJk2axDvvvMOAAQOYM2cOX3zxBbt37yY0NJSJEycSGRnJzJkzAetU8GHDhjFr1izGjBnDZ599xvPPP1/jqeD1OVvKZkf6Dt7e+DYbUzbipnyJPv4fUtdeRE6mC2Fh4OFhHYhrMFi7dbKyrINzg4PLF/FTCoYPh4kTYcMG6yJ6mZkQG2tdxE+ng/feg127rOdcdx0MHmxd7G/5cmscF1wAt98OUVE1izs5Gd55B1autCY1iYlwww3wxx/w+efWRQTj4qxJzcCB9fJWCSGEEOekNt/fTk9uAN588037In69evXi9ddfJyEhAYDhw4cTExPDwoUL7eW//PJLHn/8cfsifi+++KJTFvETQgghRONodslNY5LkRgghhGh+avP9LcNDhRBCCNGiSHIjhBBCiBZFkhshhBBCtCiS3AghhBCiRZHkRgghhBAtiiQ3QgghhGhRJLkRQgghRIsiyY0QQgghWhRJboQQQgjRojh1V3BnsC3InJub6+RIhBBCCFFTtu/tmmys0OqSm7y8PACio6OdHIkQQgghaisvLw9fX98zlml1e0tZLBaOHz+Ot7c3mqbVa925ublER0eTnJwMYP/Zx8enxo/Z9suo6lh1xxvz/Opeb0sp05RiaYplzqY+6mip9TSlWJpaPU0pFnFmjfVZUhWlFHl5eURERKDTnXlUTatrudHpdERFRTXoc1T8x/Tx8al0/0yPnX4hVHWsNmUb6vyWXqYpxdIUy5xNfdTRUutpSrE0tXqaUizizBrrs+R0Z2uxsZEBxUIIIYRoUSS5EUIIIUSL0uq6pRqSq6srM2bMwNXVFcDh59o8Vt2x2pRtqPPPVldzL9OUYmmKZc6mPupoqfU0pViaWj1NKRZxZo31WVJXrW5AsRBCCCFaNumWEkIIIUSLIsmNEEIIIVoUSW6EEEII0aJIciOEEEKIFkWSmzqaOXMm/fv3x9vbm5CQEMaOHcuePXvsj0+fPh1N03B3d8doNOLq6oper0fTNMLCwrjlllu49NJLiYiIQNM0rrnmGgIDA9Hr9bi6uqJpGpGRkXh6euLt7U1wcDDBwcFomkb//v1xc3NDr9ej1+sJCAigTZs2eHl5odPpMBgMBAQE0L59e/z9/dHpdOh0Ojw8PAgMDETTNIeb0WgkODgYf39/PD096dOnD+effz5eXl72MgMGDODXX391eA/Wrl3LhRdeiKenJz4+PrRr1w5N0/jPf/5jLzNv3jyGDx+Oj48PmqYxY8aMSmWeeuqpSjF5eHhQVFRkryMmJqZSmS5dulSKZ8iQIRgMBjRNQ6/X061bNzZu3Ggv88033zB06FD7e+zm5kb37t0dylT1XJqmMXHiRHs8bm5uVZa5++67ATCbzUyePBl3d3c0TUOn0xETE0NhYaH9eb788kvat29vvy6io6N59tlnK+2fsnHjRtq3b49Op0PTNLy8vPjxxx8dXtOFF15oj8nNzY1u3bpx/vnn26+v7777jl27dnHZZZfh6+uLh4cHERERhISE4O7uTmJiIvv27XN43ueee45u3bqh1+vtz/3dd985lPnmm28YOXKk/brasmULp3vwwQcJDAy01/G///3P/lhpaSkPP/ww3bt3x9PTk4iICCZOnMjx48drHctTTz1Fly5d8PT0xN/fn8TERNavX1/reiq644470DSNOXPm1Lqem266qdL1MXr0aIcyt956KwEBAfbHq4ql4r+bp6cn/fv3Jykpyf74vHnz6NWrl/26r6qeqq5VTdOYPXt2rV5Tfn4+99xzD1FRUbi7uxMfH8/bb7/tUKYm8aSlpXHTTTcRERGBh4cHo0ePrnT9XXHFFfbPDU3TGDNmjMNnLEBxcTF33303gYGBeHl5cdVVV5GWluZQ5t5776Vv3764urrSq1evSu9va3a27zGA9u3bV7purr32WocyUVFRlcrccccdlZ5v4cKF9OjRAzc3N0JCQuyfl/VJkps6+v3337n77rtZt24dS5YsobS0lJEjR1JQUMCyZcuYPXs2/v7+XH755Vx66aUA/Pvf/wZg4sSJfPLJJ5hMJubOnQvAzz//zN13380tt9xCz549Abj55pv5559/mD17NpGRkeTn5wPWC6lPnz7MnDmTOXPmEBYWRn5+PqWlpcyYMYMrrrgCnU5HQUEBBQUFPPPMM7z33nsEBweTl5eHl5cX8+bN4+OPP+bPP/+kT58+uLi4kJ+fz9dff82VV17J6tWrufDCC3nggQcAOP/887n88svZsWMHYE0kRo8ezciRI9mwYQMLFiygoKCA7t27O7xPhYWFjB49mkcffRQov7grSk5ORqfT8eijj7Jy5UpWrVrF66+/bl9mu7CwkI4dOxIaGgrA7t27SUlJYfXq1fY61q5dy6hRo9i5cyeXXnopX3zxBa+99hqzZs3C39/fXi49PZ1//vmHfv36AfD111/z8ssvO5T54osv8PPz48477+S3337jgw8+AKwftrZ4HnzwQftr2r17N0uWLAHg6quvBuDuu+/mgw8+YPz48SxevJhXX32VtLQ0hy+CL774grS0NPsv+L333suLL77IG2+8YS9z4MABhgwZQm5uLvPmzWPp0qVceumlTJgwgWPHjgFQUFBAeno6AQEB9np79uzJhg0beOaZZwBITU3lvPPOo0uXLqxcuZJ77rmH3NxcZs+ezfr16/H09GTUqFEUFxfbn9tkMjF48GD69++Pu7s7VSkoKOC8887jhRdeqPJxsO4H07NnTyZMmFDpscLCQjZv3swTTzzB5s2b+eabb9izZw+XXXaZQ7maxBIbG8ubb77JP//8w+rVq4mJiWHkyJGcOHGiVvXYfPvtt6xbt46IiIhKj9W0ntGjR5OSkmK/ffrpp5Vef9++fe2fEac7cOCAw7/btm3beOKJJ3Bzc3Ooo3fv3gwdOrTaOCrGkJKSwoIFC9A0jauuuqpWr2nq1KksWrSIjz/+mF27dvGf//yHe+65hx9++KHG8SilGDt2LAcPHuT777/n77//pm3btiQmJlJQUGAvt3v3bkaNGmX/Q6jiZ6zN/fffz48//siXX37J77//zvHjx7nyyisrPefNN9/M+PHjq31/WqszfY/ZZGdnM2zYMFauXMnSpUu56KKLWLNmjUMZgMGDBzNu3Dji4+NJSUnhxRdfdHj8lVde4bHHHuORRx5hx44dLF26lFGjRtX/i1KiXqWnpytA/frrr8rf319169ZNDRs2TN13331qzJgx6uabb1ZKKQWob7/9Vl155ZVqwoQJymKxKEBNmjTJXld2drYC1NSpU+3HcnJyFGA/32bPnj0KUH/88YcC1O+//67MZrMKDg5Wr7zyiv2YUkp98cUX9jpsx5RSytPTU3344YfK399fvffee0oppQICAtS7776rVqxYoQCVlZXl8HhCQoJ6/PHHlVJK5eXlqU6dOqklS5bYX/PpfvnlF3vsp5eJjIxUoaGhZ3x/Z8yYoTp06GCP5XQJCQlq8ODB6rzzzjtjPQ8//LA677zz1KFDhxSg/v7770plxo8fr2644Qb7/fvuu0916NBBWSwWh3IV35vTy/j5+amePXs6lLf9m9vYrouKsZxe5qqrrlKapqmffvrJoa4+ffqoxx57TCmlVGFhodLr9Wr+/PkOr8lWBlBDhgyxvyaLxaLCwsLU7Nmz7fVlZ2crV1dX9emnn1Z6P95//33l6+tb6dqr6Ezv5+nv18cff1xtGaWU2rBhgwLUkSNHzikWG9vvzNKlS2tdz9GjR1VkZKTavn27atu2rXr11VerfI4z1TNp0iR1+eWXnzHGivVUVcfp1+KZ2N7fmrw3l19+ubrwwgurjaW619S1a1f1zDPPOByreC3WJB7bZ9b27dvtx2yfWe+++2619ezbt8/hsys7O1u5uLioL7/80l52165dClBr166tVM+MGTMq/U4KR7bvsYrfD6d/Xp+pTHXvcWZmpnJ3d6/yd7G+SctNPcvJyQHgv//9L5qmkZiYyI4dO5g3bx6bN2/m+++/Z+/evQAcOnSI1atXc/HFF3Po0CEAe2sNlO+hYWseNJlMDn/xP/3004SEhJCQkGDvKjKZTAAEBASg0+lwdXVl1apV9mO2GPV6PQCXXXYZ3bp1Y/r06QwYMIBXX32VgoICEhIS+OyzzyguLmb48OH25/z6668pKChg0KBBpKens379ekJCQhg8eDDBwcEUFhY6/DV5OluzfsU6wdqScuzYMbKysjAajej1ekJCQvj6668r1WFrqejVqxcTJkywN83b4jlw4AAHDhzAzc0No9FIbGws7777rkMdP/zwA/369eOuu+4C4Nprr3UoY7FY+Pnnn4mNjWXUqFEEBwczd+5cBg4cWO2GqyaTiY8//pibb74ZTdNIT08nOzub5ORkevfuTWhoKH379mXFihVcfPHF9vMGDx7MsmXLOHjwIGD997ZdF7ZYFi1ahFKKGTNm2P/Nv/vuO9zd3e0tV2VlZZjN5koLZ1Uss2nTJvtrCgoKIjU11X4tgPWaS0hIYO3atVW+xsaUk5ODpmn4+fmdcx0mk4l58+bh6+vr8LtVExaLhRtvvJFp06bRtWvXc44BYOXKlYSEhNC5c2fuvPNOTp48Was4Kl6LFf/96yItLY2ff/6ZW265pdbnDh48mB9++IFjx46hlGLFihXs3buXkSNH1riOkpISAIfPC9tnVsXW2NPl5uYC5Z9nmzZtorS0lMTERHuZLl260KZNmyZxHTdHtu8x23ts87///Y+goCC6devGE088UW2ZF198kT179jB9+nSHLvglS5ZgsVg4duwYcXFxREVFcc0119g3lK5XDZ4+tSJms1mNGTNGxcbGqm7duilXV1fl6uqqoqOj1XXXXaf++9//Kr1erzRNs/8l8/zzzyullPrzzz8VoObPn+9QJ6Di4uKUp6en0jRNhYaG2s+dPHmy+vvvv9XMmTMVoEJCQlR4eLhKSEhQJSUlatasWQpQQUFBasiQIUoppU6cOKGio6NVcHCwio+PV9u2bVMzZ85UmqYpTdOUwWBQgDIYDMrHx0ctXrxYbdu2Tbm5uSlA+fj4qJ9//lkppdTatWsVoAICAtS///1v1bFjR3XPPfcoo9GoBgwYUKnl5tNPP1Xt2rWzt3JU/EvAVpeXl5d6+umn1ZtvvqnCw8MVoDZv3myv45dfflEzZsxQgPrqq6/UoEGDVJs2bVRubq69Dlv8kydPVtdff73S6/XK1dVVLVy40F6P7d/mrrvuUoB6/PHHlZubm71MSkqKApSHh4d65ZVX1AsvvKB0Op0C1MqVKx1el+0vygULFii9Xq+OHTvm8Jrc3Nwc3lu9Xq/27t3rcN08/PDD9utC0zT7dVExFp1Opzp06KAWL16snnvuOfux2NhYe9lBgwaphIQEBaiNGzeqjz76yF7G9t7YXpOtleD013T11Vera665ptL13ZgtN0VFRapPnz7q+uuvr/Lxs8Xy448/2n9nIiIi1IYNG2pdz/PPP69GjBhhb4U715abTz/9VH3//fdq27Zt6ttvv1VxcXGqf//+qqysrMp6Tq/j9GvR9juvaVqla1GpmrfcvPDCC8rf318VFRXV+jUVFxeriRMn2n/XjEaj+uCDD6qsp7p4TCaTatOmjbr66qtVZmamw2fWyJEjq61n5MiR9s8zpZT63//+p4xGY6Xy/fv3Vw899FCl49Jyc2a277GK77FSSr3zzjtq0aJFatu2berDDz9Urq6uKiAgoMoyd9xxh2rTpo2KjIxUV1xxhf3xmTNnKhcXF9W5c2e1aNEitXbtWnXRRRepzp07q5KSknp9HZLc1KM77rhDRUZGqqCgILV161bl4uKiBg0aZP8S//TTT5WXl5fq2LGjAtR9992nAgIC1MKFC8+Y3AwcOFDt27dPrV27Vl177bVVflBceumlKioqSrm4uNi/QEeNGqWio6OVm5ubSk5OVjk5OWrAgAEqOjpatW3bViUnJyullCopKVEffvihPUHy9fVVX3/9tXrqqaeUr6+v2rRpk/r4448VoP7zn/+ooKAgtWPHDnvMd999twoJCVFbt25VSinVvXt3FR0d7ZDcJCUlqZCQEPXee+9VmdzY6po+fbr9nKysLKXT6dTFF1/s8J5U7AbKyspSPj4+6r333rPXodPp1KBBg+zlu3fvrvr27asGDhxoP2b7t6n4ZTxlyhR7mWPHjilAXXfddUoppUaOHKkuueQSdemll6prr722ynguvPBCdckll9iP2+Lx9vZWn376qf1DQa/XqzFjxtjLffrppyoqKkq9/vrrClDPPvus/bqoGMsll1yihg4dav/39fPzU23btlVdunSx17V//341YMAAe5n+/furCRMmqC5dutivG9trssU3YsQIh9fk7OTGZDKpSy+9VPXu3Vvl5ORUWeZsseTn59t/Z26++WYVExOj0tLSalzPxo0bVWhoqD1RVerck5vTHThw4IzdZKfXcfq1aFPVtahUzZObzp07q3vuuafax8/0mmbPnq1iY2PVDz/8oLZu3areeOMN5eXlpZYsWVKreDZu3Kh69uzp8Jl18cUXq9GjR1dbT3R0tP2zSylJburbHXfc4fD9UF0Z2x/a+/fvr/S47T1etmyZQxnbH2WLFy+2l01PT1c6nU4tWrSoXl+HdEvVk3vuuYeffvqJJ554goyMDPr06UNpaSnr1q3j999/5/XXX+e6667j4osvtjfTDR8+nPvvv5+ZM2cSFhYGlDcHVhQYGEjHjh0ZOHCgfVDr6Y4ePUp6ejp79uwhOzublJQUOnbsSFpaGuPGjcPX15fRo0dz/PhxLBYLK1asICoqCgCj0WifPfDMM8/Qr18/Fi9ezIwZM+jXrx/z5s0jMjISsO6J1bNnT1577TXCw8MBMBgMpKen06dPHwwGA9u3byc5OZnXX38dg8GA2Wxm06ZNpKenc/vttwMQFBRkf18MBoN9kHB8fLz9Nfn5+eHr68uRI0eqfd/9/PyIjY1l//799nj8/f0d6omLi0On0znMLAkPD3coYytnKxMUFITBYCA+Pp4jR46wdOlSbr31Vocyp1u5ciW33nqrw3OAdQDytddeS/fu3bnxxhuJi4uzdxUCTJs2jUceecQ+mPSSSy6xXxcVY0lISOD3338nPz+f5ORkbr/9dvLz82nfvr29rg4dOvD5558D8Ouvv7JhwwZKS0vtZXQ6nf112665iIgIh9eUlpZmf6yxlZaWcs0113DkyBGWLFmCj4/POdXj6elp/52ZP38+BoOB+fPn1/j8VatWkZ6eTps2bTAYDBgMBo4cOcIDDzxATEzMOcVk0759e4KCgti/f3+Nyle8Fis607V4NqtWrWLPnj0O12tNFRUV8eijj/LKK69w6aWX0qNHD+655x7Gjx/PSy+9VKu6+vbty5YtW+yfWYsWLeLkyZMO17TNa6+9BsCPP/5o/+wC63VsMpnIzs52KO/M67i5sn2PVfx+qK7MsmXLAM54HSckJDiUsX0mVryWg4ODCQoKOudruTqS3NSRUop77rmHb7/9luXLl3P99dfzzz//sGXLFi6++GJ69+5Nv379mDBhAr6+vmRkZNC2bVv7+Xq9HovFQrt27QDYtm2b/TFb33Lnzp3tx2zTyU9//l27djFy5EjatWuHj48PTz/9NF9++SWlpaVceeWVjBgxgiNHjmA2m1mxYoX9+Wz+/vtvAEJDQ7FYLPb+cFt8Fdkej4mJISIiAqPRaH/NW7ZsITY2lrCwMCZMmMCWLVvQ6/VcdNFF/PPPP7z33nsA/PHHH/b3ZcuWLbRv356IiAiH6Yf5+fnk5uZWOUulYpkDBw4QHh5ujycsLMyhHtsYp4rv+5AhQypNddy7d6+9jNFopH///uzZs4f333+fkJAQxowZ41DmdMHBwYwZM8Z+3zaVvOIsHYCTJ086jHMpLCy0zwizqfi+V4wFrF/c4eHhbN++ndzcXC6//PJq48nKymLx4sX2Mp06dbLX065dO8LCwti4caP9NeXm5rJ+/XoGDRpUZZ0NyZbY7Nu3j6VLlxIYGFhvdVe8pmvixhtvZNu2bfZresuWLURERDBt2jQWL15cp1iOHj3KyZMn7R/0Z3P6v7/Nma7Fs5k/fz59+/at9TgksP47lZaWnvGarS1fX1+Cg4PZt28fGzdudLimbZ9xtnE4p7/mvn374uLiYv+yBeu4taSkJKdcx83R6d9jp38/VFXGlkye6Tq2LQlhKzNkyBAAh2s5MzOz0vdifZBdwevo7rvv5pNPPuH777/H29ubgoICgoKC8PX15emnn2bw4MFERUWh1+vp2rUrK1as4MYbb2Tt2rX88MMPfPPNN4wYMYKtW7cC8Nlnn9GlSxd8fHz45JNPAOvAu19++YXCwkI++ugjysrKAPjkk0+YN28eK1aswGQyERcXxzfffMP//vc/Fi1ahLe3N4mJiTz77LMcOnQIs9nMwoUL2bt3L6+++iqXXnop3377Le3ateOtt97CaDQyZcoUjh07xvvvv8/LL7/Mb7/9xr333su6desAa9a+cuVKvvzySzRNY9q0acyYMYMBAwbQq1cvPvjgA44cOUKPHj0IDAykW7dugHWqsG3AK1jXf1FK4enpaS8TGxvLK6+8Qnh4OEFBQTzyyCOYzWaee+45wDqN+aGHHrK38nzyySd8+OGH6HQ6rrvuOns8jz/+OLt37+aBBx6guLiYHTt2YDAYHAYM33zzzVx88cXMmDEDsH7Yv/feew5/eU6bNo1rrrkGHx8fxo0bx9tvv82PP/7IypUr7fGkpqbak6eLLrqI7du306ZNG/uaJf369WPRokVMnz6dUaNGMXfuXFJSUuwtWAAjR47kqaeesq/L8dFHH7FgwQKHKdPTpk3j6quvJiAggLFjx/L111/zyy+/EB8fz+TJkwHrh8Rnn31GRkYGYF0/54svviA8PJzevXsD1oGgH330EV27dmXcuHEMGDCAH374gRtuuIF//vmHJ554goiICMaOHWt/7qSkJI4ePcr69evtA9ZXr15NSEgIUVFRtGnThszMTJKSkuzr0tg+vMLCwux/PR84cICNGzfalxFYt24dBoOBuLg44uLiGDduHJs3b+ann37CbDaTmpoKWAcsGo3GGsUSGBjIc889x2WXXUZ4eDgZGRnMnTuXY8eO2afn1/Q1nZ5cubi4EBYW5vDHxtnqCQgI4Omnn+aqq64iLCyMAwcO8NBDD9GxY0eH6a+7du1i27Zt9vV4Vq9eTUlJCT169CAuLo5p06Yxfvx4hg4dygUXXMCiRYscrkXb9Xjw4EGWL19uP7Z69Wr8/f1p164dbdq0AawJ7JdffsnLL79MVWry3gwbNoxp06bh7u5O27Zt+f333/nwww955ZVXahXPl19+SXBwMG3atOGff/7hvvvuY+zYsQ4DkydPnszXX3/NHXfcwUsvvcTKlSvx8vIiLi6OyMhIfH19ueWWW5g6dSoBAQH4+PgwZcoUBg0axMCBA+317N+/n/z8fFJTUykqKrJ/8cbHx9uvr9bq9O8x2++er68v7u7uHDhwgOuuu45du3bx7rvvsmbNGp588kkGDhxIp06dAOvv9xtvvMGAAQPYt28fJ06c4Nprr6VPnz72tchiY2O5/PLLue+++5g3bx4+Pj5Mnz6dLl26cMEFF9Tvi6rXTq5WiFN9yaff3n//faVU+cBGvV6vIiMjqy1fk5vRaKzT+VXdbANd9Xq98vf3V8HBwcrPz095eHioHj16qDZt2pzx9SllHSQWFRWlPDw81KBBg9SqVasqTRu0DQI+/TZixAh7mfHjxytvb297XIGBgeqzzz47ax0vvPCCw7/JzJkzVWBgoH2QdNu2bdW8efMcylQcTFvxNmPGDIdy999/v/2979mzp/ruu+/OGk/F9yY3N1cNHjxY6fV6BShXV1c1ceJEh8Fzb731VpX12KbY29xxxx0OA77/9a9/qezs7LO+pqpu3t7eys3NTfXo0UNdc801KjQ0VLm6uqqLLrpI7dmzx+F5J02aVG09tqULavJ+VlfPkCFD7GN1qrqtWLGixrEUFRWpK664QkVERCij0ajCw8PVZZddVmlAcU1e0+mqGnNztnoKCwvVyJEjVXBwsHJxcVFt27ZVt912m0pNTXWoZ9SoUVXWMWrUKHuZ+fPnq44dOyo3N7dK16JS1V+Pp7+md955R7m7uztcO7V9b1JSUtRNN92kIiIilJubm+rcubN6+eWXHZZJqEk8r732mn2sYJs2bdTjjz9eaWBpdXXccsst9jJFRUXqrrvuUv7+/srDw0NdccUVKiUlxaGeYcOGVVnPoUOHqnwfWpPq3mPbZ1lSUlKNytjGaJ3pPc7JyVE333yz8vPzUwEBAeqKK65QSUlJ9f6atFMvTAghhBCiRZAxN0IIIYRoUSS5EUIIIUSLIsmNEEIIIVoUSW6EEEII0aJIciOEEEKIFkWSGyGEEEK0KJLcCCGEEKJFkeRGCCGEEC2KJDdCiCZBKcXtt99u37piy5YtDB8+nP/85z/2MjExMcyZM6dB41i2bBlxcXH2rULq20033eSwvcXZmEwmYmJi2LhxY4PEI0RLJMmNEK3QTTfdhKZpzJo1y+H4d999h6ZpTolp0aJFLFy4kJ9++omUlBS6devGN998w7PPPtuocTz00EM8/vjj9s1Nn3rqKXr16lVv9b/22mssXLiwxuWNRiMPPvggDz/8cL3FIERLJ8mNEK2Um5sbL7zwAllZWc4OBcC+u/vgwYMJCwvDYDAQEBCAt7d3o8WwevVqDhw4wFVXXVXrc0tLS2tUztfXFz8/v1rVPWHCBFavXm3fdFQIcWaS3AjRSiUmJhIWFsbMmTOrLVNVq8WcOXOIiYmx37d1szz//POEhobi5+fHM888Q1lZGdOmTSMgIICoqCjef//9ap/npptuYsqUKSQlJaFpmr3+07ulTpednc2tt95KcHAwPj4+XHjhhWzdutX++NatW7ngggvw9vbGx8eHvn37nrF757PPPmPEiBG4ubkBsHDhQp5++mm2bt2KpmlommZvddE0jf/+979cdtlleHp68txzz2E2m7nlllto164d7u7udO7cmddee63Sa63YLTV8+HDuvfdeHnroIQICAggLC+Opp55yOMff358hQ4bw2WefVRu7EKKcwdkBCCGcQ6/X8/zzz3P99ddz7733EhUVdc51LV++nKioKP744w/+/PNPbrnlFtasWcPQoUNZv349n3/+Of/+978ZMWJElc/z2muv0aFDB+bNm8dff/1l7xI6m6uvvhp3d3d+/fVXfH19eeedd7jooovYu3cvAQEBTJgwgd69e/Pf//4XvV7Pli1bcHFxqba+VatWcf3119vvjx8/nu3bt7No0SKWLl0KWFtebJ566ilmzZrFnDlzMBgMWCwWoqKi+PLLLwkMDGTNmjXcfvvthIeHc80111T7vB988AFTp05l/fr1rF27lptuuokhQ4YwYsQIe5kBAwawatWqGr0vQrR2ktwI0YpdccUV9OrVixkzZjB//vxzricgIIDXX38dnU5H586defHFFyksLOTRRx8FYPr06cyaNYvVq1dz7bXXVjrf19cXb29v9Ho9YWFhNXrO1atXs2HDBtLT03F1dQXgpZde4rvvvuOrr77i9ttvJykpiWnTptGlSxcAOnXqdMY6jxw5QkREhP2+u7s7Xl5eGAyGKuO6/vrrmTx5ssOxp59+2v5zu3btWLt2LV988cUZk5sePXowY8YMe4xvvvkmy5Ytc0huIiIiOHLkyBnjF0JYSbeUEK3cCy+8wAcffMCuXbvOuY6uXbui05V/nISGhtK9e3f7fb1eT2BgIOnp6XWKtaKtW7eSn59PYGAgXl5e9tuhQ4c4cOAAAFOnTuXWW28lMTGRWbNm2Y9Xp6ioyN4lVRP9+vWrdGzu3Ln07duX4OBgvLy8mDdvHklJSWesp0ePHg73w8PDK71X7u7uFBYW1jg2IVozSW6EaOWGDh3KqFGjmD59eqXHdDodSimHY1UNnD29q0fTtCqPWSyWeojYKj8/n/DwcLZs2eJw27NnD9OmTQOs3UY7duxgzJgxLF++nPj4eL799ttq6wwKCqrVAGtPT0+H+5999hkPPvggt9xyC7/99htbtmxh8uTJmEymM9ZTk/cqMzOT4ODgGscmRGsm3VJCCGbNmkWvXr3o3Lmzw/Hg4GBSU1NRStmniG/ZssUJEVbWp08fUlNTMRgMDgOcTxcbG0tsbCz3338/1113He+//z5XXHFFlWV79+7Nzp07HY4ZjcYar3nz559/MnjwYO666y77sbO1FtXU9u3b6d27d73UJURLJy03Qgi6d+/OhAkTeP311x2ODx8+nBMnTvDiiy9y4MAB5s6dy6+//uqkKB0lJiYyaNAgxo4dy2+//cbhw4dZs2YNjz32GBs3bqSoqIh77rmHlStXcuTIEf7880/++usv4uLiqq1z1KhRrF692uFYTEwMhw4dYsuWLWRkZFBSUlLt+Z06dWLjxo0sXryYvXv38sQTT/DXX3/Vy+tdtWoVI0eOrJe6hGjpJLkRQgDwzDPPVOoKiYuL46233mLu3Ln07NmTDRs28OCDDzopQkeapvHLL78wdOhQJk+eTGxsLNdeey1HjhwhNDQUvV7PyZMnmThxIrGxsVxzzTVcfPHFDgN+TzdhwgR27NjBnj177MeuuuoqRo8ezQUXXEBwcDCffvpptef/+9//5sorr2T8+PEkJCRw8uRJh1acc7V27VpycnIYN25cnesSojXQ1Okd6kII0YpNmzaN3Nxc3nnnHWeHYjd+/Hh69uxpn30mhDgzabkRQogKHnvsMdq2bVuvg5/rwmQy0b17d+6//35nhyJEsyEtN0IIIYRoUaTlRgghhBAtiiQ3QgghhGhRJLkRQgghRIsiyY0QQgghWhRJboQQQgjRokhyI4QQQogWRZIbIYQQQrQoktwIIYQQokWR5EYIIYQQLcr/A/7o8EbJBj3CAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/Coffee-Fruit-Maturity-â˜•ðŸ’-5/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('1', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45f02d",
   "metadata": {
    "papermill": {
     "duration": 0.833014,
     "end_time": "2024-01-16T09:35:41.387059",
     "exception": false,
     "start_time": "2024-01-16T09:35:40.554045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ Ð¸ Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4f741",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.800634,
     "end_time": "2024-01-16T09:35:43.092744",
     "exception": false,
     "start_time": "2024-01-16T09:35:42.292110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab890f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.794007,
     "end_time": "2024-01-16T09:35:44.683229",
     "exception": false,
     "start_time": "2024-01-16T09:35:43.889222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7237ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.794738,
     "end_time": "2024-01-16T09:35:46.331964",
     "exception": false,
     "start_time": "2024-01-16T09:35:45.537226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372701f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.859244,
     "end_time": "2024-01-16T09:35:47.987673",
     "exception": false,
     "start_time": "2024-01-16T09:35:47.128429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e81fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.813792,
     "end_time": "2024-01-16T09:35:49.616751",
     "exception": false,
     "start_time": "2024-01-16T09:35:48.802959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6864.575178,
   "end_time": "2024-01-16T09:35:56.811790",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-16T07:41:32.236612",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
