{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61a37da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T19:15:03.449015Z",
     "iopub.status.busy": "2023-12-02T19:15:03.448645Z",
     "iopub.status.idle": "2023-12-02T19:16:38.897104Z",
     "shell.execute_reply": "2023-12-02T19:16:38.895972Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 95.456277,
     "end_time": "2023-12-02T19:16:38.899116",
     "exception": false,
     "start_time": "2023-12-02T19:15:03.442839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\r\n",
      "pytoolconfig 1.2.6 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\r\n",
      "tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m--2023-12-02 19:16:27--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.113.4\r\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231202T191627Z&X-Amz-Expires=300&X-Amz-Signature=bdf6eb17e149ba026c2805f40cae81c6ff6e928675d1576d8d42636854631b57&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-12-02 19:16:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231202T191627Z&X-Amz-Expires=300&X-Amz-Signature=bdf6eb17e149ba026c2805f40cae81c6ff6e928675d1576d8d42636854631b57&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: ‚Äòyolov8m-seg.pt‚Äô\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   229MB/s    in 0.2s    \r\n",
      "\r\n",
      "2023-12-02 19:16:27 (229 MB/s) - ‚Äòyolov8m-seg.pt‚Äô saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.221, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in puddle-segmentation-8 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48211/48211 [00:01<00:00, 43580.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to puddle-segmentation-8 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4847/4847 [00:00<00:00, 9263.23it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"hanyang-university-bd2kb\").project(\"puddle-segmentation\")\n",
    "dataset = project.version(8).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8074816b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T19:16:38.914810Z",
     "iopub.status.busy": "2023-12-02T19:16:38.914363Z",
     "iopub.status.idle": "2023-12-02T19:16:38.953254Z",
     "shell.execute_reply": "2023-12-02T19:16:38.952288Z"
    },
    "papermill": {
     "duration": 0.048968,
     "end_time": "2023-12-02T19:16:38.955205",
     "exception": false,
     "start_time": "2023-12-02T19:16:38.906237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/puddle-segmentation-8\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/puddle-segmentation-8\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a24c42e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T19:16:38.970881Z",
     "iopub.status.busy": "2023-12-02T19:16:38.970594Z",
     "iopub.status.idle": "2023-12-02T19:16:39.066232Z",
     "shell.execute_reply": "2023-12-02T19:16:39.065395Z"
    },
    "papermill": {
     "duration": 0.10622,
     "end_time": "2023-12-02T19:16:39.068425",
     "exception": false,
     "start_time": "2023-12-02T19:16:38.962205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): –ø—É—Ç—å –¥–æ –≤–µ—Å–æ–≤ yolov8.pt\n",
    "            path_to_yaml (str): –ø—É—Ç—å –¥–æ data.yaml —Ñ–∞–π–ª–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "            train_perc (float): –¥–æ–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö \n",
    "            test_perc (float): –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            val_perc (float): –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, '–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è train –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —á–∞—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö\n",
    "            iters (int): –∫–æ–ª-–≤–æ –∏–Ω—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "        Returns:\n",
    "            YOLO: —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        \"\"\"        \n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —á–∞—Å—Ç—è—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏ –ø—Ä–æ—Å–∞–¥–∫–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —á–∞—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö\n",
    "            iters (int): –∫–æ–ª-–≤–æ –∏–Ω—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "        Returns:\n",
    "            YOLO: —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # —Å–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫—É—Å–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–æ –Ω–∞—à–µ–≥–æ folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # –∫–æ–ø–∏—Ä—É–µ–º –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –∫—É—Å–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–ø–∫—É retrain\n",
    "        for path in source_pathes:\n",
    "            # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º data.yaml —Ñ–∞–π–ª\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∏ train/test/val. –£–¥–∞–ª–µ–Ω–∏–µ 1-keep_perc –¥–æ–ª–∏ –¥–∞–Ω–Ω—ã—Ö \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å\n",
    "        \"\"\"        \n",
    "        # —Å–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã\n",
    "            allfiles = os.listdir(path)\n",
    "            # –∏—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º, —á—Ç–æ–±—ã –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –∏—Ö –≤ –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –∫ label —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # –ö–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞,\n",
    "                # –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - {empty_count}\")\n",
    "        # –û—Å—Ç–∞–≤–ª—è–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∏–º–µ–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤ –∏ –±—ã–ª —É–∂–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º train, test, val —Å —É—á–µ—Ç–æ–º —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ —Ä–∞–≤–Ω—ã–µ –¥–æ–ª–µ piece_perc –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): –¥–æ–ª—è —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–æ–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π –∫ label —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # –ö–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞,\n",
    "                # –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"–ö–ª–∞—Å—Å {key} —Å–æ–¥–µ—Ä–∂–∏—Ç {value} –æ–±—ä–µ–∫—Ç–∞(-–æ–≤)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # –†–∞–∑–¥–µ–ª–∏—Ç—å —Å–Ω–∞—á–∞–ª–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º, –∞ –ø–æ—Ç–æ–º –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"–ö–ª–∞—Å—Å {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\t–ö–æ–ª-–≤–æ train –∫–ª–∞—Å—Å–∞ {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\t–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∞ {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\t–ö–æ–ª-–≤–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "            color_dict (dict): —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAM –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # –¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/—Ç–µ—Å—Ç–æ–≤—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # –ø—É—Ç—å –∫ –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–º –≤–µ—Å–∞–º yolov8 –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –ø–æ–Ω–∏–∂–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ \n",
    "        for cls in cls_tl_dict.keys():\n",
    "            result_dict = defaultdict(list)\n",
    "            # —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "            color_dict = defaultdict(str)\n",
    "            # –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ map –≤ —Ü–µ–ª—è—Ö –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∏ –ø—Ä–æ—Å–∞–¥–æ–∫ –º–µ—Ç—Ä–∏–∫–∏\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "                model = self.train(folder_name, iters)\n",
    "                # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–µ—Ç—Ä–∏–∫–∞ —É–ª—É—á—à–∞–µ—Ç—Å—è\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ) –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: \\n {result_dict}\")\n",
    "            print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –¥–ª—è –∫–ª–∞—Å—Å–∞ {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "\n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # –¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/—Ç–µ—Å—Ç–æ–≤—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # –ø—É—Ç—å –∫ –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–º –≤–µ—Å–∞–º yolov8 –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –ø–æ–Ω–∏–∂–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ {–¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö: –º–∞—Å—Å–∏–≤ –º–µ—Ç—Ä–∏–∫}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "            metrics = self.test(model)\n",
    "            # –∑–∞–Ω–æ—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–±–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02925540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T19:16:39.083940Z",
     "iopub.status.busy": "2023-12-02T19:16:39.083644Z",
     "iopub.status.idle": "2023-12-02T23:31:38.801749Z",
     "shell.execute_reply": "2023-12-02T23:31:38.800592Z"
    },
    "papermill": {
     "duration": 15299.976166,
     "end_time": "2023-12-02T23:31:39.051759",
     "exception": false,
     "start_time": "2023-12-02T19:16:39.075593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1712_jpeg_jpg.rf.cd253201a1e39224af7ac10a51f12418.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image88_jpeg_jpg.rf.0321e07f5c0ce99e1d79187fd033cd2b.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1262_jpeg_jpg.rf.f6a8e4b4c0eb096527a742a41303d802.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image19_jpeg_jpg.rf.5b1c01c0e5778c81a7002d3c74a700ab.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230303_155124767_05_jpg.rf.462d7aa0eea136c4312720cdd11ca6ce.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image338_jpeg_jpg.rf.07290b77d8614388be0b6c5b477f26a0.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1448_jpeg_jpg.rf.3f5fe2090c8f83954eb4f85fd33640e2.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1448_jpeg_jpg.rf.1fac25f8cfc0311e0760a5ed6eac65ff.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image88_jpeg_jpg.rf.253074927d14756c8d4973890e49988d.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230426_113303172_04_jpg.rf.84776f54da07a3a109e2a92b854a78c2.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230112_175920520_mp4-1_jpg.rf.04d9f2e8993ecb9e8302e106c7aa5294.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1804_jpeg_jpg.rf.d5363ee6e9d102616061d5e9cd21c9b3.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1262_jpeg_jpg.rf.96c564b12ee68002c5df0c945a013755.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image1712_jpeg_jpg.rf.6743aa15f86650f685950f10335cf521.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/KakaoTalk_20230426_113303172_04_jpg.rf.414a8956b61140c1970b8eafa8295ca6.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image792_jpeg_jpg.rf.8c58f9581d896f6750687b056b28b03d.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image338_jpeg_jpg.rf.f9c964dba32479debf57bfd0ce1347ba.txt\n",
      "–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: temp/labels/image19_jpeg_jpg.rf.24a170542d199cfbc933b873efd7927c.txt\n",
      "–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - 18\n",
      "valid_0/images 240\n",
      "test_0/images 241\n",
      "train/labels 1920 \n",
      "\n",
      "–ö–æ–ª-–≤–æ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ - 0\n",
      "–ö–ª–∞—Å—Å 0 —Å–æ–¥–µ—Ä–∂–∏—Ç 1920 –æ–±—ä–µ–∫—Ç–∞(-–æ–≤)\n",
      "\n",
      "–ö–ª–∞—Å—Å 0\n",
      "\t–ö–æ–ª-–≤–æ train –∫–ª–∞—Å—Å–∞ 0: 1920\n",
      "\t–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∞ 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1920]\n",
      "\t–ö–æ–ª-–≤–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: 43 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 500, folder 40, cls 0\n",
      "\tnum_to_mv_train 500, folder 41, cls 0\n",
      "\tnum_to_mv_train 419, folder 42, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 500\n",
      "temp_0_41/train/images 500 \n",
      "\n",
      "temp_0_42/train/labels 500\n",
      "temp_0_42/train/images 500 \n",
      "\n",
      "temp_0_43/train/labels 419\n",
      "temp_0_43/train/images 419 \n",
      "\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 14.3MB/s]\n",
      "2023-12-02 19:16:44,695\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-02 19:16:46,280\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 68.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 136.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<00:00, 910.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/valid_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      1.59G      1.012      2.363      4.589      1.308          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0585      0.095     0.0205     0.0072     0.0333     0.0554     0.0102     0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      1.528      2.979      5.397      1.744          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0593     0.0923     0.0203    0.00693     0.0352     0.0528    0.00958      0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.61G     0.8278      2.328      8.971      1.445          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0588     0.0976     0.0205    0.00702     0.0397     0.0528     0.0097    0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.59G      1.301       3.34      6.921      1.522          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0623      0.103     0.0206    0.00698     0.0365     0.0554    0.00922     0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       1.6G     0.9385      2.367      4.779      1.172          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.066      0.103     0.0205    0.00709     0.0396     0.0528     0.0095    0.00287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0589      0.095     0.0202    0.00713     0.0329     0.0554     0.0104    0.00322\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñÉ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.93848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.77898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.17244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.36736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.03157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_191706-1xe8y5eb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_191706-1xe8y5eb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<00:00, 887.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/test_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0724     0.0813     0.0249       0.01     0.0688      0.065     0.0154    0.00577\n",
      "Speed: 1.5ms preprocess, 28.6ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1364.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.74G      2.273      7.549      3.617      2.279          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0548     0.0897     0.0184    0.00625      0.047     0.0528    0.00724    0.00258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.57G      1.915      9.911      4.139      2.113          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.054     0.0871      0.018     0.0062     0.0434     0.0554    0.00688    0.00263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.57G      3.149      7.572      5.625      2.612          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0594     0.0807     0.0186    0.00648     0.0434     0.0475    0.00719    0.00249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.61G       2.45      9.039      4.758      2.783          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0643     0.0897      0.018    0.00645     0.0404     0.0475    0.00739    0.00243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.58G      3.939      9.827      7.902      3.613          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0707     0.0818     0.0193    0.00653     0.0456     0.0528    0.00798    0.00253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0714     0.0844     0.0191    0.00643     0.0452     0.0528    0.00809    0.00252\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÇ‚ñÅ‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÅ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 3.93897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 7.90167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 3.6125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 9.82673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.01941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.13605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.7567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_192017-nya16my4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_192017-nya16my4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0561      0.108     0.0216    0.00732     0.0399     0.0596    0.00905    0.00301\n",
      "Speed: 1.3ms preprocess, 29.0ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1120.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.67G      2.294      10.16      4.369      2.269          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0608      0.095     0.0196    0.00709     0.0341     0.0528    0.00996    0.00319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.94G      2.222      8.599      5.272      2.264          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0567      0.103     0.0195    0.00684     0.0342      0.058    0.00967    0.00312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.84G      1.981      5.467      4.985      1.932          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0606      0.106     0.0201    0.00683     0.0367     0.0554    0.00975    0.00309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.84G          2      6.857      6.861      2.127          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0603     0.0976     0.0198    0.00683     0.0415     0.0607    0.00997    0.00316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.84G      1.437       4.44      5.155      1.463          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0587     0.0961     0.0197    0.00677     0.0408     0.0589    0.00977    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0578     0.0976     0.0198    0.00709     0.0336     0.0554       0.01    0.00322\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÅ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÖ‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.43669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.15527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.46297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.43996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.70135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.03356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_192216-2a7rgsm6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_192216-2a7rgsm6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0699      0.084     0.0251     0.0101     0.0621     0.0678     0.0149    0.00578\n",
      "Speed: 1.2ms preprocess, 28.5ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 3359.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.99G      2.197      5.385      2.904      2.333          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0491        0.1     0.0178    0.00616     0.0355     0.0528    0.00655    0.00256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      2.429      5.514      4.684      2.881          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0482        0.1     0.0176    0.00624     0.0386     0.0501    0.00686    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.48G      2.737      6.333      4.541      2.915          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.054        0.1     0.0184    0.00626     0.0439      0.058    0.00731    0.00257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.5G      2.397      6.133      3.396      2.349          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0582      0.106     0.0182    0.00636     0.0431     0.0554    0.00744    0.00264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.46G      2.686       6.72      5.126       3.59          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0553        0.1     0.0185     0.0064      0.045     0.0396    0.00757     0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0535     0.0976     0.0183    0.00641     0.0511     0.0475    0.00747    0.00279\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñá‚ñÜ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñà‚ñÅ‚ñÖ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñá‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÑ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.68597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.12594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 3.59017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.72033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.01838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.1188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.26708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.70527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_192606-ayhq9slv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_192606-ayhq9slv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0564      0.125     0.0227    0.00773     0.0384     0.0515     0.0101    0.00358\n",
      "Speed: 1.2ms preprocess, 28.6ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 919.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.52G      1.157      4.713      4.551      1.605          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0579     0.0923     0.0199    0.00704      0.034      0.058     0.0101    0.00318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.94G       1.64      6.087      4.584      1.864         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0604        0.1     0.0202    0.00701     0.0414      0.066       0.01    0.00311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.94G      1.331      4.427       4.12      1.698         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0595      0.102     0.0197    0.00685     0.0432     0.0607    0.00981    0.00307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.94G      1.865      9.496      4.851      2.253          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0543        0.1     0.0196    0.00679      0.034     0.0554    0.00927    0.00296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.94G      1.587      3.478      4.718       1.81         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0593      0.095     0.0203    0.00676      0.039     0.0554    0.00921      0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0586     0.0923     0.0199    0.00704     0.0328     0.0554     0.0101    0.00318\n",
      "Speed: 1.2ms preprocess, 13.3ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñá‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñá‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñà‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÑ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.58674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.71848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.80962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.47786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.68923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.24224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.01643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_192808-p45xkbsv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_192808-p45xkbsv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0687     0.0813     0.0248    0.00992     0.0719     0.0623     0.0152    0.00567\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 4718.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.99G      2.944      3.726       4.97      2.611          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0521     0.0871     0.0172    0.00618     0.0434     0.0475    0.00663    0.00261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.58G      2.965      4.222      4.538      2.568          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0554     0.0818     0.0176    0.00605     0.0408     0.0528    0.00705    0.00251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.6G      2.884      3.537      5.319      2.222          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0496     0.0792     0.0171    0.00603     0.0392      0.058    0.00731     0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.59G      2.553      4.946      6.265      2.272          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0523     0.0871     0.0178    0.00607      0.043     0.0501    0.00671     0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.58G      1.986      5.324      7.182      2.795          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0503     0.0818     0.0182    0.00603     0.0392     0.0422    0.00676    0.00243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0538     0.0897     0.0177    0.00621     0.0434     0.0475    0.00653     0.0026\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÜ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÑ‚ñà‚ñÅ‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÑ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñÉ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñà‚ñá‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÖ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÑ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñá‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.98584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 7.18243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.79459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.32426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.0182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.08683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.68517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_193159-unzrpcc6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_193159-unzrpcc6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.052      0.117     0.0204    0.00675     0.0363     0.0542    0.00813    0.00273\n",
      "Speed: 1.3ms preprocess, 28.7ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 922.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.44G      1.957      4.195      4.435      1.921         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0588      0.095     0.0204    0.00719     0.0335     0.0528     0.0102    0.00319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.65G      2.017      4.381      4.784      1.973         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0604     0.0976     0.0204    0.00692     0.0373     0.0475    0.00959    0.00305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.56G      1.785      5.034      4.536      2.133         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0562     0.0976     0.0205    0.00706     0.0413      0.058    0.00988    0.00303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.54G      2.336      5.854      4.547      2.362         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0579        0.1     0.0207    0.00711     0.0401      0.058    0.00938    0.00301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.55G      1.913      4.804      4.932      2.299         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0579     0.0923     0.0198    0.00682      0.039     0.0528    0.00949    0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0576     0.0923     0.0205    0.00722     0.0338     0.0528     0.0102    0.00317\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÖ‚ñà‚ñÅ‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÖ‚ñÅ‚ñà‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñÑ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.91268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.93181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.29924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.80407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.9517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.01418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_193357-m9z2qdis\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_193357-m9z2qdis/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0715      0.084     0.0251     0.0102     0.0748     0.0705     0.0157    0.00596\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 773.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.62G      1.583      2.798      4.414      1.728          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0494     0.0871      0.017    0.00591     0.0462     0.0501    0.00653    0.00239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.57G      1.948      4.019      5.162      2.514          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0515     0.0818     0.0171     0.0059     0.0414     0.0528    0.00689    0.00233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.58G      1.383      8.706      6.231      1.914          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0491     0.0844     0.0168    0.00573     0.0438      0.066    0.00716    0.00237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.6G      1.569      3.667      6.464      2.126          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0488      0.103     0.0166    0.00562     0.0372     0.0554    0.00678    0.00217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       1.6G      1.064      4.071      4.141      1.637          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0495     0.0897     0.0168    0.00559     0.0395     0.0528    0.00655    0.00216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0494     0.0871     0.0168    0.00589     0.0491     0.0554     0.0066     0.0024\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñà‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÜ‚ñÉ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÑ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÇ‚ñà‚ñÉ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.0637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.1408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.07065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.03347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.06961\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.66446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_193750-08eqw4tq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_193750-08eqw4tq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0487      0.136       0.02    0.00648     0.0343     0.0434    0.00767    0.00254\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 957.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.65G      2.232      5.639      4.349       2.19         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0572     0.0897       0.02    0.00697     0.0337     0.0528     0.0101    0.00312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.42G      1.936      5.194      4.461      2.087         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0586      0.095     0.0203    0.00701     0.0401      0.058    0.00994    0.00311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.26G      2.226      6.015      4.862      2.178         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0597        0.1     0.0205    0.00703      0.042      0.058    0.00981    0.00311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.25G      1.804      4.228      4.497      2.039         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0577      0.111     0.0197    0.00688      0.037      0.058    0.00942    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.27G      1.705      5.256       4.78      1.892         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.061      0.108       0.02    0.00686     0.0353     0.0554    0.00961    0.00299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0584     0.0976     0.0203    0.00698     0.0411     0.0554     0.0096    0.00307\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÖ‚ñá‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñá‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñà‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñá‚ñÖ‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.70523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.78028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.89186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.25573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.02055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_193951-00itdril\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_193951-00itdril/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0723     0.0921     0.0256     0.0099     0.0565     0.0678      0.015    0.00573\n",
      "Speed: 1.3ms preprocess, 28.7ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1201.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       5.9G      1.589       4.89      3.408      1.843         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.055     0.0891     0.0183    0.00616     0.0463     0.0554    0.00694    0.00265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.705      7.225      3.297      2.205          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0575     0.0818     0.0179    0.00611     0.0487     0.0607    0.00756    0.00257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G      1.962      6.551      3.977      2.172          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0638     0.0871      0.019    0.00624     0.0445     0.0607    0.00782    0.00255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      2.321      4.908      4.819      2.338          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0634     0.0739     0.0195    0.00643     0.0482     0.0571      0.008    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.07G      2.514      5.892      3.732      2.473         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0722     0.0792     0.0196     0.0064     0.0506      0.058    0.00823    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0693     0.0765     0.0194    0.00641     0.0504      0.058    0.00813    0.00256\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñÜ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÖ‚ñá‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÜ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.51367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.73239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.47285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.89151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.01494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.09813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.65087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_194348-qqmensnw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_194348-qqmensnw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0601      0.122     0.0217    0.00713     0.0398     0.0678    0.00902    0.00294\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 938.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.15G      1.565      3.529       5.05      1.654         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0568     0.0897     0.0202    0.00709     0.0334     0.0528     0.0099     0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.08G      2.249      5.767       4.46      2.208         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0587     0.0923     0.0202    0.00701     0.0373     0.0554    0.00965    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      6.96G      1.912      6.373      4.036      2.114         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0589     0.0976     0.0203    0.00707     0.0396      0.058    0.00984    0.00316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      6.96G      2.325      6.506      4.949      2.433         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0599      0.108     0.0198    0.00683     0.0368     0.0554    0.00918      0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      6.94G      1.808      5.187      4.571      2.058         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0567        0.1     0.0198    0.00686     0.0354      0.058    0.00923    0.00298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0575      0.095     0.0204    0.00706     0.0416      0.058    0.00974    0.00316\n",
      "Speed: 1.4ms preprocess, 13.6ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñá‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÜ‚ñá‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÖ‚ñÇ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñá‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÑ‚ñÅ‚ñá‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.80846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.57091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.05815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.18737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.67127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.00512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_194553-01jyu74o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_194553-01jyu74o/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0734     0.0921     0.0246    0.00975     0.0651     0.0678     0.0151    0.00574\n",
      "Speed: 1.3ms preprocess, 28.7ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1794.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.78G      2.561      5.319      3.932      2.362         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0475     0.0765     0.0176    0.00611     0.0409     0.0475    0.00685    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.17G      2.474      7.836      4.331      2.311          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0506     0.0739     0.0174    0.00608     0.0435     0.0528    0.00708    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.07G      2.442      6.669      4.637      2.347         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.051     0.0765     0.0171    0.00599     0.0449      0.058     0.0073    0.00251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      2.219      5.156      3.812      2.321          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0589     0.0739     0.0179      0.006      0.045     0.0528    0.00781    0.00256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.11G      2.718      5.049      3.923      2.349         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0595     0.0844      0.018    0.00603     0.0431     0.0475    0.00747    0.00246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0595     0.0792     0.0179    0.00609     0.0468     0.0607    0.00804    0.00262\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñÉ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÅ‚ñÜ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.71772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.92305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.3494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.04871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.02916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.12782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.69804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_194957-gdh325m2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_194957-gdh325m2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.056      0.106     0.0201    0.00672     0.0461     0.0569    0.00844    0.00279\n",
      "Speed: 1.2ms preprocess, 28.8ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 1155.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.32G      1.927      4.835      4.425      2.009         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0587     0.0923     0.0201    0.00714     0.0335     0.0501    0.00994     0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.53G      1.961      5.108      4.138      2.061         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0584     0.0923     0.0201    0.00683     0.0397     0.0528    0.00957    0.00299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.45G      2.049      5.045      4.145      2.039         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0563     0.0923     0.0202    0.00693     0.0471     0.0528    0.00951    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.12G      1.605       4.86        3.8      1.889         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0548     0.0976       0.02    0.00709     0.0385     0.0607    0.00959    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.11G      1.758       4.28      4.493      1.892         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0591      0.111       0.02     0.0069      0.038     0.0554    0.00906     0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0569     0.0897       0.02    0.00711     0.0328     0.0501    0.00991    0.00309\n",
      "Speed: 1.4ms preprocess, 13.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÅ‚ñÉ‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÅ‚ñÜ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.75766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.49253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.89184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.28001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.94815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.68132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.00301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_195200-hkbv3n4v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_195200-hkbv3n4v/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0702     0.0867     0.0248     0.0101     0.0733     0.0705     0.0156    0.00585\n",
      "Speed: 1.2ms preprocess, 28.6ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1050.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.84G      2.057      6.556      3.369      1.984         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0609     0.0844     0.0176    0.00637     0.0481      0.058    0.00758    0.00278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.656       7.79      4.197      2.035          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.057     0.0739     0.0166    0.00593     0.0509     0.0528    0.00726    0.00245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G      2.402      5.829      4.864      2.186          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0508     0.0818     0.0179    0.00611     0.0485     0.0528    0.00702    0.00245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      2.851      7.075      4.343      2.793          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0539     0.0792     0.0163    0.00585     0.0446     0.0501    0.00646    0.00229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G      1.701      6.886       3.62      1.897          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0647     0.0792     0.0174    0.00588     0.0423     0.0501    0.00658    0.00219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0569     0.0818     0.0177    0.00633     0.0474     0.0554    0.00747    0.00275\n",
      "Speed: 1.2ms preprocess, 13.6ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñÇ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñÜ‚ñÖ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñà‚ñÅ‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñá‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.70121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.62024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.89699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 6.88616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.04412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.11976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.28023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.74173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_195605-ax7bdht7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_195605-ax7bdht7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0511      0.125     0.0206    0.00679     0.0343     0.0569    0.00781    0.00265\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 1028.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.38G      2.451      7.487      4.571      2.395          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0631        0.1     0.0198    0.00695     0.0399      0.058    0.00981     0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.61G       2.08      6.107      3.563      2.157          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0587      0.111     0.0194    0.00677     0.0374      0.058     0.0092    0.00296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.45G      2.099      8.208      5.166      2.278          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0611      0.121     0.0203    0.00696     0.0337     0.0607    0.00899    0.00291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.17G      2.354      5.347      4.631      2.645          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0646      0.113     0.0196     0.0067     0.0354     0.0554    0.00906    0.00289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.56G       2.51      7.829      5.773      2.608          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0627      0.106     0.0197    0.00673     0.0376     0.0633    0.00944    0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0611     0.0976     0.0198    0.00693     0.0398      0.058    0.00981    0.00308\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñÅ‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÉ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÅ‚ñÜ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÉ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.50952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.77261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.60791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 7.82949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.99492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.7094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.13285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_195806-itv0w9bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_195806-itv0w9bs/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0732     0.0894      0.025    0.00977      0.066      0.065     0.0149    0.00578\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 982.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.07G      2.164      4.408       3.79      2.108         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0499     0.0923     0.0176    0.00585     0.0374     0.0554    0.00706    0.00246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.18G      2.326      6.713      3.967      2.091         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0486     0.0897     0.0177    0.00579     0.0385     0.0528    0.00701     0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.07G        2.3      6.159      3.411      2.298         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0515     0.0897     0.0175    0.00589     0.0431     0.0528    0.00723    0.00238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.07G      2.444      5.372      3.792      2.408         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.049     0.0871     0.0163    0.00569     0.0438     0.0475    0.00694    0.00236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.13G      2.182      5.054      3.424      2.008         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0492     0.0792     0.0164    0.00571     0.0525     0.0501    0.00764    0.00244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0497     0.0923     0.0175    0.00583     0.0366     0.0554    0.00689    0.00247\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñà‚ñá‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÑ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÖ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñà‚ñÅ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00689\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.1824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.42354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.00805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.05379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.03115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.06648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.28354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.7754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_200210-bch0q3w3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_200210-bch0q3w3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0549      0.125     0.0213    0.00689     0.0381     0.0542    0.00825    0.00281\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 1168.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.46G      2.009      5.963       3.87      2.087         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0585      0.095     0.0194    0.00688     0.0359     0.0554    0.00991    0.00309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G      1.878      5.531      4.277       2.13         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0575      0.111     0.0199    0.00693     0.0387      0.058    0.00917    0.00304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.54G      1.796      5.141      3.918      1.867         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0662      0.113     0.0209    0.00717     0.0388      0.058     0.0095    0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.34G      1.894       4.87      3.975      1.983         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0572      0.106     0.0194    0.00653     0.0343     0.0633    0.00842    0.00279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G      1.885      5.127       4.43      1.997         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0538     0.0844     0.0196    0.00657     0.0354     0.0528    0.00934    0.00288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0664      0.113     0.0208    0.00712     0.0382      0.058     0.0095    0.00299\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñÖ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñà‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÜ‚ñÇ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñà‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÜ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.88512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.43037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.99716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.68576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.24813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.08276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_200412-lpabqeh5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_200412-lpabqeh5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0712     0.0921     0.0246    0.00915     0.0698     0.0596      0.015    0.00535\n",
      "Speed: 1.4ms preprocess, 29.3ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 4721.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.01G      2.074      4.782      4.105      2.104         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0599     0.0844     0.0171    0.00586     0.0436      0.058    0.00714     0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.14G      1.507      4.538      4.042      1.866          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0522     0.0897     0.0174    0.00592     0.0409      0.058    0.00709    0.00236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      2.402      6.768      4.649      2.608          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0532     0.0818      0.017    0.00597      0.039     0.0554    0.00692    0.00245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.02G      2.707      6.176      4.965      2.727          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0499     0.0844     0.0166    0.00579     0.0482     0.0528     0.0067    0.00238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.05G      1.951      5.078      4.009      1.936          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0509     0.0897     0.0172    0.00589     0.0454     0.0475    0.00721    0.00251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0531      0.095     0.0172    0.00591     0.0463     0.0475    0.00717    0.00252\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÑ‚ñÇ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñÅ‚ñÜ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñÅ‚ñá‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.0463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.95134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.00863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.93586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.07843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.99742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.03041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.26233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.62737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_200816-mysq71qh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_200816-mysq71qh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0647     0.0759     0.0202    0.00677     0.0551     0.0623    0.00995    0.00325\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 1200.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.01G      2.121      5.121      3.908      2.093         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0613        0.1     0.0196     0.0068     0.0366     0.0554    0.00996    0.00307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G      1.967      5.051      3.995      2.081         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0559      0.108     0.0198    0.00696     0.0411     0.0607    0.00929    0.00298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.09G      1.812      5.709      3.951      2.012         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0589      0.116     0.0198    0.00675     0.0342      0.058    0.00862     0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.5G      1.928      4.832      4.045       1.97         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0618      0.119     0.0197    0.00678     0.0374      0.066    0.00878    0.00283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.45G       1.67      5.101       3.99      1.867         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0566     0.0976      0.019    0.00652     0.0381     0.0633    0.00888    0.00292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0556      0.106     0.0197    0.00699     0.0375      0.061    0.00933    0.00298\n",
      "Speed: 1.1ms preprocess, 13.3ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñà‚ñà‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñá‚ñÅ‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÖ‚ñÉ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÖ‚ñÉ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.66953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.98972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.86674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.10129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.9702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.09153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_201018-s1wvi9gv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_201018-s1wvi9gv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0703     0.0949     0.0257       0.01     0.0594      0.065     0.0151    0.00566\n",
      "Speed: 1.4ms preprocess, 28.8ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 860.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.93G      1.202      2.756      4.167      1.539          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0555     0.0792     0.0175    0.00583     0.0525      0.058    0.00729    0.00243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.14G      1.622      4.198      5.842      2.051          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0546     0.0686     0.0168    0.00569     0.0459     0.0554    0.00748    0.00248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G      2.128      4.021      5.345      2.179          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.056     0.0739     0.0158    0.00571     0.0404     0.0501    0.00659    0.00224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      2.524      6.339      6.637      2.139          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0522     0.0765     0.0157    0.00557     0.0335     0.0475    0.00629    0.00214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G      2.275      5.123      4.703      1.741          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0523     0.0818      0.016    0.00549     0.0417     0.0475    0.00627    0.00214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0559     0.0792     0.0172    0.00579     0.0537      0.058    0.00731    0.00246\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñà‚ñÉ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñà‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñá‚ñÜ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñá‚ñà‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.07916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.27456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.7032\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.7413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.12302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.01741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.05262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.27588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.70533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_201421-0zqf8m14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_201421-0zqf8m14/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.052        0.1     0.0191    0.00632     0.0416     0.0542     0.0074    0.00258\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 934.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.09G      1.895        5.3      4.057      2.037         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0598      0.095     0.0202    0.00698      0.039      0.058       0.01    0.00309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.59G      1.995      4.789      4.154      2.092         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0539        0.1     0.0199    0.00697     0.0381     0.0607    0.00948    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.1G      1.935      5.337      4.092      2.059         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0585      0.119     0.0199    0.00701      0.036      0.066    0.00888     0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.2G       1.97      5.402      3.798      2.054         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0648      0.103     0.0198    0.00672     0.0365     0.0572    0.00901    0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.878      4.854      3.767      1.981         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0653      0.106     0.0192    0.00647     0.0398     0.0528    0.00951    0.00299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0619      0.103     0.0204    0.00698     0.0372     0.0554    0.00985    0.00305\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñá‚ñà‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñá‚ñÅ‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÑ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñá‚ñÅ‚ñá‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.1029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.87841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.76734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.98098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.85371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.98681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.26939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.07285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_201621-njouqvfb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_201621-njouqvfb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0762     0.0921     0.0248    0.00989     0.0679     0.0705     0.0152    0.00583\n",
      "Speed: 2.1ms preprocess, 28.7ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 1051.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.07G      2.254      5.374      4.682      2.094          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0555     0.0871     0.0182    0.00599     0.0435     0.0554    0.00713    0.00249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.14G      2.025      5.815      5.612      2.109          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0613      0.095     0.0179    0.00585     0.0412     0.0554    0.00713    0.00243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.03G       1.54      5.435      3.602      1.917          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0545     0.0871      0.018    0.00593     0.0406      0.058    0.00752    0.00241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.03G      2.102      6.684      5.481      2.374          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0568     0.0818      0.018     0.0059     0.0404     0.0528    0.00708    0.00233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.05G      1.857      5.142      3.972      2.063          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.058     0.0886     0.0183    0.00598     0.0466     0.0529    0.00709    0.00241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0564     0.0871     0.0181    0.00595     0.0434     0.0554    0.00709    0.00249\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÅ‚ñÖ‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÅ‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÖ‚ñà‚ñÅ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÑ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.85672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.97218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.06301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.14196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.03935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.00591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.28301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.71732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_202026-hmajd4fr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_202026-hmajd4fr/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0563      0.122     0.0204    0.00657     0.0389      0.065    0.00772    0.00259\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:00<00:00, 1208.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.881      5.102      4.156       1.95         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0618        0.1     0.0202    0.00693     0.0393     0.0607     0.0101     0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.52G      1.673      5.059      4.107      1.951         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.055      0.108       0.02    0.00698       0.04     0.0607    0.00942    0.00311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.13G      1.913      5.546       4.19      2.108         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0602      0.116     0.0198    0.00684     0.0365     0.0686    0.00911    0.00291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.2G      1.695      4.036      3.948      1.837         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.059      0.113     0.0197    0.00686     0.0378     0.0607    0.00955    0.00298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.837      5.093      4.217      1.918         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0615      0.095     0.0206    0.00738     0.0393     0.0607     0.0106    0.00347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0637      0.095     0.0206    0.00739     0.0389      0.058     0.0108    0.00351\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñá‚ñà‚ñÅ‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñÅ‚ñà‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñÖ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÅ‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.8371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.2166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.91845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.09292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.95944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.69087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.24968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.02231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_202225-wxuk0xyd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_202225-wxuk0xyd/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0787      0.122     0.0272     0.0103     0.0604     0.0813     0.0159    0.00555\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 3070.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.05G      2.366      6.745      3.765      2.365         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0715     0.0923     0.0219    0.00749     0.0606     0.0633       0.01    0.00339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.11G      1.963      7.624      3.923      1.997         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.082     0.0871     0.0218    0.00742     0.0592     0.0712       0.01    0.00333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      2.365      6.419      4.189      2.508          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.085     0.0923     0.0222    0.00764     0.0583     0.0633    0.00986    0.00334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.972      4.983      3.899      1.967         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0869     0.0897     0.0222    0.00761     0.0574     0.0528    0.00968    0.00331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.841      5.867       4.55      1.949         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0735     0.0818     0.0211    0.00726     0.0577     0.0475    0.00937    0.00319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0823     0.0923     0.0223    0.00762     0.0565     0.0633    0.00988    0.00338\n",
      "Speed: 1.8ms preprocess, 13.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÅ‚ñá‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñà‚ñÖ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÉ‚ñÅ‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÜ‚ñá‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñà‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÉ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÇ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.08234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.84114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.55038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.94876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.8674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.99306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 5.01642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.50515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_202631-t2xa4xfq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_202631-t2xa4xfq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0583      0.111     0.0231    0.00764     0.0397     0.0623     0.0104    0.00336\n",
      "Speed: 1.3ms preprocess, 28.8ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:00<00:00, 1071.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.04G      1.871      5.413       3.87      1.999         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.056     0.0976     0.0203    0.00702     0.0365      0.058    0.00965    0.00305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G       1.81      5.781      4.054       1.99         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0605      0.103       0.02    0.00692      0.035      0.058    0.00915    0.00288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.26G      1.926      5.728      3.897      2.061         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0636      0.116     0.0199    0.00676     0.0429     0.0712     0.0095    0.00298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.31G      1.944      4.635      4.182      2.051         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.057     0.0923     0.0181    0.00644     0.0326     0.0528    0.00882    0.00296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.755      5.161      3.798       1.84         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0616        0.1     0.0191    0.00653     0.0373     0.0633     0.0101    0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0598        0.1       0.02    0.00696     0.0365      0.058    0.00966    0.00303\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñá‚ñá‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÑ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñá‚ñÖ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÅ‚ñÖ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÑ‚ñÉ‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÑ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÜ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñá‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñá‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.03655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.75504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.79823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.83983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.16135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.92441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.43041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.97512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_202832-28ls1706\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_202832-28ls1706/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0752      0.096     0.0258    0.00997     0.0743     0.0705     0.0156     0.0058\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 644.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.09G      1.337      5.407      3.476      1.788         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0598     0.0897     0.0176    0.00612     0.0443     0.0528     0.0077    0.00242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      1.898      4.994      3.661      2.137         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.055      0.095     0.0174    0.00616     0.0396      0.058    0.00739    0.00237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.457      5.146      3.563      1.838         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0548     0.0923      0.017    0.00612     0.0344      0.058    0.00729    0.00236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.906      4.027      3.522      2.154         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0523     0.0818     0.0169    0.00605     0.0331     0.0554    0.00726    0.00231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.05G      1.284      3.925      3.213      1.681         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0494     0.0844     0.0158    0.00593      0.032     0.0501    0.00696     0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0585     0.0897     0.0176    0.00617     0.0418      0.058    0.00775    0.00244\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÑ‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñá‚ñà‚ñÅ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.28448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.21344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.68066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.9249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.97444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.44532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_203245-80uzrsd7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_203245-80uzrsd7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.054     0.0949      0.021    0.00669     0.0543     0.0461    0.00852    0.00284\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<00:00, 1356.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.34G      1.876      5.537      4.194      1.966         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0576     0.0976     0.0201    0.00693     0.0431     0.0475    0.00945    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.53G      1.865      4.972      4.167       1.96         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0585      0.113     0.0198    0.00692     0.0352      0.058    0.00903    0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.5G      1.853      5.786      3.675      1.977         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0679      0.095     0.0204    0.00731     0.0422     0.0686     0.0105    0.00314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.683      4.735      3.775      1.809         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0881     0.0871     0.0264    0.00985     0.0612     0.0633     0.0153    0.00513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.54G      1.688      4.062      3.788      1.852         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.089      0.106     0.0296     0.0112     0.0732     0.0633     0.0195    0.00652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0902      0.106     0.0294     0.0112      0.072     0.0633     0.0198    0.00653\n",
      "Speed: 1.9ms preprocess, 13.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñà‚ñá‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñà‚ñÅ‚ñÇ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñá‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñá‚ñÖ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.07197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.7884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.85176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.06156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.40527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.17277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.81398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_203445-mcpb64r0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_203445-mcpb64r0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0984      0.125      0.037     0.0152     0.0842     0.0867     0.0264    0.00951\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 870.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.93G      1.348      4.528      2.557      1.706         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0658      0.108     0.0222    0.00777     0.0491     0.0739     0.0125    0.00387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G       1.81      4.326      3.158      2.031         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0648      0.103     0.0222    0.00757     0.0524     0.0686     0.0126    0.00362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.05G      1.257      5.044      2.771      1.638         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0627     0.0897     0.0219    0.00743     0.0547     0.0712     0.0119    0.00363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.983      4.626       3.02      2.059         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0564     0.0844      0.021    0.00727     0.0537     0.0712      0.012    0.00366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G       1.24       4.64      2.553      1.557         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0575     0.0844     0.0209    0.00727     0.0558     0.0686     0.0123    0.00383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0647      0.109     0.0223     0.0078     0.0502     0.0739     0.0126    0.00377\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñà‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñá‚ñà‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñá‚ñÜ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÅ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñÜ‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÑ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÅ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.06467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.24038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.55302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.55661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.97426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.7578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.21358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.12024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_203901-pku6zw96\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_203901-pku6zw96/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0798      0.144     0.0298     0.0101     0.0666      0.103     0.0173     0.0053\n",
      "Speed: 0.9ms preprocess, 29.0ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:00<00:00, 1359.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.1G       1.77       5.64      3.552      1.969         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0566        0.1     0.0197    0.00696     0.0403      0.058     0.0098    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.24G      1.927      4.841      3.936      1.991         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0589      0.113     0.0199    0.00697     0.0348     0.0554    0.00906    0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.6G      1.622      4.823      3.663      1.872         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0647      0.111     0.0207    0.00711     0.0408     0.0795    0.00958    0.00308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.68G      1.792      5.163      3.707      1.951         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0663      0.103     0.0226    0.00818     0.0468     0.0686     0.0124    0.00411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.765      5.038      3.579      1.976         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0768      0.116      0.028     0.0107     0.0536     0.0844     0.0161    0.00569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0776      0.116     0.0277     0.0106     0.0542     0.0844      0.016    0.00565\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñÜ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñá‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñà‚ñÅ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñà‚ñÅ‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÅ‚ñÅ‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñá‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÖ‚ñà‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.76509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.57859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.97612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.03755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.90173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.42326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.20069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.86137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_204101-bovw6nn6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_204101-bovw6nn6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.104      0.111     0.0334     0.0126     0.0914     0.0976     0.0219    0.00695\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1775.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.98G       1.59      3.337      3.753      1.586         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0829     0.0976     0.0274    0.00959     0.0612     0.0765     0.0139    0.00462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.17G      2.124      5.613      3.821      2.052         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0835      0.095     0.0264    0.00944     0.0579     0.0704     0.0135    0.00464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      2.519      4.722      4.336      2.481         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0779        0.1     0.0256    0.00937     0.0623     0.0818     0.0151    0.00479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.05G       1.89      4.316      3.789      1.913         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0748     0.0897     0.0249    0.00926     0.0629     0.0818     0.0153    0.00479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.05G      2.077      3.784      3.894      1.997         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0867        0.1     0.0263    0.00913     0.0613     0.0712      0.015     0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0827     0.0976     0.0276    0.00968      0.067     0.0765     0.0139    0.00463\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÅ‚ñà‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñà‚ñÉ‚ñÅ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÖ‚ñÅ‚ñà‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñá‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñá‚ñá‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñá‚ñÇ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.07744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.89381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.99711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.78367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.92012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.67201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.18805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.16184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_204519-hl8wbmo9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_204519-hl8wbmo9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0716      0.127     0.0301    0.00959     0.0485     0.0759      0.015    0.00466\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:00<00:00, 1021.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.43G       1.79      5.668      3.794      1.926          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0576      0.111       0.02    0.00693     0.0405     0.0607    0.00922    0.00296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.5G      2.019      5.477      3.971      2.178          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0567      0.103     0.0195    0.00681     0.0363      0.066     0.0089    0.00284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.27G      1.649      4.401      3.732      1.811          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0694     0.0976     0.0212    0.00828     0.0476     0.0633      0.013    0.00434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.23G      1.627      4.231      3.522      1.806         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0798      0.121     0.0279     0.0102      0.059     0.0765     0.0135    0.00418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.688      3.992      3.502      1.855         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.083      0.113     0.0322     0.0125     0.0597     0.0765     0.0168    0.00606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0822      0.113     0.0318     0.0125     0.0578     0.0742     0.0169    0.00603\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñÉ‚ñÅ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñá‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.08224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.07419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.50169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.85511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.99153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.03041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.34338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.18834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_204718-7favp1im\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_204718-7favp1im/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.113      0.117     0.0421     0.0172     0.0982     0.0813     0.0242    0.00945\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 7484.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.41G      1.938      4.727      3.503      2.092         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.055      0.113     0.0213    0.00712      0.035     0.0739     0.0081    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      2.244      5.119      3.686      2.192         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0546      0.105      0.022    0.00746     0.0337      0.066    0.00865    0.00318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.538      4.669      3.654      1.782         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0596      0.111     0.0235     0.0078      0.032     0.0607    0.00916    0.00336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         3G      1.936      5.216      3.414      2.165         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0563      0.111     0.0229    0.00767     0.0287     0.0554    0.00874    0.00332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.05G      1.835      4.251      3.017      1.804         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0555      0.119     0.0231    0.00775     0.0312     0.0607     0.0088    0.00329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0584      0.111     0.0235    0.00769       0.03      0.058    0.00894     0.0033\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÑ‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñà‚ñÅ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñà‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÑ‚ñà‚ñÅ‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.02999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.83548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.01682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.80416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.25053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.02212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.69902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.93298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_205136-f1ii4g14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_205136-f1ii4g14/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0964      0.125      0.033     0.0106     0.0847     0.0786     0.0156    0.00505\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 1155.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.38G      1.804      4.864      3.831      2.003         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.057      0.103     0.0203    0.00704     0.0371     0.0607    0.00944    0.00304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.27G      1.786      5.295      3.761      1.948         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0614      0.095     0.0211    0.00717     0.0354     0.0528     0.0102    0.00332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.25G       1.71      5.059      3.509      1.886         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0781     0.0897     0.0253    0.00979     0.0576     0.0633     0.0145    0.00555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.27G       1.73      4.426      3.383      1.922         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.104      0.127     0.0345     0.0144     0.0818     0.0897     0.0235    0.00911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.62G      1.767      3.714      3.388      1.837         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.117      0.127     0.0382     0.0159     0.0978      0.104     0.0271     0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.117      0.127     0.0382     0.0158     0.0971      0.103     0.0272     0.0105\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÇ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÅ‚ñÉ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.11692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.09708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.1029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.76705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.38802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.83717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.71415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.92381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.16441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.75263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_205339-s2lluu95\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_205339-s2lluu95/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.126       0.16     0.0508      0.021      0.104      0.117     0.0337     0.0128\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 5558.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.51G      1.724      3.868      3.886      1.856         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0864      0.129     0.0296     0.0111     0.0605      0.108     0.0168    0.00608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      1.352       3.95      3.173      1.501         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0837      0.142     0.0297     0.0112     0.0617      0.108     0.0167    0.00612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.729      4.168      3.888      2.031         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0766      0.132     0.0282     0.0112     0.0536        0.1     0.0167    0.00625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G      1.591      3.525      4.157      1.691          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0806      0.129     0.0294     0.0116     0.0569      0.095     0.0178    0.00655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         3G      1.695      4.695      5.352       1.93          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0772      0.127     0.0297     0.0118     0.0588        0.1     0.0187    0.00683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0755      0.124     0.0295     0.0117     0.0572     0.0976     0.0182     0.0068\n",
      "Speed: 1.2ms preprocess, 13.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñà‚ñÅ‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñá‚ñà‚ñÅ‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÅ‚ñà‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñÅ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.69535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.35248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.92989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.69527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.90711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.25169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.18637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.05644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_205756-zf0f9qj5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_205756-zf0f9qj5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0996      0.122     0.0419     0.0151      0.102     0.0867      0.026    0.00846\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 [00:00<00:00, 1241.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.99G      1.773      5.166      3.859       1.94         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.054        0.1     0.0201    0.00697     0.0366     0.0607    0.00939    0.00299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.2G      1.871      5.737      3.868       2.05         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0551      0.111     0.0196    0.00671     0.0357     0.0607    0.00909    0.00292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.38G      1.809      5.103      3.928      1.998         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0642     0.0818     0.0215    0.00758     0.0415     0.0633     0.0124     0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.36G       1.52      3.718       3.52      1.735         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0919     0.0923     0.0286     0.0104     0.0706      0.066     0.0176    0.00591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.631      4.036      3.134      1.798         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.117     0.0987     0.0361     0.0136      0.104     0.0818     0.0245    0.00846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.12      0.108     0.0361     0.0137      0.103     0.0818     0.0245    0.00854\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñà‚ñÅ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñá‚ñá‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.12023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.10287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.63089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.13352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.79832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.03593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.9873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.9903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.26547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.78197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_205958-r3ghw4w6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_205958-r3ghw4w6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.161      0.125     0.0488     0.0201      0.123     0.0949     0.0322     0.0108\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 936.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.63G      2.394      5.981      3.351      2.439         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0925      0.119     0.0288     0.0104     0.0658     0.0844      0.017    0.00554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.19G      1.976      4.862      3.357      1.895         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0955      0.124     0.0291     0.0104     0.0644     0.0825     0.0165    0.00552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      2.182      5.132      3.786       2.19         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0968      0.121     0.0298     0.0103      0.063     0.0844     0.0161    0.00561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         3G      2.056      4.663      3.632      2.164         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0928      0.116     0.0285     0.0101     0.0707     0.0871     0.0164    0.00569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.08G      2.118       4.55      3.356       1.95         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0818      0.111     0.0282     0.0101     0.0766     0.0923     0.0175    0.00592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0814      0.111     0.0284     0.0102     0.0742     0.0897     0.0175    0.00593\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÅ‚ñÖ‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.02837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.01753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.08141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.07417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.11758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.35592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.95008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.55005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.02862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.26794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.2901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.14643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_210418-z4wovqqu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_210418-z4wovqqu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.127      0.171     0.0466     0.0176     0.0867      0.117      0.023    0.00835\n",
      "Speed: 1.2ms preprocess, 28.8ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:00<00:00, 1180.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.37G      1.853      5.351      4.118      1.969          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0601      0.113     0.0199    0.00698      0.037     0.0607    0.00948    0.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.24G      1.738      4.863      3.675      1.831         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0587        0.1     0.0184    0.00643      0.034     0.0449    0.00861    0.00283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.27G      1.645      4.499      3.835      1.824          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0606     0.0739     0.0251    0.00871     0.0471     0.0619     0.0139    0.00446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G      1.771      4.564      3.471      1.982          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0935     0.0923     0.0339     0.0134     0.0774     0.0779     0.0227     0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G      1.562      3.691      3.181      1.779          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.095      0.129     0.0382     0.0169     0.0824        0.1     0.0283     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0953      0.129     0.0384     0.0169     0.0834        0.1     0.0284     0.0116\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÉ‚ñÉ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.09533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.08339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.56187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.18146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.77881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.69056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.8949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.76789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.16626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.77163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_210617-yvlorxto\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_210617-yvlorxto/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.151       0.13     0.0613     0.0261      0.141      0.111     0.0449     0.0184\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 850.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.08G      1.463      3.685      3.769      1.899         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0787      0.119     0.0364     0.0139     0.0715     0.0897     0.0228    0.00879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      1.932      3.784      3.743      1.996         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0887      0.142     0.0367     0.0149     0.0745     0.0923      0.023    0.00903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G       1.44       3.04      3.523      1.677         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0903       0.14     0.0369     0.0149     0.0809      0.106     0.0238    0.00956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.346       3.27      3.978      1.717         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0945      0.148     0.0356     0.0145     0.0814      0.106     0.0245    0.00926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.693      4.922      3.717       1.95         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0922      0.145     0.0348     0.0144     0.0793      0.113     0.0241    0.00917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.096      0.139      0.037     0.0148     0.0806      0.103     0.0248    0.00958\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñà‚ñà‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÖ‚ñÑ‚ñÅ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.09601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.08063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.1029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.69334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.71709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.94958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.92152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.84318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.95127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.13183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.98892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_211037-1sk745jx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_211037-1sk745jx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.114       0.16     0.0418     0.0155     0.0863      0.118     0.0259     0.0095\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71/71 [00:00<00:00, 1041.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.02G      1.869      5.648       4.08      1.956         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0583      0.113     0.0199    0.00674      0.039     0.0607    0.00896    0.00291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G      1.907      4.953       3.85       1.96         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.064      0.103     0.0202    0.00731     0.0396     0.0686     0.0109    0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.36G       1.66      4.576      3.687      1.856         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.119      0.119     0.0367     0.0134     0.0713     0.0712     0.0163     0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.38G      1.674      4.012      3.415      1.825         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.129      0.129     0.0421      0.016     0.0949     0.0871     0.0226    0.00794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.699      4.253       3.32      1.818         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.144      0.127     0.0495     0.0199      0.121      0.111     0.0305      0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.145      0.127     0.0496     0.0198      0.122      0.111     0.0303      0.012\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñà‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.04957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.03032\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.1447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.12192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.11082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.69898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.31998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.81778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.25335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.96939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.83896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.25019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.87494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_211238-i47sti38\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_211238-i47sti38/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.153      0.171     0.0616     0.0232      0.114      0.119     0.0377     0.0131\n",
      "Speed: 1.4ms preprocess, 29.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1215.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.02G       1.49      4.097      3.048      1.707         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.077      0.116     0.0326     0.0124     0.0525     0.0686     0.0168    0.00577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.16G      1.972      5.907      3.037      2.113         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0766      0.106     0.0331     0.0127     0.0536     0.0739     0.0186    0.00667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.619      4.348      3.374      1.794         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0807      0.116      0.034     0.0133     0.0609     0.0739     0.0204    0.00699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.04G      1.363      4.584      3.049      1.717         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0823      0.108     0.0352     0.0141      0.058     0.0712     0.0213    0.00747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.07G      2.525       5.13      3.564      2.257         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0875      0.128     0.0355     0.0143     0.0654     0.0818     0.0222    0.00784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.089      0.129     0.0356     0.0145     0.0651     0.0844     0.0223    0.00786\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÉ‚ñÖ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.02226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.08899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 2.52506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.56401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.25675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 5.12956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.93641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.08902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.23703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.21128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_211702-x2g21ucf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_211702-x2g21ucf/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369     0.0997      0.152     0.0429     0.0157     0.0887     0.0921     0.0256    0.00801\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76/76 [00:00<00:00, 1154.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         8G      1.863      5.478      4.154      2.066         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0591      0.116     0.0195    0.00682     0.0397      0.066     0.0094    0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.26G       1.91      5.357      3.607      1.994         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0674     0.0923     0.0222    0.00815      0.052     0.0633     0.0131    0.00433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.5G      1.782      4.867      3.738      1.957         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0862        0.1     0.0267    0.00985     0.0658     0.0765     0.0173    0.00588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.59G      1.701      4.214      3.342       1.87         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.115      0.103     0.0342     0.0138     0.0946     0.0844     0.0225    0.00828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.677      4.076       3.29      1.855         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.142      0.116      0.046     0.0191      0.122        0.1     0.0347     0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.141      0.116     0.0456      0.019      0.129      0.108     0.0341      0.013\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñá‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.04563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.03406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.14138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.12916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.11609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.67708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.29046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.85479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.07556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.97283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.73005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.22161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.85269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_211905-fzfg285g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_211905-fzfg285g/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.153      0.136     0.0565     0.0226      0.123      0.106     0.0386     0.0142\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 972.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.98G      1.016      3.613      3.174      1.534         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0664      0.095      0.025    0.00986     0.0643     0.0844     0.0176    0.00617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      1.821      4.749      3.041      1.896         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0701     0.0976     0.0258     0.0104      0.063     0.0844     0.0185    0.00653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.732      3.728        2.9      1.906         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0761      0.101     0.0282     0.0108       0.07     0.0897     0.0194    0.00692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G       1.59      4.526      3.494      2.022         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0774        0.1     0.0294     0.0113     0.0642     0.0844     0.0197    0.00714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.385      4.086       2.99      1.755         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0763      0.103     0.0302     0.0119     0.0607     0.0818       0.02    0.00748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0797      0.106     0.0304      0.012     0.0638     0.0844     0.0202    0.00748\n",
      "Speed: 1.2ms preprocess, 13.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÇ‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.03041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.01197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.07973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.06378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.10554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.38529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.9905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.75503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.08637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.02457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.98348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.24042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.16482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_212326-zwutd50l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_212326-zwutd50l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.117      0.125     0.0419     0.0146      0.101     0.0921     0.0264    0.00867\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:00<00:00, 1057.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.06G      1.904      5.839      3.714      1.965          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0599      0.119     0.0194    0.00673     0.0359     0.0613    0.00879    0.00296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.33G       1.98       5.48      3.562      1.979          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.07     0.0976      0.024    0.00965     0.0473      0.066     0.0149    0.00553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.39G       1.65      4.309      3.549      1.834          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.127      0.124     0.0462     0.0197     0.0997     0.0976     0.0307     0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.34G      1.454      3.461       3.13      1.675          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.176      0.169     0.0642     0.0294      0.154      0.145     0.0451     0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.573      3.618      3.055      1.719          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.214      0.216     0.0907     0.0455      0.198      0.198     0.0745     0.0314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.213      0.216     0.0906     0.0448      0.193      0.195     0.0716     0.0309\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñÜ‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñà‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.09062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.07163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.03086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.2126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.19322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.21636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.19525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.57253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.05519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.7192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.61771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.47505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.16024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.63976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_212526-d2tld52g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_212526-d2tld52g/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.228      0.223      0.122     0.0583      0.219      0.201      0.101     0.0432\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 537.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.97G      1.262      4.288      2.656       1.89         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.173      0.224     0.0824     0.0366      0.159      0.193     0.0632     0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      1.903      3.847      2.849      2.293         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.172      0.231     0.0843     0.0369      0.162      0.187     0.0617     0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.05G      1.666      3.748      2.795      1.816         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.163      0.248     0.0821     0.0378      0.149      0.208     0.0639      0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G       1.31      3.302      2.334      1.756         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.165      0.252     0.0858       0.04      0.147      0.206     0.0686     0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.06G      1.647       3.81      3.074      1.768         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.159      0.222     0.0885     0.0413      0.143      0.195     0.0715     0.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.161      0.231     0.0887     0.0413      0.146      0.201     0.0712     0.0304\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñà‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÉ‚ñÅ‚ñà‚ñá‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÅ‚ñà‚ñÖ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.07125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.03035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.16072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.14554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.23141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.20053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.64658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.07431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.76839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.80983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.85189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.67132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.15858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.70536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_212950-9pjbxqak\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_212950-9pjbxqak/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.206      0.244      0.116     0.0482      0.187      0.192     0.0877     0.0351\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86/86 [00:00<00:00, 1123.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.42G      1.836      5.243      3.672      1.957         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.062      0.106     0.0202    0.00721     0.0362     0.0607    0.00941     0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.36G       1.86      5.069      3.671      1.999         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0726      0.095     0.0248    0.00884     0.0487     0.0607     0.0134    0.00457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.24G      1.608      4.102      3.594      1.844         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.137       0.12     0.0427     0.0182      0.115     0.0923     0.0313     0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.31G      1.593      3.899      3.061      1.777         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.142       0.12     0.0543     0.0244      0.129     0.0976     0.0453     0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G      1.547       3.81       3.07      1.785         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.193      0.182     0.0778      0.037      0.169       0.15     0.0647     0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.19      0.182     0.0776     0.0371      0.166      0.148     0.0646     0.0287\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñà‚ñá‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.07761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.06459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.19016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.16647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.18206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.14807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.54748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.06982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.78507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.81001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.75444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.34776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.04106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.50149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_213153-47bvwehw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_213153-47bvwehw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.202      0.184      0.105     0.0499      0.196      0.163      0.086     0.0376\n",
      "Speed: 1.3ms preprocess, 29.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1212.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       5.7G      1.526       4.06      2.923      1.747         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.131       0.19     0.0639     0.0286      0.124      0.172     0.0517     0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G      1.369      4.017       2.96      1.851         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.137      0.198     0.0635     0.0288      0.121      0.148     0.0508      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.344      4.523      3.073      1.894         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.128      0.177      0.063     0.0284       0.12      0.145     0.0503      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.424      5.917      2.933      1.954         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.128       0.17     0.0618     0.0284      0.127      0.153     0.0513     0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.814      4.212      3.205      2.063         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.136      0.174     0.0623     0.0286      0.122      0.146     0.0501     0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.13       0.19     0.0642     0.0287      0.122      0.172     0.0518     0.0214\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÉ‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÅ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÖ‚ñÇ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñá‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.06422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.05175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.13039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.12212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.18997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.1715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.81405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.20497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.06312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.21177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.7625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.57031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.0109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.68123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_213618-bwdiong2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_213618-bwdiong2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.142      0.179     0.0761     0.0336      0.127      0.141     0.0623     0.0246\n",
      "Speed: 1.4ms preprocess, 28.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91/91 [00:00<00:00, 1023.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.56G       1.96      5.465      3.803      2.068         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0586      0.108     0.0202    0.00703      0.036     0.0633    0.00922    0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G      1.874      5.552      3.738      2.046         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0802     0.0923      0.024    0.00907     0.0501     0.0528     0.0139     0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.22G      1.707      4.497      3.275      1.931         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.149        0.1     0.0421     0.0173      0.136     0.0897     0.0336     0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.534      3.823      3.069      1.726         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.184      0.136     0.0657     0.0307      0.182      0.129     0.0564     0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.29G      1.425      3.602      2.824      1.673         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.176      0.158     0.0789     0.0378      0.176      0.145     0.0661     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.177      0.158     0.0787     0.0378      0.169       0.14     0.0662     0.0271\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñà‚ñá‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.07873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.06618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.1694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.15831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.13984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.42501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.82396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.67259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.60213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.91078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.41729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.16694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.75031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_213817-6j16d5vu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_213817-6j16d5vu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.229      0.209      0.107     0.0482      0.219      0.183     0.0837     0.0344\n",
      "Speed: 1.3ms preprocess, 29.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 740.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.41G      1.325      2.812      2.822      1.712         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.145      0.174     0.0674     0.0296      0.121      0.127     0.0471     0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.12G     0.9653      2.657      2.907      1.378         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.14      0.182     0.0668       0.03      0.105      0.127     0.0456     0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         3G      1.126      3.458      3.512       1.47          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.141      0.187     0.0655     0.0303       0.11      0.137     0.0465     0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.101      3.862      2.671      1.605         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.138      0.187      0.065     0.0297      0.113      0.142     0.0478     0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G       1.28      3.517      2.826      1.601         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.132      0.185     0.0665     0.0307      0.114      0.145     0.0486     0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.128      0.193     0.0659     0.0306      0.114      0.148     0.0487     0.0209\n",
      "Speed: 1.1ms preprocess, 13.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.06588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.02094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.12833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.11379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.19261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.14776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.28026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.82632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.60097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.51658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.91436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.60192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.14797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.00329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_214241-doeurrr6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_214241-doeurrr6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.159      0.211     0.0871     0.0406      0.156      0.165     0.0688     0.0283\n",
      "Speed: 1.2ms preprocess, 28.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:00<00:00, 1081.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G      1.751      5.374      3.766      1.985         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0564      0.113     0.0199    0.00698     0.0349      0.066    0.00889    0.00293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.62G      1.734      5.124      3.552      1.944         59        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.102      0.106     0.0317     0.0121     0.0729     0.0712     0.0165    0.00566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.6G      1.672      4.409      3.337      1.904         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.105      0.111     0.0389     0.0148     0.0866     0.0712     0.0241    0.00873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.539      3.667      3.036      1.773         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.132      0.113     0.0518     0.0238       0.13      0.095     0.0359     0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.31G      1.516      3.775      2.838      1.752         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.178      0.172     0.0894     0.0443      0.166      0.153     0.0727     0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.174      0.172     0.0888     0.0442      0.166      0.153     0.0723     0.0324\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñá‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.08882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.07231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.03238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.16639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.1715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.15273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.51646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.83835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.75164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.7748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.87248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.32272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.08432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.88416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_214442-7xqbpx1o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_214442-7xqbpx1o/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.215      0.171      0.104     0.0458      0.195      0.154     0.0799     0.0313\n",
      "Speed: 1.5ms preprocess, 29.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 938.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.48G      1.757      3.289       2.68      1.779         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.133      0.141      0.054     0.0233      0.126      0.129     0.0385     0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G       1.65      3.421      3.232      1.634         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.143       0.15     0.0561     0.0251      0.138       0.14     0.0405      0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.686      2.934      3.353      1.863          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.135      0.172     0.0593     0.0266      0.129       0.14     0.0432     0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G      1.842      4.032      3.285       1.93         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.137      0.166     0.0615     0.0271      0.131       0.15     0.0452     0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         3G      1.433      2.861      2.931      1.537         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.144      0.161     0.0621      0.028      0.149      0.134      0.048     0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.138      0.156     0.0618     0.0281      0.149      0.137     0.0476     0.0187\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñá‚ñà‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.04759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.02806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.01871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.1384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.14875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.15567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.1372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.43251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.93099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.86106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.91567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.65102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.07434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 4.35539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_214909-zxzbo508\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_214909-zxzbo508/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.132      0.138     0.0607     0.0216      0.145      0.117     0.0447     0.0135\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:00<00:00, 967.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.06G      1.817      5.405      3.785      1.935         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0569      0.103     0.0188    0.00666     0.0328     0.0607    0.00885    0.00283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.39G      1.686      5.204      3.585      1.897         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.125      0.116     0.0402     0.0163     0.0925     0.0871     0.0264     0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.36G      1.588      4.275       3.15      1.759         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.169      0.132     0.0657      0.028      0.167      0.119      0.047     0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.25G      1.428      3.433      2.869      1.686         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.216      0.169      0.101     0.0462      0.198       0.15     0.0816     0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G      1.459      3.201      2.714      1.687         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.258      0.237      0.156     0.0831      0.242      0.222       0.14     0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.26      0.239      0.156     0.0829       0.24      0.221      0.138     0.0659\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.13785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.08294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.06593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.23991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.23917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.2207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.71437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.68698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.20115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.83836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.96871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.07572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.56119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_215111-7y0bocpa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_215111-7y0bocpa/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.268      0.266      0.169     0.0812      0.264      0.257      0.145     0.0628\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 798.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.53G      1.179      3.317      2.414      1.552         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.198      0.187      0.122     0.0633      0.192      0.172      0.098     0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         5G      1.652      3.704      3.043      2.216         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.191      0.214      0.133     0.0699      0.218      0.164      0.114     0.0563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.92G       1.48      3.605      2.596      1.865         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.22      0.198      0.137     0.0729      0.219      0.182      0.115     0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G      1.576      3.293       2.77          2         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.226      0.193      0.145     0.0776      0.228      0.179       0.12     0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G       1.36      3.243      2.606      1.728         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.237      0.223      0.151     0.0801      0.216      0.197      0.121      0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.24      0.222      0.151     0.0804      0.217      0.198      0.121     0.0633\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñà‚ñÖ‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñà‚ñÉ‚ñÖ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñà‚ñÑ‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.12127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.08038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.06326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.23981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.21687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.22164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.19789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.35959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.60559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.72766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.24312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.79479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.19876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.0512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.83551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_215540-bnlr5328\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_215540-bnlr5328/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.256      0.219      0.141     0.0659      0.286      0.195      0.124     0.0534\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [00:00<00:00, 1005.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.43G      1.895      5.547      3.854      2.016         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0579      0.111     0.0198    0.00696     0.0363      0.066     0.0102    0.00318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.67G      1.908       5.05      3.686      2.028         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0722     0.0739     0.0245    0.00891     0.0491     0.0607     0.0144    0.00482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.56G      1.629      3.936      3.133      1.794         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.168      0.122     0.0607     0.0254      0.145      0.111     0.0459     0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.62G      1.509      3.618      2.901      1.717         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.246      0.214      0.108     0.0514      0.239      0.206     0.0952     0.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G      1.402       3.21      2.696      1.639         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.307      0.248      0.169     0.0915      0.292      0.245      0.156      0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.316      0.248      0.168     0.0917      0.295      0.249      0.156     0.0788\n",
      "Speed: 1.6ms preprocess, 13.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.1683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.15599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.09168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.07883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.31583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.29528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.24802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.24875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.40241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.69562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.20989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.67881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.81027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.98571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.19618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_215744-ejzahjb5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_215744-ejzahjb5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.295      0.298      0.179     0.0946      0.296       0.28      0.165     0.0811\n",
      "Speed: 1.3ms preprocess, 29.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1218.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       4.8G      1.328       2.84       2.37      1.651         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.209       0.24       0.14     0.0725      0.212      0.235      0.128     0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G      1.432      2.389      2.563      1.677         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.214      0.245      0.144     0.0753      0.218      0.237      0.131     0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G      1.613      2.945      2.134      1.821         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.21      0.269      0.145     0.0767      0.211      0.251      0.133     0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G      1.679      3.083      2.702      1.855         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.22      0.272      0.149     0.0792      0.214      0.264      0.136     0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G      1.419      3.244      3.223       1.64         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.23      0.269      0.154      0.081      0.223      0.261      0.142     0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.23      0.269      0.156     0.0817      0.224      0.259      0.142      0.071\n",
      "Speed: 1.0ms preprocess, 13.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.14217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.07103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.22994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.22383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.26913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.25858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.41879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.22282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.24418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.6427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.9626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.94301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.34049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_220214-5zz3by39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_220214-5zz3by39/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.281      0.238      0.162     0.0799      0.275      0.233      0.148     0.0683\n",
      "Speed: 1.3ms preprocess, 29.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 121/121 [00:00<00:00, 996.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.867      5.265      3.771      2.056         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0618      0.103     0.0194    0.00656     0.0346      0.066     0.0086     0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.63G      1.744      4.862      3.538      1.932         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.126     0.0976     0.0359     0.0144      0.091      0.066     0.0246     0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.31G      1.549      3.882      3.037      1.788         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.167      0.142     0.0586     0.0243      0.116      0.106     0.0325     0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.457      3.464      2.681      1.704         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.225      0.195       0.11     0.0511      0.217      0.164     0.0837     0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G      1.393      3.157      2.438      1.615         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.313      0.277      0.205      0.108      0.296      0.225      0.177     0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.31      0.277      0.206      0.109      0.301      0.227      0.178     0.0923\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÉ‚ñà‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.20551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.17847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.10879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.30992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.3011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.27704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.22735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.39345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.43823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.61526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.15692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.74926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.76738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.03704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.51384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_220418-djq3xbjt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_220418-djq3xbjt/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.266       0.36      0.242      0.132      0.416      0.192      0.202      0.106\n",
      "Speed: 1.3ms preprocess, 29.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 878.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.62G      1.156      2.566      2.647      1.377         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.233      0.278       0.15      0.074      0.218      0.248      0.135     0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.07G      1.341      2.129      2.729      1.484         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.228      0.263      0.156     0.0779      0.247      0.237       0.14     0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G      1.633      2.602      2.785      1.737         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.24       0.24      0.158     0.0786      0.234      0.222      0.143     0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G       1.48      3.339      2.511      1.895         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.249       0.23      0.163     0.0814      0.233       0.23       0.15     0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G      1.551      3.177       3.42      1.804         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.232      0.262      0.165      0.084      0.269       0.19      0.156     0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.223      0.266      0.164     0.0842      0.269      0.193      0.155     0.0732\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.16418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.15497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.08415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.07321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.22257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.26916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.26649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.19261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.55053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.42039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.80411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.1772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.75436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.9889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.02404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.54686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_220850-bgramo2s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_220850-bgramo2s/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.254      0.285      0.201      0.104       0.25      0.238      0.171     0.0816\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131/131 [00:00<00:00, 995.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.02G      1.781      5.398      3.938      1.999          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:07<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0602      0.103     0.0205    0.00733     0.0409     0.0633     0.0106    0.00334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.69G       1.77      4.684      3.552       1.92          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:05<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.136     0.0923     0.0426     0.0171      0.114     0.0739     0.0304     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.3G      1.538       3.58      2.868       1.78          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:05<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.256      0.243      0.126     0.0613      0.237      0.222      0.108     0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.56G        1.5      3.449      2.585      1.743          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:05<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.355      0.264      0.216      0.122      0.444      0.243      0.203      0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.368       2.95      2.234      1.615          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:05<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.433       0.38      0.338      0.197      0.421      0.369      0.325      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.432      0.384      0.338      0.198      0.419      0.375      0.324      0.177\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.33797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.32434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.19807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.17722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.43228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.38373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.37467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.36828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.2344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.61491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.94971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.56283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.2256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.8733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.04931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_221056-78iutwdk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_221056-78iutwdk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.479       0.36      0.366      0.209      0.499      0.355      0.351       0.19\n",
      "Speed: 0.9ms preprocess, 29.9ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 815.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.97G      1.589      2.352      2.334      1.917         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.435      0.354      0.313       0.17       0.47      0.343      0.312      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G      2.038      3.455      3.339      2.147         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.437      0.356      0.315       0.17      0.466      0.356      0.312      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.92G       1.49      2.313      2.162      1.802         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.474       0.34      0.314      0.173      0.484      0.348      0.315      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.94G      1.836      3.325       3.02      2.037         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.476      0.343      0.319      0.174      0.482      0.354      0.316      0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.89G      1.745      2.762      2.328      1.881         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.44      0.359      0.326      0.177       0.44      0.359       0.32      0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.435      0.359      0.326      0.177      0.435      0.359      0.319      0.158\n",
      "Speed: 1.3ms preprocess, 13.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñá‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÅ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñà‚ñÅ‚ñá‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.32602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.31903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.17701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.15813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.43488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.43488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.35884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.35884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.74491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.32816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.88106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.76165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.55312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.35939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.84387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.06835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_221532-s2vs0xqk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_221532-s2vs0xqk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.521       0.39      0.389      0.215      0.498      0.388       0.37       0.19\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 950.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.61G      1.592      4.147      2.536      1.886         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.358      0.332      0.264      0.137       0.35      0.306      0.235      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.08G      1.391      2.909      2.279      1.574         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.364      0.319      0.264      0.139      0.372      0.303      0.245       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.95G      1.397       2.89      2.333      1.661         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.343      0.332      0.266       0.14      0.367      0.309      0.247      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G      1.529      4.124      2.511      1.887         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.361       0.34      0.271      0.142      0.372      0.322      0.251      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G      1.458      3.287      2.471      1.705         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.395      0.332      0.274      0.144      0.385      0.317       0.26      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.383      0.335      0.274      0.144      0.381      0.325      0.261      0.127\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÅ‚ñÇ‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÅ‚ñÉ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.27409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.14412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.38262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.38058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.32454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.47144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.7047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.28663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.57323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.66816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.85969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.18428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_221838-mjy9vhz4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_221838-mjy9vhz4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.391      0.396      0.322      0.173       0.39      0.393      0.307      0.144\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 1137.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.02G      1.795       5.61      3.915      1.947         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.071     0.0923     0.0215    0.00772     0.0442     0.0554     0.0114     0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.36G      1.647       4.26      3.301      1.825         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.168      0.121     0.0624     0.0266      0.151      0.106     0.0482     0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G      1.531      3.449      2.791      1.746         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.278       0.24      0.168     0.0876      0.264      0.243      0.144     0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G      1.358      2.975      2.268      1.584         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.432      0.397      0.337      0.187      0.425       0.39      0.321      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.26G      1.257      2.704      1.999      1.546         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.557      0.364      0.404      0.231      0.573      0.354       0.39      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.569      0.367      0.406      0.231      0.575      0.356      0.392      0.215\n",
      "Speed: 1.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñá‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.40611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.39206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.23121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.21463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.56852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.57526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.36675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.3562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.25677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.99948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.54574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.7037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.45028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.26908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.73242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.94774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_222043-323z5yjq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_222043-323z5yjq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.495      0.374      0.401      0.228      0.486      0.379      0.379      0.203\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1310.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.89G      1.724      2.172      2.031      1.792         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.45      0.391      0.359      0.207      0.417      0.406      0.355      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.09G      1.498       2.22      2.136      1.566         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.456      0.391      0.367      0.208      0.481      0.361       0.36      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.99G      1.703      2.845      2.273      1.775         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.465      0.396      0.371      0.209      0.469       0.38      0.362      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.97G      1.596      3.658      2.684      1.734         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.445      0.391      0.371      0.208      0.447      0.385      0.363      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.94G      1.425      4.032      2.035      1.733         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.423      0.414       0.37      0.205      0.429      0.404      0.366      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.449      0.404      0.372      0.209      0.479       0.38      0.364      0.195\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñà‚ñÇ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÖ‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÉ‚ñÖ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñà‚ñá‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÅ‚ñÑ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÉ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÅ‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.37177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.36377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.20892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.1949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.44877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.47895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.37995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.42497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.03468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.73257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.0319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.47961\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.44664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.72249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.06332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_222522-adms9t7i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_222522-adms9t7i/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.442      0.365       0.34      0.191      0.445      0.374      0.334      0.172\n",
      "Speed: 1.3ms preprocess, 29.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [00:00<00:00, 978.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.59G      1.844      5.288       4.24      2.039          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:08<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0747      0.111     0.0264    0.00977     0.0563     0.0844      0.015    0.00497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.7G      1.663      4.409       3.34      1.848          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.172      0.142     0.0654     0.0285      0.185      0.135      0.055     0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.31G      1.471      3.528      2.594      1.675          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.39      0.367      0.307      0.179      0.398      0.369        0.3       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.62G      1.442      2.965      2.262      1.691          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.646      0.332      0.411      0.259      0.428      0.472      0.409      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.65G      1.326      2.516      1.922      1.577          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.638      0.412      0.469        0.3      0.675      0.398      0.458      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.674      0.404      0.468      0.299      0.675      0.398      0.458      0.266\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.46804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.45789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.2991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.26557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.67442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.67453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.39842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.32584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.92174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.57723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.51593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.38661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.02974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.68364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.90989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_222727-p4cjqci9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_222727-p4cjqci9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.655      0.444      0.517      0.308      0.661      0.424      0.502      0.279\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 782.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         5G       1.24      2.393       1.85      1.496         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.439      0.421      0.415      0.256      0.458      0.414      0.402      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G      1.432      2.787      2.075      1.585         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.499      0.391      0.423      0.261      0.481      0.422      0.411      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.03G      1.176      2.689      1.837      1.418         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.516      0.398      0.428      0.263      0.512      0.406      0.415      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G      1.251      2.986       2.39      1.461         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.551      0.385      0.437      0.269      0.566      0.396      0.425      0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.96G      1.217      2.309      1.693      1.424         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.545      0.401      0.442      0.273      0.563      0.414      0.431      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.553      0.401      0.444      0.273      0.568      0.412      0.431      0.241\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñà‚ñÅ‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñÖ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÑ‚ñà‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÇ‚ñÜ‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.44351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.27342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.55304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.56812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.41161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.21735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.6932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.42405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.30852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.16403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.66992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.99381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_223209-x3692x9l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_223209-x3692x9l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.546      0.418      0.465      0.266       0.55      0.421      0.459      0.237\n",
      "Speed: 1.1ms preprocess, 29.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171/171 [00:00<00:00, 1007.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.52G      1.743      5.337      3.901      1.939         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:08<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0704      0.106     0.0244    0.00907     0.0492     0.0712      0.013    0.00422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.48G      1.602      4.038      3.259      1.789         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.192      0.182     0.0838     0.0359      0.167      0.148     0.0599      0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.46G       1.42      3.358      2.675      1.671         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.335      0.298      0.235      0.134      0.343      0.297      0.228      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.49G      1.311      2.808      2.119      1.576         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.418      0.393       0.36      0.202      0.423      0.393      0.348      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.36G      1.303       2.62      1.879      1.537         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.535      0.414      0.443      0.272      0.546       0.42       0.44      0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.515       0.43      0.443      0.272      0.612      0.388       0.44      0.248\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.44286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.27239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.51501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.61203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.43008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.38786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.30294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.87889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.61981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.40837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.01979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.69695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.80348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_223417-8o7rcp7t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_223417-8o7rcp7t/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.617      0.442      0.494      0.299      0.588      0.452      0.472      0.267\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1186.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.47G      1.292      2.122      1.811      1.557         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.431      0.409      0.405      0.233      0.462      0.398      0.399      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       5.1G      1.373      3.099      1.724      1.482         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.42      0.433      0.407      0.235      0.546      0.361      0.407      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.98G      1.286      2.563      1.665      1.595         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.54      0.367      0.411      0.237      0.556      0.377      0.411      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.97G      1.769      4.253      2.634      1.812         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.545      0.377      0.416       0.24       0.56      0.383      0.414      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.95G      1.665      3.168      2.393      1.805         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.544      0.372      0.419      0.242      0.553      0.383      0.415      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.546      0.372      0.419      0.242       0.55      0.383      0.415      0.217\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñá‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÅ‚ñÑ‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.41903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.41534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.24234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.21739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.54648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.55002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.37203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.38259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.66492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.39254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.80493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.16794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.48631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.21741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.73048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.98519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_223859-geowmwbz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_223859-geowmwbz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.454      0.455      0.426      0.241      0.463      0.446      0.408      0.217\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181/181 [00:00<00:00, 926.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G      1.817      5.379      3.788      1.997         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:08<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379     0.0833      0.103     0.0271     0.0097     0.0623      0.066     0.0144    0.00507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.36G      1.642      4.063       3.29      1.837         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.255      0.206      0.125     0.0648      0.251      0.187      0.104     0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.57G      1.389       3.21      2.519       1.66         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.396      0.272      0.268      0.163      0.409       0.28      0.263      0.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.58G      1.311       2.72      1.993      1.541         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379        0.5      0.452      0.441      0.257        0.5      0.449      0.429      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G      1.246      2.536      1.866      1.482         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.586       0.47      0.474       0.28      0.584      0.471       0.46      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.587       0.47      0.473      0.279      0.584       0.47       0.46      0.245\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.47321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.45963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.27946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.58694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.58372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.46966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.46966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.2456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.86619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.48195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.53624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.00315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.70948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.81892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_224106-ca40fvjv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_224106-ca40fvjv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.618      0.466      0.497      0.272        0.6      0.442      0.463      0.247\n",
      "Speed: 1.2ms preprocess, 29.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 928.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.97G      1.153      2.585      2.087      1.558         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.446      0.484      0.414      0.231      0.431      0.462      0.382      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G      1.372      2.878      2.143      1.573         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.458      0.499      0.424      0.234      0.437       0.48      0.387      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G      1.262      3.041      1.914      1.581         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.451      0.522      0.427      0.236      0.434      0.511      0.391      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       4.9G     0.9848      2.755      1.657      1.497         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.466      0.502      0.433      0.239      0.451      0.496      0.395      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       4.9G      1.238      2.777       2.24      1.434         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.483      0.496      0.435       0.24      0.468      0.484      0.399      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.483      0.493      0.434       0.24      0.467      0.485      0.399      0.206\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÑ‚ñà‚ñÜ‚ñÅ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñá‚ñà‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.43411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.39924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.2404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.20551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.48324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.49347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.48549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.23753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.24022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.4336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.77739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.45409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.22287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.74696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.15538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_224554-1nxjgvmg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_224554-1nxjgvmg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.518      0.431      0.423      0.233      0.573      0.417      0.404      0.209\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 191/191 [00:00<00:00, 858.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.39G      1.869      5.144      3.868      2.003         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:09<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.116       0.14     0.0354     0.0142      0.111      0.108     0.0275     0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.36G      1.582      3.957      3.194      1.818         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.232      0.266      0.128     0.0694      0.227      0.253      0.119     0.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.31G      1.474      3.269      2.499      1.697         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.375      0.332      0.296      0.166      0.396      0.319      0.285      0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.308      2.784      2.053      1.553         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.48       0.33      0.343      0.206      0.495      0.335      0.347      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G      1.338      2.699      1.899      1.591         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:07<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.495      0.404      0.408       0.25      0.515       0.42      0.411      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.497      0.406      0.408      0.251      0.515       0.42      0.411      0.232\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.40841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.41146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.25084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.23206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.49684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.5149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.41953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.33831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.89902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.59105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.69879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.44068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.00963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.71767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.75244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_224800-u83t5el0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_224800-u83t5el0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.512      0.442       0.42      0.238      0.522      0.407      0.401      0.214\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 729.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.14G      1.554      2.635       2.09      1.641         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.394      0.385      0.359      0.215      0.529      0.332      0.374      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.08G      1.503      2.576       2.01      1.622         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.407      0.391      0.371      0.221      0.487      0.359      0.382      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.95G      1.469      2.278      1.701      1.726         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.492      0.354      0.381      0.228      0.514      0.369      0.394      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G      1.205      2.401      2.145      1.585         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.488      0.367      0.388      0.232      0.508       0.38      0.399      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G      1.338      3.353      2.203      1.638         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.497      0.385      0.397      0.237      0.519      0.401      0.404      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.495      0.391      0.398      0.237      0.523      0.404      0.404      0.222\n",
      "Speed: 1.8ms preprocess, 13.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÅ‚ñÜ‚ñÑ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñá‚ñà‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÜ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÑ‚ñÉ‚ñà‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.39763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.40374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.2372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.49464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.52308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.3905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.40369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.33809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.20337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.3529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.43779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.09899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.70274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.71088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_225250-ivu5oy8v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_225250-ivu5oy8v/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.498      0.415      0.424      0.229      0.484      0.409      0.399      0.205\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [00:00<00:00, 1136.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.43G      1.861      5.123      3.794      2.015         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:09<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.104      0.113     0.0354     0.0142     0.0756     0.0844     0.0218    0.00881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.69G      1.498      3.735      2.994      1.729         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:08<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.299      0.269      0.159     0.0854      0.282      0.243      0.137     0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.46G      1.373      2.975       2.28      1.632         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.453      0.346      0.343      0.192      0.457      0.348      0.342      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.69G       1.25       2.55      1.897      1.481         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:07<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.532       0.42      0.433      0.266      0.558       0.38      0.414      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.2G      1.253       2.53      1.788      1.488         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:07<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.605      0.453       0.49      0.306      0.617      0.443      0.479      0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.598      0.454       0.49      0.306      0.611      0.447      0.479      0.277\n",
      "Speed: 1.2ms preprocess, 13.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.03733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.49023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.47928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.30627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.27742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.5981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.61087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.45383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.25324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.78799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.4878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.53006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.42064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.8757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.65942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.77751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_225457-8ob8yga5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_225457-8ob8yga5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.597      0.485       0.54      0.323      0.581      0.491      0.513      0.296\n",
      "Speed: 1.4ms preprocess, 29.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 724.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.81G      1.245      2.701      1.813      1.503          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.535      0.388      0.414      0.249      0.541      0.393      0.408      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.21G      1.413      2.659      2.254       1.63          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.64      0.446      0.486        0.3      0.602      0.456      0.476      0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.19G      1.327      2.786      1.674      1.704          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.694      0.451      0.519      0.316      0.693      0.451      0.504      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.84G       1.23       2.26      2.017      1.491          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.584      0.528      0.535      0.329      0.587       0.53       0.53      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.22G      1.194      2.837      1.937      1.535          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.593      0.509      0.543      0.339      0.596      0.512      0.539      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.594       0.51      0.543      0.339      0.597      0.513       0.54      0.304\n",
      "Speed: 1.1ms preprocess, 13.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÉ‚ñà‚ñÅ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.54348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.53987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.33938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.30412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.59419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.59726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.50996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.5126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.1944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.93723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.83656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.32983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.76953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.59536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.5949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_225947-0udzqpbw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_225947-0udzqpbw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369       0.66      0.474      0.551      0.334      0.641      0.461      0.522      0.297\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 717.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.12G       1.21       2.88       1.93      1.497          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.553      0.448      0.483      0.287      0.584      0.459       0.48       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.84G       1.47      3.084       1.93      1.692          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.566      0.528      0.519      0.319      0.676      0.456      0.524      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.23G      1.283      2.858      1.842      1.596          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.595      0.525      0.543      0.338      0.708      0.475      0.537       0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.26G      1.188       2.27      2.088      1.558          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.667      0.488      0.535      0.335       0.68      0.475      0.531      0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G      1.303      2.611      1.786      1.539          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.594      0.557       0.54       0.34      0.625      0.527      0.535      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.636      0.488      0.542      0.338      0.704      0.475      0.538       0.31\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÖ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÜ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÜ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÅ‚ñà‚ñÖ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñà‚ñÜ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.5421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.53784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.33795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.30965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.63575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.70417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.48813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.47493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.30343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.78592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.6114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.32362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.72772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.60419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.54348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_230306-31thryl0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_230306-31thryl0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.594      0.485       0.54      0.324      0.579      0.463      0.511      0.293\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/retrain/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<00:00, 1011.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.76G      1.724      4.957      3.595        1.9         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:13<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.215      0.169     0.0928     0.0405      0.211      0.156     0.0786     0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.97G      1.438      3.206      2.503      1.673         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:12<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.333      0.282      0.252      0.152      0.322      0.288      0.233      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.64G       1.28       2.64      1.864      1.519         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:11<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379       0.47      0.467      0.422       0.25      0.596      0.396      0.427      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.65G      1.167      2.354      1.542      1.429         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:11<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.573      0.496        0.5      0.309      0.573       0.48      0.493      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.62G      1.176      2.308      1.359      1.417         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:11<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.697      0.551      0.624      0.394      0.656      0.567      0.608      0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.696      0.551      0.625      0.394      0.643      0.576      0.608      0.353\n",
      "Speed: 1.6ms preprocess, 13.8ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.62464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.60837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.39423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.35338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.69637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.64325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.55145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.57565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.17637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.35937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.41696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.30803\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.25693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.49633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.54662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.44354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_230522-ltdcvljh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_230522-ltdcvljh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.666      0.531      0.593      0.375      0.662      0.518      0.591      0.335\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 718.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.2G      1.292      2.415      1.573      1.513         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.669      0.571      0.608      0.385      0.663      0.565      0.597      0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         8G      1.253      2.364      1.653      1.486         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.587      0.574       0.61      0.387      0.603      0.591       0.62      0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.89G      1.156       2.55      1.598      1.396         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.715      0.515      0.626        0.4      0.738      0.512       0.63      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.25G      1.253      2.341      1.516      1.476         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.649      0.554       0.64      0.412      0.669      0.559      0.634      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.99G      1.142      2.037      1.352      1.414         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.682      0.573      0.644      0.417       0.68      0.599      0.644      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.684       0.57      0.643      0.416      0.676      0.596      0.644      0.386\n",
      "Speed: 1.4ms preprocess, 13.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÖ‚ñÅ‚ñà‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñà‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÖ‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÇ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÅ‚ñÜ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÉ‚ñá‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñá‚ñÇ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.64346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.64366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.41561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.38554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.68351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.67587\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.56982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.59631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.14213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.3519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.41435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.0367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.22232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.39419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.52503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.25856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_231036-ep5e36nw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_231036-ep5e36nw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.616      0.586      0.629      0.404      0.621      0.591      0.629       0.35\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 687.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.07G        1.1      2.199      1.408      1.397         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.656      0.586      0.625      0.396      0.663      0.594      0.627      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.35G      1.079      2.067       1.25      1.357          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.684      0.641      0.687      0.438      0.672      0.631      0.674      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.21G      1.151      2.256      1.271      1.385         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.733      0.616      0.697      0.451      0.742       0.62      0.694      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.24G      1.083      2.071       1.21      1.324         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.764      0.615        0.7      0.463      0.761      0.622      0.703      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.91G      1.017      2.169      1.284      1.324          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.776      0.612      0.717      0.474      0.784      0.614      0.712      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.777      0.609      0.716      0.474      0.782      0.612      0.711       0.44\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÑ‚ñá‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñÜ‚ñÅ‚ñà‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.71631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.71102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.4743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.44038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.77706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.7817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.6095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.0173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.28383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.32404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.16923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.20146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.26842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.47547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.11376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_231406-g46q54v3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_231406-g46q54v3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.591      0.626      0.642      0.429      0.595      0.628      0.646      0.387\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_41/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 698.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         8G      1.189      2.277      1.442      1.423         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:22<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.656      0.604       0.67      0.436      0.662      0.611      0.674      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.98G      1.152      2.139        1.3      1.405         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.649      0.528      0.599      0.383      0.698      0.506      0.595      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.93G      1.115      2.033      1.269      1.361         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.696      0.522      0.627      0.379        0.7      0.525      0.614       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.91G      1.098       2.02      1.132      1.368          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.741      0.651      0.696      0.436       0.74      0.646      0.695      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.96G      1.072      1.969      1.123      1.337          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.734      0.647      0.725      0.442      0.825      0.602      0.725      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.736      0.644      0.726      0.443      0.823      0.599      0.725      0.407\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñÅ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÜ‚ñÅ‚ñÇ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.72609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.72511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.44274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.40736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.73638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.82295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.6438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.59894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.486\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.07166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.12343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.3372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.96872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.21093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.61677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.51116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_231735-sgwaga3f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_231735-sgwaga3f/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.659      0.627       0.68      0.434      0.687       0.63      0.691      0.402\n",
      "Speed: 1.3ms preprocess, 29.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_42/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 710.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_42/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       7.7G      1.139      2.157      1.186      1.414          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:22<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.725      0.639      0.721      0.478      0.746      0.654       0.73      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.06G      1.084      2.012      1.074      1.376         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.827      0.675      0.782      0.493      0.812      0.668       0.77      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.94G      1.087      2.029      1.111      1.356         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.724      0.631      0.688      0.418      0.738       0.64      0.685      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.21G      1.054      1.929      1.065      1.359         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.777      0.654      0.729      0.452      0.791      0.671      0.737      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       7.9G       1.03      1.842     0.9958      1.333         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.663      0.607      0.636      0.382      0.659      0.583      0.626      0.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.826      0.675      0.782      0.493       0.81      0.674       0.77      0.448\n",
      "Speed: 1.7ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñÖ‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñá‚ñà‚ñÅ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñá‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñÇ‚ñà‚ñÅ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÇ‚ñà‚ñÅ‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñÑ‚ñá‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.78238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.77015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.49301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.44771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.82619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.80986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.67546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.67429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.03032\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.99576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.33307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.84189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.40084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.30635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.73581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.69241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_232220-qt6u8vly\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_232220-qt6u8vly/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369      0.727      0.648      0.736      0.447      0.739      0.664      0.739      0.417\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/puddle-segmentation-8/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/temp_0_43/train/labels... 419 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 419/419 [00:00<00:00, 700.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/puddle-segmentation-8/temp_0_43/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/valid_0/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.98G      1.164      2.104      1.196      1.441          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.875      0.694      0.808      0.529      0.866      0.689      0.791      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.02G      1.106      1.998      1.107      1.403         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.731      0.662      0.723      0.464      0.759      0.636      0.714      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.26G      1.086      1.924      1.093      1.353          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.755      0.635      0.708      0.421      0.742      0.652      0.709      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.22G      1.066      1.896     0.9997      1.342          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.757       0.56       0.65      0.402      0.772       0.57      0.666      0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.95G      1.015      1.826     0.9543      1.291          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.734      0.714      0.763      0.473      0.739      0.718      0.765      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:08<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240        379      0.876      0.691      0.805      0.529      0.868      0.689      0.791      0.484\n",
      "Speed: 1.3ms preprocess, 13.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñà‚ñÜ‚ñÖ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.8048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.79083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.52903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.48412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.87625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.86845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.69126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.68865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.01499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.95429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.29147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.82583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.28498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.06332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.57292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.06634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/puddle-segmentation-8/wandb/offline-run-20231202_232704-0kqnixzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231202_232704-0kqnixzz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.221 üöÄ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/puddle-segmentation-8/test_0/labels.cache... 241 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        241        369       0.72      0.726      0.779      0.509      0.723      0.728      0.776      0.478\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ) –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: \n",
      " defaultdict(<class 'list'>, {0: [0.005767803699574613, 0.015378912758548328, 0.0036575018568473635], 1: [0.005780178197380123, 0.014889149411762614, 0.003945753320144483], 2: [0.005671208904902321, 0.015196289150207197, 0.0037253008841769113], 3: [0.00595891899814536, 0.01569107834754266, 0.003924486322505436], 4: [0.005730666202207515, 0.014976556070235628, 0.004038536403151532], 5: [0.0057390446475614355, 0.015142671708810217, 0.003923136231725862], 6: [0.005854115479306049, 0.0156488735685828, 0.0037806502955590017], 7: [0.005775415409261029, 0.014855354110889618, 0.0037924339602038847], 8: [0.00534949811814986, 0.015022020358416507, 0.0034431452164729185], 9: [0.005657967430566261, 0.015134343906586146, 0.0037995035504118143], 10: [0.005834088578082629, 0.015199233750444314, 0.0038429623679299488], 11: [0.00555471896532994, 0.015896772640371523, 0.003276916827035084], 12: [0.0057984587217343566, 0.015619861948740514, 0.003942831648904268], 13: [0.00951466002922904, 0.026409401316923785, 0.005461376932358174], 14: [0.006952008324712504, 0.02191656559743893, 0.0032572642214634103], 15: [0.009452353796663938, 0.024153429669886744, 0.0065739274268204525], 16: [0.012805186810680127, 0.033719849861955406, 0.005606299942420792], 17: [0.010806740340784864, 0.03217519854077283, 0.006420966906870081], 18: [0.018395372761523136, 0.04492804818941307, 0.012531748230694804], 19: [0.013123388199831176, 0.037697732485290035, 0.006619020963569627], 20: [0.014202910659996829, 0.03864849360469294, 0.006872149711502448], 21: [0.04318804022134852, 0.10138255170309496, 0.03342595389820645], 22: [0.03758527969389328, 0.08595586238668158, 0.02573023744487271], 23: [0.03439732955686092, 0.08366112594571701, 0.024696474194397106], 24: [0.0313012981241691, 0.07989269395189595, 0.02375912689627755], 25: [0.06275632908926744, 0.14480924491376682, 0.04071355705090627], 26: [0.08109451390706006, 0.16511979713738076, 0.06960438815384354], 27: [0.10586606683463262, 0.20219610565086935, 0.09929491363635205], 28: [0.1896476523399516, 0.35088268962978725, 0.18114863259558678], 29: [0.19019322716424064, 0.36992829353186013, 0.19249985926008198], 30: [0.2033856454793142, 0.37931803090479915, 0.20771419672305286], 31: [0.2792758253187597, 0.5018272306830417, 0.28582403994007854], 32: [0.2672825054888255, 0.47213625142615556, 0.2746525075769104], 33: [0.24725948272524034, 0.4629427330003708, 0.24606693000388724], 34: [0.2137770817101973, 0.4011042944031486, 0.21367591648918308], 35: [0.2964331251954459, 0.5134458619035233, 0.323058918953795], 36: [0.29659197366834966, 0.5215572571881989, 0.31059660248833737], 37: [0.33542960412780953, 0.5906692018950054, 0.36569200750015407], 38: [0.3503207286610876, 0.6287915423012425, 0.35334979359091245], 39: [0.3869315113716004, 0.6462145039773699, 0.42696408440929345], 40: [0.40172935425852535, 0.6907764314214497, 0.42612175090975785], 41: [0.4174862403772658, 0.7390277481926906, 0.41253083491789916], 42: [0.47763366278639535, 0.7762768989560697, 0.5424564151205312]})\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (train) –¥–ª—è –∫–ª–∞—Å—Å–∞ 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 1920]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/puddle-segmentation-8/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17facc54",
   "metadata": {
    "papermill": {
     "duration": 1.628214,
     "end_time": "2023-12-02T23:31:42.372752",
     "exception": false,
     "start_time": "2023-12-02T23:31:40.744538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a286b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 1.567296,
     "end_time": "2023-12-02T23:31:45.656134",
     "exception": false,
     "start_time": "2023-12-02T23:31:44.088838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9470e6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 1.561335,
     "end_time": "2023-12-02T23:31:48.882282",
     "exception": false,
     "start_time": "2023-12-02T23:31:47.320947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dece1f9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 1.668634,
     "end_time": "2023-12-02T23:31:52.114625",
     "exception": false,
     "start_time": "2023-12-02T23:31:50.445991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46129e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 1.683328,
     "end_time": "2023-12-02T23:31:55.367655",
     "exception": false,
     "start_time": "2023-12-02T23:31:53.684327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"–ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862abdc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 1.687867,
     "end_time": "2023-12-02T23:31:58.634488",
     "exception": false,
     "start_time": "2023-12-02T23:31:56.946621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15428.861366,
   "end_time": "2023-12-02T23:32:07.755360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T19:14:58.893994",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
