{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3eabf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:17:19.532831Z",
     "iopub.status.busy": "2024-01-04T22:17:19.532478Z",
     "iopub.status.idle": "2024-01-04T22:19:01.259893Z",
     "shell.execute_reply": "2024-01-04T22:19:01.258743Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 101.73648,
     "end_time": "2024-01-04T22:19:01.262456",
     "exception": false,
     "start_time": "2024-01-04T22:17:19.525976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pytoolconfig 1.2.6 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-04 22:18:21--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240104T221821Z&X-Amz-Expires=300&X-Amz-Signature=c81a47349d583514ea03132e70cfd244abe30e85b700ebec5c4766d37324da00&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-04 22:18:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240104T221821Z&X-Amz-Expires=300&X-Amz-Signature=c81a47349d583514ea03132e70cfd244abe30e85b700ebec5c4766d37324da00&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2024-01-04 22:18:22 (359 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in feet-14 to yolov8:: 100%|██████████| 696075/696075 [00:28<00:00, 24188.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to feet-14 in yolov8:: 100%|██████████| 9508/9508 [00:02<00:00, 4271.13it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"roboarm\").project(\"feet-qevah\")\n",
    "dataset = project.version(14).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d2db52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:19:01.318171Z",
     "iopub.status.busy": "2024-01-04T22:19:01.317687Z",
     "iopub.status.idle": "2024-01-04T22:19:24.172299Z",
     "shell.execute_reply": "2024-01-04T22:19:24.171114Z"
    },
    "papermill": {
     "duration": 22.885467,
     "end_time": "2024-01-04T22:19:24.174694",
     "exception": false,
     "start_time": "2024-01-04T22:19:01.289227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a86f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:19:24.229624Z",
     "iopub.status.busy": "2024-01-04T22:19:24.228883Z",
     "iopub.status.idle": "2024-01-04T22:19:24.253707Z",
     "shell.execute_reply": "2024-01-04T22:19:24.252992Z"
    },
    "papermill": {
     "duration": 0.055064,
     "end_time": "2024-01-04T22:19:24.255665",
     "exception": false,
     "start_time": "2024-01-04T22:19:24.200601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/feet-14\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/feet-14\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8af1fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:19:24.317908Z",
     "iopub.status.busy": "2024-01-04T22:19:24.317514Z",
     "iopub.status.idle": "2024-01-04T22:19:24.431024Z",
     "shell.execute_reply": "2024-01-04T22:19:24.430285Z"
    },
    "papermill": {
     "duration": 0.152003,
     "end_time": "2024-01-04T22:19:24.433208",
     "exception": false,
     "start_time": "2024-01-04T22:19:24.281205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # Корректируем data.yaml файл\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5739a51",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-04T22:19:24.485911Z",
     "iopub.status.busy": "2024-01-04T22:19:24.485607Z",
     "iopub.status.idle": "2024-01-05T03:11:04.584058Z",
     "shell.execute_reply": "2024-01-05T03:11:04.583023Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 17501.72719,
     "end_time": "2024-01-05T03:11:06.186208",
     "exception": false,
     "start_time": "2024-01-04T22:19:24.459018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_0/images 474\n",
      "test_0/images 476\n",
      "valid_1/images 474\n",
      "test_1/images 476\n",
      "train/labels 3798 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 0 содержит 3798 объекта(-ов)\n",
      " Класс 1 содержит 3798 объекта(-ов)\n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 3798\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n",
      "\tКол-во директорий для класса 0: 47 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 500, folder 40, cls 0\n",
      "\tnum_to_mv_train 500, folder 41, cls 0\n",
      "\tnum_to_mv_train 500, folder 42, cls 0\n",
      "\tnum_to_mv_train 500, folder 43, cls 0\n",
      "\tnum_to_mv_train 500, folder 44, cls 0\n",
      "\tnum_to_mv_train 500, folder 45, cls 0\n",
      "\tnum_to_mv_train 297, folder 46, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 500\n",
      "temp_0_41/train/images 500 \n",
      "\n",
      "temp_0_42/train/labels 500\n",
      "temp_0_42/train/images 500 \n",
      "\n",
      "temp_0_43/train/labels 500\n",
      "temp_0_43/train/images 500 \n",
      "\n",
      "temp_0_44/train/labels 500\n",
      "temp_0_44/train/images 500 \n",
      "\n",
      "temp_0_45/train/labels 500\n",
      "temp_0_45/train/images 500 \n",
      "\n",
      "temp_0_46/train/labels 500\n",
      "temp_0_46/train/images 500 \n",
      "\n",
      "temp_0_47/train/labels 297\n",
      "temp_0_47/train/images 297 \n",
      "\n",
      "Класс 1\n",
      "\tКол-во train класса 1: 3798\n",
      "\tКоличество данных (train) на каждой итерации класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n",
      "\tКол-во директорий для класса 1: 47 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 50, folder 36, cls 1\n",
      "\tnum_to_mv_train 50, folder 37, cls 1\n",
      "\tnum_to_mv_train 100, folder 38, cls 1\n",
      "\tnum_to_mv_train 100, folder 39, cls 1\n",
      "\tnum_to_mv_train 500, folder 40, cls 1\n",
      "\tnum_to_mv_train 500, folder 41, cls 1\n",
      "\tnum_to_mv_train 500, folder 42, cls 1\n",
      "\tnum_to_mv_train 500, folder 43, cls 1\n",
      "\tnum_to_mv_train 500, folder 44, cls 1\n",
      "\tnum_to_mv_train 500, folder 45, cls 1\n",
      "\tnum_to_mv_train 297, folder 46, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 50\n",
      "temp_1_37/train/images 50 \n",
      "\n",
      "temp_1_38/train/labels 50\n",
      "temp_1_38/train/images 50 \n",
      "\n",
      "temp_1_39/train/labels 100\n",
      "temp_1_39/train/images 100 \n",
      "\n",
      "temp_1_40/train/labels 100\n",
      "temp_1_40/train/images 100 \n",
      "\n",
      "temp_1_41/train/labels 500\n",
      "temp_1_41/train/images 500 \n",
      "\n",
      "temp_1_42/train/labels 500\n",
      "temp_1_42/train/images 500 \n",
      "\n",
      "temp_1_43/train/labels 500\n",
      "temp_1_43/train/images 500 \n",
      "\n",
      "temp_1_44/train/labels 500\n",
      "temp_1_44/train/images 500 \n",
      "\n",
      "temp_1_45/train/labels 500\n",
      "temp_1_45/train/images 500 \n",
      "\n",
      "temp_1_46/train/labels 500\n",
      "temp_1_46/train/images 500 \n",
      "\n",
      "temp_1_47/train/labels 297\n",
      "temp_1_47/train/images 297 \n",
      "\n",
      "/kaggle/working/feet-14/data.yaml\n",
      "defaultdict(<class 'int'>, {'0': 47, '1': 47}) defaultdict(<class 'list'>, {'0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 30.3MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 178MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 202.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<00:00, 964.60it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/valid_0/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.28G     0.4503      1.356      4.092      1.023          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]\n",
      "                   all        474        474     0.0341     0.0422    0.00898    0.00783     0.0341     0.0422    0.00934    0.00805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G     0.9237      3.987      5.916      1.256          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0316     0.0485    0.00924    0.00814     0.0316     0.0485    0.00964    0.00832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G      0.552      3.478      4.422     0.8572          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0143      0.129    0.00847    0.00742     0.0147      0.133    0.00893    0.00768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.35G     0.4514       1.04      3.864       0.87          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0336     0.0506    0.00834    0.00728     0.0336     0.0506    0.00881     0.0075\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.32G      1.286      1.994      5.393      1.575          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0274     0.0865    0.00841    0.00741     0.0274     0.0865    0.00897    0.00765\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474     0.0313     0.0485    0.00924    0.00813     0.0313     0.0485     0.0096    0.00831\n",
      "                  card        474        474     0.0313     0.0485    0.00924    0.00813     0.0313     0.0485     0.0096    0.00831\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<00:00, 1029.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/test_0/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.72it/s]\n",
      "                   all        476        476     0.0053      0.628    0.00866    0.00766    0.00544      0.645    0.00919      0.008\n",
      "                  card        476        476     0.0053      0.628    0.00866    0.00766    0.00544      0.645    0.00919      0.008\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 614.28it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.05G      1.057      1.077      3.621     0.9555          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0205       0.11    0.00954    0.00815     0.0197      0.105    0.00958    0.00814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G      1.163      1.292       4.87      1.108          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0329     0.0802    0.00952    0.00809     0.0337     0.0823       0.01     0.0082\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G      1.471      1.042      4.225       1.53          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0364     0.0696    0.00967    0.00814     0.0364     0.0696     0.0101    0.00834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.31G      3.401      2.356      11.12      2.122          1        640: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0422     0.0527    0.00969    0.00822     0.0456      0.057     0.0103    0.00844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.32G      1.458      1.003      5.574      1.456          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474      0.043     0.0295    0.00965    0.00829      0.043     0.0295     0.0105    0.00855\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474     0.0431     0.0295    0.00965    0.00829     0.0431     0.0295     0.0105    0.00857\n",
      "                  card        474        474     0.0431     0.0295    0.00965    0.00829     0.0431     0.0295     0.0105    0.00857\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "                   all        476        476     0.0689     0.0294    0.00792    0.00686     0.0739     0.0315    0.00901    0.00748\n",
      "                  card        476        476     0.0689     0.0294    0.00792    0.00686     0.0739     0.0315    0.00901    0.00748\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 747.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.1G     0.6815     0.9793      3.869     0.8959          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0348     0.0422    0.00951    0.00844     0.0348     0.0422       0.01    0.00869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.85G      1.133      2.821      5.124      1.224          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0357     0.0422    0.00957    0.00849     0.0357     0.0422       0.01    0.00869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.78G      0.768      1.549      4.942      1.115          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0316     0.0654    0.00949    0.00839     0.0316     0.0654    0.00977    0.00858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.77G     0.7768      1.417      4.273      1.025          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.031     0.0633    0.00895    0.00778     0.0259     0.0802    0.00932    0.00805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.78G     0.7896      1.421      4.586      1.094          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0189     0.0928     0.0088    0.00763     0.0197      0.097    0.00922    0.00795\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.036     0.0422    0.00954    0.00844      0.036     0.0422    0.00993    0.00866\n",
      "                  card        474        474      0.036     0.0422    0.00954    0.00844      0.036     0.0422    0.00993    0.00866\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.70it/s]\n",
      "                   all        476        476     0.0027        0.2    0.00851    0.00754    0.00312      0.231     0.0089    0.00776\n",
      "                  card        476        476     0.0027        0.2    0.00851    0.00754    0.00312      0.231     0.0089    0.00776\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 711.80it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.44G     0.8676      1.167      5.092      1.087          3        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0276     0.0928    0.00915    0.00748     0.0264     0.0886    0.00918    0.00749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G      0.809      1.685      4.698      1.119          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0429      0.038    0.00883    0.00731     0.0429      0.038    0.00898    0.00744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.33G      1.455      1.098      6.021      1.216          1        640: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0616     0.0316    0.00881    0.00741     0.0575     0.0295    0.00905    0.00752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.31G     0.9692      2.301      7.846      1.207          1        640: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0784     0.0271    0.00907    0.00767     0.0732     0.0253    0.00934     0.0078\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.33G      1.231      1.771      3.936      1.218          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0823      0.019    0.00919    0.00783     0.0823      0.019     0.0094    0.00794\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474     0.0817      0.019    0.00916    0.00775     0.0817      0.019    0.00935    0.00791\n",
      "                  card        474        474     0.0817      0.019    0.00916    0.00775     0.0817      0.019    0.00935    0.00791\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.70it/s]\n",
      "                   all        476        476    0.00459      0.571     0.0067    0.00574    0.00486      0.605    0.00745    0.00597\n",
      "                  card        476        476    0.00459      0.571     0.0067    0.00574    0.00486      0.605    0.00745    0.00597\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 802.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.13G     0.7799      1.395       4.27     0.9324          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n",
      "                   all        474        474     0.0282     0.0591     0.0091    0.00793     0.0282     0.0591    0.00955    0.00821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.07G     0.9239      1.698      4.581      1.119          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0314     0.0485    0.00934    0.00813     0.0314     0.0485    0.00973    0.00843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.06G     0.5501      1.176      5.008      1.039          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0475     0.0401    0.00926    0.00814     0.0475     0.0401     0.0096    0.00833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      5.06G      1.138      2.531      5.621      1.234          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0495     0.0412    0.00923    0.00811     0.0495     0.0412    0.00952    0.00835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.94G     0.8881      1.311      4.458     0.9442         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0582     0.0295    0.00917    0.00798     0.0582     0.0295    0.00941    0.00821\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0301     0.0464    0.00932    0.00815     0.0301     0.0464     0.0097    0.00841\n",
      "                  card        474        474     0.0301     0.0464    0.00932    0.00815     0.0301     0.0464     0.0097    0.00841\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.74it/s]\n",
      "                   all        476        476    0.00306      0.319    0.00861    0.00762    0.00344      0.359     0.0091    0.00789\n",
      "                  card        476        476    0.00306      0.319    0.00861    0.00762    0.00344      0.359     0.0091    0.00789\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 857.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.43G     0.3857     0.5586      3.985     0.8632          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0483     0.0338    0.00917    0.00757     0.0483     0.0338    0.00922    0.00762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G     0.2581      7.032      3.977     0.8506          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.046     0.0359     0.0096    0.00798      0.046     0.0359    0.00998    0.00818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G     0.4252      3.001      4.424     0.9498          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0529     0.0316       0.01    0.00833     0.0529     0.0316     0.0104    0.00865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.31G     0.5444     0.8011      6.171      1.095          1        640: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0525     0.0527     0.0106    0.00879     0.0525     0.0527      0.011     0.0092\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.31G     0.5752       5.48      5.022      1.058          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0396      0.057    0.00999    0.00834      0.044     0.0633     0.0108     0.0088\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0576     0.0506     0.0105    0.00876     0.0576     0.0506      0.011     0.0092\n",
      "                  card        474        474     0.0576     0.0506     0.0105    0.00876     0.0576     0.0506      0.011     0.0092\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.67it/s]\n",
      "                   all        476        476      0.085     0.0105    0.00892    0.00772      0.094     0.0147    0.00971    0.00785\n",
      "                  card        476        476      0.085     0.0105    0.00892    0.00772      0.094     0.0147    0.00971    0.00785\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 864.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.05G     0.5308      0.789      4.314     0.8733         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0322     0.0401    0.00894    0.00781     0.0322     0.0401    0.00944    0.00809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.15G     0.6443      1.632      4.857     0.9817         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0284     0.0464    0.00946    0.00821     0.0284     0.0464    0.00985    0.00847\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.18G     0.6226      1.437      4.812     0.9894         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0346     0.0443     0.0092    0.00788     0.0346     0.0443    0.00943    0.00809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      6.19G      1.081      1.378      5.071      1.143          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.034      0.057    0.00906    0.00783      0.034      0.057    0.00926    0.00803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      6.17G     0.8228      1.056      4.495      1.078         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0397     0.0431    0.00907    0.00778     0.0397     0.0431    0.00925      0.008\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.033     0.0422    0.00939    0.00816      0.033     0.0422    0.00978    0.00841\n",
      "                  card        474        474      0.033     0.0422    0.00939    0.00816      0.033     0.0422    0.00978    0.00841\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.72it/s]\n",
      "                   all        476        476    0.00277      0.258    0.00913    0.00774    0.00319      0.298    0.00939    0.00798\n",
      "                  card        476        476    0.00277      0.258    0.00913    0.00774    0.00319      0.298    0.00939    0.00798\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 631.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G     0.7109      1.189      4.307     0.9801          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]\n",
      "                   all        474        474     0.0463     0.0274    0.00982     0.0081     0.0463     0.0274     0.0103    0.00833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G     0.5881     0.9167      5.832     0.9882          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0476      0.057    0.00977    0.00802     0.0494     0.0591     0.0104    0.00831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.31G     0.5839      1.126      4.834     0.8756          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.50it/s]\n",
      "                   all        474        474     0.0387      0.057    0.00979    0.00809     0.0416     0.0612     0.0104    0.00845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.34G     0.7135     0.7789      4.371     0.8998          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0444     0.0675     0.0107    0.00875     0.0472     0.0717     0.0114    0.00921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.43G     0.7587      1.376      5.418       1.14          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0462     0.0527     0.0107     0.0087     0.0481     0.0549     0.0113    0.00911\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474     0.0492     0.0633     0.0108    0.00878     0.0525     0.0675     0.0115    0.00924\n",
      "                  card        474        474     0.0492     0.0633     0.0108    0.00878     0.0525     0.0675     0.0115    0.00924\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.73it/s]\n",
      "                   all        476        476     0.0586     0.0168    0.00914    0.00778     0.0659     0.0189     0.0102    0.00813\n",
      "                  card        476        476     0.0586     0.0168    0.00914    0.00778     0.0659     0.0189     0.0102    0.00813\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 897.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.15G     0.7478      1.858      3.898     0.9484          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0599      0.019       0.01    0.00833     0.0599      0.019     0.0101    0.00811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.5183      1.099      4.699      1.007          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0529     0.0274     0.0101    0.00842     0.0529     0.0274     0.0103    0.00825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.87G     0.5677      1.847       4.35     0.8435          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0482      0.038    0.00946     0.0079     0.0482      0.038    0.00974    0.00793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.89G     0.5551     0.8428      4.833     0.9365          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0526     0.0401    0.00925     0.0075     0.0526     0.0401    0.00973    0.00767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.89G     0.3931      1.382      4.356      1.012          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0503     0.0401    0.00894    0.00705     0.0503     0.0401    0.00902    0.00726\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0534     0.0274       0.01    0.00836     0.0534     0.0274     0.0102    0.00826\n",
      "                  card        474        474     0.0534     0.0274       0.01    0.00836     0.0534     0.0274     0.0102    0.00826\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "                   all        476        476     0.0281     0.0525    0.00686    0.00571      0.027     0.0504    0.00716     0.0058\n",
      "                  card        476        476     0.0281     0.0525    0.00686    0.00571      0.027     0.0504    0.00716     0.0058\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 1124.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.27G     0.6486      1.539       4.74      1.042         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0316     0.0401    0.00884     0.0076     0.0316     0.0401    0.00918    0.00789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.81G     0.6914      1.611      4.848          1         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0359      0.038    0.00882     0.0076     0.0359      0.038    0.00917     0.0079\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       8.8G     0.7777      1.428      4.532      1.014         24        640: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0316     0.0422    0.00867    0.00743     0.0316     0.0422    0.00888     0.0077\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.78G     0.8646      1.965      4.653      1.125         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0331     0.0443    0.00861    0.00736     0.0331     0.0443    0.00881    0.00759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.78G       0.68      1.497       4.31      1.007         26        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0391     0.0443    0.00866    0.00744     0.0391     0.0443    0.00891    0.00764\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474     0.0358      0.038    0.00875    0.00758     0.0358      0.038     0.0091    0.00784\n",
      "                  card        474        474     0.0358      0.038    0.00875    0.00758     0.0358      0.038     0.0091    0.00784\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "                   all        476        476    0.00374      0.414     0.0085    0.00748    0.00395      0.437    0.00887    0.00778\n",
      "                  card        476        476    0.00374      0.414     0.0085    0.00748    0.00395      0.437    0.00887    0.00778\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 913.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.44G     0.5132      2.176      4.991     0.9516          4        640: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0421     0.0443    0.00916    0.00755     0.0421     0.0443    0.00957    0.00776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.6331      1.707       4.64     0.7141          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0421     0.0401     0.0091    0.00746     0.0394     0.0422    0.00954    0.00771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.89G     0.7585       2.11      4.449     0.8405          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0343     0.0527    0.00882    0.00727     0.0357     0.0549     0.0095     0.0076\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.89G     0.4845     0.7751      6.459     0.9904          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0307     0.0485    0.00872     0.0072     0.0334     0.0527    0.00948    0.00759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.87G     0.8544      2.666      4.529     0.9926          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0258     0.0506    0.00858    0.00705      0.029      0.057     0.0096    0.00746\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0414     0.0506    0.00917    0.00755     0.0414     0.0506    0.00959    0.00777\n",
      "                  card        474        474     0.0414     0.0506    0.00917    0.00755     0.0414     0.0506    0.00959    0.00777\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.70it/s]\n",
      "                   all        476        476     0.0548     0.0357    0.00845    0.00728     0.0563     0.0396    0.00903    0.00758\n",
      "                  card        476        476     0.0548     0.0357    0.00845    0.00728     0.0563     0.0396    0.00903    0.00758\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 1037.31it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.52G     0.7988      2.025      4.554       1.04         27        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0317     0.0401    0.00893    0.00776     0.0317     0.0401    0.00937    0.00802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G     0.7411      1.921       5.05      1.033         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0436      0.038    0.00893    0.00774      0.036      0.038    0.00931      0.008\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.3G     0.5989      1.827      4.574      1.035         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0427      0.038    0.00902    0.00777     0.0427      0.038     0.0092      0.008\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.3G     0.7617      2.096      4.381     0.9762         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0396     0.0359    0.00864    0.00739     0.0396     0.0359    0.00885    0.00759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.31G      0.715      1.897      4.521      1.036         24        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0409      0.038    0.00847    0.00724     0.0409      0.038    0.00871    0.00745\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0317     0.0401    0.00893    0.00776      0.029     0.0464    0.00944    0.00803\n",
      "                  card        474        474     0.0317     0.0401    0.00893    0.00776      0.029     0.0464    0.00944    0.00803\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "                   all        476        476    0.00686      0.116    0.00848    0.00742    0.00786      0.132    0.00893    0.00773\n",
      "                  card        476        476    0.00686      0.116    0.00848    0.00742    0.00786      0.132    0.00893    0.00773\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 966.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G     0.6373      1.478      4.492     0.8849          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0461      0.038     0.0093    0.00766     0.0461      0.038    0.00996    0.00799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.87G     0.7281      2.068      5.059      1.019          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.044     0.0359    0.00935    0.00764      0.044     0.0359       0.01    0.00801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.87G     0.6181      1.621      4.475     0.9577          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0376     0.0359    0.00932    0.00767     0.0399      0.038     0.0101    0.00809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.87G     0.6031      1.328      4.561     0.8387          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.036     0.0527    0.00935     0.0077     0.0389      0.057     0.0104    0.00821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.89G     0.9634       2.25      4.366     0.8346          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0258     0.0992    0.00924    0.00767     0.0269      0.103     0.0101    0.00808\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0359     0.0633    0.00937    0.00774     0.0395     0.0696     0.0104    0.00823\n",
      "                  card        474        474     0.0359     0.0633    0.00937    0.00774     0.0395     0.0696     0.0104    0.00823\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "                   all        476        476     0.0535     0.0231    0.00861    0.00741     0.0486      0.021    0.00935    0.00782\n",
      "                  card        476        476     0.0535     0.0231    0.00861    0.00741     0.0486      0.021    0.00935    0.00782\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 1059.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.29G     0.8244      1.924      5.212      1.115          2        640: 100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.034     0.0422    0.00888    0.00767      0.034     0.0422    0.00938    0.00801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.3G       0.63      1.699      4.259     0.9649          6        640: 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474     0.0351     0.0443    0.00857    0.00733     0.0351     0.0443    0.00906     0.0076\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.31G     0.6728      1.752      4.559     0.9668          4        640: 100%|██████████| 2/2 [00:01<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0363     0.0485    0.00888    0.00738     0.0363     0.0485    0.00938    0.00779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.31G     0.8674      3.185      5.585       1.15          2        640: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0467     0.0549    0.00967    0.00818     0.0431     0.0506     0.0103    0.00845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.42G     0.5554      2.232      4.762     0.9076          2        640: 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0547     0.0802     0.0123     0.0103     0.0518     0.0759     0.0133     0.0106\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0548     0.0802     0.0122     0.0103     0.0519     0.0759     0.0132     0.0106\n",
      "                  card        474        474     0.0548     0.0802     0.0122     0.0103     0.0519     0.0759     0.0132     0.0106\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.74it/s]\n",
      "                   all        476        476    0.00532      0.643     0.0102    0.00848    0.00561      0.679     0.0114    0.00923\n",
      "                  card        476        476    0.00532      0.643     0.0102    0.00848    0.00561      0.679     0.0114    0.00923\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1127.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.55G      0.579       1.03      3.684     0.8639          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0664     0.0105      0.013     0.0108     0.0664     0.0105      0.014     0.0112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.8378       2.51      6.278      1.279          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0719     0.0105     0.0132     0.0109     0.0656     0.0105      0.014     0.0115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.87G     0.5069      2.052      4.054     0.9663          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0725     0.0105     0.0128     0.0107     0.0725     0.0105     0.0136     0.0113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.87G     0.5385      5.778      4.006     0.9683          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0644    0.00844     0.0128     0.0109     0.0609    0.00844     0.0144     0.0116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.89G     0.4155      1.747      3.596     0.7813          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0641    0.00844     0.0126     0.0109     0.0639    0.00893     0.0147     0.0118\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474     0.0632    0.00844     0.0126     0.0109     0.0632    0.00844     0.0146     0.0117\n",
      "                  card        474        474     0.0632    0.00844     0.0126     0.0109     0.0632    0.00844     0.0146     0.0117\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.73it/s]\n",
      "                   all        476        476     0.0674     0.0126     0.0103    0.00876     0.0674     0.0126     0.0125    0.00983\n",
      "                  card        476        476     0.0674     0.0126     0.0103    0.00876     0.0674     0.0126     0.0125    0.00983\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1073.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.06G     0.4769      1.699      3.998     0.8593          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0706     0.0148     0.0144      0.012     0.0706     0.0148     0.0152     0.0121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.6942      1.038      4.802     0.9155          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474      0.057     0.0148     0.0143     0.0119      0.057     0.0148      0.015     0.0121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.89G     0.3479     0.5739       4.27     0.8763          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0582     0.0211     0.0141     0.0118     0.0582     0.0211      0.015     0.0121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.87G      0.386      0.886      4.691     0.9625          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0522     0.0232      0.014     0.0114     0.0569     0.0253     0.0144     0.0117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G     0.7564      1.205      4.056      1.056          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0479     0.0274     0.0138     0.0112     0.0516     0.0295     0.0145     0.0116\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474     0.0691     0.0148     0.0143      0.012     0.0691     0.0148     0.0153     0.0121\n",
      "                  card        474        474     0.0691     0.0148     0.0143      0.012     0.0691     0.0148     0.0153     0.0121\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "                   all        476        476     0.0352     0.0336    0.00933    0.00801     0.0374     0.0357     0.0105    0.00839\n",
      "                  card        476        476     0.0352     0.0336    0.00933    0.00801     0.0374     0.0357     0.0105    0.00839\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 1048.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.53G     0.7412      1.687      4.296     0.9793         19        640: 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0455     0.0391    0.00934    0.00813     0.0455     0.0391     0.0097    0.00841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.58G       0.64      1.093      4.778     0.9681          9        640: 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0484     0.0359    0.00905    0.00788     0.0484     0.0359     0.0093    0.00812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G     0.6441      1.676      4.344     0.9853         13        640: 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474     0.0477      0.038    0.00883     0.0076     0.0477      0.038     0.0092    0.00788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.31G      0.623      1.378      4.439     0.9717         14        640: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0498     0.0591     0.0111    0.00951     0.0516     0.0612     0.0119       0.01\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.41G     0.6859       1.56      4.161     0.9791         16        640: 100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474    0.00503      0.525     0.0277     0.0237    0.00543      0.568     0.0292     0.0243\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474    0.00511       0.47     0.0276     0.0236    0.00557      0.513      0.029     0.0243\n",
      "                  card        474        474    0.00511       0.47     0.0276     0.0236    0.00557      0.513      0.029     0.0243\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "                   all        476        476     0.0046      0.433     0.0178     0.0155    0.00498      0.468     0.0193     0.0162\n",
      "                  card        476        476     0.0046      0.433     0.0178     0.0155    0.00498      0.468     0.0193     0.0162\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 884.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G      0.636      1.374      3.639     0.9272          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.117      0.019     0.0274     0.0234      0.117      0.019     0.0288     0.0238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.3999      1.335      5.586     0.9224          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.112     0.0185     0.0278     0.0238      0.109      0.019     0.0291     0.0242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.89G     0.7594      2.861      4.276      1.093          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.108      0.019     0.0283     0.0241      0.136      0.038     0.0293     0.0246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.89G     0.7552      1.952      5.596      1.062          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.108      0.019     0.0284     0.0241      0.108      0.019     0.0295     0.0248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G     0.8882      3.071      3.985      1.203          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0998     0.0169     0.0277     0.0235      0.106      0.019     0.0286     0.0238\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.112     0.0198     0.0283      0.024      0.112     0.0198     0.0294     0.0246\n",
      "                  card        474        474      0.112     0.0198     0.0283      0.024      0.112     0.0198     0.0294     0.0246\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.78it/s]\n",
      "                   all        476        476     0.0671     0.0147     0.0217     0.0189     0.0671     0.0147     0.0229     0.0194\n",
      "                  card        476        476     0.0671     0.0147     0.0217     0.0189     0.0671     0.0147     0.0229     0.0194\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1100.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.04G     0.4667     0.8973      3.787     0.9689          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.103     0.0387     0.0274     0.0236      0.103     0.0387     0.0278     0.0232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G     0.7818     0.8978      5.208     0.9675          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.108     0.0316     0.0266     0.0228      0.107     0.0316     0.0273     0.0227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.87G     0.5342      1.264      3.871      1.009          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0964     0.0274     0.0259     0.0222     0.0964     0.0274     0.0267      0.022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.89G     0.8099     0.5011      4.495     0.7311          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474     0.0898     0.0295     0.0248     0.0211     0.0987     0.0359     0.0256     0.0211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.86G     0.5782      1.454      4.116     0.8416          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0908     0.0316     0.0235     0.0199     0.0852     0.0338     0.0246       0.02\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474     0.0996     0.0359      0.027     0.0232     0.0996     0.0359     0.0274     0.0228\n",
      "                  card        474        474     0.0996     0.0359      0.027     0.0232     0.0996     0.0359     0.0274     0.0228\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.78it/s]\n",
      "                   all        476        476     0.0744     0.0336     0.0225     0.0189     0.0744     0.0336     0.0238     0.0189\n",
      "                  card        476        476     0.0744     0.0336     0.0225     0.0189     0.0744     0.0336     0.0238     0.0189\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 1122.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.53G     0.6602      1.482       4.59     0.9673         16        640: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0459     0.0401    0.00927    0.00801     0.0459     0.0401    0.00969    0.00834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.58G     0.6154      1.171       4.28     0.9183         27        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0472     0.0359     0.0089    0.00766     0.0472     0.0359    0.00915    0.00792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.34G     0.7474      2.138      4.625      1.011         24        640: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0436     0.0401    0.00876    0.00746     0.0436     0.0401    0.00915    0.00776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.31G     0.6393      1.437      4.391     0.9535         21        640: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0688     0.0591     0.0153      0.013     0.0688     0.0591     0.0163     0.0133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.41G     0.6979      1.394      4.208      0.956         31        640: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.184     0.0781     0.0557     0.0484      0.198     0.0893      0.057     0.0485\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.189     0.0844      0.056     0.0487      0.189     0.0844     0.0573     0.0488\n",
      "                  card        474        474      0.189     0.0844      0.056     0.0487      0.189     0.0844     0.0573     0.0488\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "                   all        476        476      0.149     0.0672     0.0381     0.0335      0.149     0.0672     0.0404     0.0343\n",
      "                  card        476        476      0.149     0.0672     0.0381     0.0335      0.149     0.0672     0.0404     0.0343\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1135.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.56G     0.6631      1.535      4.471      1.019          8        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.163     0.0274     0.0584       0.05      0.163     0.0274     0.0594     0.0502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G     0.8913      2.797      3.467      1.267          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.171     0.0295     0.0605     0.0522      0.171     0.0295     0.0625     0.0526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.5644      1.309      3.509     0.9493          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]\n",
      "                   all        474        474      0.163     0.0274     0.0601     0.0518      0.163     0.0274     0.0615     0.0523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.5896       1.97      3.818     0.9801          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]\n",
      "                   all        474        474      0.168     0.0295     0.0589     0.0502      0.168     0.0295     0.0594     0.0506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.3535     0.5479      3.605     0.8565          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]\n",
      "                   all        474        474      0.154     0.0274      0.059     0.0505      0.154     0.0274     0.0601     0.0508\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.172     0.0295     0.0606     0.0524      0.172     0.0295     0.0619     0.0526\n",
      "                  card        474        474      0.172     0.0295     0.0606     0.0524      0.172     0.0295     0.0619     0.0526\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:11<00:00,  2.71it/s]\n",
      "                   all        476        476      0.111     0.0294      0.049     0.0434      0.111     0.0294     0.0524     0.0435\n",
      "                  card        476        476      0.111     0.0294      0.049     0.0434      0.111     0.0294     0.0524     0.0435\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1125.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.07G      1.161      3.247      4.907      1.304          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474      0.178     0.0591     0.0517     0.0443      0.178     0.0591     0.0519     0.0439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.4878      1.177      4.496     0.9779          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.141     0.0422     0.0496     0.0427      0.141     0.0422       0.05     0.0423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G     0.4875      1.287       4.01     0.8507          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474       0.13     0.0401      0.048     0.0414       0.13     0.0401     0.0486      0.041\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.4571      1.078      4.111     0.8349          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474       0.14     0.0443     0.0481      0.041       0.14     0.0443     0.0484     0.0405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.7673     0.9697      4.513     0.9036          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.137     0.0443     0.0484     0.0411      0.137     0.0443     0.0487     0.0407\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.177     0.0591     0.0517     0.0443      0.177     0.0591      0.052      0.044\n",
      "                  card        474        474      0.177     0.0591     0.0517     0.0443      0.177     0.0591      0.052      0.044\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "                   all        476        476      0.125      0.063     0.0426     0.0369      0.125      0.063     0.0438     0.0364\n",
      "                  card        476        476      0.125      0.063     0.0426     0.0369      0.125      0.063     0.0438     0.0364\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 1164.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.6256      1.862      4.369      1.026         16        640: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.50it/s]\n",
      "                   all        474        474     0.0455      0.038     0.0092    0.00795     0.0455      0.038    0.00943     0.0082\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.41G     0.6933      1.967      4.447     0.9911         18        640: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0523     0.0401    0.00863    0.00733     0.0523     0.0401    0.00916    0.00771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.31G      0.635       1.32      4.162     0.9271         17        640: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.164     0.0549     0.0555     0.0481      0.164     0.0549     0.0569     0.0486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.41G     0.5661      1.087      3.546     0.9035         16        640: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.818      0.532      0.706      0.631      0.815       0.53      0.703      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.4G     0.5489      1.081      2.312     0.9057         15        640: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.877      0.831      0.914      0.818      0.874      0.833       0.91      0.795\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.877      0.831      0.914      0.818      0.875      0.831      0.909      0.795\n",
      "                  card        474        474      0.877      0.831      0.914      0.818      0.875      0.831      0.909      0.795\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.79it/s]\n",
      "                   all        476        476      0.895      0.832      0.921       0.82      0.893       0.83      0.916      0.798\n",
      "                  card        476        476      0.895      0.832      0.921       0.82      0.893       0.83      0.916      0.798\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 890.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.55G     0.4708     0.6017      1.886     0.9349         11        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.822      0.793       0.86      0.763      0.819      0.791      0.856      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.3157      0.778      1.724     0.8715          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.823      0.807       0.86      0.764      0.821      0.805      0.858      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.2909     0.6543      1.608     0.8615          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.824      0.801      0.859      0.764      0.822      0.799      0.857      0.742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.5288      0.936      1.588     0.8629          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.814      0.795      0.855       0.76      0.812      0.793      0.852      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.3291     0.5066      1.253     0.8637          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.823      0.776      0.856      0.762       0.82      0.774      0.853       0.74\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.828      0.802      0.861      0.764      0.821      0.805      0.857      0.743\n",
      "                  card        474        474      0.828      0.802      0.861      0.764      0.821      0.805      0.857      0.743\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.79it/s]\n",
      "                   all        476        476      0.835      0.832      0.874      0.775      0.831      0.828      0.868      0.751\n",
      "                  card        476        476      0.835      0.832      0.874      0.775      0.831      0.828      0.868      0.751\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 979.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.65G     0.5651      1.366      4.327      0.925         24        640: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0428     0.0443    0.00902    0.00776     0.0428     0.0443    0.00926    0.00797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.7G     0.6629      2.017      4.507     0.9762         23        640: 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0435     0.0485    0.00879    0.00742     0.0435     0.0485    0.00923     0.0078\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.43G     0.6814      1.628      4.254      0.971         27        640: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474       0.15     0.0372     0.0747     0.0645       0.15     0.0372     0.0762     0.0645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.52G      0.529      1.134      3.762     0.9073         17        640: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.795       0.58      0.748      0.665      0.792      0.578      0.745      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.53G     0.6033      1.078      2.769     0.9198         19        640: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.867      0.798      0.896        0.8      0.865      0.796      0.893      0.777\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.866      0.797      0.896        0.8      0.865      0.785      0.892      0.777\n",
      "                  card        474        474      0.866      0.797      0.896        0.8      0.865      0.785      0.892      0.777\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "                   all        476        476      0.879      0.811      0.904      0.804      0.877      0.811        0.9      0.783\n",
      "                  card        476        476      0.879      0.811      0.904      0.804      0.877      0.811        0.9      0.783\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 977.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.64G     0.3942     0.7611      1.324     0.9076          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.824      0.774      0.843      0.746      0.821      0.772      0.841       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G     0.8468      1.875      2.202     0.9608          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.812      0.766      0.842      0.746      0.809      0.764      0.839      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.7663      2.209      2.419     0.9745          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.823      0.753      0.839      0.744      0.821      0.751      0.836      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.5529      2.437      2.141     0.8815          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.824       0.76      0.837      0.741      0.822      0.758      0.834      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.6562      1.244      1.531     0.9337          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.822      0.766      0.839      0.743      0.819      0.764      0.836      0.726\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.824      0.774      0.844      0.748      0.821      0.772      0.841      0.731\n",
      "                  card        474        474      0.824      0.774      0.844      0.748      0.821      0.772      0.841      0.731\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.80it/s]\n",
      "                   all        476        476      0.854      0.772      0.856      0.758      0.851      0.778      0.852      0.736\n",
      "                  card        476        476      0.854      0.772      0.856      0.758      0.851      0.778      0.852      0.736\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 1009.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G     0.6251      1.434      4.535     0.9472          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.50it/s]\n",
      "                   all        474        474     0.0447     0.0464    0.00904    0.00783     0.0447     0.0464    0.00945    0.00804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.53G     0.6729      1.465      4.465      0.976          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474     0.0899     0.0253     0.0197     0.0172     0.0899     0.0253      0.021     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.54G     0.6521      1.482      4.136     0.8912          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474       0.81      0.585      0.744      0.665      0.807      0.583      0.742       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.53G     0.5842      1.338      1.983     0.9393          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.931       0.88      0.956      0.862      0.928      0.878      0.953      0.838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.54G     0.5793     0.8228      1.829     0.8762          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.941      0.899      0.966      0.874      0.939      0.897      0.963       0.85\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.941      0.902      0.966      0.874      0.938        0.9      0.963      0.849\n",
      "                  card        474        474      0.941      0.902      0.966      0.874      0.938        0.9      0.963      0.849\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "                   all        476        476       0.92      0.918      0.973      0.876      0.917      0.916      0.971      0.852\n",
      "                  card        476        476       0.92      0.918      0.973      0.876      0.917      0.916      0.971      0.852\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 936.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.28G      0.631      1.045      1.469     0.8698          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.882      0.917      0.937      0.842       0.88      0.915      0.935      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.03G     0.5238      1.005      1.837     0.9952          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.874       0.92      0.939      0.844      0.872      0.918      0.937      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G     0.4948     0.6864      2.058     0.9586          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.874      0.922      0.941      0.846      0.872       0.92      0.939      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G       0.39     0.6557      1.839      1.015          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.869      0.924      0.943      0.849      0.867      0.921      0.939      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.4835     0.4873      2.011     0.8079          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.868      0.919      0.943       0.85      0.866      0.917       0.94      0.827\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.868      0.918      0.943      0.851      0.866      0.916       0.94      0.827\n",
      "                  card        474        474      0.868      0.918      0.943      0.851      0.866      0.916       0.94      0.827\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "                   all        476        476      0.925       0.88       0.95      0.851       0.92      0.876      0.946      0.825\n",
      "                  card        476        476      0.925       0.88       0.95      0.851       0.92      0.876      0.946      0.825\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<00:00, 958.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.64G     0.6185      1.374      4.636     0.9521          9        640: 100%|██████████| 4/4 [00:02<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0563      0.038     0.0093    0.00807     0.0563      0.038    0.00956    0.00829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.44G     0.6824      1.439      4.282     0.9841         17        640: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0631     0.0338    0.00965    0.00808     0.0631     0.0338     0.0105    0.00857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.42G     0.6526      1.444      3.987       0.94         10        640: 100%|██████████| 4/4 [00:02<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.822      0.586       0.75      0.671      0.819      0.584      0.748      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.5756       1.02      2.163     0.8913         15        640: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.952      0.876      0.967      0.874       0.95      0.874      0.964       0.85\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.53G     0.4865     0.8311      1.367     0.8858         12        640: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474       0.94      0.898       0.97      0.877      0.938      0.896      0.968      0.855\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474       0.94        0.9       0.97      0.877      0.938      0.898      0.968      0.855\n",
      "                  card        474        474       0.94        0.9       0.97      0.877      0.938      0.898      0.968      0.855\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.77it/s]\n",
      "                   all        476        476      0.926       0.92      0.971      0.876      0.924      0.918      0.968      0.854\n",
      "                  card        476        476      0.926       0.92      0.971      0.876      0.924      0.918      0.968      0.854\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 814.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.36G      0.545     0.8088      1.074     0.8278          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.903      0.882      0.942      0.847      0.901       0.88      0.938      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.5893     0.9395       2.78      1.089          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.908      0.876      0.943      0.848      0.906      0.874      0.939      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G     0.7182     0.8929      2.015      1.091          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.909      0.869      0.944       0.85      0.907      0.867      0.939      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G     0.4316      1.002      1.965     0.9102          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.907      0.868      0.944      0.851      0.905      0.866       0.94      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.7513     0.9467      1.362      1.024          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.908      0.872      0.945      0.852      0.906       0.87      0.941      0.827\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.908      0.875      0.945      0.852      0.906      0.873      0.941      0.827\n",
      "                  card        474        474      0.908      0.875      0.945      0.852      0.906      0.873      0.941      0.827\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "                   all        476        476      0.918      0.874      0.953      0.855      0.913       0.87      0.947      0.829\n",
      "                  card        476        476      0.918      0.874      0.953      0.855      0.913       0.87      0.947      0.829\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<00:00, 954.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.65G     0.6298      1.554      4.568     0.9484         15        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0435     0.0464    0.00905    0.00775     0.0435     0.0464    0.00926      0.008\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G     0.6431      1.255      4.365     0.9707         25        640: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0107      0.319     0.0239     0.0205     0.0117       0.35      0.025     0.0209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G     0.5608      1.102      3.525     0.9423         19        640: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.872      0.852      0.927      0.833       0.87      0.849      0.925      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.53G      0.543     0.9966      1.751     0.9098         23        640: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.946      0.918      0.972      0.883      0.932      0.916      0.968      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.56G     0.4564     0.7427      1.249     0.8743         21        640: 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.942      0.927      0.977      0.891      0.938      0.923      0.975      0.862\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.942      0.927      0.977       0.89      0.938      0.923      0.975      0.861\n",
      "                  card        474        474      0.942      0.927      0.977       0.89      0.938      0.923      0.975      0.861\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "                   all        476        476      0.953       0.93      0.982      0.891       0.95      0.928       0.98      0.859\n",
      "                  card        476        476      0.953       0.93      0.982      0.891       0.95      0.928       0.98      0.859\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1145.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.81G     0.8223     0.8324      1.402      0.949         11        640: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.917      0.883      0.954      0.864      0.912      0.879      0.951      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.6878     0.9883       1.13     0.9081          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.918      0.884      0.955      0.865      0.914       0.88      0.952      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.07G      0.823      1.465      2.063      1.148          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.923      0.881      0.954      0.866      0.918      0.877      0.952      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.6588      1.508      2.135     0.9323          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.925      0.878      0.955      0.866       0.92      0.873      0.953      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G      1.197      1.983      1.593      1.151         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474       0.93      0.875      0.956      0.866      0.926      0.871      0.953      0.838\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474       0.93      0.874      0.956      0.867      0.926       0.87      0.953      0.838\n",
      "                  card        474        474       0.93      0.874      0.956      0.867      0.926       0.87      0.953      0.838\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "                   all        476        476      0.938      0.884      0.959      0.864      0.936      0.882      0.958      0.833\n",
      "                  card        476        476      0.938      0.884      0.959      0.864      0.936      0.882      0.958      0.833\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 1060.79it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G     0.6644      1.536      4.516     0.9548          3        640: 100%|██████████| 5/5 [00:03<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0582     0.0274    0.00918    0.00787     0.0516     0.0274    0.00966    0.00811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.34G      0.619      1.198      3.865     0.9399          4        640: 100%|██████████| 5/5 [00:03<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474      0.586       0.23      0.377      0.334      0.578       0.23      0.378       0.33\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.42G     0.5387     0.8477      2.099     0.8752          3        640: 100%|██████████| 5/5 [00:03<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.936      0.928      0.972       0.88      0.934      0.926      0.969      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.43G     0.4328     0.7212      1.422     0.8315          3        640: 100%|██████████| 5/5 [00:03<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.966      0.892      0.971      0.881      0.964       0.89      0.968      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G     0.4021     0.7159       1.03     0.8757          5        640: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.957      0.899      0.968      0.882      0.955      0.897      0.966      0.852\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.966      0.895      0.971       0.88      0.964      0.893      0.968      0.853\n",
      "                  card        474        474      0.966      0.895      0.971       0.88      0.964      0.893      0.968      0.853\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.963      0.891      0.973      0.882      0.961      0.889       0.97       0.85\n",
      "                  card        476        476      0.963      0.891      0.973      0.882      0.961      0.889       0.97       0.85\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 997.93it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G     0.7168      1.183     0.8848     0.9435         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.951      0.866      0.956      0.863      0.949      0.864      0.953      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G     0.8432      1.592      1.616      1.062          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.958      0.866      0.955      0.864      0.956      0.864      0.953      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G     0.5091     0.7536      1.123     0.8458          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.945      0.877      0.955      0.864      0.943      0.875      0.952      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.08G     0.7726      2.193      1.019     0.8685          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.939      0.883      0.955      0.866      0.937       0.88      0.953      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.4427     0.7547     0.9191      0.893          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.934       0.89      0.955      0.866      0.927      0.892      0.952      0.837\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.933       0.89      0.955      0.867      0.931      0.888      0.952      0.837\n",
      "                  card        474        474      0.933       0.89      0.955      0.867      0.931      0.888      0.952      0.837\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.83it/s]\n",
      "                   all        476        476      0.943      0.887      0.956      0.867      0.941      0.884      0.954      0.835\n",
      "                  card        476        476      0.943      0.887      0.956      0.867      0.941      0.884      0.954      0.835\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 966.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.65G     0.6895      1.583      4.473     0.9695          9        640: 100%|██████████| 5/5 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0498      0.038    0.00922    0.00791     0.0498      0.038    0.00952    0.00816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G     0.5992      1.365      4.147     0.9456         12        640: 100%|██████████| 5/5 [00:03<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.655      0.253      0.436      0.387      0.655      0.253      0.436      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.53G     0.5246     0.9387      2.182     0.9087         13        640: 100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.927      0.936      0.977      0.887      0.925      0.934      0.975      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.4784     0.7668       1.25     0.8736         14        640: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.968      0.924      0.982      0.893      0.965      0.922      0.978      0.864\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.58G     0.4414     0.7039      1.117     0.8758         12        640: 100%|██████████| 5/5 [00:03<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.959      0.946      0.982      0.897      0.972      0.928      0.978      0.864\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.957      0.945      0.982      0.897      0.971      0.928      0.978      0.864\n",
      "                  card        474        474      0.957      0.945      0.982      0.897      0.971      0.928      0.978      0.864\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "                   all        476        476      0.967      0.939      0.982      0.896      0.964      0.937      0.981      0.864\n",
      "                  card        476        476      0.967      0.939      0.982      0.896      0.964      0.937      0.981      0.864\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1031.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.68G     0.3901      0.531     0.8113     0.8584          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.956      0.912      0.974      0.884      0.954      0.907      0.967      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G     0.5081     0.9394      1.076     0.9118          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.961      0.918      0.975      0.886      0.959      0.909      0.968      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G       0.54     0.8711      1.154     0.8432          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.956      0.916      0.975      0.885       0.95      0.909      0.967      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.4821      1.711      1.473     0.9396          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.962       0.91      0.975      0.885      0.956      0.903      0.967      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G     0.6032      1.147      1.306     0.8908          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.954      0.918      0.975      0.886      0.947      0.911      0.968      0.854\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.952      0.922      0.975      0.885      0.945      0.916      0.968      0.854\n",
      "                  card        474        474      0.952      0.922      0.975      0.885      0.945      0.916      0.968      0.854\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.88it/s]\n",
      "                   all        476        476      0.933      0.931      0.976      0.882      0.931      0.928      0.975      0.852\n",
      "                  card        476        476      0.933      0.931      0.976      0.882      0.931      0.928      0.975      0.852\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 1062.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.63G      0.564       1.11       4.24     0.9314         28        640: 100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0524     0.0338    0.00896    0.00767     0.0524     0.0338    0.00921    0.00794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.69G     0.6126      1.313      4.002     0.9575         18        640: 100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.741      0.371      0.532      0.476      0.737      0.369      0.531      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.55G     0.5479      1.001      1.943     0.9056         27        640: 100%|██████████| 5/5 [00:03<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.967      0.911      0.972      0.883      0.965      0.909      0.971      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.53G      0.471     0.8009      1.271     0.8725         15        640: 100%|██████████| 5/5 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.938      0.911      0.972      0.882      0.936      0.909       0.97       0.85\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.58G     0.4374      0.621     0.9413     0.8514         23        640: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.961      0.905      0.973      0.884      0.959      0.903      0.971      0.857\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.964      0.902      0.973      0.885      0.962        0.9      0.971      0.857\n",
      "                  card        474        474      0.964      0.902      0.973      0.885      0.962        0.9      0.971      0.857\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "                   all        476        476      0.969      0.914      0.981      0.896      0.966      0.912      0.979      0.862\n",
      "                  card        476        476      0.969      0.914      0.981      0.896      0.966      0.912      0.979      0.862\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 878.87it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.69G     0.3316     0.5885     0.7942      0.845          8        640: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.926      0.899      0.964      0.876      0.924      0.897      0.959      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.08G     0.3261     0.6783     0.8886     0.8751          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.932      0.899      0.964      0.877       0.93      0.897       0.96      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.3174     0.6811     0.6454     0.8288          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.933      0.899      0.964      0.875      0.931      0.897       0.96      0.842\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.3131     0.4863      1.194     0.8849          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.936      0.897      0.963      0.874      0.934      0.895      0.959      0.841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G     0.5756      1.452      1.012     0.7768          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.938      0.893      0.963      0.871      0.936      0.891      0.957      0.841\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.932      0.896      0.964      0.877       0.93      0.894       0.96      0.843\n",
      "                  card        474        474      0.932      0.896      0.964      0.877       0.93      0.894       0.96      0.843\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.89it/s]\n",
      "                   all        476        476      0.954      0.891      0.967      0.875      0.952      0.889      0.965      0.849\n",
      "                  card        476        476      0.954      0.891      0.967      0.875      0.952      0.889      0.965      0.849\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 1079.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.7129      1.526      4.491      1.001          2        640: 100%|██████████| 6/6 [00:04<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n",
      "                   all        474        474     0.0678     0.0549     0.0152      0.013    0.00631      0.314      0.016     0.0135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G     0.5839      1.235      3.493     0.9085          1        640: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.891      0.876      0.936       0.84      0.886      0.873      0.933      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.4737     0.8583      1.452     0.8954          1        640: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.953      0.932      0.977      0.888      0.951       0.93      0.975       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G      0.515      1.069      1.015     0.8466          2        640: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.958      0.966      0.985        0.9      0.953      0.962      0.982      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G       0.52      0.829     0.9363     0.8673          1        640: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.968      0.965      0.988      0.906      0.964      0.961      0.986      0.874\n",
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.67it/s]\n",
      "                   all        474        474      0.968      0.965      0.988      0.906      0.964      0.961      0.986      0.875\n",
      "                  card        474        474      0.968      0.965      0.988      0.906      0.964      0.961      0.986      0.875\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.80it/s]\n",
      "                   all        476        476      0.961      0.975      0.991      0.904      0.959      0.973      0.991      0.876\n",
      "                  card        476        476      0.961      0.975      0.991      0.904      0.959      0.973      0.991      0.876\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 830.33it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.67G     0.8096      1.032     0.7681     0.9261          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.956      0.947      0.986      0.898      0.952      0.943      0.983      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.9854      1.206      1.529      1.235          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.961      0.933      0.986      0.898      0.957      0.929      0.983      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.7258     0.8696     0.9553     0.9975          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.963      0.939      0.986      0.898      0.959      0.935      0.983      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.7462     0.9902      1.025      1.074          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.959      0.939      0.986      0.899      0.955      0.935      0.983      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G      1.013      1.074     0.9154      1.004          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.973      0.922      0.986      0.899      0.969      0.918      0.983      0.869\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.973      0.923      0.986      0.899      0.969      0.918      0.983      0.869\n",
      "                  card        474        474      0.973      0.923      0.986      0.899      0.969      0.918      0.983      0.869\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.85it/s]\n",
      "                   all        476        476      0.962      0.971      0.988      0.897       0.96      0.968      0.987      0.873\n",
      "                  card        476        476      0.962      0.971      0.988      0.897       0.96      0.968      0.987      0.873\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 1068.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.65G     0.6201      1.433      4.392     0.9612         13        640: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474    0.00483      0.447     0.0212     0.0182    0.00519      0.481     0.0217     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.55G     0.6128      1.132      3.377     0.9388         10        640: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474      0.897      0.863       0.94      0.841      0.895      0.861      0.938      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.55G     0.5059     0.9236       1.32     0.9081         10        640: 100%|██████████| 6/6 [00:04<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.963      0.922      0.968      0.877      0.959      0.918      0.963      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.58G     0.4649     0.7365      1.034     0.8755         10        640: 100%|██████████| 6/6 [00:04<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.974      0.933      0.976      0.887      0.971      0.931      0.972      0.857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.59G     0.4582     0.8206     0.9647     0.9067         11        640: 100%|██████████| 6/6 [00:04<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.979      0.951      0.982      0.898      0.974      0.948      0.981      0.868\n",
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.978      0.951      0.982      0.898      0.974      0.949      0.981      0.868\n",
      "                  card        474        474      0.978      0.951      0.982      0.898      0.974      0.949      0.981      0.868\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "                   all        476        476      0.963      0.962       0.99      0.903      0.961       0.96       0.99      0.872\n",
      "                  card        476        476      0.963      0.962       0.99      0.903      0.961       0.96       0.99      0.872\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1221.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.57G     0.5999     0.8103     0.7789     0.8458          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.969      0.937      0.977      0.889      0.966      0.932      0.975      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.7353     0.6613      1.249     0.9239          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.967      0.938      0.976      0.888      0.971      0.928      0.975      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G     0.4747     0.6867     0.9034     0.7747          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.974      0.932      0.976      0.887      0.973      0.929      0.974       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.4939     0.4636      1.433     0.8824          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.969      0.933      0.976      0.886      0.973       0.93      0.975       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G     0.5351     0.6704       1.12     0.9575          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.968      0.939      0.977      0.887      0.973      0.928      0.972      0.859\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.969      0.936      0.977      0.889      0.966      0.932      0.975      0.862\n",
      "                  card        474        474      0.969      0.936      0.977      0.889      0.966      0.932      0.975      0.862\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.941      0.952      0.983      0.892      0.975       0.92      0.982      0.862\n",
      "                  card        476        476      0.941      0.952      0.983      0.892      0.975       0.92      0.982      0.862\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 1078.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.25G     0.6234       1.44      4.407     0.9419         19        640: 100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0579     0.0401    0.00897    0.00769     0.0579     0.0401    0.00952    0.00803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.31G       0.63      1.556      3.698     0.9342         16        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.843      0.782      0.874      0.785      0.837      0.781      0.872      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.4G       0.55      0.889       1.52     0.8889         18        640: 100%|██████████| 6/6 [00:04<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.945      0.937      0.974      0.884      0.943      0.935       0.97      0.855\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.43G     0.4929     0.7946       1.11     0.9025         19        640: 100%|██████████| 6/6 [00:04<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.969      0.954      0.983      0.895      0.967      0.951      0.981      0.868\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G     0.4485     0.7114     0.9133     0.8674         19        640: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474       0.96      0.949      0.983      0.899      0.958      0.947       0.98      0.866\n",
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474       0.96      0.949      0.983      0.899      0.958      0.947       0.98      0.866\n",
      "                  card        474        474       0.96      0.949      0.983      0.899      0.958      0.947       0.98      0.866\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.954      0.947      0.987      0.901      0.952      0.945      0.986       0.87\n",
      "                  card        476        476      0.954      0.947      0.987      0.901      0.952      0.945      0.986       0.87\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 901.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       6.1G     0.3001       1.57      1.441     0.8239          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.954      0.953       0.98       0.89      0.951      0.951      0.975      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.08G     0.2842      1.026      1.157     0.8033          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.956      0.953       0.98      0.891      0.953      0.951      0.975      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.97G     0.3761     0.7268      1.827     0.8675          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.972      0.932       0.98       0.89       0.97       0.93      0.974      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G     0.5221     0.8406      1.585     0.9699          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.972      0.937       0.98       0.89       0.97      0.935      0.974       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G     0.3609      0.275     0.8065     0.8662          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.969      0.939      0.979      0.891      0.967      0.937      0.974      0.861\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.969      0.939      0.979      0.891      0.966      0.937      0.974      0.861\n",
      "                  card        474        474      0.969      0.939      0.979      0.891      0.966      0.937      0.974      0.861\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.973       0.92       0.98      0.892      0.971      0.918      0.978      0.863\n",
      "                  card        476        476      0.973       0.92       0.98      0.892      0.971      0.918      0.978      0.863\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 1017.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G     0.6318      1.549      4.419      1.003         22        640: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "                   all        474        474     0.0553     0.0422      0.009    0.00772     0.0553     0.0422    0.00951    0.00805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G     0.6363      1.477       3.87     0.9491         23        640: 100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.867      0.825      0.917      0.821      0.865      0.825      0.914      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.44G      0.539     0.8765      1.576     0.9009         25        640: 100%|██████████| 6/6 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.955      0.934      0.969      0.885      0.953      0.932      0.968      0.855\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.4622     0.8128      1.135     0.8756         21        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.958      0.918      0.972      0.889      0.956      0.916      0.971      0.862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.43G     0.4837     0.7288      1.015     0.8936         19        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474       0.97      0.937      0.983      0.902      0.968      0.935      0.982      0.873\n",
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474       0.97      0.937      0.983      0.902      0.968      0.935      0.982      0.873\n",
      "                  card        474        474       0.97      0.937      0.983      0.902      0.968      0.935      0.982      0.873\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "                   all        476        476      0.964      0.958      0.986      0.901      0.961      0.956      0.985      0.873\n",
      "                  card        476        476      0.964      0.958      0.986      0.901      0.961      0.956      0.985      0.873\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 841.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.58G     0.5371     0.8146     0.7111     0.8702          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.956      0.935       0.98      0.894      0.954      0.932      0.979      0.873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G     0.3995     0.7608      1.238      0.829          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.941      0.951       0.98      0.894      0.939      0.949      0.979      0.872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.03G      0.693      1.229      1.692     0.9609          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.969      0.924       0.98      0.894      0.967      0.922      0.976      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G     0.5134      0.701      1.244     0.9855          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.968       0.93      0.981      0.894       0.97      0.924      0.976      0.868\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G     0.6123     0.7062      1.114     0.8408          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474       0.97      0.939      0.981      0.894      0.966      0.935      0.976      0.868\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.956      0.935       0.98      0.895      0.954      0.932      0.979      0.874\n",
      "                  card        474        474      0.956      0.935       0.98      0.895      0.954      0.932      0.979      0.874\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.959      0.936       0.98      0.893      0.957      0.934      0.979      0.866\n",
      "                  card        476        476      0.959      0.936       0.98      0.893      0.957      0.934      0.979      0.866\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 1065.18it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.38G     0.6802      1.788      4.406      0.963         10        640: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474     0.0742      0.148     0.0251     0.0221     0.0764      0.152     0.0261     0.0223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G     0.6801      1.431      3.282     0.9667          6        640: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.961      0.892      0.961      0.863      0.959       0.89      0.958      0.842\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.54G     0.5084     0.9135      1.295     0.8954         11        640: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.967      0.927      0.979      0.896      0.965      0.925      0.977      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.4833     0.6969     0.9762     0.8554          9        640: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474       0.97      0.953      0.985      0.903      0.968      0.951      0.984      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.56G     0.4249     0.6084     0.8481     0.8473         11        640: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.976       0.97      0.991      0.913      0.973      0.968      0.991       0.88\n",
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.976       0.97      0.991      0.913      0.973      0.968      0.991      0.879\n",
      "                  card        474        474      0.976       0.97      0.991      0.913      0.973      0.968      0.991      0.879\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "                   all        476        476      0.989      0.975      0.994      0.913      0.987      0.973      0.993      0.882\n",
      "                  card        476        476      0.989      0.975      0.994      0.913      0.987      0.973      0.993      0.882\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 964.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.18G     0.6395     0.8005      1.004     0.9691         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.978       0.95      0.988       0.91      0.976      0.948      0.987      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.5971     0.6642      1.434     0.8337          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.978      0.949      0.989      0.911      0.976      0.947      0.988      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.05G      0.618      1.563     0.8536     0.7997         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.982      0.946      0.989      0.911       0.98      0.944      0.988      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G     0.5218     0.5677      1.086     0.8917         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.982      0.947      0.989      0.912       0.98      0.945      0.988      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.6417     0.6572     0.8503     0.9012         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.978      0.949      0.989      0.912      0.976      0.947      0.988      0.875\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.982      0.947      0.989      0.913       0.98      0.945      0.988      0.876\n",
      "                  card        474        474      0.982      0.947      0.989      0.913       0.98      0.945      0.988      0.876\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.92it/s]\n",
      "                   all        476        476      0.974      0.973      0.989      0.906       0.97      0.968      0.988      0.881\n",
      "                  card        476        476      0.974      0.973      0.989      0.906       0.97      0.968      0.988      0.881\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 1110.08it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G     0.6209      1.396      4.298     0.9368         25        640: 100%|██████████| 7/7 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "                   all        474        474     0.0434     0.0506    0.00899    0.00766     0.0434     0.0506    0.00952    0.00803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G     0.6052      1.107      3.011     0.9236         30        640: 100%|██████████| 7/7 [00:05<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.952      0.927      0.978      0.888       0.95      0.925      0.977      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.54G     0.5138     0.9974      1.305     0.8943         20        640: 100%|██████████| 7/7 [00:05<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.965      0.954      0.987        0.9      0.963      0.951      0.985      0.871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.4692     0.7635     0.9477     0.8658         31        640: 100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.977      0.973      0.992      0.911      0.975       0.97      0.992      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.57G     0.4446     0.6131     0.8408     0.8888         24        640: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.977      0.974      0.992      0.911      0.975      0.972      0.992      0.879\n",
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.979      0.974      0.992       0.91      0.977      0.972      0.992      0.883\n",
      "                  card        474        474      0.979      0.974      0.992       0.91      0.977      0.972      0.992      0.883\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.83it/s]\n",
      "                   all        476        476      0.977      0.968      0.992      0.907      0.975      0.966      0.991      0.879\n",
      "                  card        476        476      0.977      0.968      0.992      0.907      0.975      0.966      0.991      0.879\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1071.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.17G     0.4916     0.5752     0.8195     0.8932         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.953      0.973      0.991      0.907       0.95      0.972       0.99      0.875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G     0.3474      0.578     0.7537     0.8586         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.956      0.972      0.991      0.905      0.952      0.968       0.99      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.4694     0.7855     0.9797     0.8663         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.957      0.975      0.991      0.905      0.952      0.971       0.99      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G      0.446     0.7027      0.965      1.032         16        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.957      0.975      0.991      0.905      0.952      0.971       0.99      0.875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.3749     0.8417     0.8914     0.8342         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.963       0.97      0.991      0.906      0.959      0.966       0.99      0.875\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.952      0.973      0.991      0.906       0.95      0.975       0.99      0.874\n",
      "                  card        474        474      0.952      0.973      0.991      0.906       0.95      0.975       0.99      0.874\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.88it/s]\n",
      "                   all        476        476      0.979      0.968       0.99      0.903      0.977      0.966       0.99      0.876\n",
      "                  card        476        476      0.979      0.968       0.99      0.903      0.977      0.966       0.99      0.876\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 1011.47it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.26G     0.6385      1.506      4.447     0.9713         16        640: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "                   all        474        474       0.15      0.114     0.0427     0.0362      0.148      0.112     0.0433      0.037\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.41G     0.5887      1.179      2.581     0.9431         14        640: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "                   all        474        474      0.968      0.909      0.975      0.888      0.966      0.907      0.974      0.856\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.44G     0.4732     0.7496      1.006      0.867         19        640: 100%|██████████| 8/8 [00:06<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.971      0.939      0.984      0.904      0.969      0.937      0.982      0.867\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G     0.4443      0.692     0.8372     0.8647         17        640: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.983      0.973      0.993       0.91      0.981      0.971      0.992      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G     0.4505     0.6468     0.7209     0.8584         12        640: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.981      0.971      0.993      0.906      0.971      0.981      0.992      0.879\n",
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.983      0.973      0.993       0.91      0.981       0.97      0.992      0.884\n",
      "                  card        474        474      0.983      0.973      0.993       0.91      0.981       0.97      0.992      0.884\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:51<00:00,  1.72s/it]\n",
      "                   all        476        476      0.979      0.982      0.994       0.91      0.979      0.982      0.994      0.884\n",
      "                  card        476        476      0.979      0.982      0.994       0.91      0.979      0.982      0.994      0.884\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 989.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.79G     0.6169     0.8793     0.7036     0.8714         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.966      0.975      0.991      0.905      0.962       0.97       0.99      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.5292       1.17     0.8333     0.9634         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.967      0.975      0.992      0.905      0.963       0.97       0.99      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.4752      0.757     0.6851     0.8652         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.969      0.973      0.992      0.904      0.965      0.968       0.99      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.07G      0.561     0.8889      0.899     0.9907         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.968      0.972      0.992      0.903      0.964      0.968      0.991      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.2967     0.5086     0.8585     0.7856         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.968      0.979      0.992      0.905      0.964      0.975      0.991      0.877\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.67it/s]\n",
      "                   all        474        474      0.969      0.978      0.992      0.905      0.964      0.974      0.991      0.877\n",
      "                  card        474        474      0.969      0.978      0.992      0.905      0.964      0.974      0.991      0.877\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.90it/s]\n",
      "                   all        476        476      0.979      0.983      0.992      0.905      0.979      0.983      0.992      0.881\n",
      "                  card        476        476      0.979      0.983      0.992      0.905      0.979      0.983      0.992      0.881\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:00<00:00, 968.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.37G     0.6673      1.635      4.314     0.9842          6        640: 100%|██████████| 9/9 [00:07<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.646      0.212        0.4       0.35      0.646      0.212      0.396      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G     0.5553     0.9513      1.832     0.8988          6        640: 100%|██████████| 9/9 [00:06<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.946      0.956      0.976      0.891      0.944      0.954      0.976      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.57G     0.4624     0.7868       1.03     0.8695          5        640: 100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.983      0.959      0.991      0.912      0.983      0.959      0.991      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.54G     0.4392     0.6716     0.7747     0.8636          5        640: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.987      0.967      0.993      0.915      0.985      0.965      0.993      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.55G     0.4584     0.6355     0.7046     0.8695          4        640: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.983      0.986      0.994      0.917      0.981      0.984      0.993      0.888\n",
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.981      0.986      0.994      0.917      0.979      0.984      0.993      0.887\n",
      "                  card        474        474      0.981      0.986      0.994      0.917      0.979      0.984      0.993      0.887\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.91it/s]\n",
      "                   all        476        476      0.987      0.994      0.995      0.914      0.987      0.994      0.995      0.885\n",
      "                  card        476        476      0.987      0.994      0.995      0.914      0.987      0.994      0.995      0.885\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1161.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.21G     0.2976     0.6676     0.5787     0.7924         16        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.975      0.981      0.993      0.918      0.973      0.979      0.992      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.4292      0.708     0.4731     0.8918         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.981      0.978      0.993      0.918      0.979      0.976      0.992      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.3286     0.3869     0.5638     0.8633         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.983      0.975      0.993      0.918      0.981      0.973      0.992      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.05G     0.6207     0.8493      0.786     0.8742         12        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.983      0.976      0.993      0.918      0.981      0.974      0.993      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.3243     0.5193      0.492     0.7264         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.987      0.973      0.993      0.918      0.985       0.97      0.993      0.886\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.983      0.976      0.993      0.918      0.981      0.974      0.992      0.886\n",
      "                  card        474        474      0.983      0.976      0.993      0.918      0.981      0.974      0.992      0.886\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.88it/s]\n",
      "                   all        476        476      0.979      0.992      0.994      0.912      0.979      0.992      0.994      0.886\n",
      "                  card        476        476      0.979      0.992      0.994      0.912      0.979      0.992      0.994      0.886\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1137.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.06G     0.2557     0.4132     0.5158      0.834         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.979      0.964      0.991      0.915      0.977      0.962      0.991      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.2074     0.2812     0.5702     0.7501          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.979      0.964      0.992      0.914      0.975       0.96      0.991      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.07G     0.2505     0.4397     0.4308       0.81         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474       0.98      0.964      0.992      0.915      0.975       0.96      0.991      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.07G      0.384     0.4678     0.6001     0.9086         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.981      0.965      0.992      0.916      0.976      0.961      0.991      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.2781     0.4279     0.4719     0.7944         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474       0.98      0.964      0.992      0.915      0.976       0.96      0.991       0.88\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.981      0.965      0.992      0.916      0.976      0.961      0.991      0.885\n",
      "                  card        474        474      0.981      0.965      0.992      0.916      0.976      0.961      0.991      0.885\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.89it/s]\n",
      "                   all        476        476      0.975      0.987      0.993       0.91      0.975      0.987      0.993      0.884\n",
      "                  card        476        476      0.975      0.987      0.993       0.91      0.975      0.987      0.993      0.884\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:00<00:00, 1022.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.64G     0.6166        1.3      4.305     0.9394         12        640: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.834      0.638      0.794      0.706      0.832      0.636      0.791      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.8G     0.5154     0.8417      1.543      0.885         16        640: 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.965      0.941      0.986      0.898      0.965      0.941      0.986       0.87\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.6G     0.4337     0.6884      1.006     0.8537          9        640: 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.986      0.975      0.992      0.908      0.984      0.973      0.992      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.59G     0.4626     0.6803     0.7537     0.8788         12        640: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.985      0.975      0.994      0.913      0.983      0.973      0.994      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.61G     0.4653     0.6789     0.6132     0.8779          9        640: 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.982      0.981      0.994      0.909       0.98      0.979      0.994      0.887\n",
      "\n",
      "5 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.985      0.975      0.994      0.914      0.983      0.973      0.994      0.887\n",
      "                  card        474        474      0.985      0.975      0.994      0.914      0.983      0.973      0.994      0.887\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "                   all        476        476      0.989      0.983      0.995      0.911      0.989      0.983      0.995      0.886\n",
      "                  card        476        476      0.989      0.983      0.995      0.911      0.989      0.983      0.995      0.886\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 900.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.64G     0.4718     0.5196     0.4576     0.8847         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.977      0.973      0.992      0.905      0.977      0.973      0.992      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.5841     0.8992     0.7054      0.958         12        640: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.973      0.973      0.992      0.905      0.973      0.973      0.992      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.4985     0.5793     0.5176       0.84         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.976      0.973      0.992      0.906      0.976      0.973      0.992      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G     0.6206     0.7036     0.6336     0.9526         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.969      0.982      0.992      0.906      0.969      0.982      0.992      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.07G     0.4509     0.6276     0.5538     0.8452         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.972      0.979      0.992      0.905      0.972      0.979      0.992      0.882\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.968      0.983      0.992      0.906      0.968      0.983      0.992      0.883\n",
      "                  card        474        474      0.968      0.983      0.992      0.906      0.968      0.983      0.992      0.883\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.92it/s]\n",
      "                   all        476        476      0.979      0.989      0.994      0.907      0.979      0.989      0.994      0.884\n",
      "                  card        476        476      0.979      0.989      0.994      0.907      0.979      0.989      0.994      0.884\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:00<00:00, 961.77it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.6459      1.344      4.105     0.9791          2        640: 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.712      0.271      0.481      0.428      0.712      0.271      0.481      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G     0.5176     0.8646      1.572     0.8919          2        640: 100%|██████████| 11/11 [00:08<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.957      0.924       0.97      0.885      0.955      0.922      0.967      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.58G     0.4828     0.7481     0.8575     0.8945          1        640: 100%|██████████| 11/11 [00:08<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.968      0.968      0.991      0.908      0.966      0.966      0.991      0.873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.56G     0.4562     0.6477     0.7082      0.911          1        640: 100%|██████████| 11/11 [00:08<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474      0.989      0.968      0.994      0.909      0.987      0.966      0.993       0.88\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.57G     0.4615     0.6457     0.5246     0.8589          3        640: 100%|██████████| 11/11 [00:08<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.994       0.97      0.994      0.913      0.991      0.968      0.994      0.887\n",
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.994       0.97      0.994      0.913      0.991      0.968      0.994      0.886\n",
      "                  card        474        474      0.994       0.97      0.994      0.913      0.991      0.968      0.994      0.886\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.92it/s]\n",
      "                   all        476        476      0.994      0.983      0.994      0.915      0.992      0.981      0.994       0.89\n",
      "                  card        476        476      0.994      0.983      0.994      0.915      0.992      0.981      0.994       0.89\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1120.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.92G     0.5693     0.7165     0.5233     0.7853         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.977      0.985      0.994      0.912      0.975      0.983      0.994      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G     0.4862      1.014     0.7667     0.8427         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.977      0.985      0.994      0.912      0.975      0.983      0.994      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.5182     0.6063     0.5455      0.831         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.977      0.985      0.994      0.913      0.975      0.982      0.994      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.05G      0.626      1.075      0.627     0.8527         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.985      0.974      0.994      0.913      0.983      0.972      0.994      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G     0.4266     0.5314      0.523     0.8586         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "                   all        474        474       0.98      0.979      0.994      0.913      0.977      0.977      0.994      0.885\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.977      0.985      0.994      0.913      0.975      0.983      0.994      0.886\n",
      "                  card        474        474      0.977      0.985      0.994      0.913      0.975      0.983      0.994      0.886\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.94it/s]\n",
      "                   all        476        476      0.985      0.993      0.994      0.913      0.983      0.991      0.994      0.886\n",
      "                  card        476        476      0.985      0.993      0.994      0.913      0.983      0.991      0.994      0.886\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<00:00, 956.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.26G     0.6074      1.243      4.033     0.9379         15        640: 100%|██████████| 11/11 [00:08<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.901      0.885       0.94      0.843      0.899      0.883      0.937      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.42G     0.4887     0.7952      1.267     0.8744         15        640: 100%|██████████| 11/11 [00:08<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "                   all        474        474      0.973      0.973      0.991      0.908      0.971       0.97       0.99      0.875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.45G     0.4663     0.6804     0.8337     0.8554         15        640: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.991      0.983      0.994      0.905      0.988      0.981      0.994       0.88\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.42G     0.4687     0.6204     0.6219     0.8748         20        640: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.992      0.991      0.994      0.911      0.989      0.989      0.994      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G     0.4536     0.6442     0.4811     0.8733         17        640: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.983      0.989      0.994      0.919      0.981      0.987      0.994      0.888\n",
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.983      0.989      0.994      0.919      0.981      0.987      0.994      0.889\n",
      "                  card        474        474      0.983      0.989      0.994      0.919      0.981      0.987      0.994      0.889\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.91it/s]\n",
      "                   all        476        476      0.995      0.985      0.995      0.918      0.994      0.982      0.995      0.892\n",
      "                  card        476        476      0.995      0.985      0.995      0.918      0.994      0.982      0.995      0.892\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 847.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.36G     0.4595     0.7043     0.3469     0.8423         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.983      0.985      0.994      0.917      0.981      0.983      0.993       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G     0.5315     0.6183     0.6278     0.8386          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.983      0.985      0.994      0.916      0.981      0.983      0.993      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.3555      0.515     0.3805     0.7798         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.985      0.984      0.994      0.916      0.983      0.982      0.993       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.05G     0.4842     0.6303     0.4286     0.8848         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.985      0.983      0.994      0.916      0.983      0.981      0.993      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.4306     0.5616     0.4658     0.8975         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474       0.98      0.983      0.994      0.917      0.978      0.981      0.993      0.889\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.985      0.983      0.994      0.917      0.983      0.981      0.993      0.889\n",
      "                  card        474        474      0.985      0.983      0.994      0.917      0.983      0.981      0.993      0.889\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.97it/s]\n",
      "                   all        476        476      0.991      0.987      0.995      0.917      0.992      0.987      0.995      0.894\n",
      "                  card        476        476      0.991      0.987      0.995      0.917      0.992      0.987      0.995      0.894\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1033.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.09G     0.5667     0.9936     0.6767     0.9251         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.978      0.979      0.993      0.914      0.976      0.977      0.992      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.05G      0.415     0.6902     0.7538     0.9416         11        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.977      0.979      0.993      0.915      0.977      0.977      0.992      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.5045     0.5882     0.4678     0.8384         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.975      0.984      0.993      0.915      0.975      0.977      0.992      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G     0.6457     0.8444     0.7151     0.8764         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.975      0.983      0.993      0.915      0.975      0.977      0.992      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G     0.7242     0.7949     0.8322     0.8308         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.975      0.983      0.993      0.914      0.971      0.979      0.992      0.888\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.977      0.979      0.993      0.915      0.977      0.977      0.992      0.889\n",
      "                  card        474        474      0.977      0.979      0.993      0.915      0.977      0.977      0.992      0.889\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.95it/s]\n",
      "                   all        476        476      0.977      0.987      0.994      0.914      0.977      0.987      0.994      0.891\n",
      "                  card        476        476      0.977      0.987      0.994      0.914      0.977      0.987      0.994      0.891\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:00<00:00, 1032.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.27G      0.617      1.365      4.004     0.9457         22        640: 100%|██████████| 12/12 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.867      0.864      0.937      0.841      0.857      0.876      0.934      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.41G     0.5039     0.7886      1.248     0.8817         26        640: 100%|██████████| 12/12 [00:09<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "                   all        474        474      0.978      0.964      0.991      0.909      0.974      0.962       0.99      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.41G     0.4683     0.6566     0.7918     0.8582         28        640: 100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.973      0.971      0.993      0.911       0.97      0.969      0.993      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.4G     0.4701      0.655     0.6049     0.8638         31        640: 100%|██████████| 12/12 [00:09<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.985      0.982      0.994      0.915      0.987      0.981      0.994      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.41G     0.4775     0.6707     0.5239     0.8658         17        640: 100%|██████████| 12/12 [00:09<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474       0.99      0.987      0.995      0.913       0.99      0.987      0.995      0.891\n",
      "\n",
      "5 epochs completed in 0.032 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474       0.99      0.987      0.995      0.912       0.99      0.987      0.995      0.892\n",
      "                  card        474        474       0.99      0.987      0.995      0.912       0.99      0.987      0.995      0.892\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.96it/s]\n",
      "                   all        476        476      0.991      0.987      0.995      0.909      0.991      0.987      0.995      0.889\n",
      "                  card        476        476      0.991      0.987      0.995      0.909      0.991      0.987      0.995      0.889\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1053.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.96G     0.3963     0.4783     0.5062     0.8206         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.989      0.976      0.993      0.907      0.989      0.976      0.993      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.05G     0.5404     0.6141     0.6143     0.9329         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.989      0.979      0.993      0.908      0.989      0.979      0.993      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G     0.6165     0.7711     0.6609     0.8792         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.989      0.979      0.993      0.907      0.989      0.979      0.993      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.05G     0.5454     0.6603      0.598     0.9596         11        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.989      0.978      0.994      0.906      0.989      0.978      0.994      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G     0.4935     0.7064     0.4613     0.8225         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.991      0.976      0.994      0.905      0.991      0.976      0.994      0.886\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.989      0.979      0.993      0.908      0.989      0.979      0.993      0.887\n",
      "                  card        474        474      0.989      0.979      0.993      0.908      0.989      0.979      0.993      0.887\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.98it/s]\n",
      "                   all        476        476      0.994      0.987      0.994      0.905      0.994      0.987      0.994      0.887\n",
      "                  card        476        476      0.994      0.987      0.994      0.905      0.994      0.987      0.994      0.887\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<00:00, 1089.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.27G     0.6442      1.265      3.716     0.9516         15        640: 100%|██████████| 13/13 [00:10<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.971      0.913      0.972      0.883      0.968      0.911      0.971      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.43G     0.4584     0.7808      1.141     0.8807         12        640: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "                   all        474        474      0.993      0.966      0.993      0.911      0.993      0.964      0.993      0.879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.4671     0.6615     0.7285     0.8529         15        640: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n",
      "                   all        474        474      0.992       0.97      0.993      0.897      0.992       0.97      0.993      0.872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.42G     0.5029     0.6866     0.5874     0.8572         17        640: 100%|██████████| 13/13 [00:10<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.985      0.975      0.991      0.903      0.983      0.973       0.99      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.45G     0.4616      0.618     0.4269     0.8548         14        640: 100%|██████████| 13/13 [00:10<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.987      0.974      0.994      0.913      0.985      0.972      0.994      0.891\n",
      "\n",
      "5 epochs completed in 0.032 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.987      0.974      0.994      0.913      0.985      0.972      0.994      0.891\n",
      "                  card        474        474      0.987      0.974      0.994      0.913      0.985      0.972      0.994      0.891\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.93it/s]\n",
      "                   all        476        476      0.994      0.987      0.995      0.913      0.994      0.987      0.995      0.888\n",
      "                  card        476        476      0.994      0.987      0.995      0.913      0.994      0.987      0.995      0.888\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 877.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.09G     0.4053      0.621     0.3974     0.8251          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.978      0.977      0.993       0.91      0.976      0.975      0.992      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.03G     0.4475     0.5788     0.4011     0.8447          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "                   all        474        474      0.987      0.966      0.993       0.91      0.985      0.964      0.992      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.03G     0.4827     0.6574     0.4611     0.8935          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.987       0.97      0.993      0.906      0.985      0.968      0.993      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.5327      0.674     0.6169     0.8872          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.985      0.977      0.994      0.912      0.983      0.975      0.993      0.895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.03G     0.4451     0.5745     0.3951     0.8499          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.983      0.978      0.994      0.913      0.981      0.975      0.993      0.893\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.989      0.973      0.994      0.912      0.987      0.971      0.993      0.895\n",
      "                  card        474        474      0.989      0.973      0.994      0.912      0.987      0.971      0.993      0.895\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.92it/s]\n",
      "                   all        476        476      0.996      0.987      0.995      0.914      0.996      0.987      0.995      0.894\n",
      "                  card        476        476      0.996      0.987      0.995      0.914      0.996      0.987      0.995      0.894\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 973.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.85G     0.4102     0.5076     0.4921      0.849          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.979      0.982      0.992      0.908      0.983      0.975      0.991      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.02G     0.3637     0.4541     0.4238     0.8839          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.983       0.98      0.991      0.912      0.981      0.978       0.99      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.02G     0.3705     0.5376     0.5009     0.8563          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.987      0.975      0.992      0.916      0.985      0.973      0.992      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.3126     0.4261     0.3201     0.8537          4        640: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.992      0.985      0.994      0.918      0.989      0.983      0.994      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.02G     0.3641     0.4658     0.3217     0.8423          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.992      0.989      0.995      0.921      0.989      0.987      0.994      0.899\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.75it/s]\n",
      "                   all        474        474      0.991      0.989      0.995      0.921      0.989      0.987      0.994        0.9\n",
      "                  card        474        474      0.991      0.989      0.995      0.921      0.989      0.987      0.994        0.9\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.90it/s]\n",
      "                   all        476        476      0.994      0.989      0.995      0.918      0.994      0.989      0.995      0.898\n",
      "                  card        476        476      0.994      0.989      0.995      0.918      0.994      0.989      0.995      0.898\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 995.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.91G     0.4449     0.6853     0.4754     0.8868          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.989      0.979      0.994      0.918      0.987      0.977      0.993      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.03G     0.4222     0.5414     0.4134     0.8665         10        640: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.996      0.991      0.995      0.918      0.996      0.991      0.995      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.04G     0.4348     0.6591     0.4037     0.8477          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.995      0.994      0.995       0.92      0.995      0.994      0.995      0.901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.4451      0.698     0.4294     0.9029          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.992      0.993      0.995      0.919      0.992      0.993      0.995        0.9\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.06G     0.3911     0.5555     0.3783     0.8643          7        640: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474       0.99      0.996      0.995       0.92       0.99      0.996      0.995      0.896\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.75it/s]\n",
      "                   all        474        474      0.995      0.994      0.995       0.92      0.995      0.994      0.995      0.902\n",
      "                  card        474        474      0.995      0.994      0.995       0.92      0.995      0.994      0.995      0.902\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.02it/s]\n",
      "                   all        476        476      0.993      0.994      0.995      0.915      0.993      0.994      0.995      0.889\n",
      "                  card        476        476      0.993      0.994      0.995      0.915      0.993      0.994      0.995      0.889\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 401 images, 0 backgrounds, 0 corrupt: 100%|██████████| 401/401 [00:00<00:00, 1080.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.36G     0.5076      1.149      2.567     0.8812          0        640: 100%|██████████| 26/26 [00:20<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n",
      "                   all        474        474      0.958      0.973      0.992      0.906      0.956       0.97      0.992      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.53G     0.4662     0.6426     0.6879      0.857          1        640: 100%|██████████| 26/26 [00:20<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.991      0.981      0.994       0.91      0.989      0.979      0.994      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.54G      0.474     0.6068     0.5033      0.872          1        640: 100%|██████████| 26/26 [00:20<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.981      0.984      0.994      0.912      0.981      0.984      0.994      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.51G     0.4572     0.5958      0.457     0.8338          0        640: 100%|██████████| 26/26 [00:19<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.973      0.978      0.989      0.892      0.973      0.978      0.989      0.879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.52G     0.5046       0.66     0.6093     0.8505          0        640: 100%|██████████| 26/26 [00:19<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.987      0.989      0.995      0.904      0.987      0.989      0.995      0.892\n",
      "\n",
      "5 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.76it/s]\n",
      "                   all        474        474      0.981      0.984      0.994      0.912      0.981      0.984      0.994      0.895\n",
      "                  card        474        474      0.981      0.984      0.994      0.912      0.981      0.984      0.994      0.895\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.07it/s]\n",
      "                   all        476        476      0.999      0.985      0.995      0.916      0.999      0.985      0.995      0.891\n",
      "                  card        476        476      0.999      0.985      0.995      0.916      0.999      0.985      0.995      0.891\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 923.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.2G     0.5222     0.6386     0.5654     0.8768          7        640: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.994      0.987      0.995      0.905      0.994      0.987      0.995      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         9G     0.5331     0.6297     0.3943     0.8624         10        640: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.995      0.989      0.993      0.904      0.995      0.989      0.993      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.03G      0.459     0.6213     0.3207     0.8977          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.994      0.991      0.993      0.905      0.994      0.991      0.993      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.01G     0.4949     0.7299     0.3396     0.8965          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.982      0.989      0.993      0.909      0.982      0.989      0.993      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.04G     0.5134     0.6352      0.345     0.8724          8        640: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.987      0.986      0.993       0.91      0.987      0.986      0.993      0.892\n",
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.79it/s]\n",
      "                   all        474        474      0.992      0.979      0.993      0.908      0.992      0.979      0.993      0.894\n",
      "                  card        474        474      0.992      0.979      0.993      0.908      0.992      0.979      0.993      0.894\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.07it/s]\n",
      "                   all        476        476      0.998      0.992      0.995      0.908      0.998      0.992      0.995      0.893\n",
      "                  card        476        476      0.998      0.992      0.995      0.908      0.998      0.992      0.995      0.893\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 501/501 [00:00<00:00, 932.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.34G     0.5062     0.8671      2.055     0.8949          8        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.978      0.977      0.994      0.905      0.978      0.977      0.994      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.51G     0.4748     0.6512     0.5901     0.8577         10        640: 100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.979      0.968      0.985      0.886      0.979      0.968      0.985      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.53G     0.4809     0.6014     0.5947     0.8691          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.975      0.926      0.967      0.875      0.975      0.926      0.969       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.4878     0.6644     0.4446     0.8722         10        640: 100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.974      0.983      0.988      0.894      0.974      0.983      0.988      0.897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G      0.513     0.6805      0.448     0.8644         11        640: 100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.981      0.976      0.993      0.898      0.981      0.976      0.993      0.894\n",
      "\n",
      "5 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.80it/s]\n",
      "                   all        474        474      0.979      0.977      0.993      0.897      0.979      0.977      0.993      0.893\n",
      "                  card        474        474      0.979      0.977      0.993      0.897      0.979      0.977      0.993      0.893\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.07it/s]\n",
      "                   all        476        476      0.983      0.989      0.991      0.893      0.983      0.989      0.991      0.887\n",
      "                  card        476        476      0.983      0.989      0.991      0.893      0.983      0.989      0.991      0.887\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_41/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 996.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.94G     0.4828     0.6198     0.3593     0.8618         11        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.989      0.981      0.994      0.913      0.989      0.981      0.994      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.06G     0.5013     0.6144     0.3924     0.8739          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.981      0.973       0.99      0.902      0.981      0.973       0.99      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.06G       0.49     0.6193     0.4025     0.8711          6        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.989      0.974      0.993      0.891      0.989      0.974      0.993      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.5247     0.6177     0.3878     0.8845          5        640: 100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.987       0.99      0.991       0.89      0.987       0.99      0.991      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.01G     0.5052      0.595     0.3577     0.8726          9        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.985      0.979      0.993      0.894      0.984      0.977      0.993      0.893\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.78it/s]\n",
      "                   all        474        474      0.989      0.981      0.994      0.912      0.989      0.981      0.994      0.898\n",
      "                  card        474        474      0.989      0.981      0.994      0.912      0.989      0.981      0.994      0.898\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.05it/s]\n",
      "                   all        476        476       0.99      0.992      0.994      0.911       0.99      0.992      0.994      0.891\n",
      "                  card        476        476       0.99      0.992      0.994      0.911       0.99      0.992      0.994      0.891\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 1001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1001/1001 [00:00<00:00, 1044.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.34G     0.4825      0.834      1.445     0.8824         16        640: 100%|██████████| 63/63 [00:50<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.67it/s]\n",
      "                   all        474        474      0.983      0.983      0.993      0.907      0.983      0.983      0.993      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.51G     0.4903     0.5999     0.4776     0.8757         18        640: 100%|██████████| 63/63 [00:49<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.995      0.966       0.99      0.899      0.995      0.966       0.99       0.88\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G     0.5097     0.6356     0.4464     0.8833         13        640: 100%|██████████| 63/63 [00:49<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.996      0.978      0.988      0.863      0.996      0.978      0.988      0.872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G     0.5075     0.6073     0.3838     0.8769         12        640: 100%|██████████| 63/63 [00:49<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.985      0.976      0.993      0.888      0.983      0.974      0.991      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.52G     0.5106       0.64      0.379     0.8783         14        640: 100%|██████████| 63/63 [00:49<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.988      0.935      0.983      0.887      0.986      0.932      0.983       0.88\n",
      "\n",
      "5 epochs completed in 0.085 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.983      0.983      0.993      0.906      0.983      0.983      0.993      0.888\n",
      "                  card        474        474      0.983      0.983      0.993      0.906      0.983      0.983      0.993      0.888\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.97it/s]\n",
      "                   all        476        476      0.985      0.981      0.994      0.903      0.985      0.981      0.994      0.882\n",
      "                  card        476        476      0.985      0.981      0.994      0.903      0.985      0.981      0.994      0.882\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_42/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 969.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_42/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.44G      0.487     0.6438     0.3955     0.8801          9        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.987      0.985      0.995      0.924      0.987      0.985      0.995      0.908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G     0.5075     0.6614     0.3813     0.8795          6        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.983      0.967      0.983       0.89      0.983      0.967      0.985      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.06G     0.5129      0.656     0.4147     0.8837          6        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.989       0.98      0.994      0.902      0.989       0.98      0.994      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.5081     0.6218     0.3745     0.8968          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.991      0.961      0.987      0.895      0.991      0.961      0.987      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.01G     0.5019     0.6609     0.3756     0.8788          9        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.971      0.987       0.99      0.898      0.971      0.987      0.991      0.886\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.77it/s]\n",
      "                   all        474        474      0.987      0.985      0.995      0.923      0.987      0.985      0.995      0.907\n",
      "                  card        474        474      0.987      0.985      0.995      0.923      0.987      0.985      0.995      0.907\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
      "                   all        476        476      0.995      0.989      0.995      0.918      0.995      0.989      0.995      0.903\n",
      "                  card        476        476      0.995      0.989      0.995      0.918      0.995      0.989      0.995      0.903\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_43/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 979.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_43/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.88G     0.4889     0.6238     0.3386     0.8803          8        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.996      0.988      0.995      0.914      0.996      0.988      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G     0.4934     0.6281     0.3372     0.8791          8        640: 100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.989      0.987      0.995        0.9      0.989      0.987      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.04G     0.5268     0.6231      0.378     0.8762          9        640: 100%|██████████| 32/32 [00:24<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.985      0.983      0.993       0.91      0.985      0.983      0.993      0.897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.4722     0.6116     0.3602     0.8725          8        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.991      0.979      0.994      0.912      0.991      0.979      0.994      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.02G     0.4899     0.5871      0.357     0.8772          5        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.991      0.982      0.992      0.906      0.991      0.982      0.992      0.897\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.996      0.988      0.995      0.915      0.996      0.988      0.995      0.898\n",
      "                  card        474        474      0.996      0.988      0.995      0.915      0.996      0.988      0.995      0.898\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.03it/s]\n",
      "                   all        476        476      0.998      0.993      0.995      0.913      0.998      0.993      0.995      0.898\n",
      "                  card        476        476      0.998      0.993      0.995      0.913      0.998      0.993      0.995      0.898\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 2001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2001/2001 [00:02<00:00, 914.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.35G     0.4658     0.7321      1.012     0.8713          2        640: 100%|██████████| 126/126 [01:41<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.988      0.983       0.99      0.912      0.988      0.983       0.99      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G     0.5053     0.6478     0.4245     0.8754          1        640: 100%|██████████| 126/126 [01:39<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.982       0.94      0.972      0.879      0.982       0.94      0.972      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G     0.5127     0.6329     0.4366     0.8894          1        640: 100%|██████████| 126/126 [01:38<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.978      0.964      0.986      0.883      0.978      0.964      0.986      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G     0.5236     0.6493     0.3906     0.8895          3        640: 100%|██████████| 126/126 [01:38<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]\n",
      "                   all        474        474      0.987      0.983      0.993      0.904      0.987      0.983      0.993      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.5101     0.6252     0.3738     0.8847          4        640: 100%|██████████| 126/126 [01:38<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.991      0.962      0.989      0.896      0.984      0.964      0.989      0.888\n",
      "\n",
      "5 epochs completed in 0.155 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.76it/s]\n",
      "                   all        474        474      0.988      0.983       0.99      0.913      0.988      0.983       0.99      0.887\n",
      "                  card        474        474      0.988      0.983       0.99      0.913      0.988      0.983       0.99      0.887\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.02it/s]\n",
      "                   all        476        476      0.989      0.987      0.994      0.914      0.989      0.987      0.994      0.889\n",
      "                  card        476        476      0.989      0.987      0.994      0.914      0.989      0.987      0.994      0.889\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.234 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_44/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 861.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_44/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.33G     0.5057     0.6535     0.3467     0.8813          6        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.992      0.987      0.995       0.91      0.992      0.987      0.995      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G     0.5119     0.5933     0.3547     0.8892          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.994      0.994      0.995      0.924      0.994      0.994      0.995      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.06G     0.5071     0.5779     0.3552     0.8801         10        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.998      0.968      0.994      0.908      0.998      0.968      0.994      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G     0.5141     0.5968      0.371     0.8841          9        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.996      0.989      0.995      0.911      0.996      0.989      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.02G     0.5106     0.6083       0.37     0.8893          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474       0.99      0.987      0.995       0.91       0.99      0.987      0.995      0.904\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.78it/s]\n",
      "                   all        474        474      0.994      0.994      0.995      0.924      0.994      0.994      0.995      0.908\n",
      "                  card        474        474      0.994      0.994      0.995      0.924      0.994      0.994      0.995      0.908\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.09it/s]\n",
      "                   all        476        476      0.992          1      0.995      0.917      0.992      0.997      0.995      0.908\n",
      "                  card        476        476      0.992          1      0.995      0.917      0.992      0.997      0.995      0.908\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_45/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 945.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_45/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.87G     0.4923     0.6547     0.3387     0.8875          7        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.993      0.996      0.995      0.921      0.993      0.996      0.995      0.906\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G     0.5173     0.6243     0.3364      0.885          9        640: 100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.991      0.994      0.994      0.909      0.991      0.994      0.994      0.908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.06G       0.54     0.6355     0.3747     0.8852          6        640: 100%|██████████| 32/32 [00:24<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.991      0.974      0.994      0.901      0.989      0.972      0.994      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.02G      0.499     0.5928     0.3657     0.8765          9        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.994      0.987      0.994      0.909      0.994      0.987      0.994      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.01G     0.5226     0.6322     0.3801     0.8801          8        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.997      0.979      0.994       0.91      0.997      0.979      0.991      0.898\n",
      "\n",
      "5 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.78it/s]\n",
      "                   all        474        474      0.993      0.996      0.995       0.92      0.993      0.996      0.995      0.906\n",
      "                  card        474        474      0.993      0.996      0.995       0.92      0.993      0.996      0.995      0.906\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
      "                   all        476        476      0.996      0.998      0.995      0.918      0.996      0.998      0.995      0.901\n",
      "                  card        476        476      0.996      0.998      0.995      0.918      0.996      0.998      0.995      0.901\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 3001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3001/3001 [00:02<00:00, 1079.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.35G     0.4614     0.7056     0.8491     0.8689         17        640: 100%|██████████| 188/188 [02:30<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.981      0.989      0.994      0.916      0.981      0.989      0.994      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G     0.4842     0.6055     0.3809     0.8757         12        640: 100%|██████████| 188/188 [02:28<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.73it/s]\n",
      "                   all        474        474      0.996      0.992      0.995      0.922      0.996      0.992      0.995      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G     0.5124     0.6372     0.4047     0.8811         16        640: 100%|██████████| 188/188 [02:28<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.941      0.806      0.883      0.774      0.941      0.806      0.883      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.48G     0.5137      0.634     0.3878     0.8827         17        640: 100%|██████████| 188/188 [02:28<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.997      0.981      0.995      0.913      0.997      0.981      0.995      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G     0.5104       0.63     0.3652     0.8895         14        640: 100%|██████████| 188/188 [02:28<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.993      0.985      0.994      0.919      0.991      0.983      0.994      0.902\n",
      "\n",
      "5 epochs completed in 0.224 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.994      0.992      0.995      0.922      0.994      0.992      0.995      0.904\n",
      "                  card        474        474      0.994      0.992      0.995      0.922      0.994      0.992      0.995      0.904\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.98it/s]\n",
      "                   all        476        476      0.994      0.991      0.995      0.916      0.994      0.991      0.995        0.9\n",
      "                  card        476        476      0.994      0.991      0.995      0.916      0.994      0.991      0.995        0.9\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_46/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 900.08it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_46/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.91G     0.4909      0.628     0.3384     0.8846          5        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.994      0.995      0.992      0.924      0.994      0.995      0.992      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G     0.5058      0.612     0.3341     0.8898          7        640: 100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.995      0.989      0.995      0.919      0.995      0.989      0.995      0.909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.05G     0.5256     0.6362      0.355      0.886          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n",
      "                   all        474        474      0.994      0.991      0.993      0.909      0.994      0.991      0.993      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.01G     0.5077     0.6115     0.3512     0.8846          7        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.994      0.985      0.993      0.899      0.994      0.985      0.993      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.02G      0.515     0.6429     0.3429     0.8972          4        640: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474      0.993      0.985      0.994      0.905      0.993      0.985      0.994      0.893\n",
      "\n",
      "5 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n",
      "                   all        474        474      0.995      0.989      0.995      0.919      0.995      0.989      0.995      0.908\n",
      "                  card        474        474      0.995      0.989      0.995      0.919      0.995      0.989      0.995      0.908\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.04it/s]\n",
      "                   all        476        476      0.998      0.996      0.995      0.914      0.998      0.996      0.995      0.906\n",
      "                  card        476        476      0.998      0.996      0.995      0.914      0.998      0.996      0.995      0.906\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 3501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3501/3501 [00:03<00:00, 1035.08it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.34G     0.4663     0.6951     0.8139     0.8722         22        640: 100%|██████████| 219/219 [02:56<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.993      0.989      0.995      0.919      0.993      0.989      0.995      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G     0.4971     0.6213     0.3903     0.8809         28        640: 100%|██████████| 219/219 [02:54<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.987      0.987      0.995      0.897      0.987      0.987      0.995      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.46G     0.5272     0.6447     0.3997     0.8898         19        640: 100%|██████████| 219/219 [02:53<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.991      0.984      0.992        0.9      0.991      0.984      0.992      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G      0.511     0.6293     0.3693     0.8842         24        640: 100%|██████████| 219/219 [02:52<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.65it/s]\n",
      "                   all        474        474      0.998      0.989      0.995       0.92      0.998      0.989      0.995      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G     0.5092     0.6392     0.3612     0.8882         22        640: 100%|██████████| 219/219 [02:52<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.985      0.986      0.994      0.911      0.985      0.986      0.994      0.896\n",
      "\n",
      "5 epochs completed in 0.258 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.78it/s]\n",
      "                   all        474        474      0.993      0.989      0.995      0.919      0.993      0.989      0.995      0.907\n",
      "                  card        474        474      0.993      0.989      0.995      0.919      0.993      0.989      0.995      0.907\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.93it/s]\n",
      "                   all        476        476      0.998      0.994      0.995      0.914      0.998      0.994      0.995      0.896\n",
      "                  card        476        476      0.998      0.994      0.995      0.914      0.998      0.994      0.995      0.896\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_47/train/labels... 297 images, 0 backgrounds, 0 corrupt: 100%|██████████| 297/297 [00:00<00:00, 936.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_47/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       8.9G     0.4927     0.6806     0.3499     0.8858         18        640: 100%|██████████| 19/19 [00:15<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.992      0.995      0.995      0.928      0.992      0.995      0.995      0.909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         9G     0.4527     0.6086     0.3047     0.8635         14        640: 100%|██████████| 19/19 [00:14<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n",
      "                   all        474        474      0.997      0.985      0.995       0.93      0.997      0.985      0.995      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.04G     0.4736     0.6011     0.3034     0.8615         19        640: 100%|██████████| 19/19 [00:14<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n",
      "                   all        474        474      0.997      0.983      0.995      0.916      0.997      0.983      0.995      0.901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         9G     0.4823     0.5849     0.3119     0.8724         13        640: 100%|██████████| 19/19 [00:14<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.72it/s]\n",
      "                   all        474        474          1      0.986      0.995      0.927          1      0.986      0.995      0.909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.02G     0.4617     0.5259     0.2945     0.8738         18        640: 100%|██████████| 19/19 [00:14<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "                   all        474        474      0.996      0.989      0.995       0.93      0.996      0.989      0.995      0.907\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.79it/s]\n",
      "                   all        474        474      0.992      0.995      0.995      0.928      0.992      0.995      0.995       0.91\n",
      "                  card        474        474      0.992      0.995      0.995      0.928      0.992      0.995      0.995       0.91\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:10<00:00,  2.95it/s]\n",
      "                   all        476        476       0.99          1      0.995       0.92       0.99          1      0.995      0.901\n",
      "                  card        476        476       0.99          1      0.995       0.92       0.99          1      0.995      0.901\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.0.235 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 3798 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3798/3798 [00:03<00:00, 1004.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.4G     0.4713     0.6927     0.7719     0.8733          7        640: 100%|██████████| 238/238 [03:11<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "                   all        474        474      0.994      0.979      0.992        0.9      0.994      0.979      0.992      0.879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.54G        0.5     0.6253     0.3789     0.8796          6        640: 100%|██████████| 238/238 [03:08<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.997      0.983      0.995        0.9      0.997      0.983      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.2G       0.52     0.6398     0.4073     0.8903         10        640: 100%|██████████| 238/238 [03:08<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n",
      "                   all        474        474      0.986      0.973      0.992      0.884      0.986      0.973      0.992       0.87\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.53G      0.515     0.6475     0.3757     0.8887         10        640: 100%|██████████| 238/238 [03:07<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.962      0.965      0.991      0.908      0.962      0.965      0.991      0.897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.63G     0.5247     0.6486     0.3727     0.8917         11        640: 100%|██████████| 238/238 [03:07<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n",
      "                   all        474        474      0.971      0.977      0.991        0.9      0.971      0.977      0.991      0.895\n",
      "\n",
      "5 epochs completed in 0.280 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.76it/s]\n",
      "                   all        474        474      0.962      0.965      0.991      0.908      0.962      0.965      0.991      0.897\n",
      "                  card        474        474      0.962      0.965      0.991      0.908      0.962      0.965      0.991      0.897\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
      "                   all        476        476      0.989      0.962      0.991       0.91      0.989      0.962      0.991      0.889\n",
      "                  card        476        476      0.989      0.962      0.991       0.91      0.989      0.962      0.991      0.889\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 0: \n",
      " defaultdict(<class 'list'>, {0: [0.007998354528394015, 0.009186754695156445, 0.008606147362525655], 1: [0.00775809305467159, 0.008903405699157952, 0.008382683998575368], 2: [0.007887510576507899, 0.009103264708327785, 0.008562617676043854], 3: [0.007976761185197552, 0.009388700674636881, 0.008472458499193772], 4: [0.008128921287880645, 0.010154590113724642, 0.00850070571371787], 5: [0.007777691908847677, 0.0088727719247368, 0.008399757590166312], 6: [0.007728506288320197, 0.008925087505984126, 0.008373548157532135], 7: [0.00922948596582026, 0.011387562413643438, 0.010004604964653085], 8: [0.009830105175118833, 0.01251470127853226, 0.010431511796459335], 9: [0.016232632608481602, 0.019250071054154397, 0.017880939756424352], 10: [0.01935813575332595, 0.02293274723464134, 0.02102244627053116], 11: [0.03425884742571537, 0.04044085641633806, 0.038434687557811785], 12: [0.04348134417605419, 0.05240234796048973, 0.047807220757631], 13: [0.7981414008473514, 0.9163071983531503, 0.9120677936747674], 14: [0.7829313328541312, 0.8999052024619988, 0.8962770705551195], 15: [0.8516539468266477, 0.9710455780590502, 0.9674561977170949], 16: [0.8536735498868964, 0.9682566104016648, 0.9651736808008498], 17: [0.8588358408876923, 0.9799326545384144, 0.9734864856131226], 18: [0.8497393672611633, 0.9699663571856967, 0.9645029513350497], 19: [0.8635390078208035, 0.9812904353758635, 0.9788204133404986], 20: [0.8617617248661877, 0.9794687936804066, 0.9754417767302282], 21: [0.8760845551371942, 0.9906307617911677, 0.9906307617911677], 22: [0.8717054321633478, 0.9896689377609824, 0.9823136387936259], 23: [0.8701107039804393, 0.9855825263512683, 0.9833251114642599], 24: [0.8733750949821143, 0.9853035088529142, 0.9838939900788438], 25: [0.8819648821786743, 0.9932877672086295, 0.9926266327789218], 26: [0.8790231199776593, 0.9909304828747634, 0.9905754429422742], 27: [0.8838101028026351, 0.99353427951164, 0.9926268733698828], 28: [0.8846179088115191, 0.9945065438616797, 0.9944012353854589], 29: [0.8863253598167073, 0.9937535216622144, 0.993593643603107], 30: [0.8860260420530294, 0.9946859343310154, 0.9946859343310154], 31: [0.8900228137370331, 0.9942468477482512, 0.9929516034785504], 32: [0.8918687133999349, 0.9947486941655109, 0.9936764230504587], 33: [0.8939017732115857, 0.9945112735354713, 0.99383857915555], 34: [0.8890425994672396, 0.9947250961055922, 0.9946205199771376], 35: [0.8877155300228857, 0.994787841623121, 0.9938895497235121], 36: [0.8940336882822384, 0.994746474861131, 0.993369735424209], 37: [0.8979569180213647, 0.9947461150065121, 0.9940615391532804], 38: [0.8908205747221919, 0.9948128898128897, 0.989775218597761], 39: [0.8874347168912688, 0.9908177650817663, 0.9884066460270458], 40: [0.8819347661732373, 0.9941696593954032, 0.9891731380794928], 41: [0.9026834142949844, 0.9947899103912531, 0.9932512573099025], 42: [0.8888564668594213, 0.9944103379029563, 0.9914626929817277], 43: [0.9084754651315252, 0.994937106918239, 0.9934879287301139], 44: [0.9001682192796154, 0.9949368421052632, 0.9946894055713972], 45: [0.896276146033532, 0.9949789029535866, 0.99381288981289], 46: [0.8887798363767214, 0.9908135959379993, 0.9797658349701502]})\n",
      "Количество данных (train) для класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('0', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845d033",
   "metadata": {
    "papermill": {
     "duration": 2.707544,
     "end_time": "2024-01-05T03:11:11.506001",
     "exception": false,
     "start_time": "2024-01-05T03:11:08.798457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52512f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 2.61223,
     "end_time": "2024-01-05T03:11:16.850639",
     "exception": false,
     "start_time": "2024-01-05T03:11:14.238409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e78fa2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 2.713702,
     "end_time": "2024-01-05T03:11:22.256131",
     "exception": false,
     "start_time": "2024-01-05T03:11:19.542429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23126d0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 2.710882,
     "end_time": "2024-01-05T03:11:27.669408",
     "exception": false,
     "start_time": "2024-01-05T03:11:24.958526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421379e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 2.678043,
     "end_time": "2024-01-05T03:11:32.983005",
     "exception": false,
     "start_time": "2024-01-05T03:11:30.304962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ab200",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 2.592097,
     "end_time": "2024-01-05T03:11:38.309219",
     "exception": false,
     "start_time": "2024-01-05T03:11:35.717122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17671.515983,
   "end_time": "2024-01-05T03:11:47.604494",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T22:17:16.088511",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
