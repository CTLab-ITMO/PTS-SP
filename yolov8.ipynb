{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b9e3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T08:58:01.158934Z",
     "iopub.status.busy": "2024-01-25T08:58:01.158660Z",
     "iopub.status.idle": "2024-01-25T08:59:17.465511Z",
     "shell.execute_reply": "2024-01-25T08:59:17.464550Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 76.315142,
     "end_time": "2024-01-25T08:59:17.467874",
     "exception": false,
     "start_time": "2024-01-25T08:58:01.152732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-25 08:59:03--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 192.30.255.112\r\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240125T085904Z&X-Amz-Expires=300&X-Amz-Signature=607ef2b213ef584f69595888b028d0ee542603aa208eb5e00a3f6786e173f281&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-25 08:59:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240125T085904Z&X-Amz-Expires=300&X-Amz-Signature=607ef2b213ef584f69595888b028d0ee542603aa208eb5e00a3f6786e173f281&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   330MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-01-25 08:59:04 (330 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in affected-leaves-initialD-16 to yolov8:: 100%|██████████| 190825/190825 [00:05<00:00, 34719.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to affected-leaves-initialD-16 in yolov8:: 100%|██████████| 6016/6016 [00:00<00:00, 6777.11it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"thesisp1classification\").project(\"affected-leaves-initiald\")\n",
    "dataset = project.version(16).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d865778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T08:59:17.493418Z",
     "iopub.status.busy": "2024-01-25T08:59:17.492966Z",
     "iopub.status.idle": "2024-01-25T08:59:40.406983Z",
     "shell.execute_reply": "2024-01-25T08:59:40.405821Z"
    },
    "papermill": {
     "duration": 22.928806,
     "end_time": "2024-01-25T08:59:40.409309",
     "exception": false,
     "start_time": "2024-01-25T08:59:17.480503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7aca921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T08:59:40.435102Z",
     "iopub.status.busy": "2024-01-25T08:59:40.434293Z",
     "iopub.status.idle": "2024-01-25T08:59:40.458241Z",
     "shell.execute_reply": "2024-01-25T08:59:40.457036Z"
    },
    "papermill": {
     "duration": 0.039025,
     "end_time": "2024-01-25T08:59:40.460193",
     "exception": false,
     "start_time": "2024-01-25T08:59:40.421168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/affected-leaves-initialD-16\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/affected-leaves-initialD-16\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddcfa77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T08:59:40.486223Z",
     "iopub.status.busy": "2024-01-25T08:59:40.485895Z",
     "iopub.status.idle": "2024-01-25T08:59:40.597045Z",
     "shell.execute_reply": "2024-01-25T08:59:40.596302Z"
    },
    "papermill": {
     "duration": 0.127416,
     "end_time": "2024-01-25T08:59:40.599240",
     "exception": false,
     "start_time": "2024-01-25T08:59:40.471824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # Корректируем data.yaml файл\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081f6fc6",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-25T08:59:40.624444Z",
     "iopub.status.busy": "2024-01-25T08:59:40.623758Z",
     "iopub.status.idle": "2024-01-25T10:48:17.980234Z",
     "shell.execute_reply": "2024-01-25T10:48:17.979308Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6517.37133,
     "end_time": "2024-01-25T10:48:17.982393",
     "exception": false,
     "start_time": "2024-01-25T08:59:40.611063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пустой файл: temp/labels/YOLO-JD_dataset-2789_jpg.rf.6cce81e63314307a0256cd4bf3acf0e1.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4368_jpg.rf.e7a6554239779d4d1e6735c01fa23ebf.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4213_jpg.rf.5816d07898c1977f74f814ff62ec1e4b.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4368_jpg.rf.e16a8c7f5871a4d992c99fea9f27b85f.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4213_jpg.rf.cce16141f6bbd2b74f04473e8383d5eb.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4367_jpg.rf.2dee743c6df5d5abab7739c0680e6c30.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-2789_jpg.rf.d2941d76e6dcb264e5a5ce12bd88a1dc.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4213_jpg.rf.47357e79f981bcf55efeafb4047fc5fa.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-4368_jpg.rf.baec66ee02b5b7c666a4c04017a52441.txt\n",
      "Пустой файл: temp/labels/YOLO-JD_dataset-2789_jpg.rf.ec9a8bcec87a9cf2ef13d3c26fc75006.txt\n",
      "Кол-во пустых файлов - 10\n",
      "valid_3/images 90\n",
      "test_3/images 91\n",
      "valid_1/images 28\n",
      "test_1/images 28\n",
      "valid_0/images 97\n",
      "test_0/images 97\n",
      "valid_6/images 60\n",
      "test_6/images 61\n",
      "valid_5/images 9\n",
      "test_5/images 11\n",
      "valid_2/images 12\n",
      "test_2/images 14\n",
      "valid_4/images 10\n",
      "test_4/images 11\n",
      "train/labels 2407 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 3 содержит 723 объекта(-ов)\n",
      " Класс 1 содержит 226 объекта(-ов)\n",
      " Класс 0 содержит 788 объекта(-ов)\n",
      " Класс 6 содержит 482 объекта(-ов)\n",
      " Класс 5 содержит 77 объекта(-ов)\n",
      " Класс 2 содержит 103 объекта(-ов)\n",
      " Класс 4 содержит 88 объекта(-ов)\n",
      "\n",
      "Класс 3\n",
      "\tКол-во train класса 3: 723\n",
      "\tКоличество данных (train) на каждой итерации класса 3: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 723]\n",
      "\tКол-во директорий для класса 3: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 3\n",
      "\tnum_to_mv_train 2, folder 1, cls 3\n",
      "\tnum_to_mv_train 2, folder 2, cls 3\n",
      "\tnum_to_mv_train 2, folder 3, cls 3\n",
      "\tnum_to_mv_train 2, folder 4, cls 3\n",
      "\tnum_to_mv_train 3, folder 5, cls 3\n",
      "\tnum_to_mv_train 3, folder 6, cls 3\n",
      "\tnum_to_mv_train 3, folder 7, cls 3\n",
      "\tnum_to_mv_train 3, folder 8, cls 3\n",
      "\tnum_to_mv_train 3, folder 9, cls 3\n",
      "\tnum_to_mv_train 3, folder 10, cls 3\n",
      "\tnum_to_mv_train 3, folder 11, cls 3\n",
      "\tnum_to_mv_train 5, folder 12, cls 3\n",
      "\tnum_to_mv_train 5, folder 13, cls 3\n",
      "\tnum_to_mv_train 5, folder 14, cls 3\n",
      "\tnum_to_mv_train 5, folder 15, cls 3\n",
      "\tnum_to_mv_train 5, folder 16, cls 3\n",
      "\tnum_to_mv_train 5, folder 17, cls 3\n",
      "\tnum_to_mv_train 5, folder 18, cls 3\n",
      "\tnum_to_mv_train 5, folder 19, cls 3\n",
      "\tnum_to_mv_train 5, folder 20, cls 3\n",
      "\tnum_to_mv_train 5, folder 21, cls 3\n",
      "\tnum_to_mv_train 5, folder 22, cls 3\n",
      "\tnum_to_mv_train 5, folder 23, cls 3\n",
      "\tnum_to_mv_train 5, folder 24, cls 3\n",
      "\tnum_to_mv_train 5, folder 25, cls 3\n",
      "\tnum_to_mv_train 10, folder 26, cls 3\n",
      "\tnum_to_mv_train 10, folder 27, cls 3\n",
      "\tnum_to_mv_train 10, folder 28, cls 3\n",
      "\tnum_to_mv_train 10, folder 29, cls 3\n",
      "\tnum_to_mv_train 10, folder 30, cls 3\n",
      "\tnum_to_mv_train 10, folder 31, cls 3\n",
      "\tnum_to_mv_train 10, folder 32, cls 3\n",
      "\tnum_to_mv_train 10, folder 33, cls 3\n",
      "\tnum_to_mv_train 10, folder 34, cls 3\n",
      "\tnum_to_mv_train 10, folder 35, cls 3\n",
      "\tnum_to_mv_train 50, folder 36, cls 3\n",
      "\tnum_to_mv_train 50, folder 37, cls 3\n",
      "\tnum_to_mv_train 100, folder 38, cls 3\n",
      "\tnum_to_mv_train 100, folder 39, cls 3\n",
      "\tnum_to_mv_train 222, folder 40, cls 3\n",
      "temp_3_1/train/labels 2\n",
      "temp_3_1/train/images 2 \n",
      "\n",
      "temp_3_2/train/labels 2\n",
      "temp_3_2/train/images 2 \n",
      "\n",
      "temp_3_3/train/labels 2\n",
      "temp_3_3/train/images 2 \n",
      "\n",
      "temp_3_4/train/labels 2\n",
      "temp_3_4/train/images 2 \n",
      "\n",
      "temp_3_5/train/labels 2\n",
      "temp_3_5/train/images 2 \n",
      "\n",
      "temp_3_6/train/labels 3\n",
      "temp_3_6/train/images 3 \n",
      "\n",
      "temp_3_7/train/labels 3\n",
      "temp_3_7/train/images 3 \n",
      "\n",
      "temp_3_8/train/labels 3\n",
      "temp_3_8/train/images 3 \n",
      "\n",
      "temp_3_9/train/labels 3\n",
      "temp_3_9/train/images 3 \n",
      "\n",
      "temp_3_10/train/labels 3\n",
      "temp_3_10/train/images 3 \n",
      "\n",
      "temp_3_11/train/labels 3\n",
      "temp_3_11/train/images 3 \n",
      "\n",
      "temp_3_12/train/labels 3\n",
      "temp_3_12/train/images 3 \n",
      "\n",
      "temp_3_13/train/labels 5\n",
      "temp_3_13/train/images 5 \n",
      "\n",
      "temp_3_14/train/labels 5\n",
      "temp_3_14/train/images 5 \n",
      "\n",
      "temp_3_15/train/labels 5\n",
      "temp_3_15/train/images 5 \n",
      "\n",
      "temp_3_16/train/labels 5\n",
      "temp_3_16/train/images 5 \n",
      "\n",
      "temp_3_17/train/labels 5\n",
      "temp_3_17/train/images 5 \n",
      "\n",
      "temp_3_18/train/labels 5\n",
      "temp_3_18/train/images 5 \n",
      "\n",
      "temp_3_19/train/labels 5\n",
      "temp_3_19/train/images 5 \n",
      "\n",
      "temp_3_20/train/labels 5\n",
      "temp_3_20/train/images 5 \n",
      "\n",
      "temp_3_21/train/labels 5\n",
      "temp_3_21/train/images 5 \n",
      "\n",
      "temp_3_22/train/labels 5\n",
      "temp_3_22/train/images 5 \n",
      "\n",
      "temp_3_23/train/labels 5\n",
      "temp_3_23/train/images 5 \n",
      "\n",
      "temp_3_24/train/labels 5\n",
      "temp_3_24/train/images 5 \n",
      "\n",
      "temp_3_25/train/labels 5\n",
      "temp_3_25/train/images 5 \n",
      "\n",
      "temp_3_26/train/labels 5\n",
      "temp_3_26/train/images 5 \n",
      "\n",
      "temp_3_27/train/labels 10\n",
      "temp_3_27/train/images 10 \n",
      "\n",
      "temp_3_28/train/labels 10\n",
      "temp_3_28/train/images 10 \n",
      "\n",
      "temp_3_29/train/labels 10\n",
      "temp_3_29/train/images 10 \n",
      "\n",
      "temp_3_30/train/labels 10\n",
      "temp_3_30/train/images 10 \n",
      "\n",
      "temp_3_31/train/labels 10\n",
      "temp_3_31/train/images 10 \n",
      "\n",
      "temp_3_32/train/labels 10\n",
      "temp_3_32/train/images 10 \n",
      "\n",
      "temp_3_33/train/labels 10\n",
      "temp_3_33/train/images 10 \n",
      "\n",
      "temp_3_34/train/labels 10\n",
      "temp_3_34/train/images 10 \n",
      "\n",
      "temp_3_35/train/labels 10\n",
      "temp_3_35/train/images 10 \n",
      "\n",
      "temp_3_36/train/labels 10\n",
      "temp_3_36/train/images 10 \n",
      "\n",
      "temp_3_37/train/labels 50\n",
      "temp_3_37/train/images 50 \n",
      "\n",
      "temp_3_38/train/labels 50\n",
      "temp_3_38/train/images 50 \n",
      "\n",
      "temp_3_39/train/labels 100\n",
      "temp_3_39/train/images 100 \n",
      "\n",
      "temp_3_40/train/labels 100\n",
      "temp_3_40/train/images 100 \n",
      "\n",
      "temp_3_41/train/labels 222\n",
      "temp_3_41/train/images 222 \n",
      "\n",
      "Класс 1\n",
      "\tКол-во train класса 1: 226\n",
      "\tКоличество данных (train) на каждой итерации класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 226]\n",
      "\tКол-во директорий для класса 1: 37 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 25, folder 36, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 25\n",
      "temp_1_37/train/images 25 \n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 788\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 788]\n",
      "\tКол-во директорий для класса 0: 41 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 287, folder 40, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 287\n",
      "temp_0_41/train/images 287 \n",
      "\n",
      "Класс 6\n",
      "\tКол-во train класса 6: 482\n",
      "\tКоличество данных (train) на каждой итерации класса 6: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 482]\n",
      "\tКол-во директорий для класса 6: 40 \n",
      "\tnum_to_mv_train 2, folder 0, cls 6\n",
      "\tnum_to_mv_train 2, folder 1, cls 6\n",
      "\tnum_to_mv_train 2, folder 2, cls 6\n",
      "\tnum_to_mv_train 2, folder 3, cls 6\n",
      "\tnum_to_mv_train 2, folder 4, cls 6\n",
      "\tnum_to_mv_train 3, folder 5, cls 6\n",
      "\tnum_to_mv_train 3, folder 6, cls 6\n",
      "\tnum_to_mv_train 3, folder 7, cls 6\n",
      "\tnum_to_mv_train 3, folder 8, cls 6\n",
      "\tnum_to_mv_train 3, folder 9, cls 6\n",
      "\tnum_to_mv_train 3, folder 10, cls 6\n",
      "\tnum_to_mv_train 3, folder 11, cls 6\n",
      "\tnum_to_mv_train 5, folder 12, cls 6\n",
      "\tnum_to_mv_train 5, folder 13, cls 6\n",
      "\tnum_to_mv_train 5, folder 14, cls 6\n",
      "\tnum_to_mv_train 5, folder 15, cls 6\n",
      "\tnum_to_mv_train 5, folder 16, cls 6\n",
      "\tnum_to_mv_train 5, folder 17, cls 6\n",
      "\tnum_to_mv_train 5, folder 18, cls 6\n",
      "\tnum_to_mv_train 5, folder 19, cls 6\n",
      "\tnum_to_mv_train 5, folder 20, cls 6\n",
      "\tnum_to_mv_train 5, folder 21, cls 6\n",
      "\tnum_to_mv_train 5, folder 22, cls 6\n",
      "\tnum_to_mv_train 5, folder 23, cls 6\n",
      "\tnum_to_mv_train 5, folder 24, cls 6\n",
      "\tnum_to_mv_train 5, folder 25, cls 6\n",
      "\tnum_to_mv_train 10, folder 26, cls 6\n",
      "\tnum_to_mv_train 10, folder 27, cls 6\n",
      "\tnum_to_mv_train 10, folder 28, cls 6\n",
      "\tnum_to_mv_train 10, folder 29, cls 6\n",
      "\tnum_to_mv_train 10, folder 30, cls 6\n",
      "\tnum_to_mv_train 10, folder 31, cls 6\n",
      "\tnum_to_mv_train 10, folder 32, cls 6\n",
      "\tnum_to_mv_train 10, folder 33, cls 6\n",
      "\tnum_to_mv_train 10, folder 34, cls 6\n",
      "\tnum_to_mv_train 10, folder 35, cls 6\n",
      "\tnum_to_mv_train 50, folder 36, cls 6\n",
      "\tnum_to_mv_train 50, folder 37, cls 6\n",
      "\tnum_to_mv_train 100, folder 38, cls 6\n",
      "\tnum_to_mv_train 81, folder 39, cls 6\n",
      "temp_6_1/train/labels 2\n",
      "temp_6_1/train/images 2 \n",
      "\n",
      "temp_6_2/train/labels 2\n",
      "temp_6_2/train/images 2 \n",
      "\n",
      "temp_6_3/train/labels 2\n",
      "temp_6_3/train/images 2 \n",
      "\n",
      "temp_6_4/train/labels 2\n",
      "temp_6_4/train/images 2 \n",
      "\n",
      "temp_6_5/train/labels 2\n",
      "temp_6_5/train/images 2 \n",
      "\n",
      "temp_6_6/train/labels 3\n",
      "temp_6_6/train/images 3 \n",
      "\n",
      "temp_6_7/train/labels 3\n",
      "temp_6_7/train/images 3 \n",
      "\n",
      "temp_6_8/train/labels 3\n",
      "temp_6_8/train/images 3 \n",
      "\n",
      "temp_6_9/train/labels 3\n",
      "temp_6_9/train/images 3 \n",
      "\n",
      "temp_6_10/train/labels 3\n",
      "temp_6_10/train/images 3 \n",
      "\n",
      "temp_6_11/train/labels 3\n",
      "temp_6_11/train/images 3 \n",
      "\n",
      "temp_6_12/train/labels 3\n",
      "temp_6_12/train/images 3 \n",
      "\n",
      "temp_6_13/train/labels 5\n",
      "temp_6_13/train/images 5 \n",
      "\n",
      "temp_6_14/train/labels 5\n",
      "temp_6_14/train/images 5 \n",
      "\n",
      "temp_6_15/train/labels 5\n",
      "temp_6_15/train/images 5 \n",
      "\n",
      "temp_6_16/train/labels 5\n",
      "temp_6_16/train/images 5 \n",
      "\n",
      "temp_6_17/train/labels 5\n",
      "temp_6_17/train/images 5 \n",
      "\n",
      "temp_6_18/train/labels 5\n",
      "temp_6_18/train/images 5 \n",
      "\n",
      "temp_6_19/train/labels 5\n",
      "temp_6_19/train/images 5 \n",
      "\n",
      "temp_6_20/train/labels 5\n",
      "temp_6_20/train/images 5 \n",
      "\n",
      "temp_6_21/train/labels 5\n",
      "temp_6_21/train/images 5 \n",
      "\n",
      "temp_6_22/train/labels 5\n",
      "temp_6_22/train/images 5 \n",
      "\n",
      "temp_6_23/train/labels 5\n",
      "temp_6_23/train/images 5 \n",
      "\n",
      "temp_6_24/train/labels 5\n",
      "temp_6_24/train/images 5 \n",
      "\n",
      "temp_6_25/train/labels 5\n",
      "temp_6_25/train/images 5 \n",
      "\n",
      "temp_6_26/train/labels 5\n",
      "temp_6_26/train/images 5 \n",
      "\n",
      "temp_6_27/train/labels 10\n",
      "temp_6_27/train/images 10 \n",
      "\n",
      "temp_6_28/train/labels 10\n",
      "temp_6_28/train/images 10 \n",
      "\n",
      "temp_6_29/train/labels 10\n",
      "temp_6_29/train/images 10 \n",
      "\n",
      "temp_6_30/train/labels 10\n",
      "temp_6_30/train/images 10 \n",
      "\n",
      "temp_6_31/train/labels 10\n",
      "temp_6_31/train/images 10 \n",
      "\n",
      "temp_6_32/train/labels 10\n",
      "temp_6_32/train/images 10 \n",
      "\n",
      "temp_6_33/train/labels 10\n",
      "temp_6_33/train/images 10 \n",
      "\n",
      "temp_6_34/train/labels 10\n",
      "temp_6_34/train/images 10 \n",
      "\n",
      "temp_6_35/train/labels 10\n",
      "temp_6_35/train/images 10 \n",
      "\n",
      "temp_6_36/train/labels 10\n",
      "temp_6_36/train/images 10 \n",
      "\n",
      "temp_6_37/train/labels 50\n",
      "temp_6_37/train/images 50 \n",
      "\n",
      "temp_6_38/train/labels 50\n",
      "temp_6_38/train/images 50 \n",
      "\n",
      "temp_6_39/train/labels 100\n",
      "temp_6_39/train/images 100 \n",
      "\n",
      "temp_6_40/train/labels 81\n",
      "temp_6_40/train/images 81 \n",
      "\n",
      "Класс 5\n",
      "\tКол-во train класса 5: 77\n",
      "\tКоличество данных (train) на каждой итерации класса 5: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 77]\n",
      "\tКол-во директорий для класса 5: 22 \n",
      "\tnum_to_mv_train 2, folder 0, cls 5\n",
      "\tnum_to_mv_train 2, folder 1, cls 5\n",
      "\tnum_to_mv_train 2, folder 2, cls 5\n",
      "\tnum_to_mv_train 2, folder 3, cls 5\n",
      "\tnum_to_mv_train 2, folder 4, cls 5\n",
      "\tnum_to_mv_train 3, folder 5, cls 5\n",
      "\tnum_to_mv_train 3, folder 6, cls 5\n",
      "\tnum_to_mv_train 3, folder 7, cls 5\n",
      "\tnum_to_mv_train 3, folder 8, cls 5\n",
      "\tnum_to_mv_train 3, folder 9, cls 5\n",
      "\tnum_to_mv_train 3, folder 10, cls 5\n",
      "\tnum_to_mv_train 3, folder 11, cls 5\n",
      "\tnum_to_mv_train 5, folder 12, cls 5\n",
      "\tnum_to_mv_train 5, folder 13, cls 5\n",
      "\tnum_to_mv_train 5, folder 14, cls 5\n",
      "\tnum_to_mv_train 5, folder 15, cls 5\n",
      "\tnum_to_mv_train 5, folder 16, cls 5\n",
      "\tnum_to_mv_train 5, folder 17, cls 5\n",
      "\tnum_to_mv_train 5, folder 18, cls 5\n",
      "\tnum_to_mv_train 5, folder 19, cls 5\n",
      "\tnum_to_mv_train 5, folder 20, cls 5\n",
      "\tnum_to_mv_train 1, folder 21, cls 5\n",
      "temp_5_1/train/labels 2\n",
      "temp_5_1/train/images 2 \n",
      "\n",
      "temp_5_2/train/labels 2\n",
      "temp_5_2/train/images 2 \n",
      "\n",
      "temp_5_3/train/labels 2\n",
      "temp_5_3/train/images 2 \n",
      "\n",
      "temp_5_4/train/labels 2\n",
      "temp_5_4/train/images 2 \n",
      "\n",
      "temp_5_5/train/labels 2\n",
      "temp_5_5/train/images 2 \n",
      "\n",
      "temp_5_6/train/labels 3\n",
      "temp_5_6/train/images 3 \n",
      "\n",
      "temp_5_7/train/labels 3\n",
      "temp_5_7/train/images 3 \n",
      "\n",
      "temp_5_8/train/labels 3\n",
      "temp_5_8/train/images 3 \n",
      "\n",
      "temp_5_9/train/labels 3\n",
      "temp_5_9/train/images 3 \n",
      "\n",
      "temp_5_10/train/labels 3\n",
      "temp_5_10/train/images 3 \n",
      "\n",
      "temp_5_11/train/labels 3\n",
      "temp_5_11/train/images 3 \n",
      "\n",
      "temp_5_12/train/labels 3\n",
      "temp_5_12/train/images 3 \n",
      "\n",
      "temp_5_13/train/labels 5\n",
      "temp_5_13/train/images 5 \n",
      "\n",
      "temp_5_14/train/labels 5\n",
      "temp_5_14/train/images 5 \n",
      "\n",
      "temp_5_15/train/labels 5\n",
      "temp_5_15/train/images 5 \n",
      "\n",
      "temp_5_16/train/labels 5\n",
      "temp_5_16/train/images 5 \n",
      "\n",
      "temp_5_17/train/labels 5\n",
      "temp_5_17/train/images 5 \n",
      "\n",
      "temp_5_18/train/labels 5\n",
      "temp_5_18/train/images 5 \n",
      "\n",
      "temp_5_19/train/labels 5\n",
      "temp_5_19/train/images 5 \n",
      "\n",
      "temp_5_20/train/labels 5\n",
      "temp_5_20/train/images 5 \n",
      "\n",
      "temp_5_21/train/labels 5\n",
      "temp_5_21/train/images 5 \n",
      "\n",
      "temp_5_22/train/labels 1\n",
      "temp_5_22/train/images 1 \n",
      "\n",
      "Класс 2\n",
      "\tКол-во train класса 2: 103\n",
      "\tКоличество данных (train) на каждой итерации класса 2: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 103]\n",
      "\tКол-во директорий для класса 2: 27 \n",
      "\tnum_to_mv_train 2, folder 0, cls 2\n",
      "\tnum_to_mv_train 2, folder 1, cls 2\n",
      "\tnum_to_mv_train 2, folder 2, cls 2\n",
      "\tnum_to_mv_train 2, folder 3, cls 2\n",
      "\tnum_to_mv_train 2, folder 4, cls 2\n",
      "\tnum_to_mv_train 3, folder 5, cls 2\n",
      "\tnum_to_mv_train 3, folder 6, cls 2\n",
      "\tnum_to_mv_train 3, folder 7, cls 2\n",
      "\tnum_to_mv_train 3, folder 8, cls 2\n",
      "\tnum_to_mv_train 3, folder 9, cls 2\n",
      "\tnum_to_mv_train 3, folder 10, cls 2\n",
      "\tnum_to_mv_train 3, folder 11, cls 2\n",
      "\tnum_to_mv_train 5, folder 12, cls 2\n",
      "\tnum_to_mv_train 5, folder 13, cls 2\n",
      "\tnum_to_mv_train 5, folder 14, cls 2\n",
      "\tnum_to_mv_train 5, folder 15, cls 2\n",
      "\tnum_to_mv_train 5, folder 16, cls 2\n",
      "\tnum_to_mv_train 5, folder 17, cls 2\n",
      "\tnum_to_mv_train 5, folder 18, cls 2\n",
      "\tnum_to_mv_train 5, folder 19, cls 2\n",
      "\tnum_to_mv_train 5, folder 20, cls 2\n",
      "\tnum_to_mv_train 5, folder 21, cls 2\n",
      "\tnum_to_mv_train 5, folder 22, cls 2\n",
      "\tnum_to_mv_train 5, folder 23, cls 2\n",
      "\tnum_to_mv_train 5, folder 24, cls 2\n",
      "\tnum_to_mv_train 5, folder 25, cls 2\n",
      "\tnum_to_mv_train 2, folder 26, cls 2\n",
      "temp_2_1/train/labels 2\n",
      "temp_2_1/train/images 2 \n",
      "\n",
      "temp_2_2/train/labels 2\n",
      "temp_2_2/train/images 2 \n",
      "\n",
      "temp_2_3/train/labels 2\n",
      "temp_2_3/train/images 2 \n",
      "\n",
      "temp_2_4/train/labels 2\n",
      "temp_2_4/train/images 2 \n",
      "\n",
      "temp_2_5/train/labels 2\n",
      "temp_2_5/train/images 2 \n",
      "\n",
      "temp_2_6/train/labels 3\n",
      "temp_2_6/train/images 3 \n",
      "\n",
      "temp_2_7/train/labels 3\n",
      "temp_2_7/train/images 3 \n",
      "\n",
      "temp_2_8/train/labels 3\n",
      "temp_2_8/train/images 3 \n",
      "\n",
      "temp_2_9/train/labels 3\n",
      "temp_2_9/train/images 3 \n",
      "\n",
      "temp_2_10/train/labels 3\n",
      "temp_2_10/train/images 3 \n",
      "\n",
      "temp_2_11/train/labels 3\n",
      "temp_2_11/train/images 3 \n",
      "\n",
      "temp_2_12/train/labels 3\n",
      "temp_2_12/train/images 3 \n",
      "\n",
      "temp_2_13/train/labels 5\n",
      "temp_2_13/train/images 5 \n",
      "\n",
      "temp_2_14/train/labels 5\n",
      "temp_2_14/train/images 5 \n",
      "\n",
      "temp_2_15/train/labels 5\n",
      "temp_2_15/train/images 5 \n",
      "\n",
      "temp_2_16/train/labels 5\n",
      "temp_2_16/train/images 5 \n",
      "\n",
      "temp_2_17/train/labels 5\n",
      "temp_2_17/train/images 5 \n",
      "\n",
      "temp_2_18/train/labels 5\n",
      "temp_2_18/train/images 5 \n",
      "\n",
      "temp_2_19/train/labels 5\n",
      "temp_2_19/train/images 5 \n",
      "\n",
      "temp_2_20/train/labels 5\n",
      "temp_2_20/train/images 5 \n",
      "\n",
      "temp_2_21/train/labels 5\n",
      "temp_2_21/train/images 5 \n",
      "\n",
      "temp_2_22/train/labels 5\n",
      "temp_2_22/train/images 5 \n",
      "\n",
      "temp_2_23/train/labels 5\n",
      "temp_2_23/train/images 5 \n",
      "\n",
      "temp_2_24/train/labels 5\n",
      "temp_2_24/train/images 5 \n",
      "\n",
      "temp_2_25/train/labels 5\n",
      "temp_2_25/train/images 5 \n",
      "\n",
      "temp_2_26/train/labels 5\n",
      "temp_2_26/train/images 5 \n",
      "\n",
      "temp_2_27/train/labels 2\n",
      "temp_2_27/train/images 2 \n",
      "\n",
      "Класс 4\n",
      "\tКол-во train класса 4: 88\n",
      "\tКоличество данных (train) на каждой итерации класса 4: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 88]\n",
      "\tКол-во директорий для класса 4: 24 \n",
      "\tnum_to_mv_train 2, folder 0, cls 4\n",
      "\tnum_to_mv_train 2, folder 1, cls 4\n",
      "\tnum_to_mv_train 2, folder 2, cls 4\n",
      "\tnum_to_mv_train 2, folder 3, cls 4\n",
      "\tnum_to_mv_train 2, folder 4, cls 4\n",
      "\tnum_to_mv_train 3, folder 5, cls 4\n",
      "\tnum_to_mv_train 3, folder 6, cls 4\n",
      "\tnum_to_mv_train 3, folder 7, cls 4\n",
      "\tnum_to_mv_train 3, folder 8, cls 4\n",
      "\tnum_to_mv_train 3, folder 9, cls 4\n",
      "\tnum_to_mv_train 3, folder 10, cls 4\n",
      "\tnum_to_mv_train 3, folder 11, cls 4\n",
      "\tnum_to_mv_train 5, folder 12, cls 4\n",
      "\tnum_to_mv_train 5, folder 13, cls 4\n",
      "\tnum_to_mv_train 5, folder 14, cls 4\n",
      "\tnum_to_mv_train 5, folder 15, cls 4\n",
      "\tnum_to_mv_train 5, folder 16, cls 4\n",
      "\tnum_to_mv_train 5, folder 17, cls 4\n",
      "\tnum_to_mv_train 5, folder 18, cls 4\n",
      "\tnum_to_mv_train 5, folder 19, cls 4\n",
      "\tnum_to_mv_train 5, folder 20, cls 4\n",
      "\tnum_to_mv_train 5, folder 21, cls 4\n",
      "\tnum_to_mv_train 5, folder 22, cls 4\n",
      "\tnum_to_mv_train 2, folder 23, cls 4\n",
      "temp_4_1/train/labels 2\n",
      "temp_4_1/train/images 2 \n",
      "\n",
      "temp_4_2/train/labels 2\n",
      "temp_4_2/train/images 2 \n",
      "\n",
      "temp_4_3/train/labels 2\n",
      "temp_4_3/train/images 2 \n",
      "\n",
      "temp_4_4/train/labels 2\n",
      "temp_4_4/train/images 2 \n",
      "\n",
      "temp_4_5/train/labels 2\n",
      "temp_4_5/train/images 2 \n",
      "\n",
      "temp_4_6/train/labels 3\n",
      "temp_4_6/train/images 3 \n",
      "\n",
      "temp_4_7/train/labels 3\n",
      "temp_4_7/train/images 3 \n",
      "\n",
      "temp_4_8/train/labels 3\n",
      "temp_4_8/train/images 3 \n",
      "\n",
      "temp_4_9/train/labels 3\n",
      "temp_4_9/train/images 3 \n",
      "\n",
      "temp_4_10/train/labels 3\n",
      "temp_4_10/train/images 3 \n",
      "\n",
      "temp_4_11/train/labels 3\n",
      "temp_4_11/train/images 3 \n",
      "\n",
      "temp_4_12/train/labels 3\n",
      "temp_4_12/train/images 3 \n",
      "\n",
      "temp_4_13/train/labels 5\n",
      "temp_4_13/train/images 5 \n",
      "\n",
      "temp_4_14/train/labels 5\n",
      "temp_4_14/train/images 5 \n",
      "\n",
      "temp_4_15/train/labels 5\n",
      "temp_4_15/train/images 5 \n",
      "\n",
      "temp_4_16/train/labels 5\n",
      "temp_4_16/train/images 5 \n",
      "\n",
      "temp_4_17/train/labels 5\n",
      "temp_4_17/train/images 5 \n",
      "\n",
      "temp_4_18/train/labels 5\n",
      "temp_4_18/train/images 5 \n",
      "\n",
      "temp_4_19/train/labels 5\n",
      "temp_4_19/train/images 5 \n",
      "\n",
      "temp_4_20/train/labels 5\n",
      "temp_4_20/train/images 5 \n",
      "\n",
      "temp_4_21/train/labels 5\n",
      "temp_4_21/train/images 5 \n",
      "\n",
      "temp_4_22/train/labels 5\n",
      "temp_4_22/train/images 5 \n",
      "\n",
      "temp_4_23/train/labels 5\n",
      "temp_4_23/train/images 5 \n",
      "\n",
      "temp_4_24/train/labels 2\n",
      "temp_4_24/train/images 2 \n",
      "\n",
      "/kaggle/working/affected-leaves-initialD-16/data.yaml\n",
      "defaultdict(<class 'int'>, {'3': 41, '1': 37, '0': 41, '6': 40, '5': 22, '2': 27, '4': 24}) defaultdict(<class 'list'>, {'3': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 723], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 226], '0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 788], '6': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 482], '5': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 77], '2': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 103], '4': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 88]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 19.0MB/s]\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 95.8MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 214.28it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 943.74it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.19G      4.962      4.262      7.776      2.285         21        640: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.21G      3.619      5.311      11.65      2.968          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.32G      4.096      8.322      10.07      2.848          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.42G      5.633       5.93      7.911      3.468         19        640: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.24G      3.561      6.154      8.006       2.95          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 943.24it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 586.08it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.01G      4.962      4.262      7.776      2.285         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.55G      3.619      5.311      11.65      2.968          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.55G      4.096      8.322      10.07      2.848          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.75G      5.633       5.93      7.911      3.468         19        640: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.65G      3.561      6.154      8.006       2.95          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.9ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 864.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.57G      4.363      5.609      7.937      2.107         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.32G      3.715      5.833      6.792      2.268         11        640: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.32G      3.669      5.001      6.898      2.275          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.3G      3.277      6.142      7.353      2.311          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.32G      3.538      5.166      6.426      2.335         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 1263.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.06G      3.545      5.028      6.389      2.341         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.69G      3.527       6.09      6.765      2.451         23        640: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.71G      4.521      7.535      18.08      2.254          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.68G      2.744      5.404      8.851      1.948         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       3.7G      3.304      4.856       6.95      2.396         22        640: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 934.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      4.501      5.388      6.976      2.625         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.3G       3.66      5.638      7.548      2.556          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.3G      4.014      4.684      7.389      2.868          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.26G       4.59       5.85      9.076      2.763         27        640: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.34G      3.897      5.894       7.07       2.72         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 874.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.06G      3.856      5.331      6.446      2.204         47        640: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.91G      3.367       5.97      6.765      2.448         34        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.88G      3.725      5.557      7.073      2.415         30        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.92G      4.132      5.187      6.806       2.78         42        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.87G      4.055      5.496      8.675      2.327         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 1128.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.34G      2.987      3.978      6.847      1.251          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.31G      3.158      5.075       9.88       1.89          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.28G      2.509      4.001      13.12       1.78          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.28G      3.468      5.375      8.143      1.659          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.29G        3.8       5.25      9.653      2.215          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 802.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.52G      3.771      5.711      9.546      2.507         37        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.21G      4.224      5.509       9.09       2.23         48        640: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.09G      4.218      5.601      7.277      2.577         49        640: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       6.1G      4.138      5.497      10.04      2.439         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.95G      3.296      5.065      7.534      2.228         34        640: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.07it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 4807.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.17G      3.938      4.256      6.948      1.409         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.31G      3.668      5.546       7.92       1.62          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.29G      3.436      4.783      10.46      1.811          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.28G      3.891      7.604      12.22      1.611          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.3G       3.78      5.473      8.656      1.993          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 937.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.35G      3.985      5.166      6.714      2.175         80        640: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.38G      3.374      5.456      8.336      2.082         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.37G        3.7      4.824      8.771      1.932         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.37G      3.635      6.444      7.971      2.328         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.38G      3.539      5.557       8.47      2.074         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 555.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.11G      3.596      4.798      5.808      3.001         26        640: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.93G      3.392      5.644      5.481       2.94         15        640: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.82G       3.07      5.763      5.429      2.632         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.82G      3.554      6.414       5.57      2.945         17        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.95G       3.46      5.463      5.294       2.84         45        640: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 937.50it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.22G      3.901      5.788      7.276      2.216         81        640: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.72G      3.659      5.569      6.826      2.391         74        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.98G      3.509      5.517      6.587      2.397         85        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.69G      3.614      5.631      8.002      2.248         52        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.69G      3.602      5.757      6.379      2.546         78        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 715.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.34G      2.639      4.263      5.293      1.606         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.89G       1.86      4.702      5.125      1.393         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.82G       2.26      3.724      5.265      1.643         22        640: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.77G       2.19      4.282       5.59      1.674         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.84G      2.704      4.629      5.607      1.454         30        640: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 884.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      3.237      4.891      6.168      2.029        111        640: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.24G       2.99      4.878      5.779      2.102        121        640: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.21G      2.912      4.848      6.019      1.955        112        640: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.22G      3.301      5.418      5.648      2.654        133        640: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.21G      3.447       5.47      6.522      2.375         81        640: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 857.32it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.35G      3.794      5.342      6.091      1.973         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.9G      3.769      5.388      8.052       1.98         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.9G      3.044       5.37      6.292      2.224         17        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.92G      3.324      5.366      6.566      1.803         22        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.9G      3.776      5.447      6.992      2.022         24        640: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 844.04it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      3.318      5.458      6.392      2.294         12        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.24G      3.935      5.304      7.079      2.248         17        640: 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.22G       3.93      5.738      8.927      2.312         13        640: 100%|██████████| 2/2 [00:01<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.22G      3.438      5.406      7.414      2.283          9        640: 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.24G      3.492      4.971      6.899      2.307         11        640: 100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 939.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      2.857      4.655      6.259      1.841         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.86G      2.065      3.846      6.239      1.844          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.84G      3.104      4.645      7.434       2.34          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.74G      3.163      4.818      7.507      2.547          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.86G      2.611      5.797      12.54      2.089          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<00:00, 946.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      2.664      4.561      5.775          2         24        640: 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      3.433       5.07      6.216      2.213         40        640: 100%|██████████| 2/2 [00:01<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.2G      2.966      4.759      5.998      1.922         64        640: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.2G      3.265      5.157      6.844       1.98         30        640: 100%|██████████| 2/2 [00:01<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G      3.138      4.755       6.55       1.94         31        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 793.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      3.842      4.726      5.532      2.258         40        640: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.87G      3.232      4.642      6.656      2.194         13        640: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.9G      3.622      5.022      6.009       2.63         20        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.9G      3.423      5.435      6.246      2.804         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.8G      3.479      5.726      6.421      2.157         23        640: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.07it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 948.89it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      3.119      5.113      6.471       2.32         31        640: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G      3.464      5.467      6.572      2.282         40        640: 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.22G      3.356      4.631      6.335      1.961         59        640: 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.22G      3.482      5.147      5.994      2.286         81        640: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      2.984      4.955      5.871      2.088         58        640: 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 996.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      3.741      4.941      9.843      2.635          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.88G      3.956      5.452      11.07      2.481          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.86G      3.243      4.461      7.418      2.166          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.86G      3.371      6.139      10.79      2.442          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.88G      4.153      5.589      9.507      2.177         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 15.3ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 882.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      2.849      4.727      6.218      2.122         61        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G      3.455      5.454      6.905      2.433         46        640: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.21G      2.806      4.576      5.975      1.866         80        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.2G      3.452      5.223      6.625      2.258         84        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G       3.32      4.868      6.341       1.97         92        640: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 801.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      3.391      5.677      6.287      1.801         23        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.9G      3.302      5.287       6.64      2.062         17        640: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.85G       2.92      4.802      6.223      1.773         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.77G      3.038      4.591      6.108      1.837         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.96G       4.12      5.673      6.232       2.08         39        640: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 897.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      3.154      5.263      7.078      2.059         56        640: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.24G      3.355      5.069      6.518      2.004         80        640: 100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.2G      3.029      4.995      6.253      2.193        114        640: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.2G      2.877      4.683      6.097      1.931         86        640: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      3.301      4.894      5.899       2.08        164        640: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1026.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      2.844      4.248      7.526      1.657         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G      3.438      5.534       6.73      2.599         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      2.804      4.526      6.125      2.027         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.93G       3.05      4.919        6.4      2.306         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G      3.127      4.052      5.773       2.18         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 833.37it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      3.215      5.321      6.199       2.21         36        640: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.25G      3.178      5.031      6.459      2.236         14        640: 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.24G      3.348      5.195      6.206      2.333         18        640: 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      3.135      4.721      6.087      1.896         25        640: 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G      3.032      4.615      6.186      2.012         14        640: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93   0.000849     0.0215   0.000448   0.000156    0.00127     0.0323   0.000688   0.000158\n",
      "  cercospora-leaf-spot         28         93   0.000849     0.0215   0.000448   0.000156    0.00127     0.0323   0.000688   0.000158\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1073.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G      3.353      4.449      5.862      1.801         34        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110   0.000816     0.0182   0.000431   0.000129   0.000408    0.00909   0.000206   2.06e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G      3.654      4.231      7.452      1.845         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110   0.000412    0.00909   0.000222   6.67e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      4.483      5.286      15.65      2.031          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110   0.000412    0.00909   0.000221   6.63e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      3.104        3.9         11      1.158          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110   0.000419    0.00909   0.000224   6.72e-05   0.000419    0.00909   0.000212   2.12e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      2.458       4.89      7.715      1.355         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110   0.000422    0.00909   0.000224   6.71e-05   0.000422    0.00909   0.000213   2.13e-05\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110   0.000818     0.0182   0.000432    0.00013   0.000409    0.00909   0.000206   2.06e-05\n",
      "  cercospora-leaf-spot         28        110   0.000818     0.0182   0.000432    0.00013   0.000409    0.00909   0.000206   2.06e-05\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n",
      "                   all         28         93    0.00172      0.043   0.000983   0.000491    0.00215     0.0538    0.00128   0.000653\n",
      "  cercospora-leaf-spot         28         93    0.00172      0.043   0.000983   0.000491    0.00215     0.0538    0.00128   0.000653\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 781.32it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.01G      3.284      4.678      5.306      2.209         48        640: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110   0.000427    0.00909   0.000216   6.49e-05   0.000427    0.00909   0.000216   2.16e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         4G      3.124      4.772      5.852      2.343         38        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110   0.000427    0.00909   0.000216   6.49e-05   0.000427    0.00909   0.000216   2.16e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.86G      3.633      4.858      5.889      2.599         36        640: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110   0.000427    0.00909   0.000216   6.49e-05   0.000427    0.00909   0.000216   2.16e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G      3.703      5.017      5.488       2.59         38        640: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110   0.000438    0.00909   0.000263   2.63e-05   0.000438    0.00909   0.000263   2.63e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.87G       2.52      4.659      5.247      1.884         41        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110   0.000438    0.00909   0.000266   2.66e-05   0.000438    0.00909   0.000266   2.66e-05\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110   0.000438    0.00909   0.000266   2.66e-05   0.000438    0.00909   0.000266   2.66e-05\n",
      "  cercospora-leaf-spot         28        110   0.000438    0.00909   0.000266   2.66e-05   0.000438    0.00909   0.000266   2.66e-05\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         28         93   0.000975     0.0215   0.000592   0.000311   0.000975     0.0215   0.000527   0.000321\n",
      "  cercospora-leaf-spot         28         93   0.000975     0.0215   0.000592   0.000311   0.000975     0.0215   0.000527   0.000321\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 949.04it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G      3.363      5.338      6.299      2.288        102        640: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.48G      3.131      4.816      6.591      2.048         44        640: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.24G      3.321      5.038      6.192      2.014         79        640: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.32G      3.205      4.895      6.178      2.074         79        640: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G      2.984      4.385      5.582      1.791        116        640: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110    0.00044    0.00909   0.000223   8.92e-05    0.00132     0.0273   0.000729   0.000141\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110   0.000439    0.00909   0.000223   6.68e-05    0.00132     0.0273   0.000727   0.000141\n",
      "  cercospora-leaf-spot         28        110   0.000439    0.00909   0.000223   6.68e-05    0.00132     0.0273   0.000727   0.000141\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         28         93    0.00213     0.0538    0.00133   0.000425    0.00341      0.086     0.0021   0.000426\n",
      "  cercospora-leaf-spot         28         93    0.00213     0.0538    0.00133   0.000425    0.00341      0.086     0.0021   0.000426\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1030.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.45G        2.5      4.458       5.34      1.633         23        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110     0.0013     0.0273   0.000916   0.000197    0.00217     0.0455    0.00148   0.000222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G      2.997       4.43      6.086      1.665         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110    0.00132     0.0273   0.000916   0.000224     0.0022     0.0455    0.00149    0.00026\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G       3.38      4.343      6.938      1.839         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110    0.00132     0.0273   0.000948   0.000228    0.00219     0.0455    0.00153   0.000228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      2.678      4.006      6.849      1.293         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110    0.00133     0.0273   0.000958   0.000259    0.00222     0.0455    0.00154    0.00023\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.93G      3.014      4.151      6.403      1.667         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110    0.00135     0.0273   0.000998   0.000266    0.00224     0.0455    0.00159   0.000235\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110    0.00134     0.0273    0.00101   0.000267    0.00224     0.0455     0.0016   0.000236\n",
      "  cercospora-leaf-spot         28        110    0.00134     0.0273    0.00101   0.000267    0.00224     0.0455     0.0016   0.000236\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         28         93     0.0022     0.0538    0.00169    0.00052    0.00264     0.0645    0.00212   0.000513\n",
      "  cercospora-leaf-spot         28         93     0.0022     0.0538    0.00169    0.00052    0.00264     0.0645    0.00212   0.000513\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 916.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      3.001      4.686      7.423        1.9          6        640: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G       3.21      5.198      7.782      2.176          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      3.243      4.812      6.148      2.159         13        640: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G       3.02      4.667      5.643      1.985         18        640: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110   0.000392    0.00909   0.000352   3.52e-05   0.000392    0.00909   0.000309   9.28e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.33G      3.132      4.231      4.569      1.842         30        640: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110     0.0438    0.00909    0.00357    0.00103     0.0789     0.0182    0.00765    0.00126\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        110     0.0456    0.00909    0.00337    0.00093       0.08     0.0182    0.00763    0.00124\n",
      "  cercospora-leaf-spot         28        110     0.0456    0.00909    0.00337    0.00093       0.08     0.0182    0.00763    0.00124\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n",
      "                   all         28         93    0.00521       0.14     0.0112    0.00434    0.00682      0.183     0.0142    0.00401\n",
      "  cercospora-leaf-spot         28         93    0.00521       0.14     0.0112    0.00434    0.00682      0.183     0.0142    0.00401\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 767.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.56G      3.478      4.299      8.229      1.993         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110     0.0692    0.00909     0.0078    0.00147    0.00462      0.118    0.00574    0.00119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G      3.819      4.552      6.032      2.073         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110     0.0727    0.00909     0.0081    0.00184     0.0727    0.00909     0.0108    0.00169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.96G      3.417      4.038      4.698      1.945         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110     0.0743    0.00909    0.00798    0.00202     0.0743    0.00909     0.0107     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      3.115      4.069      6.779      2.029         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110     0.0831    0.00909    0.00785    0.00241     0.0831    0.00909     0.0101    0.00167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      3.361      4.718      5.838      1.591         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110     0.0925    0.00909    0.00848    0.00247     0.0925    0.00909     0.0101    0.00173\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        110     0.0925    0.00909    0.00846    0.00263     0.0925    0.00909     0.0101    0.00171\n",
      "  cercospora-leaf-spot         28        110     0.0925    0.00909    0.00846    0.00263     0.0925    0.00909     0.0101    0.00171\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.21it/s]\n",
      "                   all         28         93    0.00615      0.172     0.0117    0.00382    0.00807      0.226     0.0167    0.00446\n",
      "  cercospora-leaf-spot         28         93    0.00615      0.172     0.0117    0.00382    0.00807      0.226     0.0167    0.00446\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 793.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.02G      3.391      4.884      4.742      2.113         52        640: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110     0.0884     0.0182     0.0144    0.00431      0.144     0.0182     0.0127    0.00197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         4G      3.508      5.197      5.035      2.326         34        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110      0.106     0.0182     0.0179    0.00541      0.137     0.0182     0.0159     0.0022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      3.618      4.931      5.038       2.17         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.156     0.0273     0.0184    0.00576      0.162     0.0273     0.0166    0.00323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.85G      3.164      4.351      4.824      2.119         39        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.149     0.0273      0.019    0.00599      0.172     0.0273      0.017    0.00335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      3.069      4.494      4.872        1.6         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.187     0.0273     0.0191    0.00623      0.181     0.0273     0.0173    0.00351\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110      0.154     0.0273       0.02    0.00631      0.181     0.0273     0.0175    0.00353\n",
      "  cercospora-leaf-spot         28        110      0.154     0.0273       0.02    0.00631      0.181     0.0273     0.0175    0.00353\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n",
      "                   all         28         93     0.0692     0.0323     0.0134    0.00491     0.0923      0.043      0.017    0.00555\n",
      "  cercospora-leaf-spot         28         93     0.0692     0.0323     0.0134    0.00491     0.0923      0.043      0.017    0.00555\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 921.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5         4G      3.802       5.07      5.757       2.09         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         28        110      0.113     0.0364     0.0189    0.00584     0.0849     0.0273     0.0175    0.00308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G      3.123      4.362      4.913      2.073         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0884     0.0273      0.022    0.00733     0.0913     0.0273     0.0179    0.00367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.87G      3.277      4.283      4.933      2.176         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110     0.0978     0.0273     0.0227    0.00769     0.0978     0.0273     0.0189    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.97G      3.071      4.103      4.835      2.076         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110        0.1     0.0273     0.0245    0.00853        0.1     0.0273     0.0209    0.00474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.86G      3.142      4.687      5.292      1.986         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110     0.0939     0.0273     0.0237    0.00846      0.096     0.0273     0.0207    0.00458\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110     0.0999     0.0273     0.0245    0.00855     0.0999     0.0273      0.021    0.00475\n",
      "  cercospora-leaf-spot         28        110     0.0999     0.0273     0.0245    0.00855     0.0999     0.0273      0.021    0.00475\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                   all         28         93      0.112      0.043     0.0164    0.00443      0.141     0.0538     0.0257     0.0065\n",
      "  cercospora-leaf-spot         28         93      0.112      0.043     0.0164    0.00443      0.141     0.0538     0.0257     0.0065\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 778.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.99G      3.353      4.416      4.664       2.04         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        110     0.0973     0.0273      0.012    0.00323     0.0949     0.0273     0.0141    0.00287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G      4.016      4.147      5.849      2.587         24        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110     0.0945     0.0273     0.0117    0.00331     0.0924     0.0273     0.0152    0.00356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      3.428      4.306      5.135      2.293         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.114     0.0364     0.0136    0.00392      0.133     0.0419      0.017    0.00387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.85G      3.862      4.745       5.13      2.693         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        110     0.0838     0.0364      0.016    0.00486       0.11     0.0364     0.0163    0.00417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.87G      2.834      3.296      4.186      1.613         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110     0.0772     0.0364     0.0161    0.00516      0.101     0.0364     0.0169    0.00422\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110      0.075     0.0364     0.0168    0.00533      0.101     0.0364     0.0164    0.00415\n",
      "  cercospora-leaf-spot         28        110      0.075     0.0364     0.0168    0.00533      0.101     0.0364     0.0164    0.00415\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n",
      "                   all         28         93     0.0771      0.043     0.0125    0.00381     0.0931     0.0538     0.0205    0.00526\n",
      "  cercospora-leaf-spot         28         93     0.0771      0.043     0.0125    0.00381     0.0931     0.0538     0.0205    0.00526\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 841.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.45G       3.19      5.021      6.621      2.064         62        640: 100%|██████████| 5/5 [00:03<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      3.256      4.945      6.417      2.131         67        640: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      3.131      4.505      5.779      2.026         32        640: 100%|██████████| 5/5 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110    0.00133     0.0273     0.0011   0.000353    0.00177     0.0364    0.00385    0.00109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      2.831      4.155      4.488      1.733         39        640: 100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110     0.0654     0.0182     0.0336    0.00794     0.0671     0.0182     0.0288    0.00747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.947      4.074      4.312      1.917         40        640: 100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        110      0.121     0.0909     0.0575     0.0153      0.122      0.121     0.0588     0.0138\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110      0.149     0.0909     0.0579     0.0152      0.126      0.127      0.059      0.014\n",
      "  cercospora-leaf-spot         28        110      0.149     0.0909     0.0579     0.0152      0.126      0.127      0.059      0.014\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n",
      "                   all         28         93      0.163      0.151      0.103     0.0393       0.22      0.151      0.108     0.0426\n",
      "  cercospora-leaf-spot         28         93      0.163      0.151      0.103     0.0393       0.22      0.151      0.108     0.0426\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 910.89it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.46G      2.121      2.977      2.923      1.445         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110     0.0909      0.137     0.0493     0.0119     0.0899      0.136     0.0432      0.011\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         4G       2.48       3.62       3.48      1.691         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.093      0.136      0.052     0.0124       0.09      0.136     0.0474     0.0115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.02G      1.878      2.676      3.666      1.569         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.113      0.145     0.0535     0.0126     0.0942      0.136      0.049     0.0119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.93G      2.157      3.205      4.396      1.853         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.113      0.118      0.056     0.0137     0.0975      0.136     0.0481     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.97G      1.944      3.134      2.988      1.215         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.121      0.127     0.0585     0.0141     0.0932      0.136     0.0488     0.0126\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110       0.12      0.127     0.0582     0.0139     0.0995      0.136     0.0486     0.0126\n",
      "  cercospora-leaf-spot         28        110       0.12      0.127     0.0582     0.0139     0.0995      0.136     0.0486     0.0126\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93       0.15      0.194      0.097     0.0403      0.171      0.215      0.102     0.0433\n",
      "  cercospora-leaf-spot         28         93       0.15      0.194      0.097     0.0403      0.171      0.215      0.102     0.0433\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 932.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5         4G      2.855      4.228      5.648       1.42         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110     0.0774      0.173     0.0549     0.0142      0.077      0.182     0.0452     0.0117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.95G      2.529      3.566      4.644      1.442         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110     0.0894      0.155     0.0595     0.0152     0.0758      0.155      0.046      0.012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      3.034      3.494      3.835      1.877         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0961      0.145     0.0598     0.0153     0.0803      0.173     0.0475     0.0118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      2.832      3.841      4.576      1.746         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.113      0.155     0.0651     0.0165      0.091      0.155     0.0493     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.94G      1.669      2.332      3.835      1.188         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110      0.132      0.125      0.064     0.0168     0.0767      0.136     0.0497     0.0112\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.108      0.155     0.0637     0.0163     0.0897      0.155     0.0487     0.0121\n",
      "  cercospora-leaf-spot         28        110      0.108      0.155     0.0637     0.0163     0.0897      0.155     0.0487     0.0121\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         28         93      0.107      0.151     0.0736     0.0379      0.156      0.183      0.086      0.038\n",
      "  cercospora-leaf-spot         28         93      0.107      0.151     0.0736     0.0379      0.156      0.183      0.086      0.038\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 954.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.5G      2.919       4.98       5.87      1.979          8        640: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.64G      3.323      5.108      6.331      2.159          3        640: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.38G      3.175      4.323       5.57       1.91          4        640: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110     0.0181    0.00909    0.00759     0.0017     0.0128    0.00909    0.00613    0.00118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G      2.969       4.06      4.612      1.784          2        640: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0646        0.1     0.0315    0.00889      0.083      0.127     0.0343     0.0084\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.967      3.686      4.694      1.728          3        640: 100%|██████████| 6/6 [00:04<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.123      0.173     0.0797     0.0203     0.0988      0.145     0.0619     0.0174\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110       0.12      0.173     0.0799     0.0202     0.0984      0.145     0.0617     0.0174\n",
      "  cercospora-leaf-spot         28        110       0.12      0.173     0.0799     0.0202     0.0984      0.145     0.0617     0.0174\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         28         93      0.207      0.194      0.141     0.0382      0.204      0.226      0.118     0.0337\n",
      "  cercospora-leaf-spot         28         93      0.207      0.194      0.141     0.0382      0.204      0.226      0.118     0.0337\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 887.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.58G      2.878      4.299      4.418       2.31         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.102      0.145     0.0772     0.0197     0.0981      0.155     0.0755     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.99G      2.807      4.602      4.793      2.179         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110     0.0938      0.136     0.0826     0.0204     0.0994      0.145     0.0759     0.0167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G      3.089       4.37      3.768      1.427         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110      0.105      0.155      0.091     0.0224     0.0982      0.155     0.0818     0.0181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.96G      3.106      4.518      5.387      1.555         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.117      0.164     0.0932     0.0236      0.117      0.182     0.0885      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.93G      2.946      4.085      5.685      2.122         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.126      0.182     0.0949     0.0266      0.133      0.182     0.0891     0.0198\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.125      0.182     0.0967      0.027      0.131      0.182     0.0899     0.0198\n",
      "  cercospora-leaf-spot         28        110      0.125      0.182     0.0967      0.027      0.131      0.182     0.0899     0.0198\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93      0.123      0.183     0.0878     0.0306      0.153      0.204     0.0917     0.0241\n",
      "  cercospora-leaf-spot         28         93      0.123      0.183     0.0878     0.0306      0.153      0.204     0.0917     0.0241\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 826.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.46G      3.311      5.125      6.383      2.076         40        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      3.293       5.13       6.24      1.996         47        640: 100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110   0.000413    0.00909   0.000208   4.16e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      2.847      4.242      4.868      1.773         43        640: 100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0561     0.0545     0.0171    0.00416     0.0641     0.0636     0.0219     0.0049\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.38G        2.9      4.037      4.112      1.885         33        640: 100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0859      0.127     0.0602     0.0159     0.0798      0.118     0.0505     0.0126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G      2.759      3.746      3.464      1.681         37        640: 100%|██████████| 6/6 [00:04<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.126      0.227     0.0957     0.0281      0.121        0.2     0.0846     0.0192\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.126      0.227     0.0965     0.0282      0.122      0.205     0.0851     0.0194\n",
      "  cercospora-leaf-spot         28        110      0.126      0.227     0.0965     0.0282      0.122      0.205     0.0851     0.0194\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93      0.267      0.247      0.182     0.0605       0.21      0.247      0.175     0.0544\n",
      "  cercospora-leaf-spot         28         93      0.267      0.247      0.182     0.0605       0.21      0.247      0.175     0.0544\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 873.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.34G      2.936      3.176      3.188      1.294         43        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        110      0.195      0.155     0.0909     0.0247      0.134      0.182     0.0811     0.0175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.96G      2.426      3.519      3.553      1.434         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.136      0.245     0.0976     0.0269      0.125        0.2     0.0827     0.0182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.86G       2.73      3.598      2.886      1.522         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.127        0.2      0.097     0.0276      0.116      0.182     0.0795     0.0181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.94G      3.022      4.347      3.433        1.7         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110       0.18      0.155      0.103     0.0284      0.133      0.182     0.0828     0.0191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.96G      2.071       3.29      2.355      1.275         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.177      0.155      0.101     0.0274      0.125      0.182     0.0863      0.019\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110      0.191      0.164      0.103     0.0279      0.137      0.182     0.0831     0.0193\n",
      "  cercospora-leaf-spot         28        110      0.191      0.164      0.103     0.0279      0.137      0.182     0.0831     0.0193\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93      0.281      0.226      0.153     0.0551      0.255      0.204      0.149      0.046\n",
      "  cercospora-leaf-spot         28         93      0.281      0.226      0.153     0.0551      0.255      0.204      0.149      0.046\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 961.89it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      3.164      5.014      6.547       2.01         45        640: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      3.332      4.928      6.353      2.128         60        640: 100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      3.084      4.524      5.044      1.936         51        640: 100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110     0.0554     0.0182       0.02    0.00541     0.0831     0.0273     0.0175    0.00425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G       2.83      4.162      3.976      1.804         73        640: 100%|██████████| 6/6 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.116      0.127     0.0673     0.0203     0.0991      0.109     0.0536     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.658      3.761      3.684      1.741         71        640: 100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.153      0.174      0.108     0.0325      0.145      0.164     0.0976     0.0255\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.155      0.176      0.106     0.0322      0.155      0.176     0.0962     0.0254\n",
      "  cercospora-leaf-spot         28        110      0.155      0.176      0.106     0.0322      0.155      0.176     0.0962     0.0254\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         28         93       0.25      0.312      0.203      0.076      0.357      0.215      0.198     0.0686\n",
      "  cercospora-leaf-spot         28         93       0.25      0.312      0.203      0.076      0.357      0.215      0.198     0.0686\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 990.48it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.61G      2.327      3.737      3.231       1.58         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        110      0.164        0.2      0.107     0.0311      0.155      0.173     0.0818     0.0213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.94G      2.688      3.531      4.162      1.737         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.168      0.227       0.11     0.0313      0.175      0.191     0.0936     0.0224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.94G          2      3.543      3.576      1.877         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.167      0.227      0.112     0.0305      0.151        0.2     0.0838      0.021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.95G      2.588      3.203      3.824      1.958         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.158      0.218      0.112     0.0308      0.144        0.2     0.0819     0.0209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.93G      2.114      3.343      4.212      1.704         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         28        110      0.139      0.264      0.103     0.0296       0.12      0.227     0.0836     0.0222\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110      0.168      0.227       0.11     0.0318      0.175      0.191     0.0945     0.0225\n",
      "  cercospora-leaf-spot         28        110      0.168      0.227       0.11     0.0318      0.175      0.191     0.0945     0.0225\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n",
      "                   all         28         93      0.271      0.237      0.156     0.0602       0.25      0.226      0.141     0.0526\n",
      "  cercospora-leaf-spot         28         93      0.271      0.237      0.156     0.0602       0.25      0.226      0.141     0.0526\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 840.21it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G      3.084      5.044      6.542      2.135         93        640: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.23G      3.194      4.933      6.249      2.023         98        640: 100%|██████████| 6/6 [00:05<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110   0.000415    0.00909   0.000244   2.44e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G      2.876      4.187      4.886      1.795         78        640: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        110     0.0567     0.0455     0.0198    0.00572     0.0699     0.0545     0.0207    0.00476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      2.831      3.755      3.904      1.792         90        640: 100%|██████████| 6/6 [00:04<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.132      0.136     0.0681     0.0173      0.105      0.109     0.0563     0.0132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.32G      2.638      3.681      3.494      1.671         59        640: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.194      0.145      0.117     0.0345      0.118      0.136      0.105     0.0238\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.188      0.145      0.117     0.0348      0.124      0.145      0.105     0.0243\n",
      "  cercospora-leaf-spot         28        110      0.188      0.145      0.117     0.0348      0.124      0.145      0.105     0.0243\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93      0.411      0.204       0.21     0.0736      0.278      0.237      0.195     0.0656\n",
      "  cercospora-leaf-spot         28         93      0.411      0.204       0.21     0.0736      0.278      0.237      0.195     0.0656\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 801.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.4G      3.279      3.982      4.212      2.342         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         28        110      0.144      0.164      0.109     0.0302      0.136      0.191      0.101     0.0226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.97G       2.75      3.457      3.073      1.861         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.152      0.164      0.111     0.0309      0.107      0.182      0.095     0.0215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5         4G      2.857      3.893      3.286      1.845         30        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.163      0.164      0.115     0.0314     0.0978      0.173      0.097     0.0213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G      2.355        3.1      2.755      1.587         34        640: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.153      0.164      0.115     0.0321     0.0992      0.173     0.0964     0.0217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.02G      3.034      4.159      2.971      1.856         48        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.173      0.173      0.114     0.0315      0.099      0.182     0.0953     0.0213\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.154      0.164      0.115     0.0321     0.0997      0.173     0.0963     0.0215\n",
      "  cercospora-leaf-spot         28        110      0.154      0.164      0.115     0.0321     0.0997      0.173     0.0963     0.0215\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "                   all         28         93      0.279      0.237      0.175     0.0532      0.263      0.258      0.162     0.0443\n",
      "  cercospora-leaf-spot         28         93      0.279      0.237      0.175     0.0532      0.263      0.258      0.162     0.0443\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 925.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G       3.26      5.027      6.806      2.003         30        640: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.32G      3.236      4.812      5.946      2.233         19        640: 100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110    0.00109     0.0273    0.00128   0.000496    0.00182     0.0455    0.00243   0.000519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G       3.02      4.267      4.666      1.819         22        640: 100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110     0.0866      0.127     0.0594     0.0172       0.12     0.0909     0.0449     0.0107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.33G      2.795      3.825      3.846      1.734         23        640: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.214      0.173      0.117     0.0371      0.209      0.155      0.108     0.0279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G      2.448      3.561      3.101      1.546         45        640: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.229      0.227      0.196     0.0634       0.18      0.327      0.176     0.0533\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.208      0.309      0.198     0.0638       0.18      0.327      0.177     0.0537\n",
      "  cercospora-leaf-spot         28        110      0.208      0.309      0.198     0.0638       0.18      0.327      0.177     0.0537\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         28         93      0.409      0.355      0.343       0.12      0.322      0.355      0.292      0.109\n",
      "  cercospora-leaf-spot         28         93      0.409      0.355      0.343       0.12      0.322      0.355      0.292      0.109\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 828.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.99G      2.911      3.933      3.333      1.639         67        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.252      0.327      0.214      0.067      0.232        0.3      0.176     0.0571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G       2.55      3.283      3.045      1.449         60        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110       0.26      0.336      0.216     0.0676      0.244        0.3      0.171     0.0565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      3.059      3.846      3.351      1.572         84        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        110       0.25      0.355      0.222     0.0668      0.232      0.324      0.174      0.056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      3.044      3.712      3.816      1.935         49        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.263      0.382      0.222      0.068      0.276      0.309      0.178     0.0583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      3.039      3.482      3.254      1.796         58        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.271      0.409      0.226     0.0667      0.277      0.309      0.179     0.0578\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.266      0.389      0.221     0.0677      0.242      0.355      0.174     0.0579\n",
      "  cercospora-leaf-spot         28        110      0.266      0.389      0.221     0.0677      0.242      0.355      0.174     0.0579\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "                   all         28         93      0.365      0.389      0.312      0.103      0.283      0.376       0.27     0.0899\n",
      "  cercospora-leaf-spot         28         93      0.365      0.389      0.312      0.103      0.283      0.376       0.27     0.0899\n",
      "Speed: 0.3ms preprocess, 15.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 950.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.21G      3.174      5.184      6.735      1.947         99        640: 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.22G      3.203      4.701      5.869      1.963         92        640: 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110      0.261    0.00909    0.00506   0.000942      0.154     0.0182    0.00937    0.00153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.33G      2.872      4.058      4.337      1.781        101        640: 100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.114      0.173     0.0676     0.0171      0.114      0.173     0.0592     0.0133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      2.654      3.606      3.286      1.618         91        640: 100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.145      0.264      0.124     0.0376      0.128      0.245      0.106     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.421      3.409      3.005      1.536         87        640: 100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110       0.21      0.289      0.168     0.0556      0.223        0.3      0.176     0.0496\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110      0.206      0.281      0.167     0.0559      0.225        0.3      0.176     0.0499\n",
      "  cercospora-leaf-spot         28        110      0.206      0.281      0.167     0.0559      0.225        0.3      0.176     0.0499\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      "                   all         28         93      0.358      0.355       0.28      0.119      0.346      0.344      0.244     0.0935\n",
      "  cercospora-leaf-spot         28         93      0.358      0.355       0.28      0.119      0.346      0.344      0.244     0.0935\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 725.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.98G      2.251      3.269      2.117      1.305         79        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        110       0.22      0.364      0.155     0.0499      0.214      0.273      0.178      0.048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G       2.46      3.477      2.585      1.365         66        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.239      0.382      0.166     0.0517      0.221      0.273      0.178     0.0503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      2.633      3.505      2.732      1.463         88        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.231      0.355      0.164     0.0509      0.255      0.318        0.2     0.0519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      2.528       2.88      2.777      1.503         46        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.232      0.376       0.16     0.0499      0.244      0.345      0.179     0.0497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G       2.61      3.423        2.6      1.522         47        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.229      0.379      0.158     0.0496      0.237      0.352      0.177     0.0499\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110       0.23      0.355      0.163     0.0508      0.254      0.318      0.201     0.0522\n",
      "  cercospora-leaf-spot         28        110       0.23      0.355      0.163     0.0508      0.254      0.318      0.201     0.0522\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n",
      "                   all         28         93      0.307      0.366      0.267     0.0972      0.288      0.323      0.222     0.0858\n",
      "  cercospora-leaf-spot         28         93      0.307      0.366      0.267     0.0972      0.288      0.323      0.222     0.0858\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 914.96it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G      3.078       4.93      6.104      2.006         45        640: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G       3.16      4.594      5.516      1.984         63        640: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110     0.0554     0.0455      0.021    0.00544     0.0544     0.0455       0.02    0.00543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.34G      2.828      3.911      3.936      1.756         52        640: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.143      0.214     0.0977     0.0296      0.128      0.191     0.0904     0.0241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G       2.59      3.574      3.108      1.576         56        640: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.195      0.364      0.174     0.0596      0.195      0.364      0.169     0.0564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.396       3.29      2.717      1.436         48        640: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110       0.26      0.364      0.217     0.0825      0.282      0.373      0.221     0.0789\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.248      0.391      0.215     0.0819      0.281      0.373      0.222     0.0791\n",
      "  cercospora-leaf-spot         28        110      0.248      0.391      0.215     0.0819      0.281      0.373      0.222     0.0791\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n",
      "                   all         28         93      0.406      0.484      0.408      0.163      0.378      0.471       0.37      0.156\n",
      "  cercospora-leaf-spot         28         93      0.406      0.484      0.408      0.163      0.378      0.471       0.37      0.156\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 909.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.66G      2.491      3.364      2.792       1.44         73        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        110      0.235      0.373      0.223     0.0808      0.252      0.418      0.229      0.068\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      2.579        3.5      2.544      1.585         56        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.243      0.382      0.234     0.0805      0.238        0.4      0.235     0.0701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      2.772      3.664      2.952      1.475         74        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.247      0.373      0.225     0.0809      0.262      0.427      0.245     0.0741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      2.622      3.304      2.459      1.722         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.264        0.4      0.228     0.0825      0.286      0.427      0.261     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      2.731      3.832      2.942      1.785         65        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.262      0.382       0.23     0.0845      0.277        0.4      0.257     0.0803\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.266        0.4      0.232     0.0859      0.293        0.4      0.258     0.0785\n",
      "  cercospora-leaf-spot         28        110      0.266        0.4      0.232     0.0859      0.293        0.4      0.258     0.0785\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                   all         28         93      0.531      0.355      0.411       0.16      0.394      0.387      0.387      0.159\n",
      "  cercospora-leaf-spot         28         93      0.531      0.355      0.411       0.16      0.394      0.387      0.387      0.159\n",
      "Speed: 0.2ms preprocess, 15.5ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 891.82it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.91G      2.692      3.854      2.743      1.883         85        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        110      0.249      0.318      0.211     0.0741      0.226      0.455      0.213     0.0599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.01G      2.497      3.867      2.872       1.82         43        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.294      0.291      0.219     0.0768      0.239      0.445      0.225     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      2.282      3.547      2.202      1.468         74        640: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.293      0.291      0.217     0.0781      0.244      0.418      0.227     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G      2.585      3.754      3.006      2.003         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.309      0.285      0.223     0.0776      0.318      0.318      0.252     0.0676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      2.626      3.959      3.097      1.871         64        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.307        0.3      0.229     0.0807      0.316      0.309       0.23     0.0675\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        110      0.305      0.303      0.229     0.0813      0.311      0.309      0.229      0.067\n",
      "  cercospora-leaf-spot         28        110      0.305      0.303      0.229     0.0813      0.311      0.309      0.229      0.067\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                   all         28         93      0.505      0.355      0.414      0.162      0.555      0.344      0.405      0.153\n",
      "  cercospora-leaf-spot         28         93      0.505      0.355      0.414      0.162      0.555      0.344      0.405      0.153\n",
      "Speed: 0.2ms preprocess, 15.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:00<00:00, 956.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G       3.16      5.117      6.467      2.069         65        640: 100%|██████████| 9/9 [00:07<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.6G      3.103      4.499      5.151      1.964         82        640: 100%|██████████| 9/9 [00:07<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110     0.0827     0.0727     0.0302    0.00749     0.0968     0.0818     0.0344    0.00828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.4G      2.736      3.773      3.429       1.73         74        640: 100%|██████████| 9/9 [00:07<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.214      0.218      0.168     0.0516      0.201      0.213      0.161     0.0475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G      2.437      3.329      2.787      1.494         68        640: 100%|██████████| 9/9 [00:07<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.214      0.382      0.215     0.0781        0.3       0.32      0.239     0.0798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      2.368      3.223      2.464      1.464         85        640: 100%|██████████| 9/9 [00:07<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.282      0.454      0.259     0.0883      0.268      0.436      0.246      0.078\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.286      0.445       0.26     0.0884      0.261      0.427      0.241     0.0775\n",
      "  cercospora-leaf-spot         28        110      0.286      0.445       0.26     0.0884      0.261      0.427      0.241     0.0775\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                   all         28         93      0.575      0.484      0.495      0.181      0.493       0.45      0.431      0.175\n",
      "  cercospora-leaf-spot         28         93      0.575      0.484      0.495      0.181      0.493       0.45      0.431      0.175\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 871.85it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.98G      2.378      2.922      2.722      1.289         41        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         28        110      0.278      0.327      0.233     0.0841       0.29      0.336      0.248     0.0789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      2.339      2.634       2.92      1.272         51        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.292      0.373      0.239      0.087      0.305      0.391      0.259     0.0782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      2.522      2.786      2.405      1.237         53        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.291      0.382      0.248     0.0889      0.297      0.409      0.263     0.0804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      2.354      2.907       2.94       1.37         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.303      0.373      0.255     0.0893      0.307      0.382      0.262     0.0814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      2.409      2.918      2.796       1.32         46        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.314      0.391      0.258     0.0881        0.3      0.391      0.256     0.0807\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110      0.311      0.373      0.259     0.0906      0.305      0.382      0.261     0.0814\n",
      "  cercospora-leaf-spot         28        110      0.311      0.373      0.259     0.0906      0.305      0.382      0.261     0.0814\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]\n",
      "                   all         28         93      0.499      0.481       0.45      0.159      0.444      0.481      0.401      0.143\n",
      "  cercospora-leaf-spot         28         93      0.499      0.481       0.45      0.159      0.444      0.481      0.401      0.143\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:00<00:00, 814.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.19G      3.155      5.013       6.59      1.964         31        640: 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G      2.943      4.331      4.898       1.97         38        640: 100%|██████████| 10/10 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.108     0.0971     0.0471     0.0139      0.132      0.118     0.0591     0.0132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G       2.62      3.639      3.283      1.631         57        640: 100%|██████████| 10/10 [00:07<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.196      0.364      0.175     0.0697      0.203      0.364      0.169      0.057\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G      2.446      3.416      2.862      1.501         33        640: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110      0.256      0.582       0.28     0.0954        0.3      0.455      0.274     0.0914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.38G      2.344      3.077       2.48      1.421         47        640: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.284      0.409      0.272     0.0908      0.226      0.452      0.208     0.0708\n",
      "\n",
      "5 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110      0.252      0.582      0.284     0.0973      0.293      0.455       0.27     0.0903\n",
      "  cercospora-leaf-spot         28        110      0.252      0.582      0.284     0.0973      0.293      0.455       0.27     0.0903\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         28         93      0.588      0.505      0.528      0.207      0.675      0.387      0.492      0.218\n",
      "  cercospora-leaf-spot         28         93      0.588      0.505      0.528      0.207      0.675      0.387      0.492      0.218\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 871.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.62G      2.223      3.102      2.255      1.309         89        640: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         28        110      0.251      0.518      0.229      0.085      0.228      0.527      0.205     0.0718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      2.364      3.391      3.146      1.854         33        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.245      0.482      0.232     0.0857      0.219      0.459      0.206     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      2.318      2.898      2.581      1.445         48        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110       0.27      0.447      0.239     0.0858      0.237      0.382      0.209     0.0711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      2.448      3.008      3.259      1.364         26        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.284      0.455      0.241     0.0873      0.254      0.391      0.213     0.0722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      2.159      3.346      2.887      1.385         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110       0.29      0.445      0.241     0.0872      0.243      0.418      0.211     0.0701\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110       0.29      0.464      0.244     0.0867      0.256       0.41      0.211     0.0701\n",
      "  cercospora-leaf-spot         28        110       0.29      0.464      0.244     0.0867      0.256       0.41      0.211     0.0701\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93      0.533      0.527      0.502      0.207      0.773      0.366      0.474      0.193\n",
      "  cercospora-leaf-spot         28         93      0.533      0.527      0.502      0.207      0.773      0.366      0.474      0.193\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:00<00:00, 868.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.24G      3.065      4.787      6.349      1.981          2        640: 100%|██████████| 11/11 [00:08<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        110          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.36G      2.986      4.304      4.741      1.885          6        640: 100%|██████████| 11/11 [00:08<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.126      0.209     0.0704     0.0208      0.093      0.155     0.0519     0.0143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.39G      2.346      3.234      3.786      1.425          0        640: 100%|██████████| 11/11 [00:08<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                   all         28        110      0.297      0.288      0.218     0.0789      0.258      0.253       0.18     0.0574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.36G      2.329      3.143      2.577      1.365          7        640: 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         28        110      0.315        0.4      0.267     0.0948      0.318        0.4      0.255     0.0822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.37G      2.236      2.939       2.35       1.34          3        640: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.271      0.473      0.265      0.086      0.265      0.472      0.246     0.0744\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110      0.315        0.4      0.268     0.0952      0.317        0.4      0.256      0.082\n",
      "  cercospora-leaf-spot         28        110      0.315        0.4      0.268     0.0952      0.317        0.4      0.256      0.082\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "                   all         28         93      0.573      0.505       0.51      0.216      0.521      0.462      0.454      0.195\n",
      "  cercospora-leaf-spot         28         93      0.573      0.505       0.51      0.216      0.521      0.462      0.454      0.195\n",
      "Speed: 0.2ms preprocess, 15.7ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 902.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.91G      2.317      3.088      2.431      1.338         92        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.328      0.464      0.287     0.0947       0.33      0.464      0.272     0.0891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.866      2.723      1.899      1.191         63        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110       0.32      0.473       0.28     0.0926      0.313       0.39      0.276     0.0879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G      1.922      2.524      2.154      1.182         76        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.307      0.462       0.28     0.0961      0.315      0.418      0.276     0.0873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.03G      1.601      2.476       2.48      1.208         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.302      0.455      0.289     0.0969      0.294      0.455      0.275     0.0871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.03G      1.885      2.491      2.729      1.283         35        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110        0.3      0.455      0.283     0.0968      0.315      0.455      0.281     0.0841\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.302      0.455      0.288     0.0961      0.294      0.455      0.273     0.0867\n",
      "  cercospora-leaf-spot         28        110      0.302      0.455      0.288     0.0961      0.294      0.455      0.273     0.0867\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.04it/s]\n",
      "                   all         28         93       0.46      0.462      0.444      0.181       0.43      0.441      0.413      0.178\n",
      "  cercospora-leaf-spot         28         93       0.46      0.462      0.444      0.181       0.43      0.441      0.413      0.178\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<00:00, 888.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.24G      3.115      4.926      6.179       1.99         48        640: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110   0.000397    0.00909   0.000202   2.02e-05   0.000397    0.00909   0.000202   2.02e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G      2.788      4.006      4.194      1.813         58        640: 100%|██████████| 11/11 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        110      0.105      0.155      0.064     0.0137      0.105      0.155     0.0538     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      2.535      3.479       3.03      1.558         85        640: 100%|██████████| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.302      0.161      0.198     0.0684      0.267      0.143      0.186     0.0647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.34G       2.24      3.058      2.511       1.44         68        640: 100%|██████████| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.286      0.482        0.3      0.103      0.273      0.467      0.266     0.0853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.35G      2.193      2.995      2.333      1.346         52        640: 100%|██████████| 11/11 [00:09<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.312      0.495      0.327      0.103      0.318      0.467        0.3     0.0945\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        110      0.314      0.473      0.329      0.104      0.314      0.461        0.3     0.0939\n",
      "  cercospora-leaf-spot         28        110      0.314      0.473      0.329      0.104      0.314      0.461        0.3     0.0939\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n",
      "                   all         28         93      0.571      0.559      0.531      0.207      0.541      0.495      0.461      0.209\n",
      "  cercospora-leaf-spot         28         93      0.571      0.559      0.531      0.207      0.541      0.495      0.461      0.209\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 936.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.08G      2.368      2.929      2.939      1.365         51        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.297        0.5      0.337      0.109      0.291      0.482      0.282     0.0924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.03G      2.147      2.907      2.443      1.312         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.284      0.491      0.338      0.109      0.315      0.464      0.298     0.0966\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.01G      2.208      2.658       2.16      1.247         78        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.281      0.494      0.327      0.107       0.32      0.445      0.305     0.0966\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G      2.201       3.49      2.397      1.514         54        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.288      0.509      0.326      0.106      0.302      0.445      0.305     0.0965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      1.861        2.8      2.423      1.229         46        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.291      0.518      0.329      0.106      0.292      0.445      0.305     0.0961\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110      0.295      0.491      0.336      0.108      0.302      0.473      0.296     0.0953\n",
      "  cercospora-leaf-spot         28        110      0.295      0.491      0.336      0.108      0.302      0.473      0.296     0.0953\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         28         93      0.493      0.527      0.457      0.185      0.531      0.473      0.428      0.186\n",
      "  cercospora-leaf-spot         28         93      0.493      0.527      0.457      0.185      0.531      0.473      0.428      0.186\n",
      "Speed: 0.2ms preprocess, 15.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:00<00:00, 925.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.25G      3.041      5.065      6.238      1.954         37        640: 100%|██████████| 12/12 [00:09<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110   0.000347    0.00909   0.000176   3.51e-05   0.000347    0.00909   0.000176   1.76e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.33G      2.832      4.005      4.173      1.782         31        640: 100%|██████████| 12/12 [00:09<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110       0.27     0.0727     0.0774     0.0243       0.27     0.0727     0.0774     0.0236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G       2.46      3.347       2.91      1.511         24        640: 100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.249      0.464      0.263      0.085      0.246      0.555      0.256     0.0881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.36G      2.251      3.011      2.517      1.409         20        640: 100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.337      0.409      0.331     0.0982      0.402      0.327      0.314     0.0895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.36G      2.109      2.938      2.314      1.358         12        640: 100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.373      0.535      0.379      0.145      0.362      0.527      0.369      0.136\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        110      0.371      0.535      0.379      0.144      0.357      0.527      0.369      0.136\n",
      "  cercospora-leaf-spot         28        110      0.371      0.535      0.379      0.144      0.357      0.527      0.369      0.136\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         28         93      0.654      0.609      0.593      0.241      0.598      0.581      0.533      0.227\n",
      "  cercospora-leaf-spot         28         93      0.654      0.609      0.593      0.241      0.598      0.581      0.533      0.227\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 981.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.16G      1.923      2.488      2.018       1.18         49        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.436      0.509      0.391      0.137      0.429      0.509      0.362      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.02G      1.927      2.519      2.172      1.293         57        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.449      0.518      0.407      0.139      0.436      0.512       0.37      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.03G      2.117      2.671      2.061      1.279         70        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.447      0.521      0.405      0.141      0.436      0.519      0.369      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      2.097      2.479      2.072      1.422         51        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.444        0.5      0.397      0.138      0.423      0.514      0.364      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G      2.177      2.835      2.243      1.278         58        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.449      0.518      0.399       0.14      0.429      0.527      0.369      0.134\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110      0.446      0.519      0.405       0.14      0.436      0.518       0.37      0.135\n",
      "  cercospora-leaf-spot         28        110      0.446      0.519      0.405       0.14      0.436      0.518       0.37      0.135\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
      "                   all         28         93      0.635      0.581      0.596      0.247      0.562      0.548      0.547      0.236\n",
      "  cercospora-leaf-spot         28         93      0.635      0.581      0.596      0.247      0.562      0.548      0.547      0.236\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 992.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.91G      2.028      2.879      2.017      1.297         99        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.432      0.527      0.408      0.128       0.39        0.5      0.346      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.01G      1.989      2.709      2.109      1.324         57        640: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.422      0.527      0.404       0.13        0.4      0.518      0.346      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.02G       2.17      2.797      1.984      1.224         89        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.431      0.518      0.397      0.134      0.413      0.518      0.352      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G      2.031      2.765      2.757      1.321         29        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        110      0.426      0.518      0.388      0.135      0.417      0.509      0.351       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.02G      1.946      2.713      2.073       1.31         43        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.437      0.527      0.395      0.137      0.415      0.518       0.35      0.132\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        110      0.426      0.521      0.389      0.136      0.405      0.521       0.35      0.132\n",
      "  cercospora-leaf-spot         28        110      0.426      0.521      0.389      0.136      0.405      0.521       0.35      0.132\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "                   all         28         93      0.633      0.556      0.575      0.245      0.554       0.57      0.559      0.234\n",
      "  cercospora-leaf-spot         28         93      0.633      0.556      0.575      0.245      0.554       0.57      0.559      0.234\n",
      "Speed: 0.3ms preprocess, 15.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<00:00, 841.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.59G       3.18      4.898      6.258      1.969         49        640: 100%|██████████| 13/13 [00:10<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110     0.0619    0.00909    0.00371   0.000619     0.0606    0.00909    0.00499   0.000689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G      2.688      3.829      3.693      1.705         36        640: 100%|██████████| 13/13 [00:10<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110      0.192      0.336      0.193     0.0703      0.263      0.309        0.2     0.0652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.51G      2.332      3.219      2.779      1.459         43        640: 100%|██████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.291      0.391      0.294     0.0963      0.272        0.4      0.269      0.094\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.45G      2.213      2.934      2.292      1.374         47        640: 100%|██████████| 13/13 [00:10<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         28        110      0.409      0.391      0.297     0.0913      0.298      0.473      0.279     0.0781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.49G      2.104      2.787      2.146      1.306         52        640: 100%|██████████| 13/13 [00:10<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        110      0.426      0.373      0.367      0.137      0.421      0.373      0.327      0.101\n",
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110      0.431      0.373      0.367      0.137      0.416      0.373      0.327      0.101\n",
      "  cercospora-leaf-spot         28        110      0.431      0.373      0.367      0.137      0.416      0.373      0.327      0.101\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "                   all         28         93      0.536      0.591      0.554      0.216      0.521      0.484      0.453      0.198\n",
      "  cercospora-leaf-spot         28         93      0.536      0.591      0.554      0.216      0.521      0.484      0.453      0.198\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/temp_1_37/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 940.14it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/temp_1_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.93G      1.951      2.581      1.821      1.202         66        640: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110       0.49      0.355      0.389      0.134      0.409      0.409      0.327     0.0994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.87G      2.028      2.705      2.049      1.258         34        640: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.496      0.364      0.379      0.129      0.413      0.364      0.322     0.0994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.86G      2.016      2.602      1.944      1.276         65        640: 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.442      0.382      0.389      0.131      0.443      0.373      0.349      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      8.97G      2.012      2.604      1.982      1.222         56        640: 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        110      0.427        0.4      0.387      0.137       0.46      0.418      0.378      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.96G      1.995       2.55      1.912      1.285         57        640: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.342      0.545       0.39      0.143      0.448      0.391       0.37      0.109\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        110       0.35      0.545      0.392      0.142      0.466      0.391       0.37      0.109\n",
      "  cercospora-leaf-spot         28        110       0.35      0.545      0.392      0.142      0.466      0.391       0.37      0.109\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n",
      "                   all         28         93      0.567      0.581      0.572      0.235      0.634      0.504      0.547      0.221\n",
      "  cercospora-leaf-spot         28         93      0.567      0.581      0.572      0.235      0.634      0.504      0.547      0.221\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.5 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/affected-leaves-initialD-16/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5163077  ultralytics.nn.modules.head.Segment          [7, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27243701 parameters, 27243685 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/retrain/train/labels... 226 images, 0 backgrounds, 0 corrupt: 100%|██████████| 226/226 [00:00<00:00, 910.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/affected-leaves-initialD-16/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.32G       3.17      4.818      6.222       1.98         10        640: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        110     0.0837     0.0182     0.0143    0.00455      0.128     0.0273     0.0226    0.00451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.45G      2.624      3.614      3.353      1.632         19        640: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        110      0.219        0.3      0.222     0.0795      0.297      0.255      0.205     0.0716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      2.255      3.079      2.606      1.397         22        640: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         28        110      0.344      0.518      0.321      0.108      0.375      0.509      0.341     0.0984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G      2.049      2.809      2.277      1.268         12        640: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.574      0.473      0.491      0.189       0.58      0.482      0.501      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G      1.964      2.706      2.004      1.233          6        640: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        110      0.665      0.505      0.555      0.219      0.598      0.501      0.566      0.219\n",
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        110      0.663      0.502      0.555      0.219       0.63        0.5      0.566      0.219\n",
      "  cercospora-leaf-spot         28        110      0.663      0.502      0.555      0.219       0.63        0.5      0.566      0.219\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/affected-leaves-initialD-16/test_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "                   all         28         93      0.736      0.629      0.678      0.288      0.697      0.624      0.645      0.264\n",
      "  cercospora-leaf-spot         28         93      0.736      0.629      0.678      0.288      0.697      0.624      0.645      0.264\n",
      "Speed: 0.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 1: \n",
      " defaultdict(<class 'list'>, {0: [0.0, 0.0, 0.0], 1: [0.0, 0.0, 0.0], 2: [0.0, 0.0, 0.0], 3: [0.0, 0.0, 0.0], 4: [0.0, 0.0, 0.0], 5: [0.0, 0.0, 0.0], 6: [0.0, 0.0, 0.0], 7: [0.0, 0.0, 0.0], 8: [0.0, 0.0, 0.0], 9: [0.0, 0.0, 0.0], 10: [0.0, 0.0, 0.0], 11: [0.0, 0.0, 0.0], 12: [0.00015844923286182215, 0.000688008463369479, 0.0], 13: [0.0006532552116001077, 0.0012843513929410265, 0.00048505007863998786], 14: [0.00042610198971729067, 0.002095773734792598, 0.0], 15: [0.004007478025481107, 0.014217881080283575, 0.0022004274891766857], 16: [0.004459147111511376, 0.016670003919221327, 0.0018588145459522843], 17: [0.005546865374332492, 0.017016001157471785, 0.001722505099880844], 18: [0.006495554216696206, 0.025735163148638246, 0.0022534123628158717], 19: [0.04255971643712573, 0.10785086596745938, 0.03205963495362801], 20: [0.04327972743149072, 0.10180933522492469, 0.03102891711282448], 21: [0.033650222665225285, 0.1181388428540453, 0.007835410758422737], 22: [0.05435934336324497, 0.17468598326747042, 0.006977608944529326], 23: [0.06861012102788956, 0.1981185897772628, 0.016186281000918477], 24: [0.06555054280446712, 0.1952153240902184, 0.027000463073533196], 25: [0.10927871996448142, 0.2920610203228904, 0.03800317502460836], 26: [0.09348393502991245, 0.24443504453966386, 0.04672665832276973], 27: [0.15564750783038866, 0.3700306083090037, 0.07872053774341001], 28: [0.15937710279830486, 0.386851746013532, 0.0953884678313101], 29: [0.1752196818372107, 0.43095759778011405, 0.10332245781006627], 30: [0.21795576105879494, 0.491901367108948, 0.11486313747811046], 31: [0.19461019286448233, 0.45406309722302995, 0.1361974609378288], 32: [0.2090394387260101, 0.4608686741520203, 0.14959068198584535], 33: [0.22727280769951452, 0.532706416679543, 0.13138154462080665], 34: [0.23609528493973136, 0.5472513544590066, 0.15152229672801365], 35: [0.19765410217776744, 0.4529746083025074, 0.14011638839874802], 36: [0.26421903775162486, 0.6454439749444443, 0.16292332724023592]})\n",
      "Количество данных (train) для класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 226]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/affected-leaves-initialD-16/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('1', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1ac7a",
   "metadata": {
    "papermill": {
     "duration": 0.824941,
     "end_time": "2024-01-25T10:48:19.556979",
     "exception": false,
     "start_time": "2024-01-25T10:48:18.732038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb1200",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.74334,
     "end_time": "2024-01-25T10:48:21.045258",
     "exception": false,
     "start_time": "2024-01-25T10:48:20.301918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa1dea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.813028,
     "end_time": "2024-01-25T10:48:22.604588",
     "exception": false,
     "start_time": "2024-01-25T10:48:21.791560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb9e3a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.743942,
     "end_time": "2024-01-25T10:48:24.092952",
     "exception": false,
     "start_time": "2024-01-25T10:48:23.349010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918887",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.763657,
     "end_time": "2024-01-25T10:48:25.680437",
     "exception": false,
     "start_time": "2024-01-25T10:48:24.916780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ff3b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.804163,
     "end_time": "2024-01-25T10:48:27.231916",
     "exception": false,
     "start_time": "2024-01-25T10:48:26.427753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6637.255114,
   "end_time": "2024-01-25T10:48:35.096876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-25T08:57:57.841762",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
